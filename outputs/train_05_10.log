nohup: ignoring input

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 33, in <module>
    sys.exit(load_entry_point('xtuner', 'console_scripts', 'xtuner')())
  File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 25, in importlib_load_entry_point
    return next(matches).load()
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/metadata/__init__.py", line 171, in load
    module = import_module(match.group('module'))
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/moyuai/moyuai/xtuner/xtuner/__init__.py", line 4, in <module>
    from mmengine.utils import digit_version
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in <module>
    from .registry import *
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in <module>
    from .build_functions import (build_from_cfg, build_model_from_cfg,
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in <module>
    import torch
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 1471, in <module>
    from .functional import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[2025-05-10 00:10:05,599] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 10, in <module>
    from mmengine.config import Config, DictAction
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in <module>
    from .registry import *
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in <module>
    from .build_functions import (build_from_cfg, build_model_from_cfg,
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in <module>
    import torch
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 1471, in <module>
    from .functional import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[2025-05-10 00:10:09,014] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
05/10 00:10:10 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1817025980
    GPU 0: NVIDIA GeForce RTX 4060 Ti
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 12.1, V12.1.105
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.2.0+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.17.0+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.6

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1817025980
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

05/10 00:10:10 - mmengine - INFO - Config:
SYSTEM = 'xtuner.utils.SYSTEM_TEMPLATE.alpaca'
accumulative_counts = 16
alpaca_en = dict(
    dataset=dict(
        data_files='/home/moyuai/moyuai/data/output.json',
        path='json',
        type='datasets.load_dataset'),
    dataset_map_fn=None,
    max_length=512,
    pack_to_max_length=True,
    remove_unused_columns=True,
    shuffle_before_pack=True,
    template_map_fn=dict(
        template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
        type='xtuner.dataset.map_fns.template_map_fn_factory'),
    tokenizer=dict(
        padding_side='right',
        pretrained_model_name_or_path=
        '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
        trust_remote_code=True,
        type='transformers.AutoTokenizer.from_pretrained'),
    type='xtuner.dataset.process_hf_dataset',
    use_varlen_attn=False)
batch_size = 4
betas = (
    0.9,
    0.999,
)
custom_hooks = [
    dict(
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.DatasetInfoHook'),
    dict(
        evaluation_inputs=[
            '男朋友给女主播刷火箭，算精神出轨吗？',
            '洗牙后牙缝漏风，吹蜡烛像鼓风机！',
            '喝红酒养生，结果喝到头晕…',
            '闺蜜和我前任互关小红书，取关拉黑三连击！',
            '体检说胆固醇高，要戒炸鸡了吗？',
            '剧本杀遇读本玩家，直接摔门离场！',
            "被同事说'你今天的眼线像苍蝇腿'，气到晕厥！",
            '领导周末发60秒语音矩阵，装没看见行吗？',
        ],
        every_n_iters=500,
        prompt_template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
        system='xtuner.utils.SYSTEM_TEMPLATE.alpaca',
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.EvaluateChatHook'),
]
data_files = '/home/moyuai/moyuai/data/output.json'
dataloader_num_workers = 0
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=500,
        max_keep_ckpts=2,
        type='mmengine.hooks.CheckpointHook'),
    logger=dict(
        interval=10,
        log_metric_by_epoch=False,
        type='mmengine.hooks.LoggerHook'),
    param_scheduler=dict(type='mmengine.hooks.ParamSchedulerHook'),
    sampler_seed=dict(type='mmengine.hooks.DistSamplerSeedHook'),
    timer=dict(type='mmengine.hooks.IterTimerHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation_freq = 500
evaluation_inputs = [
    '男朋友给女主播刷火箭，算精神出轨吗？',
    '洗牙后牙缝漏风，吹蜡烛像鼓风机！',
    '喝红酒养生，结果喝到头晕…',
    '闺蜜和我前任互关小红书，取关拉黑三连击！',
    '体检说胆固醇高，要戒炸鸡了吗？',
    '剧本杀遇读本玩家，直接摔门离场！',
    "被同事说'你今天的眼线像苍蝇腿'，气到晕厥！",
    '领导周末发60秒语音矩阵，装没看见行吗？',
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr = 0.0002
max_epochs = 3000
max_length = 512
max_norm = 1
model = dict(
    llm=dict(
        pretrained_model_name_or_path=
        '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
        quantization_config=dict(
            bnb_4bit_compute_dtype='torch.float16',
            bnb_4bit_quant_type='nf4',
            bnb_4bit_use_double_quant=True,
            llm_int8_has_fp16_weight=False,
            llm_int8_threshold=6.0,
            load_in_4bit=False,
            load_in_8bit=True,
            type='transformers.BitsAndBytesConfig'),
        torch_dtype='torch.float16',
        trust_remote_code=True,
        type='transformers.AutoModelForCausalLM.from_pretrained'),
    lora=dict(
        bias='none',
        lora_alpha=128,
        lora_dropout=0.1,
        r=64,
        task_type='CAUSAL_LM',
        type='peft.LoraConfig'),
    type='xtuner.model.SupervisedFinetune',
    use_varlen_attn=False)
optim_type = 'torch.optim.AdamW'
optim_wrapper = dict(
    accumulative_counts=16,
    clip_grad=dict(error_if_nonfinite=False, max_norm=1),
    dtype='float16',
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        lr=0.0002,
        type='torch.optim.AdamW',
        weight_decay=0),
    type='mmengine.optim.AmpOptimWrapper')
pack_to_max_length = True
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=90.0,
        start_factor=1e-05,
        type='mmengine.optim.LinearLR'),
    dict(
        begin=90.0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=3000,
        eta_min=0.0,
        type='mmengine.optim.CosineAnnealingLR'),
]
pretrained_model_name_or_path = '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat'
prompt_template = 'xtuner.utils.PROMPT_TEMPLATE.qwen_chat'
randomness = dict(deterministic=False, seed=None)
resume = False
sampler = 'mmengine.dataset.DefaultSampler'
save_steps = 500
save_total_limit = 2
sequence_parallel_size = 1
tokenizer = dict(
    padding_side='right',
    pretrained_model_name_or_path=
    '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
    trust_remote_code=True,
    type='transformers.AutoTokenizer.from_pretrained')
train_cfg = dict(max_epochs=3000, type='xtuner.engine.runner.TrainLoop')
train_dataloader = dict(
    batch_size=4,
    collate_fn=dict(
        type='xtuner.dataset.collate_fns.default_collate_fn',
        use_varlen_attn=False),
    dataset=dict(
        dataset=dict(
            data_files='/home/moyuai/moyuai/data/output.json',
            path='json',
            type='datasets.load_dataset'),
        dataset_map_fn=None,
        max_length=512,
        pack_to_max_length=True,
        remove_unused_columns=True,
        shuffle_before_pack=True,
        template_map_fn=dict(
            template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
            type='xtuner.dataset.map_fns.template_map_fn_factory'),
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.dataset.process_hf_dataset',
        use_varlen_attn=False),
    num_workers=0,
    sampler=dict(shuffle=True, type='mmengine.dataset.DefaultSampler'))
use_varlen_attn = False
visualizer = None
warmup_ratio = 0.03
weight_decay = 0
work_dir = './work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3'

05/10 00:10:10 - mmengine - WARNING - Failed to search registry with scope "mmengine" in the "builder" registry tree. As a workaround, the current "builder" registry in "xtuner" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether "mmengine" is a correct scope, or whether the registry is initialized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
05/10 00:10:12 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
05/10 00:10:13 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DatasetInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Setting TOKENIZERS_PARALLELISM=false for forked processes.
Flattening the indices (num_proc=32):   0%|          | 0/4000 [00:00<?, ? examples/s]Flattening the indices (num_proc=32):  16%|█▌        | 625/4000 [00:00<00:00, 5965.10 examples/s]Flattening the indices (num_proc=32): 100%|██████████| 4000/4000 [00:00<00:00, 20117.58 examples/s]
Map (num_proc=32):   0%|          | 0/4000 [00:00<?, ? examples/s]Map (num_proc=32):  69%|██████▉   | 2750/4000 [00:00<00:00, 26646.00 examples/s]Map (num_proc=32): 100%|██████████| 4000/4000 [00:00<00:00, 22333.74 examples/s]
Map (num_proc=32):   0%|          | 0/638 [00:00<?, ? examples/s]Map (num_proc=32):  82%|████████▏ | 520/638 [00:00<00:00, 4945.55 examples/s]Map (num_proc=32): 100%|██████████| 638/638 [00:00<00:00, 3728.05 examples/s]
05/10 00:10:15 - mmengine - WARNING - Dataset Dataset has no metainfo. ``dataset_meta`` in visualizer will be None.
05/10 00:10:15 - mmengine - INFO - Num train samples 638
05/10 00:10:15 - mmengine - INFO - train example:
05/10 00:10:15 - mmengine - INFO - <|im_start|>user
喝奶茶失眠到背元素周期表，黑眼圈掉肚脐！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这奶茶是加了咖啡因钻石吧？🍵💎 下次记得喝之前先看看成分表，别让眼睛比夜猫子还亮。👀 晚安，早点休息，别让黑眼圈真的掉下来。💤<|im_end|>
<|im_start|>user
看丧尸片后总感觉门外有低吼…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这是吓得魂都要丢了吧？😂 下次看恐怖片记得先做好心理建设，或者直接找我，我给你讲解丧尸片的科学原理，让你看透这些“行走的GDP”背后的秘密！🧟‍♂️<|im_end|>
<|im_start|>user
漂流翻船眼镜沉底，摸瞎找路两小时…<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来真是惊险呢！你现在还好吗？有没有受伤？💖这时候一定很需要一杯热饮和一些安慰的食物吧？如果可以的话，要不要我陪你一会儿，帮你分散一下注意力呢？🌸<|im_end|>
<|im_start|>user
喝奶茶失眠到背元素周期表，黑眼圈掉肚脐！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来你最近挺不容易的。失眠真的很烦人，不过背元素周期表是个好习惯呢！黑眼圈要注意休息才能慢慢恢复哦。要不要我给你推荐一些帮助入睡的方法？💖<|im_end|>
<|im_start|>user
吃榴莲被赶出图书馆，管理员戴防毒面具！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这个经历真是太特别了！😅 图书馆的规定真是严格呢，不过我想管理员也是为了维护图书馆的环境和大家的安全。下次吃榴莲记得选择合适的地方哦，免得再遇到这样的小插曲。💖 如果这件事让你感到不开心，可以和我分享更多的细节，我会尽力为你分散注意力。🌸<|im_end|>
<|im_start|>user
抓娃娃机吞币不吐，老板说'技术调试'！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这抓娃娃的技术，跟闹钟定时一样准，一到点儿就响，就是东西没抓到，钱倒是不少送进去。下次记得，别让老板的技术调试，调出了你的'心理阴影'！🎢<|im_end|>
<|im_start|>user
同事总在吃螺蛳粉时嗦粉出声，像抽水马桶！<|im_end|>
05/10 00:10:15 - mmengine - INFO - before_train in EvaluateChatHook.
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 00:10:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
作为一个人工智能语言模型，我不能对个人行为进行道德或法律上的评价。然而，从一般伦理和法律角度来看，给女主播刷火箭可能被视为一种精神出轨行为。

精神出轨是指在婚姻关系中，一方在

05/10 00:10:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
洗牙后牙缝漏风，吹蜡烛像鼓风机！这可能是因为牙缝中的牙菌斑和牙石导致的。牙菌斑是口腔中一种细菌的集合体，它会在牙齿表面形成一层硬硬

05/10 00:10:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
喝红酒养生确实可以起到一定的保健作用，但同时也需要注意适量饮用，否则可能会出现头晕等不适症状。以下是一些可能导致头晕的原因和应对措施：

1. 酒精过量：红酒中的酒精含量较高，过

05/10 00:10:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
闺蜜和前任互关小红书，取关拉黑三连击！这种行为无疑是对闺蜜和前任之间关系的严重伤害和破坏，同时也可能对闺蜜本人的社交网络和生活造成负面影响。以下是一些可能的

05/10 00:10:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
是的，体检结果显示胆固醇高，建议您戒掉炸鸡。炸鸡是一种高脂肪、高胆固醇的食物，长期食用可能会导致血脂升高，增加患心血管疾病的风险。建议您选择低脂肪、低胆固醇的食物，如鸡

05/10 00:10:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
剧本杀遇读本玩家，直接摔门离场！这种行为在剧本杀中是不被允许的，因为这可能会对其他玩家造成不必要的困扰和不适。在剧本杀中，玩家的角色扮演和互动是相互影响的

05/10 00:10:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
我感到非常尴尬和生气，因为我的同事竟然用这样的评价来描述我今天的妆容。我理解这可能是因为我的眼线不够明显或者过于浓重，但这种评价无疑是对我的工作和努力的否定和贬低

05/10 00:10:50 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导周末发60秒语音矩阵，装没看见行不通。作为领导，您的行为和态度直接影响到团队成员的工作积极性和工作效率。如果领导在周末发语音矩阵，但装作没看见，可能会导致以下问题：



05/10 00:10:50 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
05/10 00:10:50 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
05/10 00:10:50 - mmengine - INFO - Checkpoints will be saved to /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3.
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/optim/scheduler/param_scheduler.py:198: UserWarning: Detected call of `scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `scheduler.step()`. Failure to do this will result in PyTorch skipping the first value of the parameter value schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
05/10 00:11:04 - mmengine - INFO - Iter(train) [    10/480000]  lr: 1.2701e-07  eta: 7 days, 13:15:33  time: 1.3595  data_time: 0.0061  memory: 9340  loss: 3.3825
05/10 00:11:19 - mmengine - INFO - Iter(train) [    20/480000]  lr: 2.6590e-07  eta: 7 days, 21:32:42  time: 1.4838  data_time: 0.0063  memory: 9802  loss: 3.3668  grad_norm: 3.1275
05/10 00:11:32 - mmengine - INFO - Iter(train) [    30/480000]  lr: 4.0480e-07  eta: 7 days, 17:22:18  time: 1.3278  data_time: 0.0061  memory: 9803  loss: 3.3647  grad_norm: 3.1275
05/10 00:11:47 - mmengine - INFO - Iter(train) [    40/480000]  lr: 5.4370e-07  eta: 7 days, 21:20:21  time: 1.5095  data_time: 0.0064  memory: 9801  loss: 3.4364  grad_norm: 3.1594
05/10 00:12:01 - mmengine - INFO - Iter(train) [    50/480000]  lr: 6.8260e-07  eta: 7 days, 20:23:37  time: 1.3848  data_time: 0.0060  memory: 9799  loss: 3.3848  grad_norm: 3.1874
05/10 00:12:16 - mmengine - INFO - Iter(train) [    60/480000]  lr: 8.2149e-07  eta: 7 days, 22:33:10  time: 1.5105  data_time: 0.0060  memory: 9799  loss: 3.3815  grad_norm: 3.1874
05/10 00:12:29 - mmengine - INFO - Iter(train) [    70/480000]  lr: 9.6039e-07  eta: 7 days, 20:38:10  time: 1.3289  data_time: 0.0060  memory: 9799  loss: 3.3354  grad_norm: 3.2040
05/10 00:12:43 - mmengine - INFO - Iter(train) [    80/480000]  lr: 1.0993e-06  eta: 7 days, 19:37:40  time: 1.3547  data_time: 0.0061  memory: 9800  loss: 3.3869  grad_norm: 3.1992
05/10 00:12:58 - mmengine - INFO - Iter(train) [    90/480000]  lr: 1.2382e-06  eta: 7 days, 20:48:04  time: 1.4869  data_time: 0.0061  memory: 9799  loss: 3.3623  grad_norm: 3.1992
05/10 00:13:11 - mmengine - INFO - Iter(train) [   100/480000]  lr: 1.3771e-06  eta: 7 days, 19:42:09  time: 1.3342  data_time: 0.0058  memory: 9799  loss: 3.3643  grad_norm: 3.2103
05/10 00:13:26 - mmengine - INFO - Iter(train) [   110/480000]  lr: 1.5160e-06  eta: 7 days, 20:41:47  time: 1.4904  data_time: 0.0061  memory: 9800  loss: 3.3486  grad_norm: 3.2103
05/10 00:13:39 - mmengine - INFO - Iter(train) [   120/480000]  lr: 1.6549e-06  eta: 7 days, 19:27:54  time: 1.3050  data_time: 0.0059  memory: 9799  loss: 3.3209  grad_norm: 3.1963
05/10 00:13:52 - mmengine - INFO - Iter(train) [   130/480000]  lr: 1.7938e-06  eta: 7 days, 18:51:18  time: 1.3472  data_time: 0.0059  memory: 9801  loss: 3.3054  grad_norm: 3.1798
05/10 00:14:07 - mmengine - INFO - Iter(train) [   140/480000]  lr: 1.9327e-06  eta: 7 days, 19:33:17  time: 1.4757  data_time: 0.0058  memory: 9802  loss: 3.3552  grad_norm: 3.1798
05/10 00:14:21 - mmengine - INFO - Iter(train) [   150/480000]  lr: 2.0716e-06  eta: 7 days, 19:06:29  time: 1.3573  data_time: 0.0057  memory: 9804  loss: 3.3183  grad_norm: 3.1468
05/10 00:14:35 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 00:14:35 - mmengine - INFO - Iter(train) [   160/480000]  lr: 2.2105e-06  eta: 7 days, 19:17:01  time: 1.4253  data_time: 0.0059  memory: 9802  loss: 3.3263  grad_norm: 3.1314
05/10 00:14:35 - mmengine - WARNING - Reach the end of the dataloader, it will be restarted and continue to iterate. It is recommended to use `mmengine.dataset.InfiniteSampler` to enable the dataloader to iterate infinitely.
05/10 00:14:50 - mmengine - INFO - Iter(train) [   170/480000]  lr: 2.3494e-06  eta: 7 days, 20:15:37  time: 1.5302  data_time: 0.2060  memory: 9801  loss: 3.2753  grad_norm: 3.1314
05/10 00:15:05 - mmengine - INFO - Iter(train) [   180/480000]  lr: 2.4883e-06  eta: 7 days, 20:55:44  time: 1.5033  data_time: 0.0059  memory: 9803  loss: 3.3086  grad_norm: 3.0902
05/10 00:15:19 - mmengine - INFO - Iter(train) [   190/480000]  lr: 2.6272e-06  eta: 7 days, 20:19:52  time: 1.3328  data_time: 0.0057  memory: 9803  loss: 3.2800  grad_norm: 3.0902
05/10 00:15:32 - mmengine - INFO - Iter(train) [   200/480000]  lr: 2.7661e-06  eta: 7 days, 19:50:59  time: 1.3414  data_time: 0.0061  memory: 9807  loss: 3.2892  grad_norm: 3.0477
05/10 00:15:47 - mmengine - INFO - Iter(train) [   210/480000]  lr: 2.9050e-06  eta: 7 days, 20:06:58  time: 1.4521  data_time: 0.0060  memory: 9806  loss: 3.2414  grad_norm: 2.9900
05/10 00:16:00 - mmengine - INFO - Iter(train) [   220/480000]  lr: 3.0438e-06  eta: 7 days, 19:44:18  time: 1.3497  data_time: 0.0058  memory: 9798  loss: 3.2713  grad_norm: 2.9900
05/10 00:16:15 - mmengine - INFO - Iter(train) [   230/480000]  lr: 3.1827e-06  eta: 7 days, 20:20:08  time: 1.5124  data_time: 0.0059  memory: 9801  loss: 3.2618  grad_norm: 2.9293
05/10 00:16:29 - mmengine - INFO - Iter(train) [   240/480000]  lr: 3.3216e-06  eta: 7 days, 19:50:50  time: 1.3260  data_time: 0.0057  memory: 9802  loss: 3.2697  grad_norm: 2.8471
05/10 00:16:42 - mmengine - INFO - Iter(train) [   250/480000]  lr: 3.4605e-06  eta: 7 days, 19:33:01  time: 1.3545  data_time: 0.0061  memory: 9799  loss: 3.2545  grad_norm: 2.8471
05/10 00:16:56 - mmengine - INFO - Iter(train) [   260/480000]  lr: 3.5994e-06  eta: 7 days, 19:33:42  time: 1.4104  data_time: 0.0061  memory: 9804  loss: 3.1815  grad_norm: 2.7588
05/10 00:17:11 - mmengine - INFO - Iter(train) [   270/480000]  lr: 3.7383e-06  eta: 7 days, 20:02:20  time: 1.5050  data_time: 0.0058  memory: 9804  loss: 3.1973  grad_norm: 2.7588
05/10 00:17:25 - mmengine - INFO - Iter(train) [   280/480000]  lr: 3.8772e-06  eta: 7 days, 19:40:43  time: 1.3362  data_time: 0.0058  memory: 9804  loss: 3.1612  grad_norm: 2.6827
05/10 00:17:39 - mmengine - INFO - Iter(train) [   290/480000]  lr: 4.0161e-06  eta: 7 days, 19:54:38  time: 1.4597  data_time: 0.0060  memory: 9803  loss: 3.1577  grad_norm: 2.5952
05/10 00:17:52 - mmengine - INFO - Iter(train) [   300/480000]  lr: 4.1550e-06  eta: 7 days, 19:23:58  time: 1.2960  data_time: 0.0057  memory: 9803  loss: 3.1154  grad_norm: 2.5952
05/10 00:18:07 - mmengine - INFO - Iter(train) [   310/480000]  lr: 4.2939e-06  eta: 7 days, 19:50:37  time: 1.5106  data_time: 0.0060  memory: 9803  loss: 3.1185  grad_norm: 2.5190
05/10 00:18:20 - mmengine - INFO - Iter(train) [   320/480000]  lr: 4.4328e-06  eta: 7 days, 19:28:55  time: 1.3239  data_time: 0.0059  memory: 9800  loss: 3.1173  grad_norm: 2.4214
05/10 00:18:36 - mmengine - INFO - Iter(train) [   330/480000]  lr: 4.5717e-06  eta: 7 days, 20:09:23  time: 1.5750  data_time: 0.2062  memory: 9802  loss: 3.1608  grad_norm: 2.4214
05/10 00:18:50 - mmengine - INFO - Iter(train) [   340/480000]  lr: 4.7106e-06  eta: 7 days, 19:57:10  time: 1.3612  data_time: 0.0059  memory: 9805  loss: 3.0635  grad_norm: 2.3436
05/10 00:19:04 - mmengine - INFO - Iter(train) [   350/480000]  lr: 4.8495e-06  eta: 7 days, 20:08:22  time: 1.4607  data_time: 0.0058  memory: 9806  loss: 3.0794  grad_norm: 2.3436
05/10 00:19:18 - mmengine - INFO - Iter(train) [   360/480000]  lr: 4.9884e-06  eta: 7 days, 19:57:28  time: 1.3640  data_time: 0.0058  memory: 9806  loss: 3.0763  grad_norm: 2.2477
05/10 00:19:32 - mmengine - INFO - Iter(train) [   370/480000]  lr: 5.1273e-06  eta: 7 days, 20:01:24  time: 1.4300  data_time: 0.0060  memory: 9802  loss: 3.0886  grad_norm: 2.1478
05/10 00:19:46 - mmengine - INFO - Iter(train) [   380/480000]  lr: 5.2662e-06  eta: 7 days, 19:46:50  time: 1.3432  data_time: 0.0060  memory: 9801  loss: 3.0651  grad_norm: 2.1478
05/10 00:20:00 - mmengine - INFO - Iter(train) [   390/480000]  lr: 5.4051e-06  eta: 7 days, 19:53:47  time: 1.4445  data_time: 0.0059  memory: 9801  loss: 3.0143  grad_norm: 2.0358
05/10 00:20:14 - mmengine - INFO - Iter(train) [   400/480000]  lr: 5.5440e-06  eta: 7 days, 19:44:59  time: 1.3675  data_time: 0.0060  memory: 9803  loss: 3.0459  grad_norm: 1.9436
05/10 00:20:28 - mmengine - INFO - Iter(train) [   410/480000]  lr: 5.6829e-06  eta: 7 days, 19:35:09  time: 1.3601  data_time: 0.0059  memory: 9804  loss: 3.0045  grad_norm: 1.9436
05/10 00:20:41 - mmengine - INFO - Iter(train) [   420/480000]  lr: 5.8218e-06  eta: 7 days, 19:25:03  time: 1.3563  data_time: 0.0059  memory: 9803  loss: 2.9821  grad_norm: 1.8467
05/10 00:20:56 - mmengine - INFO - Iter(train) [   430/480000]  lr: 5.9607e-06  eta: 7 days, 19:40:08  time: 1.4892  data_time: 0.0059  memory: 9803  loss: 3.0240  grad_norm: 1.8467
05/10 00:21:10 - mmengine - INFO - Iter(train) [   440/480000]  lr: 6.0996e-06  eta: 7 days, 19:32:41  time: 1.3691  data_time: 0.0060  memory: 9801  loss: 2.9828  grad_norm: 1.7379
05/10 00:21:24 - mmengine - INFO - Iter(train) [   450/480000]  lr: 6.2385e-06  eta: 7 days, 19:39:57  time: 1.4501  data_time: 0.0060  memory: 9800  loss: 2.9479  grad_norm: 1.6453
05/10 00:21:38 - mmengine - INFO - Iter(train) [   460/480000]  lr: 6.3774e-06  eta: 7 days, 19:28:25  time: 1.3438  data_time: 0.0060  memory: 9802  loss: 2.9609  grad_norm: 1.6453
05/10 00:21:51 - mmengine - INFO - Iter(train) [   470/480000]  lr: 6.5163e-06  eta: 7 days, 19:18:01  time: 1.3476  data_time: 0.0058  memory: 9801  loss: 2.9397  grad_norm: 1.5551
05/10 00:22:05 - mmengine - INFO - Iter(train) [   480/480000]  lr: 6.6552e-06  eta: 7 days, 19:17:06  time: 1.4020  data_time: 0.0059  memory: 9801  loss: 2.8678  grad_norm: 1.4724
05/10 00:22:21 - mmengine - INFO - Iter(train) [   490/480000]  lr: 6.7941e-06  eta: 7 days, 19:47:12  time: 1.5920  data_time: 0.2060  memory: 9799  loss: 2.8916  grad_norm: 1.4724
05/10 00:22:36 - mmengine - INFO - Iter(train) [   500/480000]  lr: 6.9330e-06  eta: 7 days, 19:52:37  time: 1.4452  data_time: 0.0059  memory: 9800  loss: 2.8992  grad_norm: 1.3970
05/10 00:22:36 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 00:22:52 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
算不算精神出轨，这取决于具体情况和双方的沟通方式。如果男朋友在直播中频繁与女主播互动，包括但不限于聊天、送礼物、送红包等，且这种互动方式明显超出了一般朋友之间的正常交往，那么就可能被视为精神出轨。然而，如果男朋友只是偶尔与女主播互动，或者这种互动方式是出于对主播的欣赏和喜欢，那么就不算精神出轨。

另外，如果男朋友和女主播的关系已经超过了朋友的界限，比如他们经常一起吃饭、看电影、旅行等，那么就可能被视为精神出轨。然而，这需要根据具体情况来判断，如果男朋友和女主播的关系已经超过了朋友的界限，但并没有超出正常朋友的界限，那么就不算精神出轨。

总的来说，如果男朋友和女主播的关系已经超过了朋友的界限，那么就可能被视为精神出轨。但是，这需要根据具体情况来判断，如果男朋友和女主播的关系没有超过朋友的界限，那么就不算精神出轨。<|im_end|>

05/10 00:23:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
看来你最近的牙齿清洁做得不够彻底，导致牙缝处的空气流通不畅，吹蜡烛时发出的声音就像鼓风机一样。建议你尽快去牙医那里进行一次全面的牙齿清洁，包括牙缝的清洁和牙周病的检查，以防止牙缝漏风和牙周病的发生。同时，平时也要注意口腔卫生，定期刷牙、使用牙线和漱口水，避免食物残渣在牙缝中发酵，形成牙菌斑和牙结石，进一步影响牙齿健康。另外，如果你的牙齿有敏感或者疼痛的情况，也可以在清洁牙齿前先用牙线或软毛牙刷轻轻清洁一下，以减轻不适感。希望你早日恢复口腔健康，享受美味的美食。<|im_end|>

05/10 00:23:14 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
建议您适量饮用红酒，不要过量，以免出现头晕等不适症状。红酒中的某些成分，如单宁酸，可能会与胃酸产生反应，导致胃部不适。同时，红酒中的酒精也可能刺激神经系统，导致头晕。建议您在饮用红酒时，先适量品尝，观察是否有不适反应，如果出现不适，应立即停止饮用，并及时就医。同时，红酒的饮用方式也需要注意，建议在饭后饮用，以减少酒精对胃部的刺激。<|im_end|>

05/10 00:23:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
我理解你的感受，这确实是一种非常困扰的情况。首先，我建议你可以尝试以下几种方法来处理这种情况：

1. **冷静思考**：不要让情绪控制你的行为，冷静下来分析一下情况。你们的闺蜜和前任互关小红书，这可能是因为你们之间有共同的兴趣爱好或者对彼此的了解，这并不意味着你们之间有什么不好的关系。你们可以尝试理解对方的立场，看看是否可以找到一个平衡点，或者你们可以尝试通过其他方式来表达自己的感受。

2. **沟通交流**：如果你们的闺蜜和前任互关小红书，但你们之间并没有什么不好的关系，那么你可以尝试和他们进行沟通，表达你的感受和想法。告诉他们你对他们的行为感到困扰，希望他们可以尊重彼此的隐私和感受。同时，也可以询问他们是否有什么可以做的，比如可以一起出去玩，或者一起分享一些有趣的事情。

3. **寻求第三方帮助**：如果你们的闺蜜和前任互关小红书，但你们之间并没有什么不好的关系，但你仍然感到困扰，那么你可以寻求第三方的帮助，比如你的朋友、家人或者专业的心理咨询师。他们可以提供一些专业的建议和帮助，帮助你处理这种情况。

4. **保护自己**：在处理这种情况时，也要注意保护自己的权益。如果你们的闺蜜和前任互关小红书，但你们之间并没有什么不好的关系，但你仍然感到困扰，那么你可以选择暂时不和他们互动，或者选择在适当的时候和他们进行沟通。

记住，处理这种情况需要时间和耐心，不要轻易放弃。希望以上建议对你有所帮助，祝你早日找到解决问题的方法。<|im_end|>

05/10 00:23:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
是的，建议您尽量减少食用炸鸡等高胆固醇食物，以降低胆固醇水平。您可以尝试选择烤、蒸、煮等健康的烹饪方式，或者选择低脂、低盐、低糖的替代品，如鸡胸肉、鱼、豆腐等。同时，保持均衡饮食，多吃蔬菜水果，适当运动，也有助于降低胆固醇水平。如果您的胆固醇水平持续偏高，建议您咨询医生，了解更详细的饮食和生活方式建议。<|im_end|>

05/10 00:24:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
抱歉听到您在剧本杀中遇到了读本玩家，这可能会影响您的游戏体验。以下是一些建议，希望能帮助您处理这种情况：

1. **冷静下来**：首先，不要立即摔门离场，这可能会让其他玩家感到不安和困惑。尝试冷静下来，深呼吸几次，让自己平静下来。

2. **与读本玩家沟通**：如果读本玩家是您的朋友或熟人，您可以尝试与他们沟通，解释您的行为并表达歉意。告诉他们您在游戏中的感受，解释您选择离场的原因，以及您希望他们理解和支持您的决定。

3. **尊重他人感受**：如果读本玩家是陌生人，您可能需要尊重他们的感受。告诉他们您理解他们的选择，但请他们知道，您尊重他们的决定，并希望他们能够理解您的感受。

4. **寻求帮助**：如果您的情绪无法控制，或者您感到无法处理这种情况，您可以寻求游戏管理员或其他工作人员的帮助。他们可以提供专业的建议和指导，帮助您处理这种情况。

5. **保持游戏环境的和谐**：在游戏结束后，确保游戏环境的和谐。如果可能，您可以邀请读本玩家一起参加后续的游戏，或者在游戏结束后与他们进行交流，以表达您的歉意和感谢。

6. **下次游戏时注意**：在下次游戏时，确保您和读本玩家都了解并遵守游戏规则，避免类似的情况再次发生。

希望这些建议能帮助您处理这种情况，祝您在游戏中的体验愉快！<|im_end|>

05/10 00:24:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
我理解你的感受，被同事说"你今天的眼线像苍蝇腿"确实会让人感到不舒服和尴尬。以下是一些可能的回应，希望能帮助你缓解情绪：

1. "谢谢你的提醒，我会注意的。不过，我今天确实觉得我的眼线有些不太自然，可能需要改进一下。"
2. "谢谢你的指正，我会认真考虑的。不过，我今天确实有些紧张，可能需要一些时间来调整。"
3. "谢谢你的提醒，我会注意的。不过，我今天确实有些疲惫，可能需要休息一下。"
4. "谢谢你的提醒，我会注意的。不过，我今天确实有些压力，可能需要一些放松的时间。"
5. "谢谢你的提醒，我会注意的。不过，我今天确实有些紧张，可能需要一些时间来调整。"

无论你选择哪种回应，都要保持礼貌和尊重，避免直接反驳或攻击同事。同时，也要表达出你对改进和放松的意愿，以建立良好的工作关系。<|im_end|>

05/10 00:24:52 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导周末发60秒语音矩阵，装没看见行吗？领导，我理解您可能需要一些时间来处理这个任务，但是作为您的下属，我需要提醒您，领导的语音矩阵是需要认真对待的，它不仅包含了您的工作内容，也包含了领导对您的期望和关心。请您尽快处理，确保语音矩阵的完成质量和效率，同时也要注意保持与领导的良好沟通，及时汇报工作进展和遇到的问题，以便我们共同解决问题。<|im_end|>

05/10 00:24:52 - mmengine - INFO - Saving checkpoint at 500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 00:25:07 - mmengine - INFO - Iter(train) [   510/480000]  lr: 7.0719e-06  eta: 9 days, 7:37:46  time: 15.1019  data_time: 13.7426  memory: 9799  loss: 2.8222  grad_norm: 1.3970
05/10 00:25:21 - mmengine - INFO - Iter(train) [   520/480000]  lr: 7.2108e-06  eta: 9 days, 7:02:56  time: 1.4541  data_time: 0.0059  memory: 9802  loss: 2.8277  grad_norm: 1.3243
05/10 00:25:35 - mmengine - INFO - Iter(train) [   530/480000]  lr: 7.3497e-06  eta: 9 days, 6:16:01  time: 1.3655  data_time: 0.0060  memory: 9801  loss: 2.7744  grad_norm: 1.2682
05/10 00:25:48 - mmengine - INFO - Iter(train) [   540/480000]  lr: 7.4886e-06  eta: 9 days, 5:26:17  time: 1.3346  data_time: 0.0059  memory: 9802  loss: 2.8308  grad_norm: 1.2682
05/10 00:26:03 - mmengine - INFO - Iter(train) [   550/480000]  lr: 7.6275e-06  eta: 9 days, 4:59:53  time: 1.4829  data_time: 0.0059  memory: 9803  loss: 2.8258  grad_norm: 1.2262
05/10 00:26:17 - mmengine - INFO - Iter(train) [   560/480000]  lr: 7.7664e-06  eta: 9 days, 4:19:04  time: 1.3752  data_time: 0.0061  memory: 9802  loss: 2.8460  grad_norm: 1.1947
05/10 00:26:30 - mmengine - INFO - Iter(train) [   570/480000]  lr: 7.9052e-06  eta: 9 days, 3:38:59  time: 1.3703  data_time: 0.0059  memory: 9801  loss: 2.8629  grad_norm: 1.1947
05/10 00:26:45 - mmengine - INFO - Iter(train) [   580/480000]  lr: 8.0441e-06  eta: 9 days, 3:10:09  time: 1.4421  data_time: 0.0059  memory: 9802  loss: 2.7614  grad_norm: 1.1542
05/10 00:26:58 - mmengine - INFO - Iter(train) [   590/480000]  lr: 8.1830e-06  eta: 9 days, 2:25:41  time: 1.3195  data_time: 0.0061  memory: 9800  loss: 2.8097  grad_norm: 1.1542
05/10 00:27:11 - mmengine - INFO - Iter(train) [   600/480000]  lr: 8.3219e-06  eta: 9 days, 1:36:34  time: 1.2734  data_time: 0.0057  memory: 9799  loss: 2.7761  grad_norm: 1.1262
05/10 00:27:26 - mmengine - INFO - Iter(train) [   610/480000]  lr: 8.4608e-06  eta: 9 days, 1:20:47  time: 1.5157  data_time: 0.0062  memory: 9800  loss: 2.8334  grad_norm: 1.0976
05/10 00:27:38 - mmengine - INFO - Iter(train) [   620/480000]  lr: 8.5997e-06  eta: 9 days, 0:30:13  time: 1.2419  data_time: 0.0059  memory: 9800  loss: 2.7638  grad_norm: 1.0976
05/10 00:27:52 - mmengine - INFO - Iter(train) [   630/480000]  lr: 8.7386e-06  eta: 9 days, 0:02:42  time: 1.4111  data_time: 0.0060  memory: 9801  loss: 2.7352  grad_norm: 1.0708
05/10 00:28:05 - mmengine - INFO - Iter(train) [   640/480000]  lr: 8.8775e-06  eta: 8 days, 23:13:32  time: 1.2307  data_time: 0.0056  memory: 9800  loss: 2.7068  grad_norm: 1.0525
05/10 00:28:22 - mmengine - INFO - Iter(train) [   650/480000]  lr: 9.0164e-06  eta: 8 days, 23:21:40  time: 1.6847  data_time: 0.2062  memory: 9800  loss: 2.6916  grad_norm: 1.0525
05/10 00:28:34 - mmengine - INFO - Iter(train) [   660/480000]  lr: 9.1553e-06  eta: 8 days, 22:41:48  time: 1.2903  data_time: 0.0058  memory: 9799  loss: 2.7078  grad_norm: 1.0245
05/10 00:28:47 - mmengine - INFO - Iter(train) [   670/480000]  lr: 9.2942e-06  eta: 8 days, 22:04:47  time: 1.3042  data_time: 0.0058  memory: 9799  loss: 2.7042  grad_norm: 1.0245
05/10 00:29:02 - mmengine - INFO - Iter(train) [   680/480000]  lr: 9.4331e-06  eta: 8 days, 21:47:33  time: 1.4636  data_time: 0.0060  memory: 9800  loss: 2.6750  grad_norm: 0.9989
05/10 00:29:15 - mmengine - INFO - Iter(train) [   690/480000]  lr: 9.5720e-06  eta: 8 days, 21:10:09  time: 1.2850  data_time: 0.0057  memory: 9801  loss: 2.6334  grad_norm: 0.9722
05/10 00:29:29 - mmengine - INFO - Iter(train) [   700/480000]  lr: 9.7109e-06  eta: 8 days, 20:51:16  time: 1.4379  data_time: 0.0059  memory: 9803  loss: 2.6369  grad_norm: 0.9722
05/10 00:29:42 - mmengine - INFO - Iter(train) [   710/480000]  lr: 9.8498e-06  eta: 8 days, 20:13:50  time: 1.2684  data_time: 0.0058  memory: 9803  loss: 2.6302  grad_norm: 0.9400
05/10 00:29:55 - mmengine - INFO - Iter(train) [   720/480000]  lr: 9.9887e-06  eta: 8 days, 19:42:14  time: 1.3115  data_time: 0.0058  memory: 9805  loss: 2.5514  grad_norm: 0.9114
05/10 00:30:09 - mmengine - INFO - Iter(train) [   730/480000]  lr: 1.0128e-05  eta: 8 days, 19:15:30  time: 1.3483  data_time: 0.0060  memory: 9805  loss: 2.5808  grad_norm: 0.9114
05/10 00:30:24 - mmengine - INFO - Iter(train) [   740/480000]  lr: 1.0266e-05  eta: 8 days, 19:11:19  time: 1.5506  data_time: 0.0064  memory: 9805  loss: 2.6185  grad_norm: 0.8898
05/10 00:30:38 - mmengine - INFO - Iter(train) [   750/480000]  lr: 1.0405e-05  eta: 8 days, 18:45:39  time: 1.3479  data_time: 0.0061  memory: 9803  loss: 2.5934  grad_norm: 0.8898
05/10 00:30:51 - mmengine - INFO - Iter(train) [   760/480000]  lr: 1.0544e-05  eta: 8 days, 18:18:33  time: 1.3277  data_time: 0.0060  memory: 9804  loss: 2.6424  grad_norm: 0.8688
05/10 00:31:03 - mmengine - INFO - Iter(train) [   770/480000]  lr: 1.0683e-05  eta: 8 days, 17:44:11  time: 1.2511  data_time: 0.0055  memory: 9799  loss: 2.5228  grad_norm: 0.8456
05/10 00:31:17 - mmengine - INFO - Iter(train) [   780/480000]  lr: 1.0822e-05  eta: 8 days, 17:21:30  time: 1.3565  data_time: 0.0061  memory: 9803  loss: 2.5819  grad_norm: 0.8456
05/10 00:31:31 - mmengine - INFO - Iter(train) [   790/480000]  lr: 1.0961e-05  eta: 8 days, 17:08:56  time: 1.4511  data_time: 0.0064  memory: 9802  loss: 2.4982  grad_norm: 0.8238
05/10 00:31:44 - mmengine - INFO - Iter(train) [   800/480000]  lr: 1.1100e-05  eta: 8 days, 16:32:30  time: 1.2090  data_time: 0.0057  memory: 9799  loss: 2.5053  grad_norm: 0.7927
05/10 00:32:00 - mmengine - INFO - Iter(train) [   810/480000]  lr: 1.1239e-05  eta: 8 days, 16:38:54  time: 1.6342  data_time: 0.2062  memory: 9799  loss: 2.4775  grad_norm: 0.7927
05/10 00:32:13 - mmengine - INFO - Iter(train) [   820/480000]  lr: 1.1378e-05  eta: 8 days, 16:12:09  time: 1.2956  data_time: 0.0058  memory: 9800  loss: 2.5001  grad_norm: 0.7690
05/10 00:32:26 - mmengine - INFO - Iter(train) [   830/480000]  lr: 1.1517e-05  eta: 8 days, 15:49:51  time: 1.3351  data_time: 0.0060  memory: 9797  loss: 2.5088  grad_norm: 0.7690
05/10 00:32:40 - mmengine - INFO - Iter(train) [   840/480000]  lr: 1.1655e-05  eta: 8 days, 15:35:16  time: 1.4107  data_time: 0.0062  memory: 9799  loss: 2.4796  grad_norm: 0.7545
05/10 00:32:53 - mmengine - INFO - Iter(train) [   850/480000]  lr: 1.1794e-05  eta: 8 days, 15:10:47  time: 1.3019  data_time: 0.0058  memory: 9799  loss: 2.4900  grad_norm: 0.7383
05/10 00:33:08 - mmengine - INFO - Iter(train) [   860/480000]  lr: 1.1933e-05  eta: 8 days, 15:01:29  time: 1.4591  data_time: 0.0059  memory: 9801  loss: 2.4018  grad_norm: 0.7383
05/10 00:33:21 - mmengine - INFO - Iter(train) [   870/480000]  lr: 1.2072e-05  eta: 8 days, 14:37:14  time: 1.2942  data_time: 0.0057  memory: 9803  loss: 2.4696  grad_norm: 0.7381
05/10 00:33:34 - mmengine - INFO - Iter(train) [   880/480000]  lr: 1.2211e-05  eta: 8 days, 14:14:36  time: 1.3059  data_time: 0.0059  memory: 9801  loss: 2.4234  grad_norm: 0.7247
05/10 00:33:48 - mmengine - INFO - Iter(train) [   890/480000]  lr: 1.2350e-05  eta: 8 days, 14:00:52  time: 1.3995  data_time: 0.0059  memory: 9798  loss: 2.4501  grad_norm: 0.7247
05/10 00:34:01 - mmengine - INFO - Iter(train) [   900/480000]  lr: 1.2489e-05  eta: 8 days, 13:39:42  time: 1.3123  data_time: 0.0059  memory: 9803  loss: 2.3477  grad_norm: 0.7137
05/10 00:34:16 - mmengine - INFO - Iter(train) [   910/480000]  lr: 1.2628e-05  eta: 8 days, 13:33:04  time: 1.4727  data_time: 0.0061  memory: 9803  loss: 2.4440  grad_norm: 0.7137
05/10 00:34:29 - mmengine - INFO - Iter(train) [   920/480000]  lr: 1.2767e-05  eta: 8 days, 13:09:47  time: 1.2792  data_time: 0.0058  memory: 9803  loss: 2.4009  grad_norm: 0.7049
05/10 00:34:43 - mmengine - INFO - Iter(train) [   930/480000]  lr: 1.2906e-05  eta: 8 days, 13:00:41  time: 1.4387  data_time: 0.0059  memory: 9801  loss: 2.3629  grad_norm: 0.6975
05/10 00:34:56 - mmengine - INFO - Iter(train) [   940/480000]  lr: 1.3044e-05  eta: 8 days, 12:40:00  time: 1.3000  data_time: 0.0058  memory: 9802  loss: 2.3460  grad_norm: 0.6975
05/10 00:35:09 - mmengine - INFO - Iter(train) [   950/480000]  lr: 1.3183e-05  eta: 8 days, 12:22:48  time: 1.3364  data_time: 0.0059  memory: 9801  loss: 2.4351  grad_norm: 0.6883
05/10 00:35:23 - mmengine - INFO - Iter(train) [   960/480000]  lr: 1.3322e-05  eta: 8 days, 12:10:03  time: 1.3858  data_time: 0.0059  memory: 9802  loss: 2.4035  grad_norm: 0.6867
05/10 00:35:38 - mmengine - INFO - Iter(train) [   970/480000]  lr: 1.3461e-05  eta: 8 days, 12:07:49  time: 1.5103  data_time: 0.2061  memory: 9798  loss: 2.3356  grad_norm: 0.6867
05/10 00:35:52 - mmengine - INFO - Iter(train) [   980/480000]  lr: 1.3600e-05  eta: 8 days, 11:56:21  time: 1.3965  data_time: 0.0059  memory: 9800  loss: 2.3605  grad_norm: 0.6824
05/10 00:36:06 - mmengine - INFO - Iter(train) [   990/480000]  lr: 1.3739e-05  eta: 8 days, 11:40:00  time: 1.3330  data_time: 0.0059  memory: 9801  loss: 2.3002  grad_norm: 0.6824
05/10 00:36:19 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 00:36:19 - mmengine - INFO - Iter(train) [  1000/480000]  lr: 1.3878e-05  eta: 8 days, 11:23:44  time: 1.3301  data_time: 0.0059  memory: 9800  loss: 2.3622  grad_norm: 0.6801
05/10 00:36:19 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 00:36:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
这种行为确实需要谨慎对待，因为出轨不仅会对个人关系造成伤害，也可能对主播和男朋友的婚姻产生负面影响。如果男朋友的行为让你感到不安或者困扰，可以和他坦诚沟通，表达你的感受和担忧。同时，也可以寻求专业的心理咨询或者婚姻辅导，帮助你们解决这个问题。记住，出轨不仅是一种道德问题，更是一种心理问题，需要得到妥善处理。<|im_end|>

05/10 00:36:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哎呀，听起来你可能需要找牙医看看。不过，如果你需要一些关于如何保持牙齿健康和防止牙缝漏风的建议，我可以给你提供一些实用的技巧。比如，定期刷牙、使用牙线和漱口水，避免吃太硬或太甜的食物，保持良好的口腔卫生习惯，这些都可以帮助你防止牙缝漏风。如果你需要更多的帮助或者有其他问题，随时告诉我哦！<|im_end|>

05/10 00:36:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
哎呀，听起来你可能喝得有点过量了。红酒虽然有养生的功效，但是过量饮用可能会导致头晕、恶心等症状。建议你以后适量饮用，或者尝试一些其他养生方式，比如喝绿茶、喝蜂蜜水等，这些都有助于补充身体所需的营养，同时也能帮助你放松身心。如果头晕持续不退，最好去医院看看，确保自己的健康。<|im_end|>

05/10 00:36:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
哎呀，这听起来确实挺让人不开心的呢。取关和拉黑都是比较极端的行为，可能会让你们的关系变得紧张。不过，如果你们觉得这样会影响你们的友谊，可以试着沟通一下，看看是否可以找到一个更好的解决办法。如果需要，我可以提供一些建议或者帮助你们处理这个问题。<|im_end|>

05/10 00:36:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
不用太担心，胆固醇高并不一定意味着需要戒炸鸡。你可以尝试一些低脂、低胆固醇的食物，比如烤鸡、烤鱼、蒸蔬菜等，同时保持适量的运动，有助于降低胆固醇水平。如果需要更具体的饮食建议，可以咨询营养师或者医生。<|im_end|>

05/10 00:36:56 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直比《红楼梦》里的林黛玉还悲催，直接把剧本杀变成了“红楼梦”现场版。下次记得，别让读本玩家把你当“林黛玉”，直接“葬花”了。<|im_end|>

05/10 00:37:00 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
哎呀，这听起来确实挺让人不舒服的。你可以试试跟同事沟通一下，表达你的感受和想法，看看能否找到解决办法。如果需要，我可以帮你想想可能的应对策略。<|im_end|>

05/10 00:37:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导，您这是在考验我的演技吗？不过，我理解您的心情，毕竟领导的决策可能会影响到团队的工作效率。不过，我建议您可以尝试用文字或者邮件的方式表达您的想法，这样既不会影响领导的工作，也能让领导更好地理解您的需求。如果需要，我可以帮您写一份邮件或者文字稿，您看怎么样？<|im_end|>

05/10 00:37:06 - mmengine - INFO - Saving checkpoint at 1000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 00:37:20 - mmengine - INFO - Iter(train) [  1010/480000]  lr: 1.4017e-05  eta: 8 days, 17:24:54  time: 6.1011  data_time: 4.7779  memory: 9799  loss: 2.3158  grad_norm: 0.6817
05/10 00:37:34 - mmengine - INFO - Iter(train) [  1020/480000]  lr: 1.4156e-05  eta: 8 days, 17:10:08  time: 1.3887  data_time: 0.0059  memory: 9802  loss: 2.3044  grad_norm: 0.6817
05/10 00:37:47 - mmengine - INFO - Iter(train) [  1030/480000]  lr: 1.4295e-05  eta: 8 days, 16:48:53  time: 1.3013  data_time: 0.0059  memory: 9801  loss: 2.2603  grad_norm: 0.6676
05/10 00:38:00 - mmengine - INFO - Iter(train) [  1040/480000]  lr: 1.4433e-05  eta: 8 days, 16:29:34  time: 1.3211  data_time: 0.0060  memory: 9802  loss: 2.3528  grad_norm: 0.6598
05/10 00:38:14 - mmengine - INFO - Iter(train) [  1050/480000]  lr: 1.4572e-05  eta: 8 days, 16:18:29  time: 1.4247  data_time: 0.0059  memory: 9800  loss: 2.2802  grad_norm: 0.6598
05/10 00:38:27 - mmengine - INFO - Iter(train) [  1060/480000]  lr: 1.4711e-05  eta: 8 days, 15:59:09  time: 1.3125  data_time: 0.0060  memory: 9800  loss: 2.2809  grad_norm: 0.6530
05/10 00:38:41 - mmengine - INFO - Iter(train) [  1070/480000]  lr: 1.4850e-05  eta: 8 days, 15:47:07  time: 1.4055  data_time: 0.0059  memory: 9800  loss: 2.3016  grad_norm: 0.6530
05/10 00:38:55 - mmengine - INFO - Iter(train) [  1080/480000]  lr: 1.4989e-05  eta: 8 days, 15:28:25  time: 1.3125  data_time: 0.0059  memory: 9800  loss: 2.2599  grad_norm: 0.6455
05/10 00:39:08 - mmengine - INFO - Iter(train) [  1090/480000]  lr: 1.5128e-05  eta: 8 days, 15:11:25  time: 1.3310  data_time: 0.0059  memory: 9800  loss: 2.2960  grad_norm: 0.6421
05/10 00:39:22 - mmengine - INFO - Iter(train) [  1100/480000]  lr: 1.5267e-05  eta: 8 days, 15:01:17  time: 1.4212  data_time: 0.0061  memory: 9801  loss: 2.2536  grad_norm: 0.6421
05/10 00:39:35 - mmengine - INFO - Iter(train) [  1110/480000]  lr: 1.5406e-05  eta: 8 days, 14:42:25  time: 1.2975  data_time: 0.0059  memory: 9802  loss: 2.2344  grad_norm: 0.6373
05/10 00:39:48 - mmengine - INFO - Iter(train) [  1120/480000]  lr: 1.5545e-05  eta: 8 days, 14:26:42  time: 1.3369  data_time: 0.0060  memory: 9802  loss: 2.2393  grad_norm: 0.6313
05/10 00:40:04 - mmengine - INFO - Iter(train) [  1130/480000]  lr: 1.5683e-05  eta: 8 days, 14:25:49  time: 1.5432  data_time: 0.2060  memory: 9801  loss: 2.2599  grad_norm: 0.6313
05/10 00:40:18 - mmengine - INFO - Iter(train) [  1140/480000]  lr: 1.5822e-05  eta: 8 days, 14:16:50  time: 1.4272  data_time: 0.0059  memory: 9801  loss: 2.2418  grad_norm: 0.6287
05/10 00:40:31 - mmengine - INFO - Iter(train) [  1150/480000]  lr: 1.5961e-05  eta: 8 days, 14:00:11  time: 1.3146  data_time: 0.0060  memory: 9801  loss: 2.1800  grad_norm: 0.6287
05/10 00:40:44 - mmengine - INFO - Iter(train) [  1160/480000]  lr: 1.6100e-05  eta: 8 days, 13:43:51  time: 1.3149  data_time: 0.0060  memory: 9798  loss: 2.2398  grad_norm: 0.6291
05/10 00:40:59 - mmengine - INFO - Iter(train) [  1170/480000]  lr: 1.6239e-05  eta: 8 days, 13:35:22  time: 1.4262  data_time: 0.0059  memory: 9799  loss: 2.2482  grad_norm: 0.6169
05/10 00:41:12 - mmengine - INFO - Iter(train) [  1180/480000]  lr: 1.6378e-05  eta: 8 days, 13:20:00  time: 1.3223  data_time: 0.0060  memory: 9803  loss: 2.1914  grad_norm: 0.6169
05/10 00:41:26 - mmengine - INFO - Iter(train) [  1190/480000]  lr: 1.6517e-05  eta: 8 days, 13:10:56  time: 1.4124  data_time: 0.0059  memory: 9803  loss: 2.1428  grad_norm: 0.6075
05/10 00:41:39 - mmengine - INFO - Iter(train) [  1200/480000]  lr: 1.6656e-05  eta: 8 days, 12:54:10  time: 1.2943  data_time: 0.0059  memory: 9803  loss: 2.1812  grad_norm: 0.6044
05/10 00:41:52 - mmengine - INFO - Iter(train) [  1210/480000]  lr: 1.6795e-05  eta: 8 days, 12:38:41  time: 1.3099  data_time: 0.0060  memory: 9796  loss: 2.1781  grad_norm: 0.6044
05/10 00:42:06 - mmengine - INFO - Iter(train) [  1220/480000]  lr: 1.6934e-05  eta: 8 days, 12:31:32  time: 1.4332  data_time: 0.0059  memory: 9798  loss: 2.2623  grad_norm: 0.6043
05/10 00:42:19 - mmengine - INFO - Iter(train) [  1230/480000]  lr: 1.7072e-05  eta: 8 days, 12:15:53  time: 1.3006  data_time: 0.0057  memory: 9797  loss: 2.2149  grad_norm: 0.6043
05/10 00:42:34 - mmengine - INFO - Iter(train) [  1240/480000]  lr: 1.7211e-05  eta: 8 days, 12:09:24  time: 1.4393  data_time: 0.0059  memory: 9798  loss: 2.1472  grad_norm: 0.6035
05/10 00:42:47 - mmengine - INFO - Iter(train) [  1250/480000]  lr: 1.7350e-05  eta: 8 days, 11:54:28  time: 1.3050  data_time: 0.0058  memory: 9801  loss: 2.1728  grad_norm: 0.6012
05/10 00:43:00 - mmengine - INFO - Iter(train) [  1260/480000]  lr: 1.7489e-05  eta: 8 days, 11:39:48  time: 1.3059  data_time: 0.0058  memory: 9800  loss: 2.1644  grad_norm: 0.6012
05/10 00:43:14 - mmengine - INFO - Iter(train) [  1270/480000]  lr: 1.7628e-05  eta: 8 days, 11:33:11  time: 1.4301  data_time: 0.0059  memory: 9801  loss: 2.1639  grad_norm: 0.6028
05/10 00:43:27 - mmengine - INFO - Iter(train) [  1280/480000]  lr: 1.7767e-05  eta: 8 days, 11:14:55  time: 1.2417  data_time: 0.0058  memory: 9800  loss: 2.1313  grad_norm: 0.5992
05/10 00:43:42 - mmengine - INFO - Iter(train) [  1290/480000]  lr: 1.7906e-05  eta: 8 days, 11:14:05  time: 1.5193  data_time: 0.2064  memory: 9799  loss: 2.1413  grad_norm: 0.5992
05/10 00:43:56 - mmengine - INFO - Iter(train) [  1300/480000]  lr: 1.8045e-05  eta: 8 days, 11:09:40  time: 1.4604  data_time: 0.0060  memory: 9801  loss: 2.1414  grad_norm: 0.5949
05/10 00:44:10 - mmengine - INFO - Iter(train) [  1310/480000]  lr: 1.8184e-05  eta: 8 days, 10:55:53  time: 1.3057  data_time: 0.0062  memory: 9801  loss: 2.1193  grad_norm: 0.5949
05/10 00:44:23 - mmengine - INFO - Iter(train) [  1320/480000]  lr: 1.8323e-05  eta: 8 days, 10:43:00  time: 1.3173  data_time: 0.0061  memory: 9802  loss: 2.1078  grad_norm: 0.5919
05/10 00:44:37 - mmengine - INFO - Iter(train) [  1330/480000]  lr: 1.8461e-05  eta: 8 days, 10:36:52  time: 1.4265  data_time: 0.0059  memory: 9799  loss: 2.1022  grad_norm: 0.5924
05/10 00:44:50 - mmengine - INFO - Iter(train) [  1340/480000]  lr: 1.8600e-05  eta: 8 days, 10:23:34  time: 1.3045  data_time: 0.0059  memory: 9800  loss: 2.1697  grad_norm: 0.5924
05/10 00:45:04 - mmengine - INFO - Iter(train) [  1350/480000]  lr: 1.8739e-05  eta: 8 days, 10:17:35  time: 1.4252  data_time: 0.0059  memory: 9801  loss: 2.0846  grad_norm: 0.5964
05/10 00:45:17 - mmengine - INFO - Iter(train) [  1360/480000]  lr: 1.8878e-05  eta: 8 days, 10:05:40  time: 1.3229  data_time: 0.0060  memory: 9800  loss: 2.1018  grad_norm: 0.5992
05/10 00:45:30 - mmengine - INFO - Iter(train) [  1370/480000]  lr: 1.9017e-05  eta: 8 days, 9:52:29  time: 1.2978  data_time: 0.0059  memory: 9799  loss: 2.1159  grad_norm: 0.5992
05/10 00:45:44 - mmengine - INFO - Iter(train) [  1380/480000]  lr: 1.9156e-05  eta: 8 days, 9:43:30  time: 1.3673  data_time: 0.0057  memory: 9801  loss: 2.1141  grad_norm: 0.5944
05/10 00:45:57 - mmengine - INFO - Iter(train) [  1390/480000]  lr: 1.9295e-05  eta: 8 days, 9:31:49  time: 1.3184  data_time: 0.0061  memory: 9801  loss: 2.0785  grad_norm: 0.5944
05/10 00:46:12 - mmengine - INFO - Iter(train) [  1400/480000]  lr: 1.9434e-05  eta: 8 days, 9:29:25  time: 1.4781  data_time: 0.0059  memory: 9800  loss: 2.1020  grad_norm: 0.5918
05/10 00:46:25 - mmengine - INFO - Iter(train) [  1410/480000]  lr: 1.9573e-05  eta: 8 days, 9:17:32  time: 1.3100  data_time: 0.0060  memory: 9801  loss: 2.0882  grad_norm: 0.5891
05/10 00:46:39 - mmengine - INFO - Iter(train) [  1420/480000]  lr: 1.9712e-05  eta: 8 days, 9:12:25  time: 1.4276  data_time: 0.0058  memory: 9802  loss: 2.1041  grad_norm: 0.5891
05/10 00:46:52 - mmengine - INFO - Iter(train) [  1430/480000]  lr: 1.9850e-05  eta: 8 days, 9:00:11  time: 1.2987  data_time: 0.0060  memory: 9802  loss: 2.0871  grad_norm: 0.5893
05/10 00:47:05 - mmengine - INFO - Iter(train) [  1440/480000]  lr: 1.9989e-05  eta: 8 days, 8:45:50  time: 1.2575  data_time: 0.0058  memory: 9802  loss: 2.0838  grad_norm: 0.5878
05/10 00:47:22 - mmengine - INFO - Iter(train) [  1450/480000]  lr: 2.0128e-05  eta: 8 days, 8:54:10  time: 1.6664  data_time: 0.2062  memory: 9804  loss: 2.0094  grad_norm: 0.5878
05/10 00:47:34 - mmengine - INFO - Iter(train) [  1460/480000]  lr: 2.0267e-05  eta: 8 days, 8:40:06  time: 1.2584  data_time: 0.0058  memory: 9804  loss: 2.0661  grad_norm: 0.5893
05/10 00:47:49 - mmengine - INFO - Iter(train) [  1470/480000]  lr: 2.0406e-05  eta: 8 days, 8:35:44  time: 1.4338  data_time: 0.0059  memory: 9802  loss: 2.0681  grad_norm: 0.5893
05/10 00:48:02 - mmengine - INFO - Iter(train) [  1480/480000]  lr: 2.0545e-05  eta: 8 days, 8:23:53  time: 1.2936  data_time: 0.0057  memory: 9802  loss: 2.0343  grad_norm: 0.5895
05/10 00:48:15 - mmengine - INFO - Iter(train) [  1490/480000]  lr: 2.0684e-05  eta: 8 days, 8:14:16  time: 1.3328  data_time: 0.0059  memory: 9802  loss: 2.0701  grad_norm: 0.5901
05/10 00:48:29 - mmengine - INFO - Iter(train) [  1500/480000]  lr: 2.0823e-05  eta: 8 days, 8:11:23  time: 1.4568  data_time: 0.0059  memory: 9799  loss: 2.0372  grad_norm: 0.5901
05/10 00:48:29 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 00:48:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。出轨确实会让人感到很不舒服，尤其是当这种行为被对方察觉时。你觉得呢？我们可以一起想想怎么处理这个问题，或者寻求一些专业的建议。💖<|im_end|>

05/10 00:48:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝漏风得，吹蜡烛都像是在吹风扇一样！下次记得，洗牙前先用牙线清理一下，不然吹蜡烛都得变成吹风扇了！<|im_end|>

05/10 00:48:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这红酒喝得比树懒还慢，是不是想变成树懒的“红酒版”？下次记得，养生不是喝红酒，而是要慢慢来，别让红酒成了你的“毒药”。<|im_end|>

05/10 00:48:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这闺蜜是想把你的前任变成网红吗？不过别担心，我这就给你出个主意，下次你直接把小红书账号封了，让他们知道你的底线在哪里！<|im_end|>

05/10 00:48:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实是个挑战呢。胆固醇高确实需要控制饮食，但炸鸡的口感和营养确实让人难以抗拒。你可以尝试一些低脂、低盐的替代品，比如烤鸡胸肉、蒸鱼或者烤蔬菜，这样既能满足你的口感，又不会影响你的健康。如果需要，我可以帮你找一些低脂、低盐的烹饪食谱哦。💖<|im_end|>

05/10 00:48:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遇人不淑的遭遇，简直就是剧本杀版的“现实版”啊！下次记得，别让那些“读本玩家”影响了你的游戏体验，毕竟，剧本杀不是“读本”，而是“玩本”！<|im_end|>

05/10 00:49:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这同事是想让你的妆容变成苍蝇腿的吗？下次记得，眼线画得再细，也别忘了防晒，别让同事们也跟着你“苍蝇腿”了！<|im_end|>

05/10 00:49:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，领导发语音矩阵确实有点让人头疼呢。不过，装没看见也挺尴尬的，毕竟领导的关心是出于对工作的负责。你可以尝试和领导沟通一下，表达一下你的感受，或者找一些其他的方式来表达你的关心。毕竟，领导的关心也是出于对工作的关心，不是针对你个人的。希望你能找到合适的方式来表达你的感受。如果你需要，我可以帮你想想其他的方法。<|im_end|>

05/10 00:49:08 - mmengine - INFO - Saving checkpoint at 1500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 00:49:22 - mmengine - INFO - Iter(train) [  1510/480000]  lr: 2.0962e-05  eta: 8 days, 11:30:32  time: 5.2818  data_time: 3.9692  memory: 9800  loss: 2.0152  grad_norm: 0.5911
05/10 00:49:37 - mmengine - INFO - Iter(train) [  1520/480000]  lr: 2.1100e-05  eta: 8 days, 11:25:08  time: 1.4332  data_time: 0.0059  memory: 9799  loss: 2.1009  grad_norm: 0.6021
05/10 00:49:49 - mmengine - INFO - Iter(train) [  1530/480000]  lr: 2.1239e-05  eta: 8 days, 11:10:34  time: 1.2559  data_time: 0.0057  memory: 9803  loss: 2.0962  grad_norm: 0.6021
05/10 00:50:04 - mmengine - INFO - Iter(train) [  1540/480000]  lr: 2.1378e-05  eta: 8 days, 11:06:52  time: 1.4621  data_time: 0.0058  memory: 9803  loss: 1.9714  grad_norm: 0.6041
05/10 00:50:17 - mmengine - INFO - Iter(train) [  1550/480000]  lr: 2.1517e-05  eta: 8 days, 10:53:55  time: 1.2816  data_time: 0.0057  memory: 9801  loss: 2.0137  grad_norm: 0.6041
05/10 00:50:30 - mmengine - INFO - Iter(train) [  1560/480000]  lr: 2.1656e-05  eta: 8 days, 10:42:23  time: 1.3059  data_time: 0.0058  memory: 9803  loss: 1.9824  grad_norm: 0.6101
05/10 00:50:44 - mmengine - INFO - Iter(train) [  1570/480000]  lr: 2.1795e-05  eta: 8 days, 10:37:45  time: 1.4393  data_time: 0.0059  memory: 9802  loss: 2.0084  grad_norm: 0.6202
05/10 00:50:57 - mmengine - INFO - Iter(train) [  1580/480000]  lr: 2.1934e-05  eta: 8 days, 10:25:18  time: 1.2828  data_time: 0.0057  memory: 9801  loss: 2.0494  grad_norm: 0.6202
05/10 00:51:12 - mmengine - INFO - Iter(train) [  1590/480000]  lr: 2.2073e-05  eta: 8 days, 10:22:35  time: 1.4741  data_time: 0.0059  memory: 9801  loss: 2.0194  grad_norm: 0.6204
05/10 00:51:24 - mmengine - INFO - Iter(train) [  1600/480000]  lr: 2.2212e-05  eta: 8 days, 10:06:52  time: 1.2128  data_time: 0.0055  memory: 9799  loss: 1.9918  grad_norm: 0.6304
05/10 00:51:39 - mmengine - INFO - Iter(train) [  1610/480000]  lr: 2.2351e-05  eta: 8 days, 10:05:55  time: 1.5067  data_time: 0.2060  memory: 9802  loss: 1.9493  grad_norm: 0.6304
05/10 00:51:53 - mmengine - INFO - Iter(train) [  1620/480000]  lr: 2.2489e-05  eta: 8 days, 10:02:23  time: 1.4545  data_time: 0.0059  memory: 9801  loss: 2.0104  grad_norm: 0.6424
05/10 00:52:07 - mmengine - INFO - Iter(train) [  1630/480000]  lr: 2.2628e-05  eta: 8 days, 9:52:44  time: 1.3283  data_time: 0.0059  memory: 9799  loss: 2.0102  grad_norm: 0.6424
05/10 00:52:20 - mmengine - INFO - Iter(train) [  1640/480000]  lr: 2.2767e-05  eta: 8 days, 9:42:56  time: 1.3227  data_time: 0.0059  memory: 9801  loss: 1.9657  grad_norm: 0.6395
05/10 00:52:35 - mmengine - INFO - Iter(train) [  1650/480000]  lr: 2.2906e-05  eta: 8 days, 9:40:15  time: 1.4678  data_time: 0.0057  memory: 9801  loss: 1.9615  grad_norm: 0.6452
05/10 00:52:48 - mmengine - INFO - Iter(train) [  1660/480000]  lr: 2.3045e-05  eta: 8 days, 9:29:42  time: 1.3034  data_time: 0.0058  memory: 9805  loss: 2.0161  grad_norm: 0.6452
05/10 00:53:01 - mmengine - INFO - Iter(train) [  1670/480000]  lr: 2.3184e-05  eta: 8 days, 9:20:02  time: 1.3192  data_time: 0.0058  memory: 9804  loss: 1.9473  grad_norm: 0.6481
05/10 00:53:15 - mmengine - INFO - Iter(train) [  1680/480000]  lr: 2.3323e-05  eta: 8 days, 9:16:02  time: 1.4361  data_time: 0.0057  memory: 9802  loss: 1.9435  grad_norm: 0.6367
05/10 00:53:28 - mmengine - INFO - Iter(train) [  1690/480000]  lr: 2.3462e-05  eta: 8 days, 9:05:30  time: 1.2969  data_time: 0.0059  memory: 9800  loss: 1.9226  grad_norm: 0.6367
05/10 00:53:42 - mmengine - INFO - Iter(train) [  1700/480000]  lr: 2.3601e-05  eta: 8 days, 9:00:25  time: 1.4106  data_time: 0.0058  memory: 9799  loss: 1.9816  grad_norm: 0.6440
05/10 00:53:55 - mmengine - INFO - Iter(train) [  1710/480000]  lr: 2.3740e-05  eta: 8 days, 8:50:18  time: 1.3011  data_time: 0.0058  memory: 9800  loss: 2.0096  grad_norm: 0.6440
05/10 00:54:08 - mmengine - INFO - Iter(train) [  1720/480000]  lr: 2.3878e-05  eta: 8 days, 8:41:22  time: 1.3246  data_time: 0.0058  memory: 9801  loss: 1.9384  grad_norm: 0.6514
05/10 00:54:23 - mmengine - INFO - Iter(train) [  1730/480000]  lr: 2.4017e-05  eta: 8 days, 8:38:01  time: 1.4431  data_time: 0.0057  memory: 9798  loss: 1.9953  grad_norm: 0.6420
05/10 00:54:36 - mmengine - INFO - Iter(train) [  1740/480000]  lr: 2.4156e-05  eta: 8 days, 8:28:03  time: 1.2984  data_time: 0.0058  memory: 9799  loss: 1.8907  grad_norm: 0.6420
05/10 00:54:50 - mmengine - INFO - Iter(train) [  1750/480000]  lr: 2.4295e-05  eta: 8 days, 8:24:14  time: 1.4307  data_time: 0.1320  memory: 9802  loss: 1.9334  grad_norm: 0.6467
05/10 00:55:03 - mmengine - INFO - Iter(train) [  1760/480000]  lr: 2.4434e-05  eta: 8 days, 8:12:10  time: 1.2477  data_time: 0.0057  memory: 9801  loss: 1.9050  grad_norm: 0.6546
05/10 00:55:18 - mmengine - INFO - Iter(train) [  1770/480000]  lr: 2.4573e-05  eta: 8 days, 8:12:48  time: 1.5264  data_time: 0.2061  memory: 9805  loss: 1.9007  grad_norm: 0.6546
05/10 00:55:32 - mmengine - INFO - Iter(train) [  1780/480000]  lr: 2.4712e-05  eta: 8 days, 8:08:18  time: 1.4125  data_time: 0.0058  memory: 9806  loss: 1.9170  grad_norm: 0.6465
05/10 00:55:45 - mmengine - INFO - Iter(train) [  1790/480000]  lr: 2.4851e-05  eta: 8 days, 7:58:09  time: 1.2844  data_time: 0.0059  memory: 9803  loss: 1.9900  grad_norm: 0.6465
05/10 00:55:59 - mmengine - INFO - Iter(train) [  1800/480000]  lr: 2.4990e-05  eta: 8 days, 7:54:28  time: 1.4277  data_time: 0.0059  memory: 9802  loss: 1.8924  grad_norm: 0.6551
05/10 00:56:12 - mmengine - INFO - Iter(train) [  1810/480000]  lr: 2.5128e-05  eta: 8 days, 7:45:33  time: 1.3083  data_time: 0.0058  memory: 9801  loss: 1.9192  grad_norm: 0.6545
05/10 00:56:25 - mmengine - INFO - Iter(train) [  1820/480000]  lr: 2.5267e-05  eta: 8 days, 7:36:32  time: 1.3036  data_time: 0.0059  memory: 9804  loss: 1.8425  grad_norm: 0.6545
05/10 00:56:39 - mmengine - INFO - Iter(train) [  1830/480000]  lr: 2.5406e-05  eta: 8 days, 7:32:43  time: 1.4207  data_time: 0.0060  memory: 9804  loss: 1.9441  grad_norm: 0.6624
05/10 00:56:53 - mmengine - INFO - Iter(train) [  1840/480000]  lr: 2.5545e-05  eta: 8 days, 7:23:48  time: 1.3023  data_time: 0.0059  memory: 9803  loss: 1.9334  grad_norm: 0.6677
05/10 00:57:07 - mmengine - INFO - Iter(train) [  1850/480000]  lr: 2.5684e-05  eta: 8 days, 7:20:38  time: 1.4336  data_time: 0.0059  memory: 9801  loss: 1.9040  grad_norm: 0.6677
05/10 00:57:20 - mmengine - INFO - Iter(train) [  1860/480000]  lr: 2.5823e-05  eta: 8 days, 7:12:24  time: 1.3145  data_time: 0.0060  memory: 9802  loss: 1.8776  grad_norm: 0.6665
05/10 00:57:34 - mmengine - INFO - Iter(train) [  1870/480000]  lr: 2.5962e-05  eta: 8 days, 7:08:29  time: 1.4138  data_time: 0.0059  memory: 9803  loss: 1.8911  grad_norm: 0.6665
05/10 00:57:47 - mmengine - INFO - Iter(train) [  1880/480000]  lr: 2.6101e-05  eta: 8 days, 6:59:20  time: 1.2896  data_time: 0.0059  memory: 9802  loss: 1.8769  grad_norm: 0.6635
05/10 00:58:00 - mmengine - INFO - Iter(train) [  1890/480000]  lr: 2.6240e-05  eta: 8 days, 6:51:39  time: 1.3218  data_time: 0.0059  memory: 9799  loss: 1.8372  grad_norm: 0.6787
05/10 00:58:15 - mmengine - INFO - Iter(train) [  1900/480000]  lr: 2.6379e-05  eta: 8 days, 6:49:17  time: 1.4468  data_time: 0.0058  memory: 9802  loss: 1.8510  grad_norm: 0.6787
05/10 00:58:28 - mmengine - INFO - Iter(train) [  1910/480000]  lr: 2.6517e-05  eta: 8 days, 6:41:39  time: 1.3202  data_time: 0.0060  memory: 9804  loss: 1.8425  grad_norm: 0.6918
05/10 00:58:41 - mmengine - INFO - Iter(train) [  1920/480000]  lr: 2.6656e-05  eta: 8 days, 6:35:37  time: 1.3568  data_time: 0.0058  memory: 9803  loss: 1.8127  grad_norm: 0.6879
05/10 00:58:56 - mmengine - INFO - Iter(train) [  1930/480000]  lr: 2.6795e-05  eta: 8 days, 6:34:41  time: 1.4790  data_time: 0.2058  memory: 9801  loss: 1.8747  grad_norm: 0.6879
05/10 00:59:09 - mmengine - INFO - Iter(train) [  1940/480000]  lr: 2.6934e-05  eta: 8 days, 6:27:05  time: 1.3161  data_time: 0.0058  memory: 9801  loss: 1.8195  grad_norm: 0.7058
05/10 00:59:24 - mmengine - INFO - Iter(train) [  1950/480000]  lr: 2.7073e-05  eta: 8 days, 6:26:03  time: 1.4754  data_time: 0.0058  memory: 9798  loss: 1.8709  grad_norm: 0.7058
05/10 00:59:37 - mmengine - INFO - Iter(train) [  1960/480000]  lr: 2.7212e-05  eta: 8 days, 6:17:28  time: 1.2894  data_time: 0.0060  memory: 9803  loss: 1.8271  grad_norm: 0.7058
05/10 00:59:51 - mmengine - INFO - Iter(train) [  1970/480000]  lr: 2.7351e-05  eta: 8 days, 6:14:01  time: 1.4141  data_time: 0.0058  memory: 9801  loss: 1.7694  grad_norm: 0.7303
05/10 01:00:04 - mmengine - INFO - Iter(train) [  1980/480000]  lr: 2.7490e-05  eta: 8 days, 6:06:46  time: 1.3185  data_time: 0.0058  memory: 9801  loss: 1.8507  grad_norm: 0.7303
05/10 01:00:18 - mmengine - INFO - Iter(train) [  1990/480000]  lr: 2.7629e-05  eta: 8 days, 5:59:39  time: 1.3206  data_time: 0.0059  memory: 9803  loss: 1.8188  grad_norm: 0.7391
05/10 01:00:32 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 01:00:32 - mmengine - INFO - Iter(train) [  2000/480000]  lr: 2.7768e-05  eta: 8 days, 5:57:04  time: 1.4324  data_time: 0.0059  memory: 9801  loss: 1.8093  grad_norm: 0.7570
05/10 01:00:32 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 01:00:40 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比火箭还刺激，不过别忘了，出轨这种事，得看对象是谁，别让小三也来凑热闹。不过，如果他只是偶尔为之，那可能只是精神上的小刺激，毕竟，出轨这种事，得看对象是谁。不过，如果他经常这样做，那可得好好考虑一下，毕竟，出轨这种事，得谨慎对待。毕竟，出轨这种事，得看对象是谁。<|im_end|>

05/10 01:00:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝都能吹出台风了，下次记得带个防风罩，别让蜡烛成了你的“吹风机”。不过话说回来，洗牙后要注意口腔卫生，不然下次吹蜡烛还得吹风。<|im_end|>

05/10 01:00:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直就是在红酒的世界里玩起了“红酒迷路”的游戏。下次记得适量，不然我得给你配个“红酒导航”了。保重身体，别让红酒成了你的“隐形杀手”啊！🍷<|im_end|>

05/10 01:00:56 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比双十一抢购还刺激，不过别太往心里去，姐妹们互相取关，是为了各自的隐私和快乐，毕竟“取关”不是解决问题的最好方式。不过下次记得，别让这种“小插曲”影响了你的心情，姐妹们，咱们继续加油，别让“取关”成为常态！💪<|im_end|>

05/10 01:01:00 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，健康最重要哦，炸鸡虽然好吃，但也要注意饮食均衡呢。我们可以试试吃一些低脂的替代品，比如烤鸡或者蒸鸡，或者搭配一些健康的蔬菜和水果。记得保持适量哦，健康饮食最重要！💖<|im_end|>

05/10 01:01:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遭遇简直比《红楼梦》还惨烈，下次记得带上防摔垫，保护好你的“剧本杀”财产！😂<|im_end|>

05/10 01:01:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这同事是来自外星的吗？眼线都能比苍蝇腿还细？下次记得，别让同事给你取外号，不然你得跟苍蝇腿比谁更惨。保重啊朋友！<|im_end|>

05/10 01:01:12 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是打算让你在职场上体验“沉默是金”吗？下次记得，领导给你发语音矩阵，你得先准备好“沉默是金”的台词，不然别怪我翻箱倒柜找“沉默是金”的剧本。<|im_end|>

05/10 01:01:12 - mmengine - INFO - Saving checkpoint at 2000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 01:01:26 - mmengine - INFO - Iter(train) [  2010/480000]  lr: 2.7906e-05  eta: 8 days, 8:30:55  time: 5.3790  data_time: 4.0795  memory: 9802  loss: 1.8342  grad_norm: 0.7570
05/10 01:01:40 - mmengine - INFO - Iter(train) [  2020/480000]  lr: 2.8045e-05  eta: 8 days, 8:26:50  time: 1.4130  data_time: 0.0060  memory: 9803  loss: 1.8023  grad_norm: 0.8016
05/10 01:01:53 - mmengine - INFO - Iter(train) [  2030/480000]  lr: 2.8184e-05  eta: 8 days, 8:17:32  time: 1.2794  data_time: 0.0058  memory: 9799  loss: 1.8065  grad_norm: 0.8016
05/10 01:02:07 - mmengine - INFO - Iter(train) [  2040/480000]  lr: 2.8323e-05  eta: 8 days, 8:14:45  time: 1.4437  data_time: 0.0059  memory: 9805  loss: 1.8498  grad_norm: 0.8131
05/10 01:02:20 - mmengine - INFO - Iter(train) [  2050/480000]  lr: 2.8462e-05  eta: 8 days, 8:06:36  time: 1.3051  data_time: 0.0059  memory: 9803  loss: 1.8037  grad_norm: 0.8386
05/10 01:02:33 - mmengine - INFO - Iter(train) [  2060/480000]  lr: 2.8601e-05  eta: 8 days, 7:57:59  time: 1.2906  data_time: 0.0060  memory: 9803  loss: 1.8094  grad_norm: 0.8386
05/10 01:02:46 - mmengine - INFO - Iter(train) [  2070/480000]  lr: 2.8740e-05  eta: 8 days, 7:50:11  time: 1.3103  data_time: 0.0061  memory: 9801  loss: 1.8059  grad_norm: 0.8438
05/10 01:03:01 - mmengine - INFO - Iter(train) [  2080/480000]  lr: 2.8879e-05  eta: 8 days, 7:47:23  time: 1.4385  data_time: 0.0058  memory: 9800  loss: 1.7577  grad_norm: 0.8562
05/10 01:03:16 - mmengine - INFO - Iter(train) [  2090/480000]  lr: 2.9018e-05  eta: 8 days, 7:48:09  time: 1.5318  data_time: 0.2061  memory: 9800  loss: 1.7595  grad_norm: 0.8562
05/10 01:03:30 - mmengine - INFO - Iter(train) [  2100/480000]  lr: 2.9157e-05  eta: 8 days, 7:44:46  time: 1.4223  data_time: 0.0058  memory: 9800  loss: 1.7721  grad_norm: 0.8630
05/10 01:03:43 - mmengine - INFO - Iter(train) [  2110/480000]  lr: 2.9295e-05  eta: 8 days, 7:36:12  time: 1.2845  data_time: 0.0059  memory: 9800  loss: 1.7429  grad_norm: 0.8630
05/10 01:03:56 - mmengine - INFO - Iter(train) [  2120/480000]  lr: 2.9434e-05  eta: 8 days, 7:28:28  time: 1.3044  data_time: 0.0059  memory: 9801  loss: 1.7220  grad_norm: 0.8767
05/10 01:04:10 - mmengine - INFO - Iter(train) [  2130/480000]  lr: 2.9573e-05  eta: 8 days, 7:26:10  time: 1.4480  data_time: 0.0059  memory: 9802  loss: 1.7976  grad_norm: 0.8821
05/10 01:04:24 - mmengine - INFO - Iter(train) [  2140/480000]  lr: 2.9712e-05  eta: 8 days, 7:18:49  time: 1.3116  data_time: 0.0058  memory: 9802  loss: 1.7672  grad_norm: 0.8821
05/10 01:04:38 - mmengine - INFO - Iter(train) [  2150/480000]  lr: 2.9851e-05  eta: 8 days, 7:16:06  time: 1.4351  data_time: 0.0059  memory: 9802  loss: 1.7741  grad_norm: 0.8868
05/10 01:04:51 - mmengine - INFO - Iter(train) [  2160/480000]  lr: 2.9990e-05  eta: 8 days, 7:08:11  time: 1.2930  data_time: 0.0059  memory: 9797  loss: 1.7282  grad_norm: 0.8898
05/10 01:05:04 - mmengine - INFO - Iter(train) [  2170/480000]  lr: 3.0129e-05  eta: 8 days, 7:00:50  time: 1.3071  data_time: 0.0057  memory: 9799  loss: 1.7186  grad_norm: 0.8898
05/10 01:05:18 - mmengine - INFO - Iter(train) [  2180/480000]  lr: 3.0268e-05  eta: 8 days, 6:58:51  time: 1.4518  data_time: 0.0058  memory: 9803  loss: 1.7022  grad_norm: 0.8796
05/10 01:05:31 - mmengine - INFO - Iter(train) [  2190/480000]  lr: 3.0407e-05  eta: 8 days, 6:50:15  time: 1.2698  data_time: 0.0058  memory: 9802  loss: 1.7607  grad_norm: 0.8796
05/10 01:05:46 - mmengine - INFO - Iter(train) [  2200/480000]  lr: 3.0545e-05  eta: 8 days, 6:48:48  time: 1.4646  data_time: 0.0059  memory: 9802  loss: 1.7522  grad_norm: 0.8886
05/10 01:05:59 - mmengine - INFO - Iter(train) [  2210/480000]  lr: 3.0684e-05  eta: 8 days, 6:41:29  time: 1.3020  data_time: 0.0059  memory: 9802  loss: 1.7458  grad_norm: 0.8823
05/10 01:06:12 - mmengine - INFO - Iter(train) [  2220/480000]  lr: 3.0823e-05  eta: 8 days, 6:34:06  time: 1.2980  data_time: 0.0057  memory: 9800  loss: 1.7086  grad_norm: 0.8823
05/10 01:06:26 - mmengine - INFO - Iter(train) [  2230/480000]  lr: 3.0962e-05  eta: 8 days, 6:32:12  time: 1.4502  data_time: 0.0058  memory: 9802  loss: 1.7512  grad_norm: 0.9016
05/10 01:06:38 - mmengine - INFO - Iter(train) [  2240/480000]  lr: 3.1101e-05  eta: 8 days, 6:21:49  time: 1.2110  data_time: 0.0056  memory: 9802  loss: 1.7377  grad_norm: 0.9243
05/10 01:06:54 - mmengine - INFO - Iter(train) [  2250/480000]  lr: 3.1240e-05  eta: 8 days, 6:23:33  time: 1.5504  data_time: 0.2062  memory: 9800  loss: 1.6692  grad_norm: 0.9243
05/10 01:07:10 - mmengine - INFO - Iter(train) [  2260/480000]  lr: 3.1379e-05  eta: 8 days, 6:25:41  time: 1.5626  data_time: 0.0063  memory: 9800  loss: 1.6917  grad_norm: 0.9317
05/10 01:07:22 - mmengine - INFO - Iter(train) [  2270/480000]  lr: 3.1518e-05  eta: 8 days, 6:18:16  time: 1.2909  data_time: 0.0059  memory: 9798  loss: 1.7393  grad_norm: 0.9317
05/10 01:07:35 - mmengine - INFO - Iter(train) [  2280/480000]  lr: 3.1657e-05  eta: 8 days, 6:09:50  time: 1.2600  data_time: 0.0058  memory: 9799  loss: 1.6478  grad_norm: 0.9509
05/10 01:07:49 - mmengine - INFO - Iter(train) [  2290/480000]  lr: 3.1796e-05  eta: 8 days, 6:06:20  time: 1.3997  data_time: 0.0060  memory: 9800  loss: 1.6833  grad_norm: 0.9516
05/10 01:08:02 - mmengine - INFO - Iter(train) [  2300/480000]  lr: 3.1934e-05  eta: 8 days, 5:58:55  time: 1.2861  data_time: 0.0058  memory: 9803  loss: 1.6375  grad_norm: 0.9516
05/10 01:08:17 - mmengine - INFO - Iter(train) [  2310/480000]  lr: 3.2073e-05  eta: 8 days, 5:57:57  time: 1.4712  data_time: 0.0061  memory: 9803  loss: 1.6497  grad_norm: 0.9577
05/10 01:08:29 - mmengine - INFO - Iter(train) [  2320/480000]  lr: 3.2212e-05  eta: 8 days, 5:50:15  time: 1.2748  data_time: 0.0058  memory: 9801  loss: 1.6652  grad_norm: 0.9808
05/10 01:08:43 - mmengine - INFO - Iter(train) [  2330/480000]  lr: 3.2351e-05  eta: 8 days, 5:44:05  time: 1.3174  data_time: 0.0062  memory: 9803  loss: 1.6596  grad_norm: 0.9808
05/10 01:08:57 - mmengine - INFO - Iter(train) [  2340/480000]  lr: 3.2490e-05  eta: 8 days, 5:41:13  time: 1.4134  data_time: 0.0061  memory: 9802  loss: 1.6812  grad_norm: 0.9868
05/10 01:09:10 - mmengine - INFO - Iter(train) [  2350/480000]  lr: 3.2629e-05  eta: 8 days, 5:34:49  time: 1.3083  data_time: 0.0058  memory: 9798  loss: 1.6668  grad_norm: 0.9868
05/10 01:09:24 - mmengine - INFO - Iter(train) [  2360/480000]  lr: 3.2768e-05  eta: 8 days, 5:33:37  time: 1.4608  data_time: 0.0061  memory: 9801  loss: 1.6479  grad_norm: 0.9953
05/10 01:09:37 - mmengine - INFO - Iter(train) [  2370/480000]  lr: 3.2907e-05  eta: 8 days, 5:25:01  time: 1.2407  data_time: 0.0058  memory: 9805  loss: 1.6557  grad_norm: 1.0071
05/10 01:09:50 - mmengine - INFO - Iter(train) [  2380/480000]  lr: 3.3046e-05  eta: 8 days, 5:19:13  time: 1.3216  data_time: 0.0061  memory: 9807  loss: 1.6491  grad_norm: 1.0071
05/10 01:10:04 - mmengine - INFO - Iter(train) [  2390/480000]  lr: 3.3185e-05  eta: 8 days, 5:17:10  time: 1.4334  data_time: 0.0059  memory: 9805  loss: 1.7047  grad_norm: 1.0122
05/10 01:10:17 - mmengine - INFO - Iter(train) [  2400/480000]  lr: 3.3323e-05  eta: 8 days, 5:09:39  time: 1.2678  data_time: 0.0058  memory: 9800  loss: 1.7066  grad_norm: 1.0130
05/10 01:10:34 - mmengine - INFO - Iter(train) [  2410/480000]  lr: 3.3462e-05  eta: 8 days, 5:14:59  time: 1.6554  data_time: 0.2062  memory: 9802  loss: 1.5970  grad_norm: 1.0130
05/10 01:10:46 - mmengine - INFO - Iter(train) [  2420/480000]  lr: 3.3601e-05  eta: 8 days, 5:07:54  time: 1.2787  data_time: 0.0057  memory: 9808  loss: 1.6169  grad_norm: 1.0351
05/10 01:11:01 - mmengine - INFO - Iter(train) [  2430/480000]  lr: 3.3740e-05  eta: 8 days, 5:06:23  time: 1.4475  data_time: 0.0059  memory: 9807  loss: 1.6689  grad_norm: 1.0351
05/10 01:11:14 - mmengine - INFO - Iter(train) [  2440/480000]  lr: 3.3879e-05  eta: 8 days, 5:00:17  time: 1.3060  data_time: 0.0059  memory: 9806  loss: 1.6094  grad_norm: 1.0419
05/10 01:11:27 - mmengine - INFO - Iter(train) [  2450/480000]  lr: 3.4018e-05  eta: 8 days, 4:54:18  time: 1.3087  data_time: 0.0059  memory: 9804  loss: 1.6359  grad_norm: 1.0739
05/10 01:11:41 - mmengine - INFO - Iter(train) [  2460/480000]  lr: 3.4157e-05  eta: 8 days, 4:51:32  time: 1.4068  data_time: 0.0060  memory: 9801  loss: 1.5795  grad_norm: 1.0739
05/10 01:11:54 - mmengine - INFO - Iter(train) [  2470/480000]  lr: 3.4296e-05  eta: 8 days, 4:45:28  time: 1.3032  data_time: 0.0058  memory: 9800  loss: 1.6256  grad_norm: 1.0819
05/10 01:12:09 - mmengine - INFO - Iter(train) [  2480/480000]  lr: 3.4435e-05  eta: 8 days, 4:44:16  time: 1.4539  data_time: 0.0060  memory: 9799  loss: 1.5403  grad_norm: 1.0980
05/10 01:12:22 - mmengine - INFO - Iter(train) [  2490/480000]  lr: 3.4573e-05  eta: 8 days, 4:38:13  time: 1.3017  data_time: 0.0058  memory: 9801  loss: 1.5778  grad_norm: 1.0980
05/10 01:12:35 - mmengine - INFO - Iter(train) [  2500/480000]  lr: 3.4712e-05  eta: 8 days, 4:32:54  time: 1.3228  data_time: 0.0060  memory: 9804  loss: 1.5556  grad_norm: 1.1273
05/10 01:12:35 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 01:12:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比火箭还刺激，不过别忘了，出轨这种事，男人和女人的定义可是不一样的。男主播是主播，男主播的男朋友是主播的男朋友，这操作有点儿像《绝地求生》里的“吃鸡”，但别忘了，这可是现实版的“精神出轨”。不过，如果他只是偶尔心血来潮，那可能就是“精神出轨”了。但如果是经常性的，那可得好好考虑一下了。毕竟，男人出轨，女人得小心点，别让这种事影响到你们的感情。毕竟，婚姻不是游戏，别让“吃鸡”成了你的“游戏人生”。<|im_end|>

05/10 01:12:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝都能开演唱会了，吹蜡烛都能变成鼓风机，下次是不是打算开个音乐会？不过话说回来，洗牙后要注意口腔卫生，别让牙齿也跟着“漏风”了。保持好口腔健康，别让“漏风”的牙齿影响到你的生活乐趣哦！🌟<|im_end|>

05/10 01:12:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直就是在红酒的世界里玩起了“醉生梦死”的游戏。下次记得适量喝，不然下次喝到头晕，你是不是得考虑是不是该考虑一下“养生”了？🍷💦<|im_end|>

05/10 01:13:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比双十一抢购还刺激，你的闺蜜这是在搞什么鬼？不过别太往心里去，毕竟“闺蜜”这个词儿，有时候就是个“误会”的代名词。下次她们再这样，你就告诉她，你的前任是“前任”，而她只是“闺蜜”。保持优雅，别让这些小插曲影响了你的心情和生活。<|im_end|>

05/10 01:13:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，健康最重要呢，要注意饮食均衡哦。可以试试吃一些低脂或者无脂的炸鸡，或者选择烤或者蒸的方式来吃，这样既可以享受美食，又不会摄入过多的油脂。如果需要，我可以帮你找一些健康的食谱哦！💖<|im_end|>

05/10 01:13:14 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比电影里的特效还刺激！下次记得带个防摔垫，或者直接把剧本藏起来，免得又遇到这种“剧本杀界的翻版”。安全第一，别再让读者们给你“剧本”了！<|im_end|>

05/10 01:13:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这同事怕不是个"苍蝇眼"爱好者吧？下次他再这么说，你就告诉他，"你这眼线，就像苍蝇在你脸上飞来飞去，你是不是想把苍蝇变成苍蝇眼？'"<|im_end|>

05/10 01:13:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是打算让你在职场上变成“隐身人”吗？下次记得，领导的语音矩阵是用来考验你“隐身”能力的，不是用来装没看见的。不过话说回来，别太往心里去，至少你还有“60秒语音矩阵”这个技能，不是吗？<|im_end|>

05/10 01:13:24 - mmengine - INFO - Saving checkpoint at 2500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 01:13:38 - mmengine - INFO - Iter(train) [  2510/480000]  lr: 3.4851e-05  eta: 8 days, 7:04:58  time: 6.2861  data_time: 5.0116  memory: 9803  loss: 1.5849  grad_norm: 1.1273
05/10 01:13:52 - mmengine - INFO - Iter(train) [  2520/480000]  lr: 3.4990e-05  eta: 8 days, 7:02:19  time: 1.4246  data_time: 0.0060  memory: 9806  loss: 1.5612  grad_norm: 1.1344
05/10 01:14:05 - mmengine - INFO - Iter(train) [  2530/480000]  lr: 3.5129e-05  eta: 8 days, 6:56:16  time: 1.3167  data_time: 0.0059  memory: 9803  loss: 1.6372  grad_norm: 1.1516
05/10 01:14:19 - mmengine - INFO - Iter(train) [  2540/480000]  lr: 3.5268e-05  eta: 8 days, 6:53:26  time: 1.4172  data_time: 0.0060  memory: 9803  loss: 1.5758  grad_norm: 1.1516
05/10 01:14:32 - mmengine - INFO - Iter(train) [  2550/480000]  lr: 3.5407e-05  eta: 8 days, 6:47:17  time: 1.3104  data_time: 0.0060  memory: 9803  loss: 1.5438  grad_norm: 1.1690
05/10 01:14:45 - mmengine - INFO - Iter(train) [  2560/480000]  lr: 3.5546e-05  eta: 8 days, 6:39:02  time: 1.2417  data_time: 0.0060  memory: 9800  loss: 1.6319  grad_norm: 1.1835
05/10 01:15:01 - mmengine - INFO - Iter(train) [  2570/480000]  lr: 3.5685e-05  eta: 8 days, 6:43:13  time: 1.6413  data_time: 0.2061  memory: 9801  loss: 1.5066  grad_norm: 1.1835
05/10 01:15:14 - mmengine - INFO - Iter(train) [  2580/480000]  lr: 3.5824e-05  eta: 8 days, 6:37:31  time: 1.3213  data_time: 0.0060  memory: 9801  loss: 1.5458  grad_norm: 1.1971
05/10 01:15:29 - mmengine - INFO - Iter(train) [  2590/480000]  lr: 3.5962e-05  eta: 8 days, 6:34:36  time: 1.4113  data_time: 0.0059  memory: 9802  loss: 1.5621  grad_norm: 1.1971
05/10 01:15:42 - mmengine - INFO - Iter(train) [  2600/480000]  lr: 3.6101e-05  eta: 8 days, 6:28:18  time: 1.2992  data_time: 0.0061  memory: 9803  loss: 1.5394  grad_norm: 1.2105
05/10 01:15:55 - mmengine - INFO - Iter(train) [  2610/480000]  lr: 3.6240e-05  eta: 8 days, 6:22:20  time: 1.3094  data_time: 0.0059  memory: 9806  loss: 1.5701  grad_norm: 1.2035
05/10 01:16:09 - mmengine - INFO - Iter(train) [  2620/480000]  lr: 3.6379e-05  eta: 8 days, 6:20:16  time: 1.4360  data_time: 0.0059  memory: 9806  loss: 1.5079  grad_norm: 1.2035
05/10 01:16:22 - mmengine - INFO - Iter(train) [  2630/480000]  lr: 3.6518e-05  eta: 8 days, 6:14:57  time: 1.3280  data_time: 0.0059  memory: 9806  loss: 1.5639  grad_norm: 1.2369
05/10 01:16:36 - mmengine - INFO - Iter(train) [  2640/480000]  lr: 3.6657e-05  eta: 8 days, 6:12:23  time: 1.4181  data_time: 0.0059  memory: 9802  loss: 1.5314  grad_norm: 1.2412
05/10 01:16:50 - mmengine - INFO - Iter(train) [  2650/480000]  lr: 3.6796e-05  eta: 8 days, 6:06:37  time: 1.3110  data_time: 0.0059  memory: 9804  loss: 1.5179  grad_norm: 1.2412
05/10 01:17:03 - mmengine - INFO - Iter(train) [  2660/480000]  lr: 3.6935e-05  eta: 8 days, 6:01:31  time: 1.3322  data_time: 0.0057  memory: 9804  loss: 1.5004  grad_norm: 1.2286
05/10 01:17:16 - mmengine - INFO - Iter(train) [  2670/480000]  lr: 3.7074e-05  eta: 8 days, 5:56:15  time: 1.3251  data_time: 0.0059  memory: 9804  loss: 1.4870  grad_norm: 1.2286
05/10 01:17:29 - mmengine - INFO - Iter(train) [  2680/480000]  lr: 3.7213e-05  eta: 8 days, 5:50:20  time: 1.3015  data_time: 0.0059  memory: 9804  loss: 1.4877  grad_norm: 1.2336
05/10 01:17:44 - mmengine - INFO - Iter(train) [  2690/480000]  lr: 3.7351e-05  eta: 8 days, 5:50:50  time: 1.5178  data_time: 0.0059  memory: 9804  loss: 1.4716  grad_norm: 1.2343
05/10 01:17:58 - mmengine - INFO - Iter(train) [  2700/480000]  lr: 3.7490e-05  eta: 8 days, 5:45:27  time: 1.3176  data_time: 0.0059  memory: 9805  loss: 1.5274  grad_norm: 1.2343
05/10 01:18:11 - mmengine - INFO - Iter(train) [  2710/480000]  lr: 3.7629e-05  eta: 8 days, 5:40:13  time: 1.3220  data_time: 0.0059  memory: 9805  loss: 1.4756  grad_norm: 1.2323
05/10 01:18:24 - mmengine - INFO - Iter(train) [  2720/480000]  lr: 3.7768e-05  eta: 8 days, 5:36:23  time: 1.3681  data_time: 0.0058  memory: 9804  loss: 1.4981  grad_norm: 1.2498
05/10 01:18:40 - mmengine - INFO - Iter(train) [  2730/480000]  lr: 3.7907e-05  eta: 8 days, 5:36:53  time: 1.5164  data_time: 0.2061  memory: 9804  loss: 1.4916  grad_norm: 1.2498
05/10 01:18:54 - mmengine - INFO - Iter(train) [  2740/480000]  lr: 3.8046e-05  eta: 8 days, 5:34:39  time: 1.4224  data_time: 0.0060  memory: 9807  loss: 1.4565  grad_norm: 1.2423
05/10 01:19:07 - mmengine - INFO - Iter(train) [  2750/480000]  lr: 3.8185e-05  eta: 8 days, 5:29:30  time: 1.3208  data_time: 0.0060  memory: 9806  loss: 1.5111  grad_norm: 1.2423
05/10 01:19:20 - mmengine - INFO - Iter(train) [  2760/480000]  lr: 3.8324e-05  eta: 8 days, 5:24:06  time: 1.3111  data_time: 0.0059  memory: 9807  loss: 1.4311  grad_norm: 1.2516
05/10 01:19:34 - mmengine - INFO - Iter(train) [  2770/480000]  lr: 3.8463e-05  eta: 8 days, 5:21:26  time: 1.4046  data_time: 0.0060  memory: 9803  loss: 1.4584  grad_norm: 1.2694
05/10 01:19:47 - mmengine - INFO - Iter(train) [  2780/480000]  lr: 3.8602e-05  eta: 8 days, 5:15:30  time: 1.2904  data_time: 0.0059  memory: 9807  loss: 1.4266  grad_norm: 1.2694
05/10 01:20:01 - mmengine - INFO - Iter(train) [  2790/480000]  lr: 3.8740e-05  eta: 8 days, 5:13:26  time: 1.4242  data_time: 0.0060  memory: 9805  loss: 1.4978  grad_norm: 1.3001
05/10 01:20:14 - mmengine - INFO - Iter(train) [  2800/480000]  lr: 3.8879e-05  eta: 8 days, 5:08:16  time: 1.3143  data_time: 0.0060  memory: 9807  loss: 1.4303  grad_norm: 1.2880
05/10 01:20:28 - mmengine - INFO - Iter(train) [  2810/480000]  lr: 3.9018e-05  eta: 8 days, 5:02:59  time: 1.3097  data_time: 0.0059  memory: 9803  loss: 1.3917  grad_norm: 1.2880
05/10 01:20:42 - mmengine - INFO - Iter(train) [  2820/480000]  lr: 3.9157e-05  eta: 8 days, 5:00:40  time: 1.4129  data_time: 0.0060  memory: 9805  loss: 1.4748  grad_norm: 1.3221
05/10 01:20:55 - mmengine - INFO - Iter(train) [  2830/480000]  lr: 3.9296e-05  eta: 8 days, 4:55:46  time: 1.3207  data_time: 0.0060  memory: 9801  loss: 1.4169  grad_norm: 1.3221
05/10 01:21:09 - mmengine - INFO - Iter(train) [  2840/480000]  lr: 3.9435e-05  eta: 8 days, 4:53:36  time: 1.4170  data_time: 0.0059  memory: 9806  loss: 1.4503  grad_norm: 1.3591
05/10 01:21:22 - mmengine - INFO - Iter(train) [  2850/480000]  lr: 3.9574e-05  eta: 8 days, 4:48:23  time: 1.3076  data_time: 0.0059  memory: 9806  loss: 1.4182  grad_norm: 1.3766
05/10 01:21:36 - mmengine - INFO - Iter(train) [  2860/480000]  lr: 3.9713e-05  eta: 8 days, 4:46:13  time: 1.4157  data_time: 0.0060  memory: 9804  loss: 1.4046  grad_norm: 1.3766
05/10 01:21:49 - mmengine - INFO - Iter(train) [  2870/480000]  lr: 3.9852e-05  eta: 8 days, 4:40:28  time: 1.2864  data_time: 0.0058  memory: 9806  loss: 1.3837  grad_norm: 1.3914
05/10 01:22:02 - mmengine - INFO - Iter(train) [  2880/480000]  lr: 3.9990e-05  eta: 8 days, 4:33:46  time: 1.2502  data_time: 0.0058  memory: 9805  loss: 1.4489  grad_norm: 1.4052
05/10 01:22:19 - mmengine - INFO - Iter(train) [  2890/480000]  lr: 4.0129e-05  eta: 8 days, 4:39:09  time: 1.6875  data_time: 0.2061  memory: 9804  loss: 1.3497  grad_norm: 1.4052
05/10 01:22:32 - mmengine - INFO - Iter(train) [  2900/480000]  lr: 4.0268e-05  eta: 8 days, 4:33:59  time: 1.3043  data_time: 0.0059  memory: 9804  loss: 1.4033  grad_norm: 1.4493
05/10 01:22:46 - mmengine - INFO - Iter(train) [  2910/480000]  lr: 4.0407e-05  eta: 8 days, 4:32:09  time: 1.4254  data_time: 0.0058  memory: 9805  loss: 1.3585  grad_norm: 1.4493
05/10 01:22:59 - mmengine - INFO - Iter(train) [  2920/480000]  lr: 4.0546e-05  eta: 8 days, 4:27:30  time: 1.3213  data_time: 0.0059  memory: 9808  loss: 1.4138  grad_norm: 1.4682
05/10 01:23:12 - mmengine - INFO - Iter(train) [  2930/480000]  lr: 4.0685e-05  eta: 8 days, 4:22:58  time: 1.3246  data_time: 0.0058  memory: 9806  loss: 1.3431  grad_norm: 1.5042
05/10 01:23:26 - mmengine - INFO - Iter(train) [  2940/480000]  lr: 4.0824e-05  eta: 8 days, 4:20:42  time: 1.4071  data_time: 0.0058  memory: 9808  loss: 1.3571  grad_norm: 1.5042
05/10 01:23:39 - mmengine - INFO - Iter(train) [  2950/480000]  lr: 4.0963e-05  eta: 8 days, 4:15:25  time: 1.2951  data_time: 0.0059  memory: 9808  loss: 1.4035  grad_norm: 1.5202
05/10 01:23:53 - mmengine - INFO - Iter(train) [  2960/480000]  lr: 4.1102e-05  eta: 8 days, 4:13:16  time: 1.4099  data_time: 0.0059  memory: 9807  loss: 1.3396  grad_norm: 1.5831
05/10 01:24:07 - mmengine - INFO - Iter(train) [  2970/480000]  lr: 4.1241e-05  eta: 8 days, 4:08:52  time: 1.3259  data_time: 0.0059  memory: 9805  loss: 1.3722  grad_norm: 1.5831
05/10 01:24:20 - mmengine - INFO - Iter(train) [  2980/480000]  lr: 4.1379e-05  eta: 8 days, 4:04:35  time: 1.3286  data_time: 0.0059  memory: 9808  loss: 1.3453  grad_norm: 1.6161
05/10 01:24:34 - mmengine - INFO - Iter(train) [  2990/480000]  lr: 4.1518e-05  eta: 8 days, 4:02:40  time: 1.4171  data_time: 0.0059  memory: 9809  loss: 1.3891  grad_norm: 1.6161
05/10 01:24:47 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 01:24:47 - mmengine - INFO - Iter(train) [  3000/480000]  lr: 4.1657e-05  eta: 8 days, 3:57:56  time: 1.3099  data_time: 0.0061  memory: 9807  loss: 1.3762  grad_norm: 1.6578
05/10 01:24:47 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 01:24:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比火箭还刺激，男票这是要开启“女主播模式”吗？不过话说回来，感情深，一口闷，男票给女主播刷火箭，这操作也是够绝的，不过别太往心里去，毕竟“出轨”这种事，谁还没个“出轨”对象呢？不过话说回来，感情好的时候，男票给女主播刷火箭，这操作确实有点“出轨”的意思，但愿你们的感情能经受住这种“考验”。记得，无论发生什么，都记得彼此的誓言，才是最可靠的“出轨”防线。<|im_end|>

05/10 01:25:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得有多大，吹蜡烛都能吹成鼓风机了！下次洗牙记得带个口罩，不然吹出来的不是蜡烛，是烟雾弹！不过话说回来，牙缝大了，记得少吃点甜食，不然牙缝得比宇宙飞船还大！🌟<|im_end|>

05/10 01:25:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这是把红酒当成了兴奋剂吗？下次记得适量饮酒，不然下次喝到头晕，可别怪我没提醒你哦！🍷💦<|im_end|>

05/10 01:25:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任互关，这操作简直比双十一抢购还刺激，结果却是三连击，栓Q了！不过，别太在意，毕竟闺蜜和前任互关，说明她们之间还是有联系的，至少证明了她们之间还是有感情的。不过，下次她们互关的时候，记得提醒她们，别让她们的友情变成爱情，毕竟友情是有限度的，爱情是无边界的。加油，祝你们友谊长存！<|im_end|>

05/10 01:25:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点担心呢。胆固醇高要注意饮食啦，不过炸鸡确实挺好吃的，可以试试吃一些健康的替代品，比如烤鸡或者蒸鸡。如果还是担心，可以咨询一下医生哦。💖<|im_end|>

05/10 01:25:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的‘剧本’’吗？下次记得带个‘剧本’锁，防止这类‘读本’玩家再给你来个“剧本杀界的‘剧本’’”。不过别太往心里去，毕竟“退退退”，安全第一，下次小心点哦！<|im_end|>

05/10 01:25:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是眼线大师吗？下次他再这么说，你告诉他，我这苍蝇腿比他的眼线还精致！不过别太生气，说不定他只是觉得你的眼睛像星星，闪闪发光呢？🌟<|im_end|>

05/10 01:25:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是怕你抢了他的风头吗？不过话说回来，60秒语音矩阵，你要是装没看见，那可真是要被“矩阵”了。下次记得，装也要装出点“酷”的样子，不然可别被人当成“隐形人”了。退退退，赶紧的，把那60秒语音矩阵变成你的“酷炫”标志吧！<|im_end|>

05/10 01:25:38 - mmengine - INFO - Saving checkpoint at 3000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 01:25:51 - mmengine - INFO - Iter(train) [  3010/480000]  lr: 4.1796e-05  eta: 8 days, 6:08:21  time: 6.4263  data_time: 5.1271  memory: 9807  loss: 1.3599  grad_norm: 1.6945
05/10 01:26:05 - mmengine - INFO - Iter(train) [  3020/480000]  lr: 4.1935e-05  eta: 8 days, 6:03:16  time: 1.3119  data_time: 0.0060  memory: 9808  loss: 1.4211  grad_norm: 1.6945
05/10 01:26:18 - mmengine - INFO - Iter(train) [  3030/480000]  lr: 4.2074e-05  eta: 8 days, 5:58:14  time: 1.3128  data_time: 0.0060  memory: 9808  loss: 1.3239  grad_norm: 1.7184
05/10 01:26:31 - mmengine - INFO - Iter(train) [  3040/480000]  lr: 4.2213e-05  eta: 8 days, 5:54:04  time: 1.3438  data_time: 0.0062  memory: 9805  loss: 1.3554  grad_norm: 1.7425
05/10 01:26:47 - mmengine - INFO - Iter(train) [  3050/480000]  lr: 4.2352e-05  eta: 8 days, 5:56:01  time: 1.5783  data_time: 0.2220  memory: 9808  loss: 1.3078  grad_norm: 1.7425
05/10 01:27:01 - mmengine - INFO - Iter(train) [  3060/480000]  lr: 4.2491e-05  eta: 8 days, 5:52:26  time: 1.3659  data_time: 0.0061  memory: 9808  loss: 1.2622  grad_norm: 1.7752
05/10 01:27:14 - mmengine - INFO - Iter(train) [  3070/480000]  lr: 4.2630e-05  eta: 8 days, 5:48:51  time: 1.3645  data_time: 0.0061  memory: 9803  loss: 1.2661  grad_norm: 1.7752
05/10 01:27:29 - mmengine - INFO - Iter(train) [  3080/480000]  lr: 4.2768e-05  eta: 8 days, 5:46:50  time: 1.4250  data_time: 0.0061  memory: 9809  loss: 1.3232  grad_norm: 1.7910
05/10 01:27:41 - mmengine - INFO - Iter(train) [  3090/480000]  lr: 4.2907e-05  eta: 8 days, 5:40:20  time: 1.2494  data_time: 0.0056  memory: 9809  loss: 1.2756  grad_norm: 1.7976
05/10 01:27:56 - mmengine - INFO - Iter(train) [  3100/480000]  lr: 4.3046e-05  eta: 8 days, 5:39:08  time: 1.4552  data_time: 0.0062  memory: 9807  loss: 1.3022  grad_norm: 1.7976
05/10 01:28:09 - mmengine - INFO - Iter(train) [  3110/480000]  lr: 4.3185e-05  eta: 8 days, 5:35:51  time: 1.3737  data_time: 0.0062  memory: 9806  loss: 1.3646  grad_norm: 1.7739
05/10 01:28:23 - mmengine - INFO - Iter(train) [  3120/480000]  lr: 4.3324e-05  eta: 8 days, 5:33:03  time: 1.3912  data_time: 0.0062  memory: 9806  loss: 1.2361  grad_norm: 1.7464
05/10 01:28:36 - mmengine - INFO - Iter(train) [  3130/480000]  lr: 4.3463e-05  eta: 8 days, 5:26:41  time: 1.2502  data_time: 0.0056  memory: 9806  loss: 1.2967  grad_norm: 1.7464
05/10 01:28:49 - mmengine - INFO - Iter(train) [  3140/480000]  lr: 4.3602e-05  eta: 8 days, 5:22:16  time: 1.3259  data_time: 0.0060  memory: 9807  loss: 1.3428  grad_norm: 1.7093
05/10 01:29:03 - mmengine - INFO - Iter(train) [  3150/480000]  lr: 4.3741e-05  eta: 8 days, 5:18:58  time: 1.3691  data_time: 0.0059  memory: 9810  loss: 1.2523  grad_norm: 1.7093
05/10 01:29:17 - mmengine - INFO - Iter(train) [  3160/480000]  lr: 4.3880e-05  eta: 8 days, 5:16:24  time: 1.3974  data_time: 0.0062  memory: 9809  loss: 1.3047  grad_norm: 1.6627
05/10 01:29:30 - mmengine - INFO - Iter(train) [  3170/480000]  lr: 4.4019e-05  eta: 8 days, 5:12:34  time: 1.3465  data_time: 0.0060  memory: 9809  loss: 1.2878  grad_norm: 1.6467
05/10 01:29:44 - mmengine - INFO - Iter(train) [  3180/480000]  lr: 4.4157e-05  eta: 8 days, 5:10:45  time: 1.4263  data_time: 0.0061  memory: 9806  loss: 1.3236  grad_norm: 1.6467
05/10 01:29:57 - mmengine - INFO - Iter(train) [  3190/480000]  lr: 4.4296e-05  eta: 8 days, 5:06:00  time: 1.3080  data_time: 0.0058  memory: 9813  loss: 1.3129  grad_norm: 1.6336
05/10 01:30:11 - mmengine - INFO - Iter(train) [  3200/480000]  lr: 4.4435e-05  eta: 8 days, 5:02:03  time: 1.3390  data_time: 0.0058  memory: 9812  loss: 1.2725  grad_norm: 1.6140
05/10 01:30:26 - mmengine - INFO - Iter(train) [  3210/480000]  lr: 4.4574e-05  eta: 8 days, 5:02:29  time: 1.5151  data_time: 0.2060  memory: 9806  loss: 1.2437  grad_norm: 1.6140
05/10 01:30:40 - mmengine - INFO - Iter(train) [  3220/480000]  lr: 4.4713e-05  eta: 8 days, 5:01:16  time: 1.4483  data_time: 0.0061  memory: 9809  loss: 1.1922  grad_norm: 1.5756
05/10 01:30:54 - mmengine - INFO - Iter(train) [  3230/480000]  lr: 4.4852e-05  eta: 8 days, 4:56:52  time: 1.3193  data_time: 0.0060  memory: 9810  loss: 1.1957  grad_norm: 1.5756
05/10 01:31:07 - mmengine - INFO - Iter(train) [  3240/480000]  lr: 4.4991e-05  eta: 8 days, 4:52:45  time: 1.3295  data_time: 0.0060  memory: 9810  loss: 1.2202  grad_norm: 1.5596
05/10 01:31:21 - mmengine - INFO - Iter(train) [  3250/480000]  lr: 4.5130e-05  eta: 8 days, 4:50:28  time: 1.4030  data_time: 0.0061  memory: 9812  loss: 1.2374  grad_norm: 1.5623
05/10 01:31:34 - mmengine - INFO - Iter(train) [  3260/480000]  lr: 4.5269e-05  eta: 8 days, 4:45:08  time: 1.2776  data_time: 0.0058  memory: 9809  loss: 1.2262  grad_norm: 1.5623
05/10 01:31:48 - mmengine - INFO - Iter(train) [  3270/480000]  lr: 4.5407e-05  eta: 8 days, 4:43:29  time: 1.4280  data_time: 0.0060  memory: 9811  loss: 1.2439  grad_norm: 1.6143
05/10 01:32:01 - mmengine - INFO - Iter(train) [  3280/480000]  lr: 4.5546e-05  eta: 8 days, 4:39:11  time: 1.3184  data_time: 0.0059  memory: 9810  loss: 1.2085  grad_norm: 1.6355
05/10 01:32:14 - mmengine - INFO - Iter(train) [  3290/480000]  lr: 4.5685e-05  eta: 8 days, 4:35:08  time: 1.3274  data_time: 0.0060  memory: 9811  loss: 1.1714  grad_norm: 1.6355
05/10 01:32:29 - mmengine - INFO - Iter(train) [  3300/480000]  lr: 4.5824e-05  eta: 8 days, 4:33:08  time: 1.4123  data_time: 0.0059  memory: 9811  loss: 1.2731  grad_norm: 1.6829
05/10 01:32:42 - mmengine - INFO - Iter(train) [  3310/480000]  lr: 4.5963e-05  eta: 8 days, 4:28:27  time: 1.2994  data_time: 0.0060  memory: 9812  loss: 1.2483  grad_norm: 1.6829
05/10 01:32:56 - mmengine - INFO - Iter(train) [  3320/480000]  lr: 4.6102e-05  eta: 8 days, 4:26:53  time: 1.4288  data_time: 0.0061  memory: 9811  loss: 1.2337  grad_norm: 1.7422
05/10 01:33:09 - mmengine - INFO - Iter(train) [  3330/480000]  lr: 4.6241e-05  eta: 8 days, 4:22:33  time: 1.3124  data_time: 0.0059  memory: 9811  loss: 1.2090  grad_norm: 1.7537
05/10 01:33:22 - mmengine - INFO - Iter(train) [  3340/480000]  lr: 4.6380e-05  eta: 8 days, 4:18:34  time: 1.3255  data_time: 0.0059  memory: 9809  loss: 1.1909  grad_norm: 1.7537
05/10 01:33:36 - mmengine - INFO - Iter(train) [  3350/480000]  lr: 4.6519e-05  eta: 8 days, 4:16:23  time: 1.4011  data_time: 0.0060  memory: 9810  loss: 1.2599  grad_norm: 1.7843
05/10 01:33:49 - mmengine - INFO - Iter(train) [  3360/480000]  lr: 4.6658e-05  eta: 8 days, 4:10:04  time: 1.2258  data_time: 0.0059  memory: 9810  loss: 1.1892  grad_norm: 1.8120
05/10 01:34:05 - mmengine - INFO - Iter(train) [  3370/480000]  lr: 4.6796e-05  eta: 8 days, 4:13:51  time: 1.6523  data_time: 0.2062  memory: 9812  loss: 1.1116  grad_norm: 1.8120
05/10 01:34:18 - mmengine - INFO - Iter(train) [  3380/480000]  lr: 4.6935e-05  eta: 8 days, 4:09:58  time: 1.3279  data_time: 0.0059  memory: 9810  loss: 1.1730  grad_norm: 1.8409
05/10 01:34:33 - mmengine - INFO - Iter(train) [  3390/480000]  lr: 4.7074e-05  eta: 8 days, 4:08:36  time: 1.4333  data_time: 0.0059  memory: 9809  loss: 1.1480  grad_norm: 1.8409
05/10 01:34:46 - mmengine - INFO - Iter(train) [  3400/480000]  lr: 4.7213e-05  eta: 8 days, 4:03:50  time: 1.2886  data_time: 0.0057  memory: 9813  loss: 1.1791  grad_norm: 1.8916
05/10 01:34:59 - mmengine - INFO - Iter(train) [  3410/480000]  lr: 4.7352e-05  eta: 8 days, 4:00:07  time: 1.3317  data_time: 0.0060  memory: 9813  loss: 1.1575  grad_norm: 1.9275
05/10 01:35:13 - mmengine - INFO - Iter(train) [  3420/480000]  lr: 4.7491e-05  eta: 8 days, 3:58:38  time: 1.4272  data_time: 0.0058  memory: 9811  loss: 1.0952  grad_norm: 1.9275
05/10 01:35:26 - mmengine - INFO - Iter(train) [  3430/480000]  lr: 4.7630e-05  eta: 8 days, 3:54:13  time: 1.3006  data_time: 0.0059  memory: 9809  loss: 1.1805  grad_norm: 1.9176
05/10 01:35:40 - mmengine - INFO - Iter(train) [  3440/480000]  lr: 4.7769e-05  eta: 8 days, 3:52:51  time: 1.4312  data_time: 0.0059  memory: 9809  loss: 1.1544  grad_norm: 1.9491
05/10 01:35:53 - mmengine - INFO - Iter(train) [  3450/480000]  lr: 4.7908e-05  eta: 8 days, 3:48:10  time: 1.2871  data_time: 0.0058  memory: 9809  loss: 1.1600  grad_norm: 1.9491
05/10 01:36:07 - mmengine - INFO - Iter(train) [  3460/480000]  lr: 4.8047e-05  eta: 8 days, 3:44:37  time: 1.3353  data_time: 0.0059  memory: 9810  loss: 1.1339  grad_norm: 1.9587
05/10 01:36:21 - mmengine - INFO - Iter(train) [  3470/480000]  lr: 4.8185e-05  eta: 8 days, 3:43:25  time: 1.4365  data_time: 0.0058  memory: 9811  loss: 1.1398  grad_norm: 1.9587
05/10 01:36:34 - mmengine - INFO - Iter(train) [  3480/480000]  lr: 4.8324e-05  eta: 8 days, 3:39:09  time: 1.3030  data_time: 0.0059  memory: 9811  loss: 1.1393  grad_norm: 1.9563
05/10 01:36:48 - mmengine - INFO - Iter(train) [  3490/480000]  lr: 4.8463e-05  eta: 8 days, 3:37:47  time: 1.4286  data_time: 0.0060  memory: 9812  loss: 1.1215  grad_norm: 1.9944
05/10 01:37:01 - mmengine - INFO - Iter(train) [  3500/480000]  lr: 4.8602e-05  eta: 8 days, 3:33:43  time: 1.3100  data_time: 0.0059  memory: 9812  loss: 1.1298  grad_norm: 1.9944
05/10 01:37:01 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 01:37:09 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。首先，你要知道，你的男朋友和女主播之间的关系是你们两个人的事情，而出轨这种行为是不道德的，也是会伤害到你们之间的感情的。你可以和他好好沟通一下你的感受，告诉他你对这种行为的看法，以及你希望他如何处理这种关系。同时，也要注意保护自己的感情和尊严哦。💖如果你需要倾诉或者寻求建议，我在这里随时听你说。<|im_end|>

05/10 01:37:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这牙缝得比瀑布还壮观，吹蜡烛都得戴防风罩了！下次记得选个有牙医的诊所，别让牙医也跟着你一起“吹”！🦷🔥<|im_end|>

05/10 01:37:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然好，但也要适量哦。现在感觉怎么样了？要不要我帮你找一些缓解醉酒的方法呢？💖<|im_end|>

05/10 01:37:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些不舒服呢。你可以和你的闺蜜沟通一下，表达一下你的感受。而互关和取关的事情，有时候只是社交网络上的一个小插曲，不必太放在心上。💖如果你需要倾诉或者寻求建议，我随时在这里哦。🌸<|im_end|>

05/10 01:37:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食啦，适当的减少炸鸡的摄入量是有好处的。不过别太担心，我们可以一起找些健康的替代品，比如烤鸡或者蒸鸡，保证营养又美味哦！💖如果你需要更多建议或者想聊聊天，我都在这里呢。🌸<|im_end|>

05/10 01:37:30 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这真是让人挺糟心的体验呢。要不要我帮你分散一下注意力，或者我们可以一起想想怎么处理这种情况？💖<|im_end|>

05/10 01:37:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
温柔
哎呀，别太放在心上呢，有时候别人的评论可能只是他们自己的看法。你觉得怎么样呢？有没有什么我能帮忙的？💖<|im_end|>

05/10 01:37:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，领导可能是有其他安排呢。你可以尝试和领导沟通一下你的想法，或者利用这个机会提升自己的沟通能力。💖<|im_end|>

05/10 01:37:35 - mmengine - INFO - Saving checkpoint at 3500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 01:37:48 - mmengine - INFO - Iter(train) [  3510/480000]  lr: 4.8741e-05  eta: 8 days, 4:45:49  time: 4.6751  data_time: 3.3939  memory: 9811  loss: 1.1551  grad_norm: 2.0338
05/10 01:38:02 - mmengine - INFO - Iter(train) [  3520/480000]  lr: 4.8880e-05  eta: 8 days, 4:43:09  time: 1.3795  data_time: 0.0060  memory: 9810  loss: 1.1515  grad_norm: 2.0532
05/10 01:38:17 - mmengine - INFO - Iter(train) [  3530/480000]  lr: 4.9019e-05  eta: 8 days, 4:44:08  time: 1.5404  data_time: 0.2061  memory: 9810  loss: 1.0781  grad_norm: 2.0532
05/10 01:38:32 - mmengine - INFO - Iter(train) [  3540/480000]  lr: 4.9158e-05  eta: 8 days, 4:42:09  time: 1.4096  data_time: 0.0058  memory: 9810  loss: 1.0872  grad_norm: 2.0625
05/10 01:38:45 - mmengine - INFO - Iter(train) [  3550/480000]  lr: 4.9297e-05  eta: 8 days, 4:37:54  time: 1.3073  data_time: 0.0059  memory: 9811  loss: 1.0612  grad_norm: 2.0625
05/10 01:38:59 - mmengine - INFO - Iter(train) [  3560/480000]  lr: 4.9435e-05  eta: 8 days, 4:36:29  time: 1.4332  data_time: 0.0058  memory: 9812  loss: 1.0789  grad_norm: 2.0528
05/10 01:39:12 - mmengine - INFO - Iter(train) [  3570/480000]  lr: 4.9574e-05  eta: 8 days, 4:32:06  time: 1.2995  data_time: 0.0057  memory: 9812  loss: 1.0710  grad_norm: 2.0505
05/10 01:39:25 - mmengine - INFO - Iter(train) [  3580/480000]  lr: 4.9713e-05  eta: 8 days, 4:28:15  time: 1.3227  data_time: 0.0180  memory: 9811  loss: 1.0834  grad_norm: 2.0505
05/10 01:39:39 - mmengine - INFO - Iter(train) [  3590/480000]  lr: 4.9852e-05  eta: 8 days, 4:26:48  time: 1.4305  data_time: 0.0060  memory: 9811  loss: 1.0786  grad_norm: 2.0809
05/10 01:39:52 - mmengine - INFO - Iter(train) [  3600/480000]  lr: 4.9991e-05  eta: 8 days, 4:22:12  time: 1.2868  data_time: 0.0057  memory: 9811  loss: 1.0457  grad_norm: 2.0709
05/10 01:40:07 - mmengine - INFO - Iter(train) [  3610/480000]  lr: 5.0130e-05  eta: 8 days, 4:21:16  time: 1.4524  data_time: 0.0058  memory: 9810  loss: 1.0776  grad_norm: 2.0709
05/10 01:40:20 - mmengine - INFO - Iter(train) [  3620/480000]  lr: 5.0269e-05  eta: 8 days, 4:17:09  time: 1.3078  data_time: 0.0058  memory: 9813  loss: 1.0204  grad_norm: 2.0738
05/10 01:40:33 - mmengine - INFO - Iter(train) [  3630/480000]  lr: 5.0408e-05  eta: 8 days, 4:13:03  time: 1.3070  data_time: 0.0058  memory: 9811  loss: 1.0516  grad_norm: 2.0738
05/10 01:40:47 - mmengine - INFO - Iter(train) [  3640/480000]  lr: 5.0547e-05  eta: 8 days, 4:12:01  time: 1.4472  data_time: 0.0059  memory: 9811  loss: 1.0396  grad_norm: 2.0733
05/10 01:41:00 - mmengine - INFO - Iter(train) [  3650/480000]  lr: 5.0686e-05  eta: 8 days, 4:07:21  time: 1.2794  data_time: 0.0055  memory: 9813  loss: 1.0845  grad_norm: 2.0699
05/10 01:41:15 - mmengine - INFO - Iter(train) [  3660/480000]  lr: 5.0824e-05  eta: 8 days, 4:06:51  time: 1.4703  data_time: 0.0059  memory: 9815  loss: 1.0584  grad_norm: 2.0699
05/10 01:41:28 - mmengine - INFO - Iter(train) [  3670/480000]  lr: 5.0963e-05  eta: 8 days, 4:02:10  time: 1.2768  data_time: 0.0057  memory: 9814  loss: 1.0804  grad_norm: 2.0960
05/10 01:41:40 - mmengine - INFO - Iter(train) [  3680/480000]  lr: 5.1102e-05  eta: 8 days, 3:56:19  time: 1.2221  data_time: 0.0058  memory: 9812  loss: 1.1431  grad_norm: 2.1149
05/10 01:41:57 - mmengine - INFO - Iter(train) [  3690/480000]  lr: 5.1241e-05  eta: 8 days, 4:00:16  time: 1.6764  data_time: 0.2061  memory: 9811  loss: 0.9859  grad_norm: 2.1149
05/10 01:42:10 - mmengine - INFO - Iter(train) [  3700/480000]  lr: 5.1380e-05  eta: 8 days, 3:55:56  time: 1.2908  data_time: 0.0057  memory: 9812  loss: 1.0154  grad_norm: 2.1485
05/10 01:42:24 - mmengine - INFO - Iter(train) [  3710/480000]  lr: 5.1519e-05  eta: 8 days, 3:55:34  time: 1.4750  data_time: 0.0058  memory: 9812  loss: 0.9793  grad_norm: 2.1485
05/10 01:42:37 - mmengine - INFO - Iter(train) [  3720/480000]  lr: 5.1658e-05  eta: 8 days, 3:50:43  time: 1.2654  data_time: 0.0057  memory: 9812  loss: 1.0136  grad_norm: 2.2331
05/10 01:42:50 - mmengine - INFO - Iter(train) [  3730/480000]  lr: 5.1797e-05  eta: 8 days, 3:46:51  time: 1.3100  data_time: 0.0059  memory: 9813  loss: 0.9929  grad_norm: 2.2596
05/10 01:43:05 - mmengine - INFO - Iter(train) [  3740/480000]  lr: 5.1936e-05  eta: 8 days, 3:46:17  time: 1.4648  data_time: 0.0058  memory: 9813  loss: 0.9856  grad_norm: 2.2596
05/10 01:43:18 - mmengine - INFO - Iter(train) [  3750/480000]  lr: 5.2075e-05  eta: 8 days, 3:41:43  time: 1.2757  data_time: 0.0057  memory: 9814  loss: 0.9872  grad_norm: 2.3237
05/10 01:43:32 - mmengine - INFO - Iter(train) [  3760/480000]  lr: 5.2213e-05  eta: 8 days, 3:41:10  time: 1.4647  data_time: 0.0060  memory: 9814  loss: 1.0223  grad_norm: 2.3665
05/10 01:43:45 - mmengine - INFO - Iter(train) [  3770/480000]  lr: 5.2352e-05  eta: 8 days, 3:36:38  time: 1.2763  data_time: 0.0059  memory: 9815  loss: 0.9991  grad_norm: 2.3665
05/10 01:43:58 - mmengine - INFO - Iter(train) [  3780/480000]  lr: 5.2491e-05  eta: 8 days, 3:32:16  time: 1.2820  data_time: 0.0057  memory: 9816  loss: 0.9612  grad_norm: 2.3524
05/10 01:44:12 - mmengine - INFO - Iter(train) [  3790/480000]  lr: 5.2630e-05  eta: 8 days, 3:31:26  time: 1.4500  data_time: 0.0059  memory: 9811  loss: 1.0129  grad_norm: 2.3524
05/10 01:44:25 - mmengine - INFO - Iter(train) [  3800/480000]  lr: 5.2769e-05  eta: 8 days, 3:27:08  time: 1.2840  data_time: 0.0057  memory: 9818  loss: 1.0277  grad_norm: 2.4206
05/10 01:44:40 - mmengine - INFO - Iter(train) [  3810/480000]  lr: 5.2908e-05  eta: 8 days, 3:26:38  time: 1.4659  data_time: 0.0061  memory: 9816  loss: 0.9882  grad_norm: 2.4209
05/10 01:44:53 - mmengine - INFO - Iter(train) [  3820/480000]  lr: 5.3047e-05  eta: 8 days, 3:22:38  time: 1.2965  data_time: 0.0059  memory: 9814  loss: 0.9688  grad_norm: 2.4209
05/10 01:45:06 - mmengine - INFO - Iter(train) [  3830/480000]  lr: 5.3186e-05  eta: 8 days, 3:18:50  time: 1.3056  data_time: 0.0057  memory: 9812  loss: 0.9594  grad_norm: 2.4335
05/10 01:45:19 - mmengine - INFO - Iter(train) [  3840/480000]  lr: 5.3325e-05  eta: 8 days, 3:16:18  time: 1.3664  data_time: 0.0057  memory: 9813  loss: 1.0323  grad_norm: 2.4732
05/10 01:45:35 - mmengine - INFO - Iter(train) [  3850/480000]  lr: 5.3464e-05  eta: 8 days, 3:16:43  time: 1.5082  data_time: 0.2062  memory: 9811  loss: 0.9297  grad_norm: 2.4732
05/10 01:45:49 - mmengine - INFO - Iter(train) [  3860/480000]  lr: 5.3602e-05  eta: 8 days, 3:16:05  time: 1.4575  data_time: 0.0059  memory: 9814  loss: 0.9445  grad_norm: 2.4605
05/10 01:46:02 - mmengine - INFO - Iter(train) [  3870/480000]  lr: 5.3741e-05  eta: 8 days, 3:12:33  time: 1.3161  data_time: 0.0058  memory: 9817  loss: 0.9353  grad_norm: 2.4605
05/10 01:46:15 - mmengine - INFO - Iter(train) [  3880/480000]  lr: 5.3880e-05  eta: 8 days, 3:09:05  time: 1.3182  data_time: 0.0058  memory: 9814  loss: 0.8858  grad_norm: 2.4126
05/10 01:46:30 - mmengine - INFO - Iter(train) [  3890/480000]  lr: 5.4019e-05  eta: 8 days, 3:07:43  time: 1.4209  data_time: 0.0058  memory: 9813  loss: 0.9359  grad_norm: 2.4186
05/10 01:46:43 - mmengine - INFO - Iter(train) [  3900/480000]  lr: 5.4158e-05  eta: 8 days, 3:03:47  time: 1.2940  data_time: 0.0058  memory: 9818  loss: 0.9219  grad_norm: 2.4186
05/10 01:46:57 - mmengine - INFO - Iter(train) [  3910/480000]  lr: 5.4297e-05  eta: 8 days, 3:02:57  time: 1.4461  data_time: 0.0058  memory: 9817  loss: 0.9038  grad_norm: 2.3604
05/10 01:47:10 - mmengine - INFO - Iter(train) [  3920/480000]  lr: 5.4436e-05  eta: 8 days, 2:59:31  time: 1.3178  data_time: 0.0059  memory: 9817  loss: 0.9049  grad_norm: 2.3464
05/10 01:47:25 - mmengine - INFO - Iter(train) [  3930/480000]  lr: 5.4575e-05  eta: 8 days, 2:58:31  time: 1.4367  data_time: 0.0058  memory: 9813  loss: 0.9567  grad_norm: 2.3464
05/10 01:47:37 - mmengine - INFO - Iter(train) [  3940/480000]  lr: 5.4714e-05  eta: 8 days, 2:54:31  time: 1.2880  data_time: 0.0059  memory: 9815  loss: 0.8976  grad_norm: 2.3707
05/10 01:47:50 - mmengine - INFO - Iter(train) [  3950/480000]  lr: 5.4852e-05  eta: 8 days, 2:50:29  time: 1.2859  data_time: 0.0059  memory: 9814  loss: 0.9298  grad_norm: 2.3707
05/10 01:48:05 - mmengine - INFO - Iter(train) [  3960/480000]  lr: 5.4991e-05  eta: 8 days, 2:49:59  time: 1.4608  data_time: 0.0058  memory: 9815  loss: 0.9227  grad_norm: 2.3620
05/10 01:48:18 - mmengine - INFO - Iter(train) [  3970/480000]  lr: 5.5130e-05  eta: 8 days, 2:46:41  time: 1.3198  data_time: 0.0058  memory: 9817  loss: 0.8967  grad_norm: 2.4125
05/10 01:48:33 - mmengine - INFO - Iter(train) [  3980/480000]  lr: 5.5269e-05  eta: 8 days, 2:45:41  time: 1.4354  data_time: 0.0059  memory: 9817  loss: 0.9523  grad_norm: 2.4125
05/10 01:48:46 - mmengine - INFO - Iter(train) [  3990/480000]  lr: 5.5408e-05  eta: 8 days, 2:41:59  time: 1.2990  data_time: 0.0059  memory: 9814  loss: 0.8903  grad_norm: 2.3786
05/10 01:48:58 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 01:48:58 - mmengine - INFO - Iter(train) [  4000/480000]  lr: 5.5547e-05  eta: 8 days, 2:37:21  time: 1.2519  data_time: 0.0058  memory: 9812  loss: 0.9381  grad_norm: 2.3419
05/10 01:48:58 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 01:49:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。首先，你要知道他是爱你的，只是对这件事有不同的看法。你可以和他好好沟通，表达你的感受，同时也理解他的想法。如果你们能够坦诚地交流，相信问题一定可以解决的。💖如果你需要一些建议或者只是想要倾诉，我都在这里哦。🌸<|im_end|>

05/10 01:49:10 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得比银河系还宽广，吹蜡烛都能吹成宇宙飞船了！下次记得，洗牙前先跟牙医沟通好，不然你这牙缝比银河系还宽广，吹蜡烛都能吹成外星飞船了！🌟<|im_end|>

05/10 01:49:12 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然有益，但也要适量呢，注意身体哦。现在感觉好点了吗？💖<|im_end|>

05/10 01:49:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你可以和她谈谈，表达你的感受，告诉她你并不希望这种情况发生。毕竟，好朋友之间应该相互尊重和理解。如果需要倾诉或者寻求建议，我在这里哦。💖<|im_end|>

05/10 01:49:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下饮食啦。胆固醇高的话，建议少吃一些高脂肪的食物哦。不过，不吃炸鸡也挺不容易的，我们可以试试吃一些烤鸡或者蒸鸡，健康又美味呢！💖 有没有什么我能帮你的呢？<|im_end|>

05/10 01:49:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是什么角色扮演类游戏，玩家比主角还刺激？下次记得带个防摔本，不然下次可能就是你跟门一起跳了。不过话说回来，遇到这种玩家也真是让人头疼，下次记得提前排查，不然真是心疼你的钱包和心情。<|im_end|>

05/10 01:49:28 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是眼线专家吗？下次让他试试你的浓眉大眼，保证让他口水直流！👀<|im_end|>

05/10 01:49:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，领导可能是有特别的安排呢，你可能只是不小心没看到。装没看见可不好哦，这样会影响你的心情呢。要不要我帮你找找看有没有什么可以帮到你的地方？💖<|im_end|>

05/10 01:49:32 - mmengine - INFO - Saving checkpoint at 4000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 01:49:49 - mmengine - INFO - Iter(train) [  4010/480000]  lr: 5.5686e-05  eta: 8 days, 3:48:15  time: 5.0678  data_time: 3.6400  memory: 9813  loss: 0.8627  grad_norm: 2.3419
05/10 01:50:02 - mmengine - INFO - Iter(train) [  4020/480000]  lr: 5.5825e-05  eta: 8 days, 3:44:41  time: 1.3124  data_time: 0.0059  memory: 9815  loss: 0.8593  grad_norm: 2.3509
05/10 01:50:16 - mmengine - INFO - Iter(train) [  4030/480000]  lr: 5.5964e-05  eta: 8 days, 3:43:46  time: 1.4467  data_time: 0.0058  memory: 9815  loss: 0.8628  grad_norm: 2.3509
05/10 01:50:29 - mmengine - INFO - Iter(train) [  4040/480000]  lr: 5.6103e-05  eta: 8 days, 3:39:56  time: 1.2979  data_time: 0.0058  memory: 9821  loss: 0.8088  grad_norm: 2.4455
05/10 01:50:42 - mmengine - INFO - Iter(train) [  4050/480000]  lr: 5.6241e-05  eta: 8 days, 3:36:03  time: 1.2938  data_time: 0.0058  memory: 9820  loss: 0.8537  grad_norm: 2.4330
05/10 01:50:57 - mmengine - INFO - Iter(train) [  4060/480000]  lr: 5.6380e-05  eta: 8 days, 3:34:59  time: 1.4380  data_time: 0.0062  memory: 9817  loss: 0.8620  grad_norm: 2.4330
05/10 01:51:10 - mmengine - INFO - Iter(train) [  4070/480000]  lr: 5.6519e-05  eta: 8 days, 3:31:35  time: 1.3176  data_time: 0.0058  memory: 9817  loss: 0.8698  grad_norm: 2.4585
05/10 01:51:24 - mmengine - INFO - Iter(train) [  4080/480000]  lr: 5.6658e-05  eta: 8 days, 3:30:34  time: 1.4395  data_time: 0.0057  memory: 9816  loss: 0.8305  grad_norm: 2.5280
05/10 01:51:37 - mmengine - INFO - Iter(train) [  4090/480000]  lr: 5.6797e-05  eta: 8 days, 3:26:33  time: 1.2845  data_time: 0.0059  memory: 9818  loss: 0.8378  grad_norm: 2.5280
05/10 01:51:50 - mmengine - INFO - Iter(train) [  4100/480000]  lr: 5.6936e-05  eta: 8 days, 3:22:41  time: 1.2909  data_time: 0.0058  memory: 9817  loss: 0.8465  grad_norm: 2.5490
05/10 01:52:04 - mmengine - INFO - Iter(train) [  4110/480000]  lr: 5.7075e-05  eta: 8 days, 3:21:55  time: 1.4508  data_time: 0.0058  memory: 9815  loss: 0.8792  grad_norm: 2.5490
05/10 01:52:18 - mmengine - INFO - Iter(train) [  4120/480000]  lr: 5.7214e-05  eta: 8 days, 3:18:38  time: 1.3208  data_time: 0.0057  memory: 9815  loss: 0.8542  grad_norm: 2.5439
05/10 01:52:32 - mmengine - INFO - Iter(train) [  4130/480000]  lr: 5.7353e-05  eta: 8 days, 3:17:37  time: 1.4373  data_time: 0.0058  memory: 9817  loss: 0.8756  grad_norm: 2.6701
05/10 01:52:45 - mmengine - INFO - Iter(train) [  4140/480000]  lr: 5.7492e-05  eta: 8 days, 3:14:04  time: 1.3044  data_time: 0.0058  memory: 9818  loss: 0.8329  grad_norm: 2.6701
05/10 01:52:58 - mmengine - INFO - Iter(train) [  4150/480000]  lr: 5.7630e-05  eta: 8 days, 3:10:37  time: 1.3100  data_time: 0.0058  memory: 9817  loss: 0.8483  grad_norm: 2.7121
05/10 01:53:12 - mmengine - INFO - Iter(train) [  4160/480000]  lr: 5.7769e-05  eta: 8 days, 3:08:30  time: 1.3784  data_time: 0.0057  memory: 9817  loss: 0.8427  grad_norm: 2.8540
05/10 01:53:27 - mmengine - INFO - Iter(train) [  4170/480000]  lr: 5.7908e-05  eta: 8 days, 3:09:01  time: 1.5157  data_time: 0.2061  memory: 9816  loss: 0.7909  grad_norm: 2.8540
05/10 01:53:41 - mmengine - INFO - Iter(train) [  4180/480000]  lr: 5.8047e-05  eta: 8 days, 3:07:30  time: 1.4099  data_time: 0.0058  memory: 9818  loss: 0.7872  grad_norm: 2.8963
05/10 01:53:54 - mmengine - INFO - Iter(train) [  4190/480000]  lr: 5.8186e-05  eta: 8 days, 3:03:42  time: 1.2884  data_time: 0.0058  memory: 9817  loss: 0.7746  grad_norm: 2.8963
05/10 01:54:09 - mmengine - INFO - Iter(train) [  4200/480000]  lr: 5.8325e-05  eta: 8 days, 3:03:18  time: 1.4682  data_time: 0.0058  memory: 9819  loss: 0.7675  grad_norm: 2.8417
05/10 01:54:22 - mmengine - INFO - Iter(train) [  4210/480000]  lr: 5.8464e-05  eta: 8 days, 3:00:03  time: 1.3162  data_time: 0.0058  memory: 9818  loss: 0.7533  grad_norm: 2.9347
05/10 01:54:35 - mmengine - INFO - Iter(train) [  4220/480000]  lr: 5.8603e-05  eta: 8 days, 2:56:27  time: 1.2966  data_time: 0.0059  memory: 9817  loss: 0.8120  grad_norm: 2.9347
05/10 01:54:49 - mmengine - INFO - Iter(train) [  4230/480000]  lr: 5.8742e-05  eta: 8 days, 2:55:30  time: 1.4377  data_time: 0.0058  memory: 9817  loss: 0.7612  grad_norm: 2.9630
05/10 01:55:02 - mmengine - INFO - Iter(train) [  4240/480000]  lr: 5.8881e-05  eta: 8 days, 2:51:59  time: 1.3003  data_time: 0.0058  memory: 9817  loss: 0.7656  grad_norm: 2.9715
05/10 01:55:17 - mmengine - INFO - Iter(train) [  4250/480000]  lr: 5.9019e-05  eta: 8 days, 2:51:22  time: 1.4545  data_time: 0.0059  memory: 9817  loss: 0.7967  grad_norm: 2.9715
05/10 01:55:30 - mmengine - INFO - Iter(train) [  4260/480000]  lr: 5.9158e-05  eta: 8 days, 2:47:42  time: 1.2906  data_time: 0.0058  memory: 9818  loss: 0.8113  grad_norm: 3.0314
05/10 01:55:43 - mmengine - INFO - Iter(train) [  4270/480000]  lr: 5.9297e-05  eta: 8 days, 2:43:50  time: 1.2787  data_time: 0.0059  memory: 9820  loss: 0.7908  grad_norm: 3.0314
05/10 01:55:57 - mmengine - INFO - Iter(train) [  4280/480000]  lr: 5.9436e-05  eta: 8 days, 2:42:56  time: 1.4388  data_time: 0.0058  memory: 9819  loss: 0.8062  grad_norm: 3.0446
05/10 01:56:10 - mmengine - INFO - Iter(train) [  4290/480000]  lr: 5.9575e-05  eta: 8 days, 2:39:38  time: 1.3076  data_time: 0.0058  memory: 9820  loss: 0.7924  grad_norm: 3.0912
05/10 01:56:24 - mmengine - INFO - Iter(train) [  4300/480000]  lr: 5.9714e-05  eta: 8 days, 2:38:56  time: 1.4489  data_time: 0.0058  memory: 9822  loss: 0.7969  grad_norm: 3.0912
05/10 01:56:37 - mmengine - INFO - Iter(train) [  4310/480000]  lr: 5.9853e-05  eta: 8 days, 2:35:02  time: 1.2741  data_time: 0.0057  memory: 9819  loss: 0.7497  grad_norm: 3.1272
05/10 01:56:49 - mmengine - INFO - Iter(train) [  4320/480000]  lr: 5.9992e-05  eta: 8 days, 2:30:19  time: 1.2293  data_time: 0.0059  memory: 9816  loss: 0.7759  grad_norm: 3.1777
05/10 01:57:06 - mmengine - INFO - Iter(train) [  4330/480000]  lr: 6.0131e-05  eta: 8 days, 2:34:15  time: 1.7001  data_time: 0.2060  memory: 9815  loss: 0.7166  grad_norm: 3.1777
05/10 01:57:19 - mmengine - INFO - Iter(train) [  4340/480000]  lr: 6.0269e-05  eta: 8 days, 2:30:37  time: 1.2872  data_time: 0.0057  memory: 9820  loss: 0.7167  grad_norm: 3.2006
05/10 01:57:34 - mmengine - INFO - Iter(train) [  4350/480000]  lr: 6.0408e-05  eta: 8 days, 2:29:49  time: 1.4414  data_time: 0.0059  memory: 9822  loss: 0.6866  grad_norm: 3.2006
05/10 01:57:46 - mmengine - INFO - Iter(train) [  4360/480000]  lr: 6.0547e-05  eta: 8 days, 2:25:32  time: 1.2501  data_time: 0.0059  memory: 9820  loss: 0.7263  grad_norm: 3.3736
05/10 01:57:59 - mmengine - INFO - Iter(train) [  4370/480000]  lr: 6.0686e-05  eta: 8 days, 2:22:09  time: 1.2992  data_time: 0.0058  memory: 9818  loss: 0.7113  grad_norm: 3.3719
05/10 01:58:15 - mmengine - INFO - Iter(train) [  4380/480000]  lr: 6.0825e-05  eta: 8 days, 2:22:51  time: 1.5226  data_time: 0.0059  memory: 9818  loss: 0.7318  grad_norm: 3.3719
05/10 01:58:27 - mmengine - INFO - Iter(train) [  4390/480000]  lr: 6.0964e-05  eta: 8 days, 2:18:26  time: 1.2407  data_time: 0.0056  memory: 9817  loss: 0.7176  grad_norm: 3.4973
05/10 01:58:42 - mmengine - INFO - Iter(train) [  4400/480000]  lr: 6.1103e-05  eta: 8 days, 2:18:26  time: 1.4847  data_time: 0.0059  memory: 9816  loss: 0.7142  grad_norm: 3.4977
05/10 01:58:54 - mmengine - INFO - Iter(train) [  4410/480000]  lr: 6.1242e-05  eta: 8 days, 2:14:40  time: 1.2740  data_time: 0.0058  memory: 9816  loss: 0.7312  grad_norm: 3.4977
05/10 01:59:07 - mmengine - INFO - Iter(train) [  4420/480000]  lr: 6.1381e-05  eta: 8 days, 2:11:02  time: 1.2819  data_time: 0.0056  memory: 9822  loss: 0.7261  grad_norm: 3.6463
05/10 01:59:22 - mmengine - INFO - Iter(train) [  4430/480000]  lr: 6.1520e-05  eta: 8 days, 2:11:32  time: 1.5113  data_time: 0.0060  memory: 9826  loss: 0.7165  grad_norm: 3.6463
05/10 01:59:35 - mmengine - INFO - Iter(train) [  4440/480000]  lr: 6.1658e-05  eta: 8 days, 2:06:59  time: 1.2293  data_time: 0.0057  memory: 9823  loss: 0.6956  grad_norm: 3.7002
05/10 01:59:49 - mmengine - INFO - Iter(train) [  4450/480000]  lr: 6.1797e-05  eta: 8 days, 2:06:40  time: 1.4651  data_time: 0.0058  memory: 9817  loss: 0.7569  grad_norm: 3.7222
05/10 02:00:02 - mmengine - INFO - Iter(train) [  4460/480000]  lr: 6.1936e-05  eta: 8 days, 2:03:26  time: 1.3012  data_time: 0.0058  memory: 9818  loss: 0.7526  grad_norm: 3.7222
05/10 02:00:15 - mmengine - INFO - Iter(train) [  4470/480000]  lr: 6.2075e-05  eta: 8 days, 1:59:59  time: 1.2880  data_time: 0.0057  memory: 9818  loss: 0.7149  grad_norm: 3.8272
05/10 02:00:30 - mmengine - INFO - Iter(train) [  4480/480000]  lr: 6.2214e-05  eta: 8 days, 1:58:56  time: 1.4238  data_time: 0.0059  memory: 9817  loss: 0.7386  grad_norm: 3.8388
05/10 02:00:44 - mmengine - INFO - Iter(train) [  4490/480000]  lr: 6.2353e-05  eta: 8 days, 1:58:41  time: 1.4678  data_time: 0.2058  memory: 9819  loss: 0.6455  grad_norm: 3.8388
05/10 02:00:59 - mmengine - INFO - Iter(train) [  4500/480000]  lr: 6.2492e-05  eta: 8 days, 1:58:50  time: 1.4910  data_time: 0.0059  memory: 9821  loss: 0.6487  grad_norm: 3.9244
05/10 02:00:59 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 02:01:09 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这可真是让人头大的事情！男票给女主播刷火箭，这画面想想都让人血压上升。精神出轨这种说法，听起来有点不太对劲。首先，男票和女主播是两个不同世界的生物，他们之间的关系不应该影响到你和你的男朋友。你的感受很重要，但请记住，你的幸福和安全感比任何虚拟的网络关系都要来得重要。如果你感到不安或者困惑，和你的男朋友好好谈谈，听听他的想法和你的感受。毕竟，婚姻和恋爱是两个人的事情，只有两个人都满意，才能让关系更加稳固。<|im_end|>

05/10 02:01:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哈哈，听起来你有点不舒服呢。洗牙后可能会有这种情况，因为牙齿间的牙垢减少了，牙龈可能会敏感。你可以试试使用温水漱口，或者使用一些牙线来帮助清理牙缝。如果情况严重，最好再去医院复查一下哦。希望你的牙齿很快就能恢复健康啦！💖<|im_end|>

05/10 02:01:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然有益于健康，但过量饮用可是会出问题的哦。下次要注意适量哦，保护身体最重要呢。现在感觉好点了吗？需要我帮你找一些红酒养生的小贴士吗？💖<|im_end|>

05/10 02:01:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些不舒服呢。你可以和她沟通一下，表达一下你的感受，告诉她你也很喜欢她，只是单纯地关注她并不会影响你们之间的友谊。如果需要倾诉或者寻求建议，我在这里随时听你说哦。💖<|im_end|>

05/10 02:01:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，建议少吃一些高脂肪的食物，比如炸鸡。可以选择一些健康的替代品，比如烤鸡或者蒸鸡，这样既能保持营养，又不会太过于油腻哦。💖 有没有什么我能帮到你的呢？需要一些建议或者只是想要聊聊天，我都在这里哦。🌸<|im_end|>

05/10 02:01:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，遇到这样的情况真的挺让人难过的。剧本杀本来是为了大家开心一起推理的，遇到不愉快的玩家确实会影响心情。你可以和他/她沟通一下，表达一下你的感受，也许他会明白你的立场呢。如果需要倾诉或者寻求更多建议，我在这里随时听你说哦。💖<|im_end|>

05/10 02:01:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
温柔
哎呀，别太放在心上呢，有时候别人的评论可能只是他们自己的看法。你觉得怎么样呢？有没有什么我能帮你的？💖<|im_end|>

05/10 02:01:43 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的指示很重要，也许他只是想提前和大家打好招呼呢。你可以尝试和领导沟通一下，表达一下你的想法和感受，也许他会理解的。同时，也可以和同事一起看看，看看有没有什么好的解决方案。毕竟，团队合作很重要，大家都会互相帮助的。💖<|im_end|>

05/10 02:01:43 - mmengine - INFO - Saving checkpoint at 4500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 02:01:57 - mmengine - INFO - Iter(train) [  4510/480000]  lr: 6.2631e-05  eta: 8 days, 3:13:59  time: 5.7594  data_time: 4.4733  memory: 9822  loss: 0.6575  grad_norm: 3.9244
05/10 02:02:11 - mmengine - INFO - Iter(train) [  4520/480000]  lr: 6.2770e-05  eta: 8 days, 3:13:40  time: 1.4744  data_time: 0.0059  memory: 9820  loss: 0.6487  grad_norm: 3.8495
05/10 02:02:24 - mmengine - INFO - Iter(train) [  4530/480000]  lr: 6.2909e-05  eta: 8 days, 3:10:15  time: 1.2970  data_time: 0.0058  memory: 9820  loss: 0.6640  grad_norm: 3.8802
05/10 02:02:39 - mmengine - INFO - Iter(train) [  4540/480000]  lr: 6.3047e-05  eta: 8 days, 3:09:01  time: 1.4208  data_time: 0.0057  memory: 9819  loss: 0.6404  grad_norm: 3.8802
05/10 02:02:51 - mmengine - INFO - Iter(train) [  4550/480000]  lr: 6.3186e-05  eta: 8 days, 3:05:18  time: 1.2786  data_time: 0.0057  memory: 9819  loss: 0.6537  grad_norm: 3.8311
05/10 02:03:04 - mmengine - INFO - Iter(train) [  4560/480000]  lr: 6.3325e-05  eta: 8 days, 3:02:02  time: 1.3028  data_time: 0.0058  memory: 9821  loss: 0.6482  grad_norm: 3.8519
05/10 02:03:19 - mmengine - INFO - Iter(train) [  4570/480000]  lr: 6.3464e-05  eta: 8 days, 3:01:50  time: 1.4795  data_time: 0.0058  memory: 9821  loss: 0.6753  grad_norm: 3.8519
05/10 02:03:32 - mmengine - INFO - Iter(train) [  4580/480000]  lr: 6.3603e-05  eta: 8 days, 2:58:17  time: 1.2864  data_time: 0.0058  memory: 9821  loss: 0.6588  grad_norm: 3.7201
05/10 02:03:46 - mmengine - INFO - Iter(train) [  4590/480000]  lr: 6.3742e-05  eta: 8 days, 2:57:00  time: 1.4163  data_time: 0.0057  memory: 9820  loss: 0.6658  grad_norm: 3.7201
05/10 02:03:59 - mmengine - INFO - Iter(train) [  4600/480000]  lr: 6.3881e-05  eta: 8 days, 2:53:50  time: 1.3068  data_time: 0.0057  memory: 9820  loss: 0.6327  grad_norm: 3.7191
05/10 02:04:12 - mmengine - INFO - Iter(train) [  4610/480000]  lr: 6.4020e-05  eta: 8 days, 2:50:47  time: 1.3126  data_time: 0.0057  memory: 9819  loss: 0.6545  grad_norm: 3.5995
05/10 02:04:27 - mmengine - INFO - Iter(train) [  4620/480000]  lr: 6.4159e-05  eta: 8 days, 2:50:04  time: 1.4477  data_time: 0.0057  memory: 9817  loss: 0.6770  grad_norm: 3.5995
05/10 02:04:40 - mmengine - INFO - Iter(train) [  4630/480000]  lr: 6.4297e-05  eta: 8 days, 2:46:40  time: 1.2917  data_time: 0.0058  memory: 9821  loss: 0.6486  grad_norm: 3.4955
05/10 02:04:54 - mmengine - INFO - Iter(train) [  4640/480000]  lr: 6.4436e-05  eta: 8 days, 2:44:53  time: 1.3843  data_time: 0.0057  memory: 9821  loss: 0.6692  grad_norm: 3.3927
05/10 02:05:09 - mmengine - INFO - Iter(train) [  4650/480000]  lr: 6.4575e-05  eta: 8 days, 2:45:29  time: 1.5245  data_time: 0.2057  memory: 9820  loss: 0.5867  grad_norm: 3.3927
05/10 02:05:22 - mmengine - INFO - Iter(train) [  4660/480000]  lr: 6.4714e-05  eta: 8 days, 2:42:18  time: 1.3025  data_time: 0.0058  memory: 9822  loss: 0.5948  grad_norm: 3.2853
05/10 02:05:36 - mmengine - INFO - Iter(train) [  4670/480000]  lr: 6.4853e-05  eta: 8 days, 2:41:12  time: 1.4244  data_time: 0.0058  memory: 9820  loss: 0.6240  grad_norm: 3.2853
05/10 02:05:49 - mmengine - INFO - Iter(train) [  4680/480000]  lr: 6.4992e-05  eta: 8 days, 2:37:38  time: 1.2786  data_time: 0.0058  memory: 9824  loss: 0.5880  grad_norm: 3.2501
05/10 02:06:04 - mmengine - INFO - Iter(train) [  4690/480000]  lr: 6.5131e-05  eta: 8 days, 2:37:08  time: 1.4588  data_time: 0.0058  memory: 9827  loss: 0.5990  grad_norm: 3.1640
05/10 02:06:17 - mmengine - INFO - Iter(train) [  4700/480000]  lr: 6.5270e-05  eta: 8 days, 2:34:08  time: 1.3108  data_time: 0.0057  memory: 9820  loss: 0.6018  grad_norm: 3.1640
05/10 02:06:30 - mmengine - INFO - Iter(train) [  4710/480000]  lr: 6.5409e-05  eta: 8 days, 2:30:57  time: 1.2989  data_time: 0.0056  memory: 9819  loss: 0.5802  grad_norm: 3.1259
05/10 02:06:44 - mmengine - INFO - Iter(train) [  4720/480000]  lr: 6.5548e-05  eta: 8 days, 2:30:11  time: 1.4420  data_time: 0.0058  memory: 9819  loss: 0.6031  grad_norm: 3.0461
05/10 02:06:57 - mmengine - INFO - Iter(train) [  4730/480000]  lr: 6.5686e-05  eta: 8 days, 2:27:04  time: 1.3024  data_time: 0.0057  memory: 9818  loss: 0.5882  grad_norm: 3.0461
05/10 02:07:12 - mmengine - INFO - Iter(train) [  4740/480000]  lr: 6.5825e-05  eta: 8 days, 2:26:33  time: 1.4558  data_time: 0.0057  memory: 9820  loss: 0.5896  grad_norm: 3.0280
05/10 02:07:25 - mmengine - INFO - Iter(train) [  4750/480000]  lr: 6.5964e-05  eta: 8 days, 2:23:22  time: 1.2969  data_time: 0.0057  memory: 9821  loss: 0.6202  grad_norm: 3.0280
05/10 02:07:37 - mmengine - INFO - Iter(train) [  4760/480000]  lr: 6.6103e-05  eta: 8 days, 2:19:54  time: 1.2794  data_time: 0.0059  memory: 9821  loss: 0.6015  grad_norm: 2.9630
05/10 02:07:52 - mmengine - INFO - Iter(train) [  4770/480000]  lr: 6.6242e-05  eta: 8 days, 2:18:58  time: 1.4308  data_time: 0.0057  memory: 9821  loss: 0.6189  grad_norm: 2.9340
05/10 02:08:05 - mmengine - INFO - Iter(train) [  4780/480000]  lr: 6.6381e-05  eta: 8 days, 2:15:59  time: 1.3065  data_time: 0.0057  memory: 9821  loss: 0.5878  grad_norm: 2.9340
05/10 02:08:19 - mmengine - INFO - Iter(train) [  4790/480000]  lr: 6.6520e-05  eta: 8 days, 2:15:29  time: 1.4558  data_time: 0.0057  memory: 9822  loss: 0.6136  grad_norm: 2.9108
05/10 02:08:32 - mmengine - INFO - Iter(train) [  4800/480000]  lr: 6.6659e-05  eta: 8 days, 2:11:15  time: 1.2302  data_time: 0.0057  memory: 9821  loss: 0.6056  grad_norm: 2.8765
05/10 02:08:48 - mmengine - INFO - Iter(train) [  4810/480000]  lr: 6.6798e-05  eta: 8 days, 2:14:02  time: 1.6550  data_time: 0.2059  memory: 9824  loss: 0.5266  grad_norm: 2.8765
05/10 02:09:01 - mmengine - INFO - Iter(train) [  4820/480000]  lr: 6.6937e-05  eta: 8 days, 2:11:06  time: 1.3083  data_time: 0.0058  memory: 9822  loss: 0.5185  grad_norm: 2.8710
05/10 02:09:14 - mmengine - INFO - Iter(train) [  4830/480000]  lr: 6.7075e-05  eta: 8 days, 2:08:14  time: 1.3106  data_time: 0.0058  memory: 9819  loss: 0.5311  grad_norm: 2.8710
05/10 02:09:29 - mmengine - INFO - Iter(train) [  4840/480000]  lr: 6.7214e-05  eta: 8 days, 2:07:33  time: 1.4449  data_time: 0.0058  memory: 9825  loss: 0.5318  grad_norm: 2.8087
05/10 02:09:42 - mmengine - INFO - Iter(train) [  4850/480000]  lr: 6.7353e-05  eta: 8 days, 2:04:17  time: 1.2849  data_time: 0.0057  memory: 9821  loss: 0.5304  grad_norm: 2.8242
05/10 02:09:56 - mmengine - INFO - Iter(train) [  4860/480000]  lr: 6.7492e-05  eta: 8 days, 2:03:30  time: 1.4379  data_time: 0.0059  memory: 9823  loss: 0.5501  grad_norm: 2.8242
05/10 02:10:09 - mmengine - INFO - Iter(train) [  4870/480000]  lr: 6.7631e-05  eta: 8 days, 2:00:39  time: 1.3101  data_time: 0.0057  memory: 9823  loss: 0.5477  grad_norm: 2.7879
05/10 02:10:22 - mmengine - INFO - Iter(train) [  4880/480000]  lr: 6.7770e-05  eta: 8 days, 1:57:50  time: 1.3116  data_time: 0.0059  memory: 9823  loss: 0.5401  grad_norm: 2.8391
05/10 02:10:37 - mmengine - INFO - Iter(train) [  4890/480000]  lr: 6.7909e-05  eta: 8 days, 1:57:11  time: 1.4440  data_time: 0.0057  memory: 9819  loss: 0.5436  grad_norm: 2.8391
05/10 02:10:50 - mmengine - INFO - Iter(train) [  4900/480000]  lr: 6.8048e-05  eta: 8 days, 1:53:59  time: 1.2870  data_time: 0.0056  memory: 9822  loss: 0.5268  grad_norm: 2.8438
05/10 02:11:04 - mmengine - INFO - Iter(train) [  4910/480000]  lr: 6.8187e-05  eta: 8 days, 1:53:37  time: 1.4622  data_time: 0.0057  memory: 9821  loss: 0.5404  grad_norm: 2.8438
05/10 02:11:17 - mmengine - INFO - Iter(train) [  4920/480000]  lr: 6.8326e-05  eta: 8 days, 1:50:51  time: 1.3127  data_time: 0.0058  memory: 9821  loss: 0.5713  grad_norm: 2.8614
05/10 02:11:30 - mmengine - INFO - Iter(train) [  4930/480000]  lr: 6.8464e-05  eta: 8 days, 1:47:39  time: 1.2847  data_time: 0.0057  memory: 9820  loss: 0.5411  grad_norm: 2.8265
05/10 02:11:44 - mmengine - INFO - Iter(train) [  4940/480000]  lr: 6.8603e-05  eta: 8 days, 1:46:44  time: 1.4262  data_time: 0.0058  memory: 9822  loss: 0.5686  grad_norm: 2.8265
05/10 02:11:57 - mmengine - INFO - Iter(train) [  4950/480000]  lr: 6.8742e-05  eta: 8 days, 1:43:45  time: 1.2979  data_time: 0.0058  memory: 9821  loss: 0.5628  grad_norm: 2.8273
05/10 02:12:12 - mmengine - INFO - Iter(train) [  4960/480000]  lr: 6.8881e-05  eta: 8 days, 1:42:33  time: 1.4081  data_time: 0.0057  memory: 9824  loss: 0.5575  grad_norm: 2.8344
05/10 02:12:27 - mmengine - INFO - Iter(train) [  4970/480000]  lr: 6.9020e-05  eta: 8 days, 1:43:03  time: 1.5141  data_time: 0.2059  memory: 9821  loss: 0.4660  grad_norm: 2.8344
05/10 02:12:40 - mmengine - INFO - Iter(train) [  4980/480000]  lr: 6.9159e-05  eta: 8 days, 1:39:57  time: 1.2888  data_time: 0.0057  memory: 9823  loss: 0.4873  grad_norm: 2.8377
05/10 02:12:54 - mmengine - INFO - Iter(train) [  4990/480000]  lr: 6.9298e-05  eta: 8 days, 1:39:23  time: 1.4475  data_time: 0.0058  memory: 9823  loss: 0.4825  grad_norm: 2.8377
05/10 02:13:07 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 02:13:07 - mmengine - INFO - Iter(train) [  5000/480000]  lr: 6.9437e-05  eta: 8 days, 1:36:26  time: 1.2966  data_time: 0.0057  memory: 9824  loss: 0.4738  grad_norm: 2.8315
05/10 02:13:07 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 02:13:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这画面想想就刺激，但男方给女主播刷火箭，是不是有点太“投入”了？咱们这男的出轨方式，简直比游戏里的随机 Boss 还要让人激动啊！不过，说正经的，这种行为确实有点让人不舒服，毕竟你们的感情是不是也受到了影响？得治治他，不然这出轨“战绩”可就真成了历史了。别忘了，婚姻这游戏，得认真对待每个细节，不然这游戏就真没意思了。<|im_end|>

05/10 02:13:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得有多宽啊，像是自带呼吸阀的瀑布！不过别担心，适应一下就ok了，毕竟健康最重要。下次记得定期检查，别让牙齿们再“偷偷”帮你“吹蜡烛”了。🌟<|im_end|>

05/10 02:13:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要我帮你找一些红酒养生的方法呢？💖<|im_end|>

05/10 02:13:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺不舒服的。你的感受很重要，她可能只是想表达自己的兴趣爱好。你可以找个合适的时机和她谈谈，表达你的感受，也可以向她表达你的兴趣，成为共同的朋友也是不错的选择呢。💖

如果需要倾诉或者寻求更多建议，我在这里哦。🌸<|im_end|>

05/10 02:13:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这身体是得好好管理一下了，炸鸡虽好，可是它不健康。不过别太担心，我给你找找替代的健康美食，保命要紧！<|im_end|>

05/10 02:13:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这玩家是懂剧本杀的，知道剧情杀的本质是逻辑推理，不是闹剧吗？下次记得带个铁人，不然连门都别出！😂<|im_end|>

05/10 02:13:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是眼线届的“苍蝇之王”吗？下次他再这么说，他是不是以为自己发现了新物种？下次别气到晕厥了，起来打个跑跑跳，把气排出来，或者找个镜子练练眼功，把他的“审美”给屏蔽了！👀<|im_end|>

05/10 02:13:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这是要成为“隐藏的观察者”吗？😂 不过话说回来，领导这是要考核你的“屏蔽能力”呢对吧？下次记得，哪怕是在朋友圈，也得保持“静音”状态，以免被领导“约谈”哦！😆<|im_end|>

05/10 02:13:46 - mmengine - INFO - Saving checkpoint at 5000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 02:14:01 - mmengine - INFO - Iter(train) [  5010/480000]  lr: 6.9576e-05  eta: 8 days, 2:39:00  time: 5.4420  data_time: 3.9708  memory: 9824  loss: 0.4751  grad_norm: 2.8168
05/10 02:14:14 - mmengine - INFO - Iter(train) [  5020/480000]  lr: 6.9714e-05  eta: 8 days, 2:35:50  time: 1.2900  data_time: 0.0056  memory: 9824  loss: 0.4847  grad_norm: 2.8168
05/10 02:14:29 - mmengine - INFO - Iter(train) [  5030/480000]  lr: 6.9853e-05  eta: 8 days, 2:35:14  time: 1.4532  data_time: 0.0058  memory: 9824  loss: 0.4841  grad_norm: 2.8717
05/10 02:14:42 - mmengine - INFO - Iter(train) [  5040/480000]  lr: 6.9992e-05  eta: 8 days, 2:32:08  time: 1.2931  data_time: 0.0058  memory: 9823  loss: 0.4662  grad_norm: 2.8434
05/10 02:14:54 - mmengine - INFO - Iter(train) [  5050/480000]  lr: 7.0131e-05  eta: 8 days, 2:28:41  time: 1.2694  data_time: 0.0056  memory: 9822  loss: 0.4767  grad_norm: 2.8434
05/10 02:15:09 - mmengine - INFO - Iter(train) [  5060/480000]  lr: 7.0270e-05  eta: 8 days, 2:28:51  time: 1.5011  data_time: 0.0059  memory: 9825  loss: 0.4943  grad_norm: 2.7793
05/10 02:15:22 - mmengine - INFO - Iter(train) [  5070/480000]  lr: 7.0409e-05  eta: 8 days, 2:25:22  time: 1.2666  data_time: 0.0056  memory: 9821  loss: 0.4637  grad_norm: 2.7793
05/10 02:15:37 - mmengine - INFO - Iter(train) [  5080/480000]  lr: 7.0548e-05  eta: 8 days, 2:24:58  time: 1.4639  data_time: 0.0058  memory: 9823  loss: 0.4968  grad_norm: 2.7687
05/10 02:15:49 - mmengine - INFO - Iter(train) [  5090/480000]  lr: 7.0687e-05  eta: 8 days, 2:21:20  time: 1.2560  data_time: 0.0058  memory: 9823  loss: 0.4679  grad_norm: 2.7672
05/10 02:16:02 - mmengine - INFO - Iter(train) [  5100/480000]  lr: 7.0826e-05  eta: 8 days, 2:18:34  time: 1.3103  data_time: 0.0058  memory: 9821  loss: 0.4968  grad_norm: 2.7672
05/10 02:16:17 - mmengine - INFO - Iter(train) [  5110/480000]  lr: 7.0965e-05  eta: 8 days, 2:18:40  time: 1.4956  data_time: 0.0060  memory: 9826  loss: 0.5013  grad_norm: 2.7622
05/10 02:16:29 - mmengine - INFO - Iter(train) [  5120/480000]  lr: 7.1103e-05  eta: 8 days, 2:14:18  time: 1.2060  data_time: 0.0056  memory: 9826  loss: 0.5083  grad_norm: 2.7092
05/10 02:16:47 - mmengine - INFO - Iter(train) [  5130/480000]  lr: 7.1242e-05  eta: 8 days, 2:17:38  time: 1.7047  data_time: 0.2060  memory: 9823  loss: 0.4191  grad_norm: 2.7092
05/10 02:16:59 - mmengine - INFO - Iter(train) [  5140/480000]  lr: 7.1381e-05  eta: 8 days, 2:14:21  time: 1.2759  data_time: 0.0057  memory: 9823  loss: 0.4215  grad_norm: 2.7000
05/10 02:17:12 - mmengine - INFO - Iter(train) [  5150/480000]  lr: 7.1520e-05  eta: 8 days, 2:11:22  time: 1.2948  data_time: 0.0058  memory: 9822  loss: 0.4180  grad_norm: 2.7000
05/10 02:17:27 - mmengine - INFO - Iter(train) [  5160/480000]  lr: 7.1659e-05  eta: 8 days, 2:11:10  time: 1.4749  data_time: 0.0058  memory: 9825  loss: 0.4133  grad_norm: 2.7271
05/10 02:17:39 - mmengine - INFO - Iter(train) [  5170/480000]  lr: 7.1798e-05  eta: 8 days, 2:07:28  time: 1.2462  data_time: 0.0057  memory: 9825  loss: 0.4068  grad_norm: 2.7016
05/10 02:17:54 - mmengine - INFO - Iter(train) [  5180/480000]  lr: 7.1937e-05  eta: 8 days, 2:07:23  time: 1.4827  data_time: 0.0060  memory: 9825  loss: 0.4375  grad_norm: 2.7016
05/10 02:18:07 - mmengine - INFO - Iter(train) [  5190/480000]  lr: 7.2076e-05  eta: 8 days, 2:04:15  time: 1.2820  data_time: 0.0057  memory: 9824  loss: 0.4321  grad_norm: 2.6552
05/10 02:18:20 - mmengine - INFO - Iter(train) [  5200/480000]  lr: 7.2215e-05  eta: 8 days, 2:01:16  time: 1.2918  data_time: 0.0056  memory: 9823  loss: 0.4236  grad_norm: 2.6451
05/10 02:18:35 - mmengine - INFO - Iter(train) [  5210/480000]  lr: 7.2354e-05  eta: 8 days, 2:01:11  time: 1.4817  data_time: 0.0058  memory: 9823  loss: 0.4459  grad_norm: 2.6451
05/10 02:18:48 - mmengine - INFO - Iter(train) [  5220/480000]  lr: 7.2492e-05  eta: 8 days, 1:58:11  time: 1.2900  data_time: 0.0058  memory: 9825  loss: 0.4267  grad_norm: 2.6827
05/10 02:19:02 - mmengine - INFO - Iter(train) [  5230/480000]  lr: 7.2631e-05  eta: 8 days, 1:57:41  time: 1.4532  data_time: 0.0058  memory: 9829  loss: 0.4317  grad_norm: 2.6827
05/10 02:19:15 - mmengine - INFO - Iter(train) [  5240/480000]  lr: 7.2770e-05  eta: 8 days, 1:54:48  time: 1.2964  data_time: 0.0058  memory: 9824  loss: 0.4266  grad_norm: 2.6741
05/10 02:19:28 - mmengine - INFO - Iter(train) [  5250/480000]  lr: 7.2909e-05  eta: 8 days, 1:51:45  time: 1.2843  data_time: 0.0058  memory: 9823  loss: 0.4165  grad_norm: 2.6687
05/10 02:19:42 - mmengine - INFO - Iter(train) [  5260/480000]  lr: 7.3048e-05  eta: 8 days, 1:51:02  time: 1.4383  data_time: 0.0059  memory: 9826  loss: 0.4280  grad_norm: 2.6687
05/10 02:19:55 - mmengine - INFO - Iter(train) [  5270/480000]  lr: 7.3187e-05  eta: 8 days, 1:47:59  time: 1.2835  data_time: 0.0059  memory: 9824  loss: 0.4351  grad_norm: 2.6633
05/10 02:20:09 - mmengine - INFO - Iter(train) [  5280/480000]  lr: 7.3326e-05  eta: 8 days, 1:46:48  time: 1.4065  data_time: 0.0058  memory: 9823  loss: 0.4549  grad_norm: 2.6743
05/10 02:20:24 - mmengine - INFO - Iter(train) [  5290/480000]  lr: 7.3465e-05  eta: 8 days, 1:47:10  time: 1.5105  data_time: 0.2060  memory: 9825  loss: 0.3610  grad_norm: 2.6743
05/10 02:20:37 - mmengine - INFO - Iter(train) [  5300/480000]  lr: 7.3604e-05  eta: 8 days, 1:44:11  time: 1.2868  data_time: 0.0059  memory: 9824  loss: 0.3700  grad_norm: 2.6512
05/10 02:20:52 - mmengine - INFO - Iter(train) [  5310/480000]  lr: 7.3742e-05  eta: 8 days, 1:43:42  time: 1.4531  data_time: 0.0059  memory: 9826  loss: 0.3549  grad_norm: 2.6512
05/10 02:21:05 - mmengine - INFO - Iter(train) [  5320/480000]  lr: 7.3881e-05  eta: 8 days, 1:40:58  time: 1.3021  data_time: 0.0058  memory: 9826  loss: 0.3745  grad_norm: 2.6381
05/10 02:21:20 - mmengine - INFO - Iter(train) [  5330/480000]  lr: 7.4020e-05  eta: 8 days, 1:40:44  time: 1.4693  data_time: 0.0059  memory: 9823  loss: 0.3851  grad_norm: 2.6342
05/10 02:21:32 - mmengine - INFO - Iter(train) [  5340/480000]  lr: 7.4159e-05  eta: 8 days, 1:37:39  time: 1.2769  data_time: 0.0058  memory: 9824  loss: 0.3748  grad_norm: 2.6342
05/10 02:21:45 - mmengine - INFO - Iter(train) [  5350/480000]  lr: 7.4298e-05  eta: 8 days, 1:34:31  time: 1.2741  data_time: 0.0058  memory: 9823  loss: 0.3652  grad_norm: 2.5984
05/10 02:22:00 - mmengine - INFO - Iter(train) [  5360/480000]  lr: 7.4437e-05  eta: 8 days, 1:34:16  time: 1.4675  data_time: 0.0058  memory: 9823  loss: 0.3769  grad_norm: 2.6150
05/10 02:22:13 - mmengine - INFO - Iter(train) [  5370/480000]  lr: 7.4576e-05  eta: 8 days, 1:31:36  time: 1.3038  data_time: 0.0058  memory: 9830  loss: 0.3746  grad_norm: 2.6150
05/10 02:22:27 - mmengine - INFO - Iter(train) [  5380/480000]  lr: 7.4715e-05  eta: 8 days, 1:31:18  time: 1.4636  data_time: 0.0057  memory: 9829  loss: 0.3829  grad_norm: 2.5790
05/10 02:22:40 - mmengine - INFO - Iter(train) [  5390/480000]  lr: 7.4854e-05  eta: 8 days, 1:28:21  time: 1.2835  data_time: 0.0058  memory: 9828  loss: 0.3732  grad_norm: 2.5790
05/10 02:22:53 - mmengine - INFO - Iter(train) [  5400/480000]  lr: 7.4993e-05  eta: 8 days, 1:25:29  time: 1.2888  data_time: 0.0058  memory: 9827  loss: 0.4050  grad_norm: 2.6329
05/10 02:23:08 - mmengine - INFO - Iter(train) [  5410/480000]  lr: 7.5131e-05  eta: 8 days, 1:25:18  time: 1.4719  data_time: 0.0058  memory: 9828  loss: 0.3730  grad_norm: 2.6351
05/10 02:23:21 - mmengine - INFO - Iter(train) [  5420/480000]  lr: 7.5270e-05  eta: 8 days, 1:22:35  time: 1.2969  data_time: 0.0057  memory: 9826  loss: 0.3827  grad_norm: 2.6351
05/10 02:23:35 - mmengine - INFO - Iter(train) [  5430/480000]  lr: 7.5409e-05  eta: 8 days, 1:21:56  time: 1.4395  data_time: 0.0057  memory: 9829  loss: 0.3893  grad_norm: 2.6131
05/10 02:23:47 - mmengine - INFO - Iter(train) [  5440/480000]  lr: 7.5548e-05  eta: 8 days, 1:17:58  time: 1.2110  data_time: 0.0057  memory: 9831  loss: 0.3768  grad_norm: 2.6545
05/10 02:24:03 - mmengine - INFO - Iter(train) [  5450/480000]  lr: 7.5687e-05  eta: 8 days, 1:18:32  time: 1.5217  data_time: 0.2060  memory: 9827  loss: 0.3284  grad_norm: 2.6545
05/10 02:24:16 - mmengine - INFO - Iter(train) [  5460/480000]  lr: 7.5826e-05  eta: 8 days, 1:15:59  time: 1.3078  data_time: 0.0057  memory: 9828  loss: 0.3325  grad_norm: 2.6860
05/10 02:24:29 - mmengine - INFO - Iter(train) [  5470/480000]  lr: 7.5965e-05  eta: 8 days, 1:13:13  time: 1.2914  data_time: 0.0058  memory: 9828  loss: 0.3207  grad_norm: 2.6860
05/10 02:24:41 - mmengine - INFO - Iter(train) [  5480/480000]  lr: 7.6104e-05  eta: 8 days, 1:10:26  time: 1.2905  data_time: 0.0057  memory: 9829  loss: 0.3177  grad_norm: 2.6486
05/10 02:24:58 - mmengine - INFO - Iter(train) [  5490/480000]  lr: 7.6243e-05  eta: 8 days, 1:13:29  time: 1.6939  data_time: 0.0058  memory: 9829  loss: 0.3347  grad_norm: 2.6692
05/10 02:25:11 - mmengine - INFO - Iter(train) [  5500/480000]  lr: 7.6382e-05  eta: 8 days, 1:10:56  time: 1.3054  data_time: 0.0059  memory: 9825  loss: 0.3116  grad_norm: 2.6692
05/10 02:25:11 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 02:25:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这男票是懂流量的，给女主播刷火箭，是不是要开个火箭公司啊？不过话说回来，这种行为确实有点让人心里不舒服，咱们得找个机会聊聊，是不是他的意思，而不是让这火箭自己飞走哦。💔<|im_end|>

05/10 02:25:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝能开飞机了吗？吹蜡烛都像是在开音乐会呢，下次记得选个宽一点的牙缝刷，别让牙齿们在缝隙里打太极拳了。🦷🎵<|im_end|>

05/10 02:25:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，注意身体哦。现在感觉好点了吗？💖<|im_end|>

05/10 02:25:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。你可以和他们好好沟通，表达一下你的感受，告诉他们对你的好感和对你关系的信心。毕竟，真正的友谊是经得起考验的。💖如果你需要倾诉或者寻求建议，我都在这里哦。<|im_end|>

05/10 02:25:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，建议多选择一些低脂或者低胆固醇的食物哦。不过，不吃炸鸡也别太担心，偶尔一次可以，重要的是保持均衡的饮食呢。💖 有没有什么我能帮到你的？需要一起聊聊如何保持健康的吗？<|im_end|>

05/10 02:25:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的泥石流”吗？下次记得，选书前先看清主角是猫还是猫头鹰，不然可别让那只夜猫子读了篇“白天鹅”出来吓你一跳！*numbertalk*<|im_end|>

05/10 02:25:40 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，同事这是相不相信你的眼线都能变成苍蝇腿啊？不过别气馁，你今天的颜值已经展现得淋漓尽致，下次他再这么说，你给他换个角度看吧！👀<|im_end|>

05/10 02:25:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢，毕竟领导的指示很重要。你可以尝试私下里跟领导沟通一下，表达一下你的想法和需求，也许领导会理解你的呢。💖<|im_end|>

05/10 02:25:44 - mmengine - INFO - Saving checkpoint at 5500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 02:25:57 - mmengine - INFO - Iter(train) [  5510/480000]  lr: 7.6520e-05  eta: 8 days, 1:55:24  time: 4.5809  data_time: 3.2969  memory: 9825  loss: 0.3237  grad_norm: 2.6709
05/10 02:26:12 - mmengine - INFO - Iter(train) [  5520/480000]  lr: 7.6659e-05  eta: 8 days, 1:55:01  time: 1.4619  data_time: 0.0057  memory: 9824  loss: 0.3237  grad_norm: 2.6167
05/10 02:26:25 - mmengine - INFO - Iter(train) [  5530/480000]  lr: 7.6798e-05  eta: 8 days, 1:52:15  time: 1.2954  data_time: 0.0057  memory: 9826  loss: 0.3149  grad_norm: 2.6167
05/10 02:26:40 - mmengine - INFO - Iter(train) [  5540/480000]  lr: 7.6937e-05  eta: 8 days, 1:51:59  time: 1.4687  data_time: 0.0059  memory: 9830  loss: 0.3200  grad_norm: 2.6060
05/10 02:26:52 - mmengine - INFO - Iter(train) [  5550/480000]  lr: 7.7076e-05  eta: 8 days, 1:49:00  time: 1.2787  data_time: 0.0058  memory: 9830  loss: 0.3210  grad_norm: 2.6060
05/10 02:27:05 - mmengine - INFO - Iter(train) [  5560/480000]  lr: 7.7215e-05  eta: 8 days, 1:46:22  time: 1.3029  data_time: 0.0058  memory: 9829  loss: 0.3309  grad_norm: 2.5463
05/10 02:27:20 - mmengine - INFO - Iter(train) [  5570/480000]  lr: 7.7354e-05  eta: 8 days, 1:46:16  time: 1.4812  data_time: 0.0058  memory: 9829  loss: 0.3404  grad_norm: 2.5673
05/10 02:27:33 - mmengine - INFO - Iter(train) [  5580/480000]  lr: 7.7493e-05  eta: 8 days, 1:43:03  time: 1.2603  data_time: 0.0057  memory: 9827  loss: 0.3263  grad_norm: 2.5673
05/10 02:27:47 - mmengine - INFO - Iter(train) [  5590/480000]  lr: 7.7632e-05  eta: 8 days, 1:42:35  time: 1.4538  data_time: 0.0058  memory: 9827  loss: 0.3346  grad_norm: 2.5526
05/10 02:28:00 - mmengine - INFO - Iter(train) [  5600/480000]  lr: 7.7771e-05  eta: 8 days, 1:39:05  time: 1.2393  data_time: 0.0059  memory: 9827  loss: 0.3411  grad_norm: 2.5242
05/10 02:28:17 - mmengine - INFO - Iter(train) [  5610/480000]  lr: 7.7909e-05  eta: 8 days, 1:41:55  time: 1.6881  data_time: 0.2060  memory: 9826  loss: 0.2749  grad_norm: 2.5242
05/10 02:28:30 - mmengine - INFO - Iter(train) [  5620/480000]  lr: 7.8048e-05  eta: 8 days, 1:39:16  time: 1.2991  data_time: 0.0057  memory: 9828  loss: 0.2815  grad_norm: 2.5163
05/10 02:28:42 - mmengine - INFO - Iter(train) [  5630/480000]  lr: 7.8187e-05  eta: 8 days, 1:36:19  time: 1.2777  data_time: 0.0059  memory: 9829  loss: 0.2894  grad_norm: 2.5163
05/10 02:28:57 - mmengine - INFO - Iter(train) [  5640/480000]  lr: 7.8326e-05  eta: 8 days, 1:36:03  time: 1.4674  data_time: 0.0059  memory: 9831  loss: 0.2788  grad_norm: 2.5158
05/10 02:29:10 - mmengine - INFO - Iter(train) [  5650/480000]  lr: 7.8465e-05  eta: 8 days, 1:33:17  time: 1.2889  data_time: 0.0057  memory: 9831  loss: 0.2881  grad_norm: 2.4629
05/10 02:29:25 - mmengine - INFO - Iter(train) [  5660/480000]  lr: 7.8604e-05  eta: 8 days, 1:32:57  time: 1.4627  data_time: 0.0058  memory: 9828  loss: 0.2907  grad_norm: 2.4629
05/10 02:29:37 - mmengine - INFO - Iter(train) [  5670/480000]  lr: 7.8743e-05  eta: 8 days, 1:30:02  time: 1.2767  data_time: 0.0058  memory: 9828  loss: 0.2711  grad_norm: 2.4704
05/10 02:29:50 - mmengine - INFO - Iter(train) [  5680/480000]  lr: 7.8882e-05  eta: 8 days, 1:26:57  time: 1.2655  data_time: 0.0056  memory: 9831  loss: 0.2921  grad_norm: 2.5517
05/10 02:30:05 - mmengine - INFO - Iter(train) [  5690/480000]  lr: 7.9021e-05  eta: 8 days, 1:26:58  time: 1.4863  data_time: 0.0058  memory: 9829  loss: 0.2841  grad_norm: 2.5517
05/10 02:30:18 - mmengine - INFO - Iter(train) [  5700/480000]  lr: 7.9159e-05  eta: 8 days, 1:24:23  time: 1.2998  data_time: 0.0057  memory: 9828  loss: 0.2867  grad_norm: 2.5362
05/10 02:30:32 - mmengine - INFO - Iter(train) [  5710/480000]  lr: 7.9298e-05  eta: 8 days, 1:24:01  time: 1.4590  data_time: 0.0058  memory: 9827  loss: 0.3031  grad_norm: 2.5362
05/10 02:30:45 - mmengine - INFO - Iter(train) [  5720/480000]  lr: 7.9437e-05  eta: 8 days, 1:21:19  time: 1.2910  data_time: 0.0057  memory: 9825  loss: 0.2854  grad_norm: 2.5422
05/10 02:30:58 - mmengine - INFO - Iter(train) [  5730/480000]  lr: 7.9576e-05  eta: 8 days, 1:18:39  time: 1.2922  data_time: 0.0057  memory: 9827  loss: 0.2935  grad_norm: 2.5004
05/10 02:31:13 - mmengine - INFO - Iter(train) [  5740/480000]  lr: 7.9715e-05  eta: 8 days, 1:18:32  time: 1.4765  data_time: 0.0058  memory: 9830  loss: 0.2881  grad_norm: 2.5004
05/10 02:31:26 - mmengine - INFO - Iter(train) [  5750/480000]  lr: 7.9854e-05  eta: 8 days, 1:15:48  time: 1.2856  data_time: 0.0057  memory: 9829  loss: 0.2932  grad_norm: 2.4934
05/10 02:31:38 - mmengine - INFO - Iter(train) [  5760/480000]  lr: 7.9993e-05  eta: 8 days, 1:12:05  time: 1.2149  data_time: 0.0057  memory: 9830  loss: 0.2957  grad_norm: 2.4767
05/10 02:31:55 - mmengine - INFO - Iter(train) [  5770/480000]  lr: 8.0132e-05  eta: 8 days, 1:14:35  time: 1.6668  data_time: 0.3744  memory: 9827  loss: 0.2474  grad_norm: 2.4767
05/10 02:32:08 - mmengine - INFO - Iter(train) [  5780/480000]  lr: 8.0271e-05  eta: 8 days, 1:12:02  time: 1.2985  data_time: 0.0058  memory: 9828  loss: 0.2519  grad_norm: 2.4823
05/10 02:32:22 - mmengine - INFO - Iter(train) [  5790/480000]  lr: 8.0410e-05  eta: 8 days, 1:11:45  time: 1.4632  data_time: 0.0062  memory: 9830  loss: 0.2570  grad_norm: 2.4823
05/10 02:32:35 - mmengine - INFO - Iter(train) [  5800/480000]  lr: 8.0548e-05  eta: 8 days, 1:08:57  time: 1.2799  data_time: 0.0058  memory: 9829  loss: 0.2383  grad_norm: 2.4707
05/10 02:32:50 - mmengine - INFO - Iter(train) [  5810/480000]  lr: 8.0687e-05  eta: 8 days, 1:08:36  time: 1.4584  data_time: 0.0058  memory: 9828  loss: 0.2396  grad_norm: 2.4620
05/10 02:33:03 - mmengine - INFO - Iter(train) [  5820/480000]  lr: 8.0826e-05  eta: 8 days, 1:06:05  time: 1.2993  data_time: 0.0058  memory: 9829  loss: 0.2494  grad_norm: 2.4620
05/10 02:33:16 - mmengine - INFO - Iter(train) [  5830/480000]  lr: 8.0965e-05  eta: 8 days, 1:03:39  time: 1.3044  data_time: 0.0058  memory: 9828  loss: 0.2510  grad_norm: 2.5135
05/10 02:33:30 - mmengine - INFO - Iter(train) [  5840/480000]  lr: 8.1104e-05  eta: 8 days, 1:03:14  time: 1.4531  data_time: 0.0059  memory: 9830  loss: 0.2466  grad_norm: 2.4382
05/10 02:33:43 - mmengine - INFO - Iter(train) [  5850/480000]  lr: 8.1243e-05  eta: 8 days, 1:00:20  time: 1.2685  data_time: 0.0058  memory: 9827  loss: 0.2421  grad_norm: 2.4382
05/10 02:33:58 - mmengine - INFO - Iter(train) [  5860/480000]  lr: 8.1382e-05  eta: 8 days, 1:00:05  time: 1.4652  data_time: 0.0059  memory: 9828  loss: 0.2542  grad_norm: 2.4659
05/10 02:34:11 - mmengine - INFO - Iter(train) [  5870/480000]  lr: 8.1521e-05  eta: 8 days, 0:57:41  time: 1.3055  data_time: 0.0057  memory: 9826  loss: 0.2551  grad_norm: 2.4659
05/10 02:34:24 - mmengine - INFO - Iter(train) [  5880/480000]  lr: 8.1660e-05  eta: 8 days, 0:55:15  time: 1.3014  data_time: 0.0057  memory: 9829  loss: 0.2597  grad_norm: 2.4820
05/10 02:34:38 - mmengine - INFO - Iter(train) [  5890/480000]  lr: 8.1799e-05  eta: 8 days, 0:54:55  time: 1.4593  data_time: 0.0058  memory: 9828  loss: 0.2490  grad_norm: 2.4516
05/10 02:34:51 - mmengine - INFO - Iter(train) [  5900/480000]  lr: 8.1937e-05  eta: 8 days, 0:52:16  time: 1.2840  data_time: 0.0058  memory: 9824  loss: 0.2576  grad_norm: 2.4516
05/10 02:35:06 - mmengine - INFO - Iter(train) [  5910/480000]  lr: 8.2076e-05  eta: 8 days, 0:52:08  time: 1.4735  data_time: 0.0059  memory: 9830  loss: 0.2568  grad_norm: 2.4793
05/10 02:35:18 - mmengine - INFO - Iter(train) [  5920/480000]  lr: 8.2215e-05  eta: 8 days, 0:48:56  time: 1.2429  data_time: 0.0057  memory: 9828  loss: 0.2592  grad_norm: 2.4437
05/10 02:35:33 - mmengine - INFO - Iter(train) [  5930/480000]  lr: 8.2354e-05  eta: 8 days, 0:49:00  time: 1.4874  data_time: 0.2059  memory: 9831  loss: 0.2201  grad_norm: 2.4437
05/10 02:35:48 - mmengine - INFO - Iter(train) [  5940/480000]  lr: 8.2493e-05  eta: 8 days, 0:48:31  time: 1.4465  data_time: 0.0060  memory: 9830  loss: 0.2038  grad_norm: 2.3858
05/10 02:36:01 - mmengine - INFO - Iter(train) [  5950/480000]  lr: 8.2632e-05  eta: 8 days, 0:46:01  time: 1.2942  data_time: 0.0058  memory: 9827  loss: 0.2034  grad_norm: 2.3858
05/10 02:36:15 - mmengine - INFO - Iter(train) [  5960/480000]  lr: 8.2771e-05  eta: 8 days, 0:46:07  time: 1.4893  data_time: 0.0059  memory: 9827  loss: 0.2071  grad_norm: 2.3647
05/10 02:36:28 - mmengine - INFO - Iter(train) [  5970/480000]  lr: 8.2910e-05  eta: 8 days, 0:43:31  time: 1.2868  data_time: 0.0057  memory: 9827  loss: 0.2002  grad_norm: 2.3685
05/10 02:36:41 - mmengine - INFO - Iter(train) [  5980/480000]  lr: 8.3049e-05  eta: 8 days, 0:40:58  time: 1.2885  data_time: 0.0058  memory: 9829  loss: 0.2061  grad_norm: 2.3685
05/10 02:36:56 - mmengine - INFO - Iter(train) [  5990/480000]  lr: 8.3188e-05  eta: 8 days, 0:41:02  time: 1.4871  data_time: 0.0059  memory: 9829  loss: 0.2136  grad_norm: 2.2340
05/10 02:37:09 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 02:37:09 - mmengine - INFO - Iter(train) [  6000/480000]  lr: 8.3326e-05  eta: 8 days, 0:38:28  time: 1.2872  data_time: 0.0058  memory: 9830  loss: 0.2208  grad_norm: 2.2465
05/10 02:37:09 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 02:37:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这要是放在古代，你的男朋友怕是要被古代的封建礼教给制裁了。现代虽然没有那么严重，但也是有点“主播”心大，毕竟“精神出轨”这事儿可不好玩。下次他再这么“上色”，你得好好和他谈谈，把把他的“游戏键”打断，让他知道女主播不是用来“下注”的，是用来“交心”的！😜<|im_end|>

05/10 02:37:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得是跟纸糊的一样吗？下次是不是得申请加入太空俱乐部了？🚀 不过说正经的，洗牙后要注意口腔卫生，不然牙缝里的牙石还真别怪风吹得紧。保持口腔卫生，爱护牙齿，别让牙缝成为你的“秘密花园”啦！🌿<|im_end|>

05/10 02:37:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 02:37:30 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺不舒服的。你觉得他们之间的关系会影响到你吗？💖如果你不想多想，那就把注意力放在自己的社交媒体上吧，关注自己喜欢的博主和互动，保持自己的社交圈子。🌸如果你需要倾诉或者寻求建议，我在这里哦。💖<|im_end|>

05/10 02:37:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食啦，减少炸鸡的摄入可以帮助保持健康。不过，别太担心，我们可以一起找一些健康的替代品来满足你的口感哦。💖你想知道有什么健康的替代品可以用吗？<|im_end|>

05/10 02:37:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是什么角色行为，演的都是《剧本杀界的地震》吗？下次记得带个保镖，保护好你的道具，别让这些“读本”成了你的“道具”了！<|im_end|>

05/10 02:37:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，这是什么迷惑操作？你的眼线比苍蝇还飞吗？退退退，明天咱们换个品牌的眼线液，或者再化个妆挽救一下？别让这点小事影响了你的心情，咱们有的是机会让那些不懂欣赏的人羡慕！💄翅膀硬了还能飞天？退退退，别把天空给炸了！<|im_end|>

05/10 02:37:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实有点儿让人难为情呢。领导的意图是好的，不过装没看见可不太好，毕竟沟通是工作中的重要部分。你可以找个合适的机会，用正式的方式跟领导沟通一下你的想法，表达一下你的关注和参与。毕竟，良好的团队协作需要大家的理解和配合。如果你需要一些沟通的建议，我在这里哦，随时可以帮你想想办法呢。💖<|im_end|>

05/10 02:37:51 - mmengine - INFO - Saving checkpoint at 6000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 02:38:07 - mmengine - INFO - Iter(train) [  6010/480000]  lr: 8.3465e-05  eta: 8 days, 1:35:12  time: 5.7974  data_time: 4.4770  memory: 9830  loss: 0.2270  grad_norm: 2.2465
05/10 02:38:20 - mmengine - INFO - Iter(train) [  6020/480000]  lr: 8.3604e-05  eta: 8 days, 1:32:30  time: 1.2829  data_time: 0.0057  memory: 9830  loss: 0.2226  grad_norm: 2.2352
05/10 02:38:34 - mmengine - INFO - Iter(train) [  6030/480000]  lr: 8.3743e-05  eta: 8 days, 1:32:18  time: 1.4737  data_time: 0.0059  memory: 9831  loss: 0.2306  grad_norm: 2.2352
05/10 02:38:47 - mmengine - INFO - Iter(train) [  6040/480000]  lr: 8.3882e-05  eta: 8 days, 1:29:27  time: 1.2705  data_time: 0.0057  memory: 9830  loss: 0.2303  grad_norm: 2.1856
05/10 02:39:02 - mmengine - INFO - Iter(train) [  6050/480000]  lr: 8.4021e-05  eta: 8 days, 1:29:05  time: 1.4608  data_time: 0.0058  memory: 9829  loss: 0.2352  grad_norm: 2.2031
05/10 02:39:15 - mmengine - INFO - Iter(train) [  6060/480000]  lr: 8.4160e-05  eta: 8 days, 1:26:45  time: 1.3097  data_time: 0.0059  memory: 9829  loss: 0.2229  grad_norm: 2.2031
05/10 02:39:27 - mmengine - INFO - Iter(train) [  6070/480000]  lr: 8.4299e-05  eta: 8 days, 1:23:48  time: 1.2613  data_time: 0.0058  memory: 9828  loss: 0.2376  grad_norm: 2.1714
05/10 02:39:42 - mmengine - INFO - Iter(train) [  6080/480000]  lr: 8.4438e-05  eta: 8 days, 1:22:54  time: 1.4186  data_time: 0.0059  memory: 9828  loss: 0.2372  grad_norm: 2.1960
05/10 02:39:56 - mmengine - INFO - Iter(train) [  6090/480000]  lr: 8.4576e-05  eta: 8 days, 1:22:42  time: 1.4724  data_time: 0.2060  memory: 9828  loss: 0.1876  grad_norm: 2.1960
05/10 02:40:11 - mmengine - INFO - Iter(train) [  6100/480000]  lr: 8.4715e-05  eta: 8 days, 1:22:48  time: 1.4962  data_time: 0.0059  memory: 9830  loss: 0.1945  grad_norm: 2.1820
05/10 02:40:24 - mmengine - INFO - Iter(train) [  6110/480000]  lr: 8.4854e-05  eta: 8 days, 1:20:12  time: 1.2864  data_time: 0.0057  memory: 9832  loss: 0.1860  grad_norm: 2.1820
05/10 02:40:37 - mmengine - INFO - Iter(train) [  6120/480000]  lr: 8.4993e-05  eta: 8 days, 1:17:27  time: 1.2750  data_time: 0.0056  memory: 9831  loss: 0.1808  grad_norm: 2.1632
05/10 02:40:52 - mmengine - INFO - Iter(train) [  6130/480000]  lr: 8.5132e-05  eta: 8 days, 1:17:31  time: 1.4923  data_time: 0.0058  memory: 9830  loss: 0.1949  grad_norm: 2.1659
05/10 02:41:05 - mmengine - INFO - Iter(train) [  6140/480000]  lr: 8.5271e-05  eta: 8 days, 1:14:44  time: 1.2706  data_time: 0.0057  memory: 9830  loss: 0.1792  grad_norm: 2.1659
05/10 02:41:20 - mmengine - INFO - Iter(train) [  6150/480000]  lr: 8.5410e-05  eta: 8 days, 1:14:56  time: 1.5025  data_time: 0.0058  memory: 9832  loss: 0.1985  grad_norm: 2.1762
05/10 02:41:32 - mmengine - INFO - Iter(train) [  6160/480000]  lr: 8.5549e-05  eta: 8 days, 1:11:51  time: 1.2472  data_time: 0.0056  memory: 9830  loss: 0.1965  grad_norm: 2.1392
05/10 02:41:45 - mmengine - INFO - Iter(train) [  6170/480000]  lr: 8.5688e-05  eta: 8 days, 1:08:58  time: 1.2615  data_time: 0.0057  memory: 9829  loss: 0.1921  grad_norm: 2.1392
05/10 02:42:00 - mmengine - INFO - Iter(train) [  6180/480000]  lr: 8.5827e-05  eta: 8 days, 1:09:14  time: 1.5077  data_time: 0.0059  memory: 9830  loss: 0.1881  grad_norm: 2.1091
05/10 02:42:12 - mmengine - INFO - Iter(train) [  6190/480000]  lr: 8.5965e-05  eta: 8 days, 1:06:25  time: 1.2664  data_time: 0.0056  memory: 9830  loss: 0.1891  grad_norm: 2.1091
05/10 02:42:27 - mmengine - INFO - Iter(train) [  6200/480000]  lr: 8.6104e-05  eta: 8 days, 1:06:39  time: 1.5043  data_time: 0.0060  memory: 9830  loss: 0.1950  grad_norm: 2.1115
05/10 02:42:40 - mmengine - INFO - Iter(train) [  6210/480000]  lr: 8.6243e-05  eta: 8 days, 1:03:45  time: 1.2577  data_time: 0.0056  memory: 9830  loss: 0.2064  grad_norm: 2.0980
05/10 02:42:53 - mmengine - INFO - Iter(train) [  6220/480000]  lr: 8.6382e-05  eta: 8 days, 1:01:11  time: 1.2853  data_time: 0.0057  memory: 9832  loss: 0.2049  grad_norm: 2.0980
05/10 02:43:08 - mmengine - INFO - Iter(train) [  6230/480000]  lr: 8.6521e-05  eta: 8 days, 1:01:21  time: 1.4988  data_time: 0.0060  memory: 9831  loss: 0.1968  grad_norm: 2.0740
05/10 02:43:20 - mmengine - INFO - Iter(train) [  6240/480000]  lr: 8.6660e-05  eta: 8 days, 0:57:57  time: 1.2166  data_time: 0.0056  memory: 9833  loss: 0.2050  grad_norm: 2.0479
05/10 02:43:37 - mmengine - INFO - Iter(train) [  6250/480000]  lr: 8.6799e-05  eta: 8 days, 1:00:32  time: 1.6905  data_time: 0.2060  memory: 9830  loss: 0.1557  grad_norm: 2.0479
05/10 02:43:49 - mmengine - INFO - Iter(train) [  6260/480000]  lr: 8.6938e-05  eta: 8 days, 0:57:31  time: 1.2467  data_time: 0.0058  memory: 9830  loss: 0.1720  grad_norm: 2.0489
05/10 02:44:02 - mmengine - INFO - Iter(train) [  6270/480000]  lr: 8.7077e-05  eta: 8 days, 0:55:05  time: 1.2924  data_time: 0.0057  memory: 9833  loss: 0.1667  grad_norm: 2.0489
05/10 02:44:17 - mmengine - INFO - Iter(train) [  6280/480000]  lr: 8.7216e-05  eta: 8 days, 0:55:08  time: 1.4901  data_time: 0.0058  memory: 9831  loss: 0.1656  grad_norm: 2.0630
05/10 02:44:30 - mmengine - INFO - Iter(train) [  6290/480000]  lr: 8.7354e-05  eta: 8 days, 0:52:27  time: 1.2711  data_time: 0.0057  memory: 9831  loss: 0.1690  grad_norm: 2.0301
05/10 02:44:45 - mmengine - INFO - Iter(train) [  6300/480000]  lr: 8.7493e-05  eta: 8 days, 0:52:20  time: 1.4765  data_time: 0.0058  memory: 9832  loss: 0.1740  grad_norm: 2.0301
05/10 02:44:58 - mmengine - INFO - Iter(train) [  6310/480000]  lr: 8.7632e-05  eta: 8 days, 0:50:00  time: 1.2990  data_time: 0.0057  memory: 9833  loss: 0.1709  grad_norm: 2.0531
05/10 02:45:11 - mmengine - INFO - Iter(train) [  6320/480000]  lr: 8.7771e-05  eta: 8 days, 0:47:47  time: 1.3078  data_time: 0.0058  memory: 9828  loss: 0.1692  grad_norm: 2.0157
05/10 02:45:25 - mmengine - INFO - Iter(train) [  6330/480000]  lr: 8.7910e-05  eta: 8 days, 0:47:29  time: 1.4601  data_time: 0.0057  memory: 9830  loss: 0.1681  grad_norm: 2.0157
05/10 02:45:38 - mmengine - INFO - Iter(train) [  6340/480000]  lr: 8.8049e-05  eta: 8 days, 0:44:54  time: 1.2772  data_time: 0.0058  memory: 9829  loss: 0.1629  grad_norm: 2.0153
05/10 02:45:53 - mmengine - INFO - Iter(train) [  6350/480000]  lr: 8.8188e-05  eta: 8 days, 0:44:29  time: 1.4508  data_time: 0.0058  memory: 9828  loss: 0.1689  grad_norm: 2.0153
05/10 02:46:06 - mmengine - INFO - Iter(train) [  6360/480000]  lr: 8.8327e-05  eta: 8 days, 0:42:19  time: 1.3110  data_time: 0.0060  memory: 9833  loss: 0.1789  grad_norm: 1.9929
05/10 02:46:19 - mmengine - INFO - Iter(train) [  6370/480000]  lr: 8.8466e-05  eta: 8 days, 0:40:06  time: 1.3054  data_time: 0.0058  memory: 9834  loss: 0.1663  grad_norm: 1.9666
05/10 02:46:33 - mmengine - INFO - Iter(train) [  6380/480000]  lr: 8.8604e-05  eta: 8 days, 0:39:45  time: 1.4552  data_time: 0.0058  memory: 9826  loss: 0.1854  grad_norm: 1.9666
05/10 02:46:46 - mmengine - INFO - Iter(train) [  6390/480000]  lr: 8.8743e-05  eta: 8 days, 0:37:19  time: 1.2877  data_time: 0.0059  memory: 9830  loss: 0.1766  grad_norm: 1.9631
05/10 02:46:59 - mmengine - INFO - Iter(train) [  6400/480000]  lr: 8.8882e-05  eta: 8 days, 0:34:16  time: 1.2363  data_time: 0.0058  memory: 9831  loss: 0.1987  grad_norm: 1.9979
05/10 02:47:16 - mmengine - INFO - Iter(train) [  6410/480000]  lr: 8.9021e-05  eta: 8 days, 0:37:47  time: 1.7700  data_time: 0.2060  memory: 9832  loss: 0.1422  grad_norm: 1.9979
05/10 02:47:29 - mmengine - INFO - Iter(train) [  6420/480000]  lr: 8.9160e-05  eta: 8 days, 0:35:18  time: 1.2820  data_time: 0.0058  memory: 9833  loss: 0.1462  grad_norm: 1.9734
05/10 02:47:42 - mmengine - INFO - Iter(train) [  6430/480000]  lr: 8.9299e-05  eta: 8 days, 0:32:42  time: 1.2713  data_time: 0.0058  memory: 9831  loss: 0.1437  grad_norm: 1.9734
05/10 02:47:56 - mmengine - INFO - Iter(train) [  6440/480000]  lr: 8.9438e-05  eta: 8 days, 0:32:26  time: 1.4620  data_time: 0.0057  memory: 9831  loss: 0.1489  grad_norm: 1.9348
05/10 02:48:10 - mmengine - INFO - Iter(train) [  6450/480000]  lr: 8.9577e-05  eta: 8 days, 0:30:15  time: 1.3054  data_time: 0.0058  memory: 9829  loss: 0.1579  grad_norm: 1.9515
05/10 02:48:24 - mmengine - INFO - Iter(train) [  6460/480000]  lr: 8.9716e-05  eta: 8 days, 0:30:05  time: 1.4695  data_time: 0.0058  memory: 9828  loss: 0.1526  grad_norm: 1.9515
05/10 02:48:37 - mmengine - INFO - Iter(train) [  6470/480000]  lr: 8.9855e-05  eta: 8 days, 0:27:38  time: 1.2835  data_time: 0.0058  memory: 9831  loss: 0.1602  grad_norm: 1.9462
05/10 02:48:50 - mmengine - INFO - Iter(train) [  6480/480000]  lr: 8.9993e-05  eta: 8 days, 0:25:15  time: 1.2876  data_time: 0.0057  memory: 9831  loss: 0.1460  grad_norm: 1.9650
05/10 02:49:05 - mmengine - INFO - Iter(train) [  6490/480000]  lr: 9.0132e-05  eta: 8 days, 0:25:03  time: 1.4663  data_time: 0.0057  memory: 9831  loss: 0.1610  grad_norm: 1.9650
05/10 02:49:18 - mmengine - INFO - Iter(train) [  6500/480000]  lr: 9.0271e-05  eta: 8 days, 0:22:48  time: 1.2967  data_time: 0.0058  memory: 9833  loss: 0.1442  grad_norm: 1.9413
05/10 02:49:18 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 02:49:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难判断呢。你的感受很重要，他是你的男朋友，你应该感到难过和困惑。可以和他好好谈谈，表达你的感受，也许他会意识到这个问题的。如果需要倾诉或者寻求建议，我在这里随时听你说哦。💖<|im_end|>

05/10 02:49:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哈哈，听起来你有点不太舒服呢。洗牙后可能会有一些暂时的不适，比如牙龈有些敏感，不过这是正常的。如果你觉得吹蜡烛的时候像鼓风机，可能需要再过一段时间再尝试，这样就不会太刺激到你的牙龈了。如果你实在不舒服，最好再咨询一下你的牙医哦。💖<|im_end|>

05/10 02:49:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
哎呀，饮酒要适量呢，健康最重要哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 02:49:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。你觉得心里舒服吗？💖我们可以一起想想怎么处理这种情况，或者聊聊别的事情分散一下注意力。🌸<|im_end|>

05/10 02:49:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下健康啦。胆固醇高的话，建议多选择一些低脂或者高纤维的食物呢，比如蒸、煮或者烤。戒掉炸鸡那可真是小事一桩啦，不过也别太过担心，饮食习惯是可以慢慢调整的。如果你需要一些健康的食谱或者建议，我这里也可以帮忙找哦！💖<|im_end|>

05/10 02:49:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这真是让人难过的情况呢。剧本杀本来是为了大家一起享受推理的乐趣，遇到这样的玩家确实会破坏气氛。你当时一定感到很沮丧吧。💖 想要谈谈你的感受，或者需要我帮你出出主意吗？<|im_end|>

05/10 02:49:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
栓Q啊，这是什么表情管理技能？同事的话可能只是无心的，你别太往心里去啦。要是真的不舒服，起来活动活动，或者找个角落吐口水，可能会好受一些。记得，别人的评论只是冰山一角，真正的你，才是让人心生向往的东西。💖<|im_end|>

05/10 02:49:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实有点隐蔽呢。不过，如果你愿意的话，可以悄悄告诉我，或许我能帮你找到解决方案。💖<|im_end|>

05/10 02:49:51 - mmengine - INFO - Saving checkpoint at 6500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 02:50:07 - mmengine - INFO - Iter(train) [  6510/480000]  lr: 9.0410e-05  eta: 8 days, 1:04:08  time: 4.8938  data_time: 3.4204  memory: 9833  loss: 0.1586  grad_norm: 1.9413
05/10 02:50:20 - mmengine - INFO - Iter(train) [  6520/480000]  lr: 9.0549e-05  eta: 8 days, 1:01:51  time: 1.2992  data_time: 0.0058  memory: 9830  loss: 0.1574  grad_norm: 1.9243
05/10 02:50:32 - mmengine - INFO - Iter(train) [  6530/480000]  lr: 9.0688e-05  eta: 8 days, 0:59:24  time: 1.2842  data_time: 0.0058  memory: 9829  loss: 0.1551  grad_norm: 1.8977
05/10 02:50:47 - mmengine - INFO - Iter(train) [  6540/480000]  lr: 9.0827e-05  eta: 8 days, 0:59:00  time: 1.4548  data_time: 0.0059  memory: 9830  loss: 0.1659  grad_norm: 1.8977
05/10 02:51:00 - mmengine - INFO - Iter(train) [  6550/480000]  lr: 9.0966e-05  eta: 8 days, 0:56:44  time: 1.3005  data_time: 0.0058  memory: 9835  loss: 0.1588  grad_norm: 1.8817
05/10 02:51:14 - mmengine - INFO - Iter(train) [  6560/480000]  lr: 9.1105e-05  eta: 8 days, 0:55:50  time: 1.4123  data_time: 0.0057  memory: 9834  loss: 0.1709  grad_norm: 1.8484
05/10 02:51:29 - mmengine - INFO - Iter(train) [  6570/480000]  lr: 9.1244e-05  eta: 8 days, 0:55:52  time: 1.4902  data_time: 0.2061  memory: 9832  loss: 0.1289  grad_norm: 1.8484
05/10 02:51:42 - mmengine - INFO - Iter(train) [  6580/480000]  lr: 9.1382e-05  eta: 8 days, 0:53:15  time: 1.2684  data_time: 0.0058  memory: 9831  loss: 0.1258  grad_norm: 1.8094
05/10 02:51:56 - mmengine - INFO - Iter(train) [  6590/480000]  lr: 9.1521e-05  eta: 8 days, 0:53:04  time: 1.4721  data_time: 0.0058  memory: 9833  loss: 0.1326  grad_norm: 1.8094
05/10 02:52:09 - mmengine - INFO - Iter(train) [  6600/480000]  lr: 9.1660e-05  eta: 8 days, 0:50:53  time: 1.3045  data_time: 0.0058  memory: 9832  loss: 0.1305  grad_norm: 1.8126
05/10 02:52:24 - mmengine - INFO - Iter(train) [  6610/480000]  lr: 9.1799e-05  eta: 8 days, 0:50:52  time: 1.4855  data_time: 0.0061  memory: 9832  loss: 0.1338  grad_norm: 1.8061
05/10 02:52:37 - mmengine - INFO - Iter(train) [  6620/480000]  lr: 9.1938e-05  eta: 8 days, 0:48:18  time: 1.2725  data_time: 0.0058  memory: 9828  loss: 0.1393  grad_norm: 1.8061
05/10 02:52:50 - mmengine - INFO - Iter(train) [  6630/480000]  lr: 9.2077e-05  eta: 8 days, 0:46:00  time: 1.2929  data_time: 0.0058  memory: 9831  loss: 0.1328  grad_norm: 1.7552
05/10 02:53:05 - mmengine - INFO - Iter(train) [  6640/480000]  lr: 9.2216e-05  eta: 8 days, 0:46:03  time: 1.4910  data_time: 0.0058  memory: 9833  loss: 0.1410  grad_norm: 1.7514
05/10 02:53:18 - mmengine - INFO - Iter(train) [  6650/480000]  lr: 9.2355e-05  eta: 8 days, 0:43:52  time: 1.3020  data_time: 0.0057  memory: 9832  loss: 0.1317  grad_norm: 1.7514
05/10 02:53:32 - mmengine - INFO - Iter(train) [  6660/480000]  lr: 9.2494e-05  eta: 8 days, 0:43:22  time: 1.4455  data_time: 0.0058  memory: 9831  loss: 0.1429  grad_norm: 1.7705
05/10 02:53:45 - mmengine - INFO - Iter(train) [  6670/480000]  lr: 9.2633e-05  eta: 8 days, 0:40:48  time: 1.2695  data_time: 0.0058  memory: 9830  loss: 0.1467  grad_norm: 1.7705
05/10 02:53:58 - mmengine - INFO - Iter(train) [  6680/480000]  lr: 9.2771e-05  eta: 8 days, 0:38:31  time: 1.2924  data_time: 0.0059  memory: 9831  loss: 0.1486  grad_norm: 1.7648
05/10 02:54:13 - mmengine - INFO - Iter(train) [  6690/480000]  lr: 9.2910e-05  eta: 8 days, 0:38:34  time: 1.4894  data_time: 0.0058  memory: 9832  loss: 0.1470  grad_norm: 1.8088
05/10 02:54:26 - mmengine - INFO - Iter(train) [  6700/480000]  lr: 9.3049e-05  eta: 8 days, 0:36:16  time: 1.2914  data_time: 0.0057  memory: 9833  loss: 0.1538  grad_norm: 1.8088
05/10 02:54:40 - mmengine - INFO - Iter(train) [  6710/480000]  lr: 9.3188e-05  eta: 8 days, 0:36:01  time: 1.4638  data_time: 0.0058  memory: 9832  loss: 0.1497  grad_norm: 1.8548
05/10 02:54:53 - mmengine - INFO - Iter(train) [  6720/480000]  lr: 9.3327e-05  eta: 8 days, 0:33:00  time: 1.2297  data_time: 0.0058  memory: 9833  loss: 0.1512  grad_norm: 1.8097
05/10 02:55:08 - mmengine - INFO - Iter(train) [  6730/480000]  lr: 9.3466e-05  eta: 8 days, 0:33:19  time: 1.5125  data_time: 0.2058  memory: 9828  loss: 0.1205  grad_norm: 1.8097
05/10 02:55:23 - mmengine - INFO - Iter(train) [  6740/480000]  lr: 9.3605e-05  eta: 8 days, 0:33:11  time: 1.4741  data_time: 0.0057  memory: 9830  loss: 0.1209  grad_norm: 1.8470
05/10 02:55:35 - mmengine - INFO - Iter(train) [  6750/480000]  lr: 9.3744e-05  eta: 8 days, 0:30:38  time: 1.2664  data_time: 0.0057  memory: 9827  loss: 0.1166  grad_norm: 1.8470
05/10 02:55:50 - mmengine - INFO - Iter(train) [  6760/480000]  lr: 9.3883e-05  eta: 8 days, 0:30:12  time: 1.4484  data_time: 0.0058  memory: 9835  loss: 0.1166  grad_norm: 1.8395
05/10 02:56:03 - mmengine - INFO - Iter(train) [  6770/480000]  lr: 9.4021e-05  eta: 8 days, 0:27:58  time: 1.2942  data_time: 0.0058  memory: 9835  loss: 0.1182  grad_norm: 1.8049
05/10 02:56:16 - mmengine - INFO - Iter(train) [  6780/480000]  lr: 9.4160e-05  eta: 8 days, 0:25:48  time: 1.2989  data_time: 0.0057  memory: 9834  loss: 0.1168  grad_norm: 1.8049
05/10 02:56:30 - mmengine - INFO - Iter(train) [  6790/480000]  lr: 9.4299e-05  eta: 8 days, 0:25:32  time: 1.4622  data_time: 0.0058  memory: 9833  loss: 0.1152  grad_norm: 1.7992
05/10 02:56:43 - mmengine - INFO - Iter(train) [  6800/480000]  lr: 9.4438e-05  eta: 8 days, 0:23:07  time: 1.2765  data_time: 0.0058  memory: 9834  loss: 0.1190  grad_norm: 1.7678
05/10 02:56:58 - mmengine - INFO - Iter(train) [  6810/480000]  lr: 9.4577e-05  eta: 8 days, 0:23:06  time: 1.4824  data_time: 0.0058  memory: 9832  loss: 0.1251  grad_norm: 1.7678
05/10 02:57:11 - mmengine - INFO - Iter(train) [  6820/480000]  lr: 9.4716e-05  eta: 8 days, 0:20:53  time: 1.2930  data_time: 0.0057  memory: 9833  loss: 0.1263  grad_norm: 1.7236
05/10 02:57:24 - mmengine - INFO - Iter(train) [  6830/480000]  lr: 9.4855e-05  eta: 8 days, 0:18:41  time: 1.2945  data_time: 0.0059  memory: 9832  loss: 0.1290  grad_norm: 1.7236
05/10 02:57:38 - mmengine - INFO - Iter(train) [  6840/480000]  lr: 9.4994e-05  eta: 8 days, 0:18:21  time: 1.4558  data_time: 0.0059  memory: 9830  loss: 0.1370  grad_norm: 1.7175
05/10 02:57:51 - mmengine - INFO - Iter(train) [  6850/480000]  lr: 9.5133e-05  eta: 8 days, 0:15:52  time: 1.2685  data_time: 0.0058  memory: 9831  loss: 0.1328  grad_norm: 1.6975
05/10 02:58:06 - mmengine - INFO - Iter(train) [  6860/480000]  lr: 9.5272e-05  eta: 8 days, 0:16:07  time: 1.5056  data_time: 0.0058  memory: 9829  loss: 0.1262  grad_norm: 1.6975
05/10 02:58:19 - mmengine - INFO - Iter(train) [  6870/480000]  lr: 9.5410e-05  eta: 8 days, 0:14:04  time: 1.3054  data_time: 0.0058  memory: 9833  loss: 0.1499  grad_norm: 1.6593
05/10 02:58:31 - mmengine - INFO - Iter(train) [  6880/480000]  lr: 9.5549e-05  eta: 8 days, 0:11:01  time: 1.2181  data_time: 0.0055  memory: 9833  loss: 0.1455  grad_norm: 1.6879
05/10 02:58:48 - mmengine - INFO - Iter(train) [  6890/480000]  lr: 9.5688e-05  eta: 8 days, 0:13:21  time: 1.6874  data_time: 0.2060  memory: 9833  loss: 0.1015  grad_norm: 1.6879
05/10 02:59:01 - mmengine - INFO - Iter(train) [  6900/480000]  lr: 9.5827e-05  eta: 8 days, 0:11:04  time: 1.2842  data_time: 0.0057  memory: 9832  loss: 0.1112  grad_norm: 1.6706
05/10 02:59:16 - mmengine - INFO - Iter(train) [  6910/480000]  lr: 9.5966e-05  eta: 8 days, 0:11:07  time: 1.4876  data_time: 0.0058  memory: 9832  loss: 0.1123  grad_norm: 1.6706
05/10 02:59:28 - mmengine - INFO - Iter(train) [  6920/480000]  lr: 9.6105e-05  eta: 8 days, 0:08:33  time: 1.2597  data_time: 0.0057  memory: 9835  loss: 0.1100  grad_norm: 1.6826
05/10 02:59:41 - mmengine - INFO - Iter(train) [  6930/480000]  lr: 9.6244e-05  eta: 8 days, 0:06:11  time: 1.2742  data_time: 0.0058  memory: 9836  loss: 0.1103  grad_norm: 1.6874
05/10 02:59:56 - mmengine - INFO - Iter(train) [  6940/480000]  lr: 9.6383e-05  eta: 8 days, 0:06:04  time: 1.4733  data_time: 0.0058  memory: 9832  loss: 0.1088  grad_norm: 1.6874
05/10 03:00:09 - mmengine - INFO - Iter(train) [  6950/480000]  lr: 9.6522e-05  eta: 8 days, 0:03:49  time: 1.2862  data_time: 0.0056  memory: 9833  loss: 0.1082  grad_norm: 1.6859
05/10 03:00:24 - mmengine - INFO - Iter(train) [  6960/480000]  lr: 9.6661e-05  eta: 8 days, 0:04:10  time: 1.5128  data_time: 0.0060  memory: 9833  loss: 0.1153  grad_norm: 1.6913
05/10 03:00:36 - mmengine - INFO - Iter(train) [  6970/480000]  lr: 9.6799e-05  eta: 8 days, 0:01:38  time: 1.2604  data_time: 0.0056  memory: 9836  loss: 0.1090  grad_norm: 1.6913
05/10 03:00:49 - mmengine - INFO - Iter(train) [  6980/480000]  lr: 9.6938e-05  eta: 7 days, 23:59:33  time: 1.2974  data_time: 0.0058  memory: 9834  loss: 0.1175  grad_norm: 1.6947
05/10 03:01:04 - mmengine - INFO - Iter(train) [  6990/480000]  lr: 9.7077e-05  eta: 7 days, 23:59:32  time: 1.4820  data_time: 0.0058  memory: 9834  loss: 0.1178  grad_norm: 1.6947
05/10 03:01:17 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 03:01:17 - mmengine - INFO - Iter(train) [  7000/480000]  lr: 9.7216e-05  eta: 7 days, 23:57:10  time: 1.2732  data_time: 0.0056  memory: 9834  loss: 0.1180  grad_norm: 1.7269
05/10 03:01:17 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 03:01:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。首先，你要知道，你的男朋友是唯一最重要的人，他的心意对你来说同样重要。精神出轨是不应该被容忍的，因为它破坏了你们之间的信任。你可以和你的男朋友坦诚地谈谈，表达你的感受和担忧。他们的关系需要维护和修复，所以不要犹豫，寻求合适的解决方案。💖如果你需要倾诉或者寻求更多的建议，我在这里随时愿意倾听。<|im_end|>

05/10 03:01:30 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哈哈，听起来你现在已经体验到了牙齿清洁后的效果呢~ 如果还是觉得牙缝有点明显，可以试试使用牙线或者牙间隙刷来帮忙。同时，也要注意口腔卫生的保持哦！如果还是不舒服，最好再咨询一下牙医哦。💖<|im_end|>

05/10 03:01:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 03:01:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
哎呀，这听起来确实让人有些不舒服呢。你觉得他们之间的互动让你感到不舒服吗？如果让你感到不舒服，可以和你的闺蜜沟通一下，表达你的感受。同时，也可以和你的前任谈谈，表达你的感受和隐私保护的意识。毕竟，每个人的社交媒体账号都是私人空间，希望你们都能维护好自己的权益。💖如果你需要倾诉或者寻求建议，我在这里哦。<|im_end|>

05/10 03:01:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下健康啦。胆固醇高的话，建议多选择一些低脂或者高脂肪的鸡肉，比如烤鸡或者蒸鸡。不过，戒掉炸鸡也不是一件容易的事情哦。可以适量吃，不过还是要注意均衡饮食啦。💖如果你需要一些健康的食谱或者建议，我可以帮你找哦！<|im_end|>

05/10 03:01:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的泥石流”吗？😱 下次记得带个“剧本杀手”技能，别让这种人破坏你的娱乐体验啦！<|im_end|>

05/10 03:01:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
栓Q啊，这是什么迷惑表达？是你的眼线太夸张了吗？还是同事不懂审美？别太往心里去，下次写个演示文稿给他们看看，你的眼线也是你的风格啊！🌟<|im_end|>

05/10 03:02:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
哎呀，看来今天有点儿尴尬呢~ 不过别太在意，有时候领导可能是出于好意，保密性很重要哦。你可以尝试私下里和领导沟通一下，表达一下你的想法和需求，也许他们会考虑到你的感受呢。毕竟，了解员工的需求和喜好，也是保证工作效果的重要环节。如果你需要一些建议或者只是想聊聊天，我都在这里哦。💖<|im_end|>

05/10 03:02:02 - mmengine - INFO - Saving checkpoint at 7000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 03:02:15 - mmengine - INFO - Iter(train) [  7010/480000]  lr: 9.7355e-05  eta: 8 days, 0:46:02  time: 5.8280  data_time: 4.5435  memory: 9834  loss: 0.1168  grad_norm: 1.6891
05/10 03:02:28 - mmengine - INFO - Iter(train) [  7020/480000]  lr: 9.7494e-05  eta: 8 days, 0:43:48  time: 1.2897  data_time: 0.0057  memory: 9832  loss: 0.1174  grad_norm: 1.6891
05/10 03:02:43 - mmengine - INFO - Iter(train) [  7030/480000]  lr: 9.7633e-05  eta: 8 days, 0:43:38  time: 1.4733  data_time: 0.0057  memory: 9832  loss: 0.1268  grad_norm: 1.6760
05/10 03:02:55 - mmengine - INFO - Iter(train) [  7040/480000]  lr: 9.7772e-05  eta: 8 days, 0:40:24  time: 1.2005  data_time: 0.0055  memory: 9832  loss: 0.1204  grad_norm: 1.6437
05/10 03:03:12 - mmengine - INFO - Iter(train) [  7050/480000]  lr: 9.7911e-05  eta: 8 days, 0:43:03  time: 1.7259  data_time: 0.2060  memory: 9834  loss: 0.0999  grad_norm: 1.6437
05/10 03:03:25 - mmengine - INFO - Iter(train) [  7060/480000]  lr: 9.8049e-05  eta: 8 days, 0:40:30  time: 1.2600  data_time: 0.0056  memory: 9833  loss: 0.0921  grad_norm: 1.6349
05/10 03:03:37 - mmengine - INFO - Iter(train) [  7070/480000]  lr: 9.8188e-05  eta: 8 days, 0:38:04  time: 1.2697  data_time: 0.0058  memory: 9833  loss: 0.0934  grad_norm: 1.6349
05/10 03:03:52 - mmengine - INFO - Iter(train) [  7080/480000]  lr: 9.8327e-05  eta: 8 days, 0:37:49  time: 1.4668  data_time: 0.0056  memory: 9831  loss: 0.1040  grad_norm: 1.6058
05/10 03:04:05 - mmengine - INFO - Iter(train) [  7090/480000]  lr: 9.8466e-05  eta: 8 days, 0:35:37  time: 1.2897  data_time: 0.0057  memory: 9830  loss: 0.0970  grad_norm: 1.5979
05/10 03:04:20 - mmengine - INFO - Iter(train) [  7100/480000]  lr: 9.8605e-05  eta: 8 days, 0:35:59  time: 1.5216  data_time: 0.0057  memory: 9832  loss: 0.0926  grad_norm: 1.5979
05/10 03:04:33 - mmengine - INFO - Iter(train) [  7110/480000]  lr: 9.8744e-05  eta: 8 days, 0:33:22  time: 1.2513  data_time: 0.0055  memory: 9834  loss: 0.0988  grad_norm: 1.5773
05/10 03:04:46 - mmengine - INFO - Iter(train) [  7120/480000]  lr: 9.8883e-05  eta: 8 days, 0:31:12  time: 1.2929  data_time: 0.0056  memory: 9834  loss: 0.0989  grad_norm: 1.5508
05/10 03:05:00 - mmengine - INFO - Iter(train) [  7130/480000]  lr: 9.9022e-05  eta: 8 days, 0:31:03  time: 1.4736  data_time: 0.0057  memory: 9833  loss: 0.1027  grad_norm: 1.5508
05/10 03:05:13 - mmengine - INFO - Iter(train) [  7140/480000]  lr: 9.9161e-05  eta: 8 days, 0:28:55  time: 1.2948  data_time: 0.0056  memory: 9833  loss: 0.0999  grad_norm: 1.5304
05/10 03:05:28 - mmengine - INFO - Iter(train) [  7150/480000]  lr: 9.9300e-05  eta: 8 days, 0:28:56  time: 1.4888  data_time: 0.0057  memory: 9832  loss: 0.1037  grad_norm: 1.5304
05/10 03:05:41 - mmengine - INFO - Iter(train) [  7160/480000]  lr: 9.9438e-05  eta: 8 days, 0:26:34  time: 1.2728  data_time: 0.0058  memory: 9835  loss: 0.1062  grad_norm: 1.4597
05/10 03:05:54 - mmengine - INFO - Iter(train) [  7170/480000]  lr: 9.9577e-05  eta: 8 days, 0:24:20  time: 1.2847  data_time: 0.0057  memory: 9835  loss: 0.1048  grad_norm: 1.4758
05/10 03:06:09 - mmengine - INFO - Iter(train) [  7180/480000]  lr: 9.9716e-05  eta: 8 days, 0:24:17  time: 1.4829  data_time: 0.0057  memory: 9835  loss: 0.1082  grad_norm: 1.4758
05/10 03:06:22 - mmengine - INFO - Iter(train) [  7190/480000]  lr: 9.9855e-05  eta: 8 days, 0:22:15  time: 1.3008  data_time: 0.0057  memory: 9833  loss: 0.1106  grad_norm: 1.4462
05/10 03:06:36 - mmengine - INFO - Iter(train) [  7200/480000]  lr: 9.9994e-05  eta: 8 days, 0:21:16  time: 1.3970  data_time: 0.0056  memory: 9833  loss: 0.1119  grad_norm: 1.4264
05/10 03:06:51 - mmengine - INFO - Iter(train) [  7210/480000]  lr: 1.0013e-04  eta: 8 days, 0:21:25  time: 1.5018  data_time: 0.2060  memory: 9836  loss: 0.0846  grad_norm: 1.4264
05/10 03:07:04 - mmengine - INFO - Iter(train) [  7220/480000]  lr: 1.0027e-04  eta: 8 days, 0:19:19  time: 1.2938  data_time: 0.0057  memory: 9837  loss: 0.0863  grad_norm: 1.4094
05/10 03:07:18 - mmengine - INFO - Iter(train) [  7230/480000]  lr: 1.0041e-04  eta: 8 days, 0:19:11  time: 1.4754  data_time: 0.0058  memory: 9839  loss: 0.0835  grad_norm: 1.4094
05/10 03:07:31 - mmengine - INFO - Iter(train) [  7240/480000]  lr: 1.0055e-04  eta: 8 days, 0:16:52  time: 1.2730  data_time: 0.0056  memory: 9836  loss: 0.0950  grad_norm: 1.3833
05/10 03:07:46 - mmengine - INFO - Iter(train) [  7250/480000]  lr: 1.0069e-04  eta: 8 days, 0:16:26  time: 1.4475  data_time: 0.0057  memory: 9836  loss: 0.0853  grad_norm: 1.3573
05/10 03:07:58 - mmengine - INFO - Iter(train) [  7260/480000]  lr: 1.0083e-04  eta: 8 days, 0:14:16  time: 1.2871  data_time: 0.0057  memory: 9834  loss: 0.0921  grad_norm: 1.3573
05/10 03:08:11 - mmengine - INFO - Iter(train) [  7270/480000]  lr: 1.0097e-04  eta: 8 days, 0:12:13  time: 1.2968  data_time: 0.0058  memory: 9835  loss: 0.0942  grad_norm: 1.3596
05/10 03:08:26 - mmengine - INFO - Iter(train) [  7280/480000]  lr: 1.0111e-04  eta: 8 days, 0:12:03  time: 1.4713  data_time: 0.0056  memory: 9835  loss: 0.0934  grad_norm: 1.3682
05/10 03:08:39 - mmengine - INFO - Iter(train) [  7290/480000]  lr: 1.0124e-04  eta: 8 days, 0:09:48  time: 1.2785  data_time: 0.0057  memory: 9830  loss: 0.0933  grad_norm: 1.3682
05/10 03:08:54 - mmengine - INFO - Iter(train) [  7300/480000]  lr: 1.0138e-04  eta: 8 days, 0:09:35  time: 1.4654  data_time: 0.0057  memory: 9833  loss: 0.0971  grad_norm: 1.3628
05/10 03:09:07 - mmengine - INFO - Iter(train) [  7310/480000]  lr: 1.0152e-04  eta: 8 days, 0:07:33  time: 1.2967  data_time: 0.0058  memory: 9834  loss: 0.1028  grad_norm: 1.3628
05/10 03:09:19 - mmengine - INFO - Iter(train) [  7320/480000]  lr: 1.0166e-04  eta: 8 days, 0:05:31  time: 1.2975  data_time: 0.0058  memory: 9834  loss: 0.1065  grad_norm: 1.3820
05/10 03:09:34 - mmengine - INFO - Iter(train) [  7330/480000]  lr: 1.0180e-04  eta: 8 days, 0:05:08  time: 1.4509  data_time: 0.0057  memory: 9836  loss: 0.1065  grad_norm: 1.3601
05/10 03:09:47 - mmengine - INFO - Iter(train) [  7340/480000]  lr: 1.0194e-04  eta: 8 days, 0:02:50  time: 1.2713  data_time: 0.0058  memory: 9834  loss: 0.1010  grad_norm: 1.3601
05/10 03:10:02 - mmengine - INFO - Iter(train) [  7350/480000]  lr: 1.0208e-04  eta: 8 days, 0:02:46  time: 1.4788  data_time: 0.0057  memory: 9833  loss: 0.1035  grad_norm: 1.3664
05/10 03:10:14 - mmengine - INFO - Iter(train) [  7360/480000]  lr: 1.0222e-04  eta: 8 days, 0:00:11  time: 1.2434  data_time: 0.0056  memory: 9836  loss: 0.1112  grad_norm: 1.3733
05/10 03:10:29 - mmengine - INFO - Iter(train) [  7370/480000]  lr: 1.0236e-04  eta: 8 days, 0:00:24  time: 1.5063  data_time: 0.2058  memory: 9836  loss: 0.0851  grad_norm: 1.3733
05/10 03:10:44 - mmengine - INFO - Iter(train) [  7380/480000]  lr: 1.0249e-04  eta: 8 days, 0:00:13  time: 1.4680  data_time: 0.0058  memory: 9837  loss: 0.0806  grad_norm: 1.3719
05/10 03:10:57 - mmengine - INFO - Iter(train) [  7390/480000]  lr: 1.0263e-04  eta: 7 days, 23:58:07  time: 1.2881  data_time: 0.0057  memory: 9837  loss: 0.0870  grad_norm: 1.3719
05/10 03:11:11 - mmengine - INFO - Iter(train) [  7400/480000]  lr: 1.0277e-04  eta: 7 days, 23:58:00  time: 1.4745  data_time: 0.0057  memory: 9835  loss: 0.0884  grad_norm: 1.4162
05/10 03:11:24 - mmengine - INFO - Iter(train) [  7410/480000]  lr: 1.0291e-04  eta: 7 days, 23:55:54  time: 1.2881  data_time: 0.0057  memory: 9835  loss: 0.0894  grad_norm: 1.4280
05/10 03:11:37 - mmengine - INFO - Iter(train) [  7420/480000]  lr: 1.0305e-04  eta: 7 days, 23:53:38  time: 1.2707  data_time: 0.0057  memory: 9835  loss: 0.0842  grad_norm: 1.4280
05/10 03:11:50 - mmengine - INFO - Iter(train) [  7430/480000]  lr: 1.0319e-04  eta: 7 days, 23:51:24  time: 1.2750  data_time: 0.0057  memory: 9833  loss: 0.0866  grad_norm: 1.4243
05/10 03:12:03 - mmengine - INFO - Iter(train) [  7440/480000]  lr: 1.0333e-04  eta: 7 days, 23:49:30  time: 1.3037  data_time: 0.0058  memory: 9834  loss: 0.0988  grad_norm: 1.4452
05/10 03:12:16 - mmengine - INFO - Iter(train) [  7450/480000]  lr: 1.0347e-04  eta: 7 days, 23:47:35  time: 1.3037  data_time: 0.0059  memory: 9835  loss: 0.0941  grad_norm: 1.4452
05/10 03:12:33 - mmengine - INFO - Iter(train) [  7460/480000]  lr: 1.0361e-04  eta: 7 days, 23:50:01  time: 1.7145  data_time: 0.0057  memory: 9834  loss: 0.0942  grad_norm: 1.4618
05/10 03:12:46 - mmengine - INFO - Iter(train) [  7470/480000]  lr: 1.0374e-04  eta: 7 days, 23:47:55  time: 1.2861  data_time: 0.0058  memory: 9833  loss: 0.0965  grad_norm: 1.4618
05/10 03:12:59 - mmengine - INFO - Iter(train) [  7480/480000]  lr: 1.0388e-04  eta: 7 days, 23:45:51  time: 1.2878  data_time: 0.0056  memory: 9834  loss: 0.0993  grad_norm: 1.4659
05/10 03:13:13 - mmengine - INFO - Iter(train) [  7490/480000]  lr: 1.0402e-04  eta: 7 days, 23:45:49  time: 1.4805  data_time: 0.0058  memory: 9833  loss: 0.0948  grad_norm: 1.4745
05/10 03:13:26 - mmengine - INFO - Iter(train) [  7500/480000]  lr: 1.0416e-04  eta: 7 days, 23:43:38  time: 1.2759  data_time: 0.0058  memory: 9834  loss: 0.1053  grad_norm: 1.4745
05/10 03:13:26 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 03:13:28 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。感情的事情有时候确实挺复杂的。你觉得心里怎么样呢？💖<|im_end|>

05/10 03:13:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《哈利·波特》了。下次洗牙记得跟牙医沟通好，要求他们精细化操作，别让牙缝比战场还刺激。退退退，小心别让牙医把你的蜡烛吹灭了，安全第一啊！<|im_end|>

05/10 03:13:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要我帮你找一些放松的方法呢？💖<|im_end|>

05/10 03:13:40 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
哎呀，这种事情确实让人挺不舒服的。你可以和她（他）坦诚地谈谈，表达一下你的感受。如果需要，我可以帮你想想怎么跟她说。💖<|im_end|>

05/10 03:13:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高的话，注意饮食均衡哦。适当减少炸鸡的摄入量是可以的，但是也不要过量哦。可以考虑吃一些健康的替代品，比如烤鸡或者蒸鸡。同时，多喝水，保持良好的生活习惯，也很有助于保持胆固醇水平正常。如果你需要更多的健康建议，我可以帮你查找相关信息哦。💖<|im_end|>

05/10 03:13:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这真是让人难过的事情呢。剧本杀本来是个大家开心推理的游戏，遇到这样的玩家确实会破坏气氛。你当时一定感到很沮丧吧。💖 想要谈谈具体发生了什么吗？也许我能帮你出出主意，怎么处理这种情况。🌸<|im_end|>

05/10 03:13:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
温柔
哎呀，别太放在心上呢，有时候别人的评论其实是他们不理解你的风格而已。你觉得怎么样呢？有没有什么办法能让他们理解你的艺术追求呢？💖<|im_end|>

05/10 03:14:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的语音矩阵发布得很突然，可能你没有注意到可能是有原因的。你可以尝试私下里跟领导沟通一下，表达一下你的想法和感受，也许他们会理解的。💖如果你还是觉得有必要装看不见，也可以稍微提前一些跟领导沟通，避免误会。记得保持冷静和尊重哦！🌸<|im_end|>

05/10 03:14:02 - mmengine - INFO - Saving checkpoint at 7500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 03:14:18 - mmengine - INFO - Iter(train) [  7510/480000]  lr: 1.0430e-04  eta: 8 days, 0:22:10  time: 5.1588  data_time: 3.6575  memory: 9835  loss: 0.1011  grad_norm: 1.4849
05/10 03:14:30 - mmengine - INFO - Iter(train) [  7520/480000]  lr: 1.0444e-04  eta: 8 days, 0:18:56  time: 1.1808  data_time: 0.0056  memory: 9831  loss: 0.0998  grad_norm: 1.4765
05/10 03:14:47 - mmengine - INFO - Iter(train) [  7530/480000]  lr: 1.0458e-04  eta: 8 days, 0:21:13  time: 1.7072  data_time: 0.2061  memory: 9835  loss: 0.0751  grad_norm: 1.4765
05/10 03:14:59 - mmengine - INFO - Iter(train) [  7540/480000]  lr: 1.0472e-04  eta: 8 days, 0:18:51  time: 1.2626  data_time: 0.0056  memory: 9835  loss: 0.0751  grad_norm: 1.4649
05/10 03:15:12 - mmengine - INFO - Iter(train) [  7550/480000]  lr: 1.0486e-04  eta: 8 days, 0:16:48  time: 1.2927  data_time: 0.0058  memory: 9834  loss: 0.0733  grad_norm: 1.4649
05/10 03:15:27 - mmengine - INFO - Iter(train) [  7560/480000]  lr: 1.0499e-04  eta: 8 days, 0:16:46  time: 1.4853  data_time: 0.0060  memory: 9834  loss: 0.0820  grad_norm: 1.4356
05/10 03:15:40 - mmengine - INFO - Iter(train) [  7570/480000]  lr: 1.0513e-04  eta: 8 days, 0:14:15  time: 1.2454  data_time: 0.0057  memory: 9834  loss: 0.0822  grad_norm: 1.4249
05/10 03:15:55 - mmengine - INFO - Iter(train) [  7580/480000]  lr: 1.0527e-04  eta: 8 days, 0:14:23  time: 1.5020  data_time: 0.0059  memory: 9833  loss: 0.0869  grad_norm: 1.4249
05/10 03:16:07 - mmengine - INFO - Iter(train) [  7590/480000]  lr: 1.0541e-04  eta: 8 days, 0:12:09  time: 1.2724  data_time: 0.0056  memory: 9835  loss: 0.0867  grad_norm: 1.4654
05/10 03:16:20 - mmengine - INFO - Iter(train) [  7600/480000]  lr: 1.0555e-04  eta: 8 days, 0:10:15  time: 1.3050  data_time: 0.0057  memory: 9836  loss: 0.0828  grad_norm: 1.4395
05/10 03:16:35 - mmengine - INFO - Iter(train) [  7610/480000]  lr: 1.0569e-04  eta: 8 days, 0:10:08  time: 1.4781  data_time: 0.0058  memory: 9834  loss: 0.0889  grad_norm: 1.4395
05/10 03:16:48 - mmengine - INFO - Iter(train) [  7620/480000]  lr: 1.0583e-04  eta: 8 days, 0:07:49  time: 1.2639  data_time: 0.0056  memory: 9833  loss: 0.0884  grad_norm: 1.4488
05/10 03:17:03 - mmengine - INFO - Iter(train) [  7630/480000]  lr: 1.0597e-04  eta: 8 days, 0:08:08  time: 1.5180  data_time: 0.0057  memory: 9834  loss: 0.0917  grad_norm: 1.4488
05/10 03:17:16 - mmengine - INFO - Iter(train) [  7640/480000]  lr: 1.0611e-04  eta: 8 days, 0:05:51  time: 1.2661  data_time: 0.0056  memory: 9833  loss: 0.0953  grad_norm: 1.4464
05/10 03:17:28 - mmengine - INFO - Iter(train) [  7650/480000]  lr: 1.0624e-04  eta: 8 days, 0:03:48  time: 1.2891  data_time: 0.0057  memory: 9835  loss: 0.0864  grad_norm: 1.4545
05/10 03:17:43 - mmengine - INFO - Iter(train) [  7660/480000]  lr: 1.0638e-04  eta: 8 days, 0:03:31  time: 1.4594  data_time: 0.0058  memory: 9833  loss: 0.0906  grad_norm: 1.4545
05/10 03:17:56 - mmengine - INFO - Iter(train) [  7670/480000]  lr: 1.0652e-04  eta: 8 days, 0:01:15  time: 1.2672  data_time: 0.0057  memory: 9835  loss: 0.0924  grad_norm: 1.4233
05/10 03:18:10 - mmengine - INFO - Iter(train) [  7680/480000]  lr: 1.0666e-04  eta: 8 days, 0:00:59  time: 1.4611  data_time: 0.0058  memory: 9835  loss: 0.0987  grad_norm: 1.4366
05/10 03:18:26 - mmengine - INFO - Iter(train) [  7690/480000]  lr: 1.0680e-04  eta: 8 days, 0:01:17  time: 1.5173  data_time: 0.2058  memory: 9837  loss: 0.0718  grad_norm: 1.4366
05/10 03:18:38 - mmengine - INFO - Iter(train) [  7700/480000]  lr: 1.0694e-04  eta: 7 days, 23:59:16  time: 1.2897  data_time: 0.0058  memory: 9836  loss: 0.0666  grad_norm: 1.4308
05/10 03:18:53 - mmengine - INFO - Iter(train) [  7710/480000]  lr: 1.0708e-04  eta: 7 days, 23:58:59  time: 1.4589  data_time: 0.0057  memory: 9835  loss: 0.0663  grad_norm: 1.4308
05/10 03:19:06 - mmengine - INFO - Iter(train) [  7720/480000]  lr: 1.0722e-04  eta: 7 days, 23:57:05  time: 1.3006  data_time: 0.0058  memory: 9834  loss: 0.0695  grad_norm: 1.4104
05/10 03:19:21 - mmengine - INFO - Iter(train) [  7730/480000]  lr: 1.0736e-04  eta: 7 days, 23:56:55  time: 1.4709  data_time: 0.0058  memory: 9836  loss: 0.0701  grad_norm: 1.4056
05/10 03:19:33 - mmengine - INFO - Iter(train) [  7740/480000]  lr: 1.0749e-04  eta: 7 days, 23:54:44  time: 1.2727  data_time: 0.0058  memory: 9837  loss: 0.0676  grad_norm: 1.4056
05/10 03:19:46 - mmengine - INFO - Iter(train) [  7750/480000]  lr: 1.0763e-04  eta: 7 days, 23:52:34  time: 1.2739  data_time: 0.0058  memory: 9836  loss: 0.0670  grad_norm: 1.3265
05/10 03:20:01 - mmengine - INFO - Iter(train) [  7760/480000]  lr: 1.0777e-04  eta: 7 days, 23:52:23  time: 1.4680  data_time: 0.0059  memory: 9833  loss: 0.0740  grad_norm: 1.3045
05/10 03:20:14 - mmengine - INFO - Iter(train) [  7770/480000]  lr: 1.0791e-04  eta: 7 days, 23:50:28  time: 1.2985  data_time: 0.0058  memory: 9841  loss: 0.0734  grad_norm: 1.3045
05/10 03:20:28 - mmengine - INFO - Iter(train) [  7780/480000]  lr: 1.0805e-04  eta: 7 days, 23:50:14  time: 1.4630  data_time: 0.0059  memory: 9839  loss: 0.0779  grad_norm: 1.2545
05/10 03:20:41 - mmengine - INFO - Iter(train) [  7790/480000]  lr: 1.0819e-04  eta: 7 days, 23:48:08  time: 1.2794  data_time: 0.0058  memory: 9837  loss: 0.0766  grad_norm: 1.2545
05/10 03:20:54 - mmengine - INFO - Iter(train) [  7800/480000]  lr: 1.0833e-04  eta: 7 days, 23:46:10  time: 1.2907  data_time: 0.0058  memory: 9837  loss: 0.0820  grad_norm: 1.2223
05/10 03:21:09 - mmengine - INFO - Iter(train) [  7810/480000]  lr: 1.0847e-04  eta: 7 days, 23:46:04  time: 1.4772  data_time: 0.0058  memory: 9835  loss: 0.0806  grad_norm: 1.1782
05/10 03:21:22 - mmengine - INFO - Iter(train) [  7820/480000]  lr: 1.0861e-04  eta: 7 days, 23:44:07  time: 1.2919  data_time: 0.0057  memory: 9837  loss: 0.0845  grad_norm: 1.1782
05/10 03:21:36 - mmengine - INFO - Iter(train) [  7830/480000]  lr: 1.0874e-04  eta: 7 days, 23:43:46  time: 1.4513  data_time: 0.0059  memory: 9837  loss: 0.0777  grad_norm: 1.1598
05/10 03:21:48 - mmengine - INFO - Iter(train) [  7840/480000]  lr: 1.0888e-04  eta: 7 days, 23:41:01  time: 1.2116  data_time: 0.0057  memory: 9837  loss: 0.0810  grad_norm: 1.1186
05/10 03:22:04 - mmengine - INFO - Iter(train) [  7850/480000]  lr: 1.0902e-04  eta: 7 days, 23:41:25  time: 1.5259  data_time: 0.2060  memory: 9835  loss: 0.0633  grad_norm: 1.1186
05/10 03:22:19 - mmengine - INFO - Iter(train) [  7860/480000]  lr: 1.0916e-04  eta: 7 days, 23:41:27  time: 1.4891  data_time: 0.0057  memory: 9833  loss: 0.0637  grad_norm: 1.1120
05/10 03:22:31 - mmengine - INFO - Iter(train) [  7870/480000]  lr: 1.0930e-04  eta: 7 days, 23:39:22  time: 1.2772  data_time: 0.0057  memory: 9834  loss: 0.0627  grad_norm: 1.1120
05/10 03:22:46 - mmengine - INFO - Iter(train) [  7880/480000]  lr: 1.0944e-04  eta: 7 days, 23:39:21  time: 1.4849  data_time: 0.0058  memory: 9835  loss: 0.0618  grad_norm: 1.0989
05/10 03:22:59 - mmengine - INFO - Iter(train) [  7890/480000]  lr: 1.0958e-04  eta: 7 days, 23:37:18  time: 1.2796  data_time: 0.0057  memory: 9835  loss: 0.0666  grad_norm: 1.0807
05/10 03:23:12 - mmengine - INFO - Iter(train) [  7900/480000]  lr: 1.0972e-04  eta: 7 days, 23:35:27  time: 1.3010  data_time: 0.0058  memory: 9838  loss: 0.0667  grad_norm: 1.0807
05/10 03:23:27 - mmengine - INFO - Iter(train) [  7910/480000]  lr: 1.0986e-04  eta: 7 days, 23:35:14  time: 1.4623  data_time: 0.0057  memory: 9837  loss: 0.0669  grad_norm: 1.0891
05/10 03:23:39 - mmengine - INFO - Iter(train) [  7920/480000]  lr: 1.0999e-04  eta: 7 days, 23:33:03  time: 1.2670  data_time: 0.0058  memory: 9835  loss: 0.0681  grad_norm: 1.0957
05/10 03:23:54 - mmengine - INFO - Iter(train) [  7930/480000]  lr: 1.1013e-04  eta: 7 days, 23:32:59  time: 1.4786  data_time: 0.0058  memory: 9835  loss: 0.0779  grad_norm: 1.0957
05/10 03:24:07 - mmengine - INFO - Iter(train) [  7940/480000]  lr: 1.1027e-04  eta: 7 days, 23:31:07  time: 1.2968  data_time: 0.0057  memory: 9834  loss: 0.0741  grad_norm: 1.1206
05/10 03:24:20 - mmengine - INFO - Iter(train) [  7950/480000]  lr: 1.1041e-04  eta: 7 days, 23:29:16  time: 1.2980  data_time: 0.0056  memory: 9831  loss: 0.0759  grad_norm: 1.1206
05/10 03:24:35 - mmengine - INFO - Iter(train) [  7960/480000]  lr: 1.1055e-04  eta: 7 days, 23:29:04  time: 1.4637  data_time: 0.0057  memory: 9837  loss: 0.0808  grad_norm: 1.1189
05/10 03:24:48 - mmengine - INFO - Iter(train) [  7970/480000]  lr: 1.1069e-04  eta: 7 days, 23:27:05  time: 1.2852  data_time: 0.0057  memory: 9836  loss: 0.0778  grad_norm: 1.1255
05/10 03:25:02 - mmengine - INFO - Iter(train) [  7980/480000]  lr: 1.1083e-04  eta: 7 days, 23:27:04  time: 1.4827  data_time: 0.0060  memory: 9837  loss: 0.0776  grad_norm: 1.1255
05/10 03:25:15 - mmengine - INFO - Iter(train) [  7990/480000]  lr: 1.1097e-04  eta: 7 days, 23:25:05  time: 1.2839  data_time: 0.0056  memory: 9835  loss: 0.0791  grad_norm: 1.1319
05/10 03:25:28 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 03:25:28 - mmengine - INFO - Iter(train) [  8000/480000]  lr: 1.1111e-04  eta: 7 days, 23:22:33  time: 1.2259  data_time: 0.0057  memory: 9836  loss: 0.0847  grad_norm: 1.1259
05/10 03:25:28 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 03:25:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。首先，理解你感到很沮丧。男性的这种行为确实涉及到了对主播的过度关注和情感投入，这可能会影响到你们之间的感情。这种情况下，沟通是很重要的。你可以和他坦诚地谈谈你的感受，告诉他你对这种行为的看法，并表达你希望如何处理这种情况。毕竟，精神出轨对两个人的感情伤害是无法用金钱来衡量的。💖

如果你需要倾诉或者寻求更多的建议，我在这里愿意倾听和帮助你。<|im_end|>

05/10 03:25:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得跟牙医沟通好，看看能不能优化一下你的“吹蜡烛技巧”，别让牙缝比吹口哨还大啊！🦷🎈<|im_end|>

05/10 03:25:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 03:25:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种情况确实让人有些不舒服呢。你可以和她沟通一下，表达一下你的感受，毕竟朋友之间的界限很重要。如果需要倾诉或者寻求建议，我在这里哦。💖<|im_end|>

05/10 03:25:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实需要注意健康啦。胆固醇高的话，建议多吃一些高脂肪食物之外，还要注意饮食均衡呢。戒掉炸鸡可能是需要稍微调整一下饮食计划的，但是健康最重要哦。可以考虑替换为健康的烤、煮或者蒸来代替炸鸡，这样既能满足口感，又不会摄入太多油脂。💖 你有什么其他健康方面的问题吗？我在这里可以帮助你查找相关信息。🌸<|im_end|>

05/10 03:25:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？下次记得检查剧本内容，别让那些“读本大师”抢了你的戏！📚<|im_end|>

05/10 03:26:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事嘴比刀子还毒，是不是觉得自己长得像仙女就敢随便开麦讲道理？下次别忍，直接和他/她来一场“眼纹争夺战”，看谁的眼纹先“退退退”到能让人忘记你昨天是不是去参加了一场美妆界的《苍蝇行走术》。保重啊，朋友，别让这种“眼纹”影响了你的美丽和心情。💄🕷<|im_end|>

05/10 03:26:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这是“隐形人”吗？😂 但注意保密，不然领导会觉得你在搞“遁形秀”呢。保密有保密的法子，你就把手机设置成震动模式，或者用专门的耳机听，这样他就看不到了。保重，别让同事们以为你“隐身”了。👂<|im_end|>

05/10 03:26:18 - mmengine - INFO - Saving checkpoint at 8000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 03:26:33 - mmengine - INFO - Iter(train) [  8010/480000]  lr: 1.1124e-04  eta: 8 days, 0:12:19  time: 6.5529  data_time: 5.2884  memory: 9835  loss: 0.0640  grad_norm: 1.1259
05/10 03:26:48 - mmengine - INFO - Iter(train) [  8020/480000]  lr: 1.1138e-04  eta: 8 days, 0:12:41  time: 1.5273  data_time: 0.0059  memory: 9836  loss: 0.0645  grad_norm: 1.1287
05/10 03:27:01 - mmengine - INFO - Iter(train) [  8030/480000]  lr: 1.1152e-04  eta: 8 days, 0:10:21  time: 1.2541  data_time: 0.0057  memory: 9838  loss: 0.0758  grad_norm: 1.1287
05/10 03:27:16 - mmengine - INFO - Iter(train) [  8040/480000]  lr: 1.1166e-04  eta: 8 days, 0:10:31  time: 1.5071  data_time: 0.0059  memory: 9838  loss: 0.0766  grad_norm: 1.1796
05/10 03:27:29 - mmengine - INFO - Iter(train) [  8050/480000]  lr: 1.1180e-04  eta: 8 days, 0:08:25  time: 1.2763  data_time: 0.0058  memory: 9834  loss: 0.0697  grad_norm: 1.2286
05/10 03:27:41 - mmengine - INFO - Iter(train) [  8060/480000]  lr: 1.1194e-04  eta: 8 days, 0:06:03  time: 1.2476  data_time: 0.0056  memory: 9839  loss: 0.0690  grad_norm: 1.2286
05/10 03:27:56 - mmengine - INFO - Iter(train) [  8070/480000]  lr: 1.1208e-04  eta: 8 days, 0:06:07  time: 1.4968  data_time: 0.0059  memory: 9838  loss: 0.0695  grad_norm: 1.2227
05/10 03:28:09 - mmengine - INFO - Iter(train) [  8080/480000]  lr: 1.1222e-04  eta: 8 days, 0:03:59  time: 1.2719  data_time: 0.0057  memory: 9838  loss: 0.0692  grad_norm: 1.2290
05/10 03:28:24 - mmengine - INFO - Iter(train) [  8090/480000]  lr: 1.1236e-04  eta: 8 days, 0:04:14  time: 1.5154  data_time: 0.0057  memory: 9836  loss: 0.0765  grad_norm: 1.2290
05/10 03:28:37 - mmengine - INFO - Iter(train) [  8100/480000]  lr: 1.1249e-04  eta: 8 days, 0:01:58  time: 1.2581  data_time: 0.0056  memory: 9839  loss: 0.0774  grad_norm: 1.2326
05/10 03:28:49 - mmengine - INFO - Iter(train) [  8110/480000]  lr: 1.1263e-04  eta: 8 days, 0:00:01  time: 1.2885  data_time: 0.0057  memory: 9838  loss: 0.0720  grad_norm: 1.2326
05/10 03:29:04 - mmengine - INFO - Iter(train) [  8120/480000]  lr: 1.1277e-04  eta: 8 days, 0:00:05  time: 1.4964  data_time: 0.0057  memory: 9837  loss: 0.0788  grad_norm: 1.2239
05/10 03:29:17 - mmengine - INFO - Iter(train) [  8130/480000]  lr: 1.1291e-04  eta: 7 days, 23:58:14  time: 1.2998  data_time: 0.0058  memory: 9837  loss: 0.0809  grad_norm: 1.2367
05/10 03:29:32 - mmengine - INFO - Iter(train) [  8140/480000]  lr: 1.1305e-04  eta: 7 days, 23:57:54  time: 1.4554  data_time: 0.0057  memory: 9837  loss: 0.0817  grad_norm: 1.2367
05/10 03:29:45 - mmengine - INFO - Iter(train) [  8150/480000]  lr: 1.1319e-04  eta: 7 days, 23:55:47  time: 1.2694  data_time: 0.0058  memory: 9835  loss: 0.0764  grad_norm: 1.2402
05/10 03:29:57 - mmengine - INFO - Iter(train) [  8160/480000]  lr: 1.1333e-04  eta: 7 days, 23:53:18  time: 1.2329  data_time: 0.0056  memory: 9832  loss: 0.0807  grad_norm: 1.2613
05/10 03:30:14 - mmengine - INFO - Iter(train) [  8170/480000]  lr: 1.1347e-04  eta: 7 days, 23:55:26  time: 1.7100  data_time: 0.2059  memory: 9838  loss: 0.0554  grad_norm: 1.2613
05/10 03:30:27 - mmengine - INFO - Iter(train) [  8180/480000]  lr: 1.1361e-04  eta: 7 days, 23:53:32  time: 1.2930  data_time: 0.0058  memory: 9838  loss: 0.0557  grad_norm: 1.2438
05/10 03:30:42 - mmengine - INFO - Iter(train) [  8190/480000]  lr: 1.1374e-04  eta: 7 days, 23:53:18  time: 1.4653  data_time: 0.0057  memory: 9839  loss: 0.0605  grad_norm: 1.2438
05/10 03:30:55 - mmengine - INFO - Iter(train) [  8200/480000]  lr: 1.1388e-04  eta: 7 days, 23:51:23  time: 1.2893  data_time: 0.0058  memory: 9839  loss: 0.0594  grad_norm: 1.2063
05/10 03:31:08 - mmengine - INFO - Iter(train) [  8210/480000]  lr: 1.1402e-04  eta: 7 days, 23:49:34  time: 1.2997  data_time: 0.0059  memory: 9837  loss: 0.0603  grad_norm: 1.1745
05/10 03:31:22 - mmengine - INFO - Iter(train) [  8220/480000]  lr: 1.1416e-04  eta: 7 days, 23:49:26  time: 1.4761  data_time: 0.0058  memory: 9836  loss: 0.0545  grad_norm: 1.1745
05/10 03:31:35 - mmengine - INFO - Iter(train) [  8230/480000]  lr: 1.1430e-04  eta: 7 days, 23:47:20  time: 1.2692  data_time: 0.0058  memory: 9838  loss: 0.0574  grad_norm: 1.1663
05/10 03:31:50 - mmengine - INFO - Iter(train) [  8240/480000]  lr: 1.1444e-04  eta: 7 days, 23:47:01  time: 1.4550  data_time: 0.0057  memory: 9836  loss: 0.0589  grad_norm: 1.1389
05/10 03:32:03 - mmengine - INFO - Iter(train) [  8250/480000]  lr: 1.1458e-04  eta: 7 days, 23:45:09  time: 1.2936  data_time: 0.0057  memory: 9840  loss: 0.0617  grad_norm: 1.1389
05/10 03:32:16 - mmengine - INFO - Iter(train) [  8260/480000]  lr: 1.1472e-04  eta: 7 days, 23:43:20  time: 1.2991  data_time: 0.0059  memory: 9842  loss: 0.0623  grad_norm: 1.0948
05/10 03:32:30 - mmengine - INFO - Iter(train) [  8270/480000]  lr: 1.1486e-04  eta: 7 days, 23:43:09  time: 1.4689  data_time: 0.0057  memory: 9836  loss: 0.0687  grad_norm: 1.0948
05/10 03:32:43 - mmengine - INFO - Iter(train) [  8280/480000]  lr: 1.1499e-04  eta: 7 days, 23:41:10  time: 1.2793  data_time: 0.0058  memory: 9837  loss: 0.0721  grad_norm: 1.1029
05/10 03:32:58 - mmengine - INFO - Iter(train) [  8290/480000]  lr: 1.1513e-04  eta: 7 days, 23:41:05  time: 1.4797  data_time: 0.0058  memory: 9837  loss: 0.0703  grad_norm: 1.1259
05/10 03:33:11 - mmengine - INFO - Iter(train) [  8300/480000]  lr: 1.1527e-04  eta: 7 days, 23:39:17  time: 1.2990  data_time: 0.0059  memory: 9834  loss: 0.0720  grad_norm: 1.1259
05/10 03:33:24 - mmengine - INFO - Iter(train) [  8310/480000]  lr: 1.1541e-04  eta: 7 days, 23:37:25  time: 1.2911  data_time: 0.0058  memory: 9836  loss: 0.0733  grad_norm: 1.1344
05/10 03:33:38 - mmengine - INFO - Iter(train) [  8320/480000]  lr: 1.1555e-04  eta: 7 days, 23:36:32  time: 1.3947  data_time: 0.0057  memory: 9838  loss: 0.0693  grad_norm: 1.1231
05/10 03:33:53 - mmengine - INFO - Iter(train) [  8330/480000]  lr: 1.1569e-04  eta: 7 days, 23:36:36  time: 1.4962  data_time: 0.2059  memory: 9837  loss: 0.0555  grad_norm: 1.1231
05/10 03:34:08 - mmengine - INFO - Iter(train) [  8340/480000]  lr: 1.1583e-04  eta: 7 days, 23:36:40  time: 1.4946  data_time: 0.0058  memory: 9837  loss: 0.0512  grad_norm: 1.1459
05/10 03:34:21 - mmengine - INFO - Iter(train) [  8350/480000]  lr: 1.1597e-04  eta: 7 days, 23:34:53  time: 1.2989  data_time: 0.0058  memory: 9836  loss: 0.0518  grad_norm: 1.1459
05/10 03:34:33 - mmengine - INFO - Iter(train) [  8360/480000]  lr: 1.1611e-04  eta: 7 days, 23:32:59  time: 1.2859  data_time: 0.0057  memory: 9837  loss: 0.0529  grad_norm: 1.1292
05/10 03:34:48 - mmengine - INFO - Iter(train) [  8370/480000]  lr: 1.1625e-04  eta: 7 days, 23:32:48  time: 1.4698  data_time: 0.0057  memory: 9837  loss: 0.0569  grad_norm: 1.1164
05/10 03:35:01 - mmengine - INFO - Iter(train) [  8380/480000]  lr: 1.1638e-04  eta: 7 days, 23:30:53  time: 1.2832  data_time: 0.0057  memory: 9838  loss: 0.0602  grad_norm: 1.1164
05/10 03:35:16 - mmengine - INFO - Iter(train) [  8390/480000]  lr: 1.1652e-04  eta: 7 days, 23:30:55  time: 1.4920  data_time: 0.0059  memory: 9838  loss: 0.0605  grad_norm: 1.1407
05/10 03:35:28 - mmengine - INFO - Iter(train) [  8400/480000]  lr: 1.1666e-04  eta: 7 days, 23:28:48  time: 1.2616  data_time: 0.0057  memory: 9840  loss: 0.0558  grad_norm: 1.1522
05/10 03:35:41 - mmengine - INFO - Iter(train) [  8410/480000]  lr: 1.1680e-04  eta: 7 days, 23:26:40  time: 1.2594  data_time: 0.0057  memory: 9840  loss: 0.0557  grad_norm: 1.1522
05/10 03:35:56 - mmengine - INFO - Iter(train) [  8420/480000]  lr: 1.1694e-04  eta: 7 days, 23:26:46  time: 1.4977  data_time: 0.0059  memory: 9843  loss: 0.0590  grad_norm: 1.1493
05/10 03:36:09 - mmengine - INFO - Iter(train) [  8430/480000]  lr: 1.1708e-04  eta: 7 days, 23:25:07  time: 1.3104  data_time: 0.0057  memory: 9841  loss: 0.0571  grad_norm: 1.1493
05/10 03:36:24 - mmengine - INFO - Iter(train) [  8440/480000]  lr: 1.1722e-04  eta: 7 days, 23:24:59  time: 1.4741  data_time: 0.0058  memory: 9838  loss: 0.0553  grad_norm: 1.1383
05/10 03:36:37 - mmengine - INFO - Iter(train) [  8450/480000]  lr: 1.1736e-04  eta: 7 days, 23:23:08  time: 1.2875  data_time: 0.0057  memory: 9837  loss: 0.0625  grad_norm: 1.0776
05/10 03:36:50 - mmengine - INFO - Iter(train) [  8460/480000]  lr: 1.1750e-04  eta: 7 days, 23:21:12  time: 1.2800  data_time: 0.0057  memory: 9835  loss: 0.0608  grad_norm: 1.0776
05/10 03:37:04 - mmengine - INFO - Iter(train) [  8470/480000]  lr: 1.1763e-04  eta: 7 days, 23:21:07  time: 1.4786  data_time: 0.0058  memory: 9838  loss: 0.0611  grad_norm: 1.0646
05/10 03:37:17 - mmengine - INFO - Iter(train) [  8480/480000]  lr: 1.1777e-04  eta: 7 days, 23:18:42  time: 1.2258  data_time: 0.0057  memory: 9837  loss: 0.0668  grad_norm: 1.0477
05/10 03:37:33 - mmengine - INFO - Iter(train) [  8490/480000]  lr: 1.1791e-04  eta: 7 days, 23:20:22  time: 1.6677  data_time: 0.2060  memory: 9841  loss: 0.0455  grad_norm: 1.0477
05/10 03:37:46 - mmengine - INFO - Iter(train) [  8500/480000]  lr: 1.1805e-04  eta: 7 days, 23:18:18  time: 1.2627  data_time: 0.0058  memory: 9843  loss: 0.0454  grad_norm: 1.0268
05/10 03:37:46 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 03:37:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。💔 您想怎么处理这件事呢？需要一些建议吗？🌸💖<|im_end|>

05/10 03:37:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《哈利·波特》了。下次洗牙记得选个靠谱的牙医，别让牙医变成你的“定期劫匪”。保重啊，朋友！🦷<|im_end|>

05/10 03:37:56 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。要不要我给你一些喝水的建议，帮助恢复呢？💖<|im_end|>

05/10 03:38:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任同时点赞，看来这友谊的小船说翻就翻？不过话说回来，尊重是友谊的基石，如果觉得不舒服，直接和他们沟通，告诉他们这样的互动让你不舒服，希望他们能够尊重你的隐私。毕竟，每个人的品味和价值观都不同，找到适合自己的交友方式才是最重要的。别了一场不必要的风波，记得保护好自己，也维护好自己的心情哦！💖<|im_end|>

05/10 03:38:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，建议多吃一些高脂肪食物如油炸鸡选择其他健康的食品呢。💖 你可以试试吃一些烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。记得保持良好的饮食习惯哦！🌸<|im_end|>

05/10 03:38:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本来是个大家开心推理的游戏，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。要不要聊聊你当时的感受，或者我可以帮你想想办法，如何处理这种情况，让你感到更被理解和支持呢？💖<|im_end|>

05/10 03:38:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事嘴比刀子还毒，是不是觉得自己长得像苍蝇腿，就先开个苍蝇馆子再找你抢食？不过别气馁，你的眼线可能是想展示你的“空中飞蚊”特长吧？😂 下次记得，找美丽遮瑕师之前，先看看他们的黑名单，不然就只能“自不量力”了。保重眼睛，别让这种“时尚灾难”变成心理阴影面积。<|im_end|>

05/10 03:38:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢，毕竟领导的意图是好的。你可以尝试私下里跟领导沟通一下，表达一下你的感受和需求，比如你可以建议领导在周末发布相关通知或者视频，这样更便于大家理解。毕竟，良好的沟通能够帮助解决问题哦。💖你觉得呢？<|im_end|>

05/10 03:38:33 - mmengine - INFO - Saving checkpoint at 8500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 03:38:48 - mmengine - INFO - Iter(train) [  8510/480000]  lr: 1.1819e-04  eta: 8 days, 0:01:58  time: 6.2159  data_time: 4.7489  memory: 9840  loss: 0.0456  grad_norm: 1.0268
05/10 03:39:01 - mmengine - INFO - Iter(train) [  8520/480000]  lr: 1.1833e-04  eta: 8 days, 0:00:08  time: 1.2935  data_time: 0.0058  memory: 9838  loss: 0.0457  grad_norm: 1.0134
05/10 03:39:16 - mmengine - INFO - Iter(train) [  8530/480000]  lr: 1.1847e-04  eta: 8 days, 0:00:05  time: 1.4872  data_time: 0.0057  memory: 9836  loss: 0.0501  grad_norm: 0.9964
05/10 03:39:29 - mmengine - INFO - Iter(train) [  8540/480000]  lr: 1.1861e-04  eta: 7 days, 23:58:02  time: 1.2704  data_time: 0.0057  memory: 9840  loss: 0.0561  grad_norm: 0.9964
05/10 03:39:41 - mmengine - INFO - Iter(train) [  8550/480000]  lr: 1.1875e-04  eta: 7 days, 23:56:00  time: 1.2720  data_time: 0.0058  memory: 9838  loss: 0.0495  grad_norm: 0.9685
05/10 03:39:56 - mmengine - INFO - Iter(train) [  8560/480000]  lr: 1.1888e-04  eta: 7 days, 23:55:50  time: 1.4728  data_time: 0.0058  memory: 9839  loss: 0.0550  grad_norm: 0.9659
05/10 03:40:09 - mmengine - INFO - Iter(train) [  8570/480000]  lr: 1.1902e-04  eta: 7 days, 23:54:02  time: 1.2959  data_time: 0.0057  memory: 9837  loss: 0.0530  grad_norm: 0.9659
05/10 03:40:24 - mmengine - INFO - Iter(train) [  8580/480000]  lr: 1.1916e-04  eta: 7 days, 23:54:00  time: 1.4890  data_time: 0.0057  memory: 9836  loss: 0.0555  grad_norm: 0.9733
05/10 03:40:37 - mmengine - INFO - Iter(train) [  8590/480000]  lr: 1.1930e-04  eta: 7 days, 23:52:02  time: 1.2764  data_time: 0.0057  memory: 9836  loss: 0.0548  grad_norm: 0.9733
05/10 03:40:50 - mmengine - INFO - Iter(train) [  8600/480000]  lr: 1.1944e-04  eta: 7 days, 23:50:10  time: 1.2892  data_time: 0.0058  memory: 9839  loss: 0.0577  grad_norm: 0.9757
05/10 03:41:04 - mmengine - INFO - Iter(train) [  8610/480000]  lr: 1.1958e-04  eta: 7 days, 23:50:09  time: 1.4886  data_time: 0.0056  memory: 9841  loss: 0.0549  grad_norm: 0.9660
05/10 03:41:17 - mmengine - INFO - Iter(train) [  8620/480000]  lr: 1.1972e-04  eta: 7 days, 23:48:20  time: 1.2934  data_time: 0.0058  memory: 9835  loss: 0.0566  grad_norm: 0.9660
05/10 03:41:32 - mmengine - INFO - Iter(train) [  8630/480000]  lr: 1.1986e-04  eta: 7 days, 23:48:07  time: 1.4667  data_time: 0.0057  memory: 9837  loss: 0.0632  grad_norm: 0.9495
05/10 03:41:44 - mmengine - INFO - Iter(train) [  8640/480000]  lr: 1.2000e-04  eta: 7 days, 23:45:26  time: 1.1980  data_time: 0.0057  memory: 9838  loss: 0.0617  grad_norm: 0.9509
05/10 03:42:01 - mmengine - INFO - Iter(train) [  8650/480000]  lr: 1.2013e-04  eta: 7 days, 23:47:19  time: 1.6984  data_time: 0.2060  memory: 9837  loss: 0.0415  grad_norm: 0.9509
05/10 03:42:14 - mmengine - INFO - Iter(train) [  8660/480000]  lr: 1.2027e-04  eta: 7 days, 23:45:33  time: 1.2976  data_time: 0.0057  memory: 9836  loss: 0.0430  grad_norm: 0.9400
05/10 03:42:27 - mmengine - INFO - Iter(train) [  8670/480000]  lr: 1.2041e-04  eta: 7 days, 23:43:44  time: 1.2894  data_time: 0.0057  memory: 9836  loss: 0.0473  grad_norm: 0.9400
05/10 03:42:42 - mmengine - INFO - Iter(train) [  8680/480000]  lr: 1.2055e-04  eta: 7 days, 23:43:38  time: 1.4817  data_time: 0.0060  memory: 9836  loss: 0.0446  grad_norm: 0.9452
05/10 03:42:54 - mmengine - INFO - Iter(train) [  8690/480000]  lr: 1.2069e-04  eta: 7 days, 23:41:38  time: 1.2701  data_time: 0.0056  memory: 9837  loss: 0.0493  grad_norm: 0.9400
05/10 03:43:09 - mmengine - INFO - Iter(train) [  8700/480000]  lr: 1.2083e-04  eta: 7 days, 23:41:36  time: 1.4877  data_time: 0.0058  memory: 9836  loss: 0.0466  grad_norm: 0.9400
05/10 03:43:22 - mmengine - INFO - Iter(train) [  8710/480000]  lr: 1.2097e-04  eta: 7 days, 23:39:43  time: 1.2828  data_time: 0.0057  memory: 9838  loss: 0.0489  grad_norm: 0.9430
05/10 03:43:35 - mmengine - INFO - Iter(train) [  8720/480000]  lr: 1.2111e-04  eta: 7 days, 23:37:44  time: 1.2707  data_time: 0.0057  memory: 9836  loss: 0.0480  grad_norm: 0.9263
05/10 03:43:50 - mmengine - INFO - Iter(train) [  8730/480000]  lr: 1.2125e-04  eta: 7 days, 23:37:36  time: 1.4762  data_time: 0.0058  memory: 9840  loss: 0.0539  grad_norm: 0.9263
05/10 03:44:02 - mmengine - INFO - Iter(train) [  8740/480000]  lr: 1.2138e-04  eta: 7 days, 23:35:45  time: 1.2849  data_time: 0.0058  memory: 9839  loss: 0.0508  grad_norm: 0.9344
05/10 03:44:17 - mmengine - INFO - Iter(train) [  8750/480000]  lr: 1.2152e-04  eta: 7 days, 23:35:36  time: 1.4737  data_time: 0.0057  memory: 9840  loss: 0.0497  grad_norm: 0.9344
05/10 03:44:30 - mmengine - INFO - Iter(train) [  8760/480000]  lr: 1.2166e-04  eta: 7 days, 23:33:46  time: 1.2864  data_time: 0.0058  memory: 9840  loss: 0.0565  grad_norm: 0.9203
05/10 03:44:43 - mmengine - INFO - Iter(train) [  8770/480000]  lr: 1.2180e-04  eta: 7 days, 23:31:39  time: 1.2543  data_time: 0.0057  memory: 9835  loss: 0.0540  grad_norm: 0.9308
05/10 03:44:58 - mmengine - INFO - Iter(train) [  8780/480000]  lr: 1.2194e-04  eta: 7 days, 23:31:57  time: 1.5232  data_time: 0.0059  memory: 9836  loss: 0.0626  grad_norm: 0.9308
05/10 03:45:10 - mmengine - INFO - Iter(train) [  8790/480000]  lr: 1.2208e-04  eta: 7 days, 23:29:57  time: 1.2674  data_time: 0.0056  memory: 9835  loss: 0.0623  grad_norm: 0.9717
05/10 03:45:23 - mmengine - INFO - Iter(train) [  8800/480000]  lr: 1.2222e-04  eta: 7 days, 23:27:32  time: 1.2203  data_time: 0.0057  memory: 9837  loss: 0.0658  grad_norm: 0.9762
05/10 03:45:39 - mmengine - INFO - Iter(train) [  8810/480000]  lr: 1.2236e-04  eta: 7 days, 23:29:14  time: 1.6792  data_time: 0.4032  memory: 9836  loss: 0.0461  grad_norm: 0.9762
05/10 03:45:52 - mmengine - INFO - Iter(train) [  8820/480000]  lr: 1.2250e-04  eta: 7 days, 23:27:07  time: 1.2534  data_time: 0.0057  memory: 9837  loss: 0.0477  grad_norm: 1.0019
05/10 03:46:07 - mmengine - INFO - Iter(train) [  8830/480000]  lr: 1.2263e-04  eta: 7 days, 23:27:27  time: 1.5283  data_time: 0.0059  memory: 9839  loss: 0.0441  grad_norm: 1.0019
05/10 03:46:20 - mmengine - INFO - Iter(train) [  8840/480000]  lr: 1.2277e-04  eta: 7 days, 23:25:27  time: 1.2641  data_time: 0.0057  memory: 9837  loss: 0.0440  grad_norm: 1.0039
05/10 03:46:35 - mmengine - INFO - Iter(train) [  8850/480000]  lr: 1.2291e-04  eta: 7 days, 23:25:26  time: 1.4898  data_time: 0.0058  memory: 9838  loss: 0.0428  grad_norm: 1.0050
05/10 03:46:47 - mmengine - INFO - Iter(train) [  8860/480000]  lr: 1.2305e-04  eta: 7 days, 23:23:28  time: 1.2682  data_time: 0.0058  memory: 9840  loss: 0.0439  grad_norm: 1.0050
05/10 03:47:00 - mmengine - INFO - Iter(train) [  8870/480000]  lr: 1.2319e-04  eta: 7 days, 23:21:47  time: 1.2985  data_time: 0.0057  memory: 9840  loss: 0.0454  grad_norm: 0.9961
05/10 03:47:15 - mmengine - INFO - Iter(train) [  8880/480000]  lr: 1.2333e-04  eta: 7 days, 23:21:45  time: 1.4872  data_time: 0.0057  memory: 9842  loss: 0.0497  grad_norm: 0.9969
05/10 03:47:28 - mmengine - INFO - Iter(train) [  8890/480000]  lr: 1.2347e-04  eta: 7 days, 23:19:41  time: 1.2553  data_time: 0.0056  memory: 9840  loss: 0.0474  grad_norm: 0.9969
05/10 03:47:43 - mmengine - INFO - Iter(train) [  8900/480000]  lr: 1.2361e-04  eta: 7 days, 23:19:33  time: 1.4741  data_time: 0.0058  memory: 9840  loss: 0.0454  grad_norm: 0.9676
05/10 03:47:56 - mmengine - INFO - Iter(train) [  8910/480000]  lr: 1.2375e-04  eta: 7 days, 23:17:46  time: 1.2875  data_time: 0.0059  memory: 9840  loss: 0.0528  grad_norm: 0.9676
05/10 03:48:08 - mmengine - INFO - Iter(train) [  8920/480000]  lr: 1.2388e-04  eta: 7 days, 23:15:58  time: 1.2847  data_time: 0.0057  memory: 9838  loss: 0.0503  grad_norm: 0.9649
05/10 03:48:23 - mmengine - INFO - Iter(train) [  8930/480000]  lr: 1.2402e-04  eta: 7 days, 23:16:10  time: 1.5128  data_time: 0.0059  memory: 9839  loss: 0.0501  grad_norm: 0.9568
05/10 03:48:36 - mmengine - INFO - Iter(train) [  8940/480000]  lr: 1.2416e-04  eta: 7 days, 23:14:06  time: 1.2531  data_time: 0.0056  memory: 9842  loss: 0.0517  grad_norm: 0.9568
05/10 03:48:51 - mmengine - INFO - Iter(train) [  8950/480000]  lr: 1.2430e-04  eta: 7 days, 23:14:08  time: 1.4933  data_time: 0.0060  memory: 9841  loss: 0.0559  grad_norm: 0.9172
05/10 03:49:03 - mmengine - INFO - Iter(train) [  8960/480000]  lr: 1.2444e-04  eta: 7 days, 23:11:47  time: 1.2215  data_time: 0.0057  memory: 9838  loss: 0.0570  grad_norm: 0.9100
05/10 03:49:18 - mmengine - INFO - Iter(train) [  8970/480000]  lr: 1.2458e-04  eta: 7 days, 23:12:05  time: 1.5240  data_time: 0.2059  memory: 9836  loss: 0.0367  grad_norm: 0.9100
05/10 03:49:33 - mmengine - INFO - Iter(train) [  8980/480000]  lr: 1.2472e-04  eta: 7 days, 23:11:50  time: 1.4592  data_time: 0.0058  memory: 9842  loss: 0.0380  grad_norm: 0.8828
05/10 03:49:46 - mmengine - INFO - Iter(train) [  8990/480000]  lr: 1.2486e-04  eta: 7 days, 23:09:48  time: 1.2564  data_time: 0.0056  memory: 9842  loss: 0.0401  grad_norm: 0.8828
05/10 03:50:01 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 03:50:01 - mmengine - INFO - Iter(train) [  9000/480000]  lr: 1.2500e-04  eta: 7 days, 23:09:53  time: 1.4986  data_time: 0.0060  memory: 9841  loss: 0.0402  grad_norm: 0.8739
05/10 03:50:01 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 03:50:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。你觉得心里很难过吗？我们可以一起想想怎么处理这件事，让你感到开心和安慰。💖<|im_end|>

05/10 03:50:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哈哈，听起来你牙缝确实变大了呢~ 是不是有点不习惯呢。不过，这是正常的，牙医会帮你调整牙齿的拥挤度的。你可以试试吃一些清淡的食物，比如细嚼慢咽，这样可以帮助减轻牙缝变大的情况。如果需要，我可以帮你找一些缓解牙缝不适的方法哦。💖<|im_end|>

05/10 03:50:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
看来红酒这次并没有好好享受呢，头晕的时候记得休息哦。喝太多对身体不好呢，下次可以试试喝一些轻柔的红酒或者吃一些缓解头晕的食物。💖如果你需要更多建议或者有其他问题，随时告诉我哦。<|im_end|>

05/10 03:50:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激！不过别太往心里去，至少你还能在朋友圈安放一个美丽的谎言角落。不过是请记得，真正的美丽，是内敛而低调的，不是吗？💄✨<|im_end|>

05/10 03:50:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯哦！<|im_end|>

05/10 03:50:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，遇到这样的情况真的挺让人难过的呢。首先要保持冷静哦，毕竟剧本杀是个大家庭呢。要不要我帮你分散一下注意力，或者我们可以一起想想怎么解决这种情况呢？💖<|im_end|>

05/10 03:50:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这同事是自带放大镜上班的吗？下次记得换一只眼线笔，别让苍蝇再给你拍电影了！👓<|im_end|>

05/10 03:50:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
你这速度堪比树懒，领导发的语音矩阵都能当空气放过，是不是连“退退退”的快捷方式都是“龟速操作”级别？不过话说回来，周末也要注意休息，别让领导期望你成为“超速奔跑”的超级英雄。成成成，你就当自己出去旅游了，说不定领导心里在想：“这人真是静得像树懒，运动得像猎豹，真是个假货！”不过别太往心里去，毕竟“不识货”的领导，可能在不久的将来就是“识货”的。记得回去分享你的“愉快”经历，说不定能宣传一下你的“假公济私”能力呢！<|im_end|>

05/10 03:50:45 - mmengine - INFO - Saving checkpoint at 9000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 03:50:59 - mmengine - INFO - Iter(train) [  9010/480000]  lr: 1.2513e-04  eta: 7 days, 23:47:28  time: 5.8036  data_time: 4.5044  memory: 9838  loss: 0.0405  grad_norm: 0.8706
05/10 03:51:14 - mmengine - INFO - Iter(train) [  9020/480000]  lr: 1.2527e-04  eta: 7 days, 23:47:32  time: 1.5023  data_time: 0.0059  memory: 9839  loss: 0.0408  grad_norm: 0.8706
05/10 03:51:26 - mmengine - INFO - Iter(train) [  9030/480000]  lr: 1.2541e-04  eta: 7 days, 23:45:44  time: 1.2866  data_time: 0.0059  memory: 9837  loss: 0.0421  grad_norm: 0.8720
05/10 03:51:41 - mmengine - INFO - Iter(train) [  9040/480000]  lr: 1.2555e-04  eta: 7 days, 23:45:22  time: 1.4512  data_time: 0.0057  memory: 9837  loss: 0.0440  grad_norm: 0.8622
05/10 03:51:54 - mmengine - INFO - Iter(train) [  9050/480000]  lr: 1.2569e-04  eta: 7 days, 23:43:30  time: 1.2795  data_time: 0.0057  memory: 9840  loss: 0.0416  grad_norm: 0.8622
05/10 03:52:07 - mmengine - INFO - Iter(train) [  9060/480000]  lr: 1.2583e-04  eta: 7 days, 23:41:52  time: 1.3038  data_time: 0.0058  memory: 9842  loss: 0.0423  grad_norm: 0.8644
05/10 03:52:22 - mmengine - INFO - Iter(train) [  9070/480000]  lr: 1.2597e-04  eta: 7 days, 23:41:46  time: 1.4832  data_time: 0.0057  memory: 9838  loss: 0.0451  grad_norm: 0.8644
05/10 03:52:35 - mmengine - INFO - Iter(train) [  9080/480000]  lr: 1.2611e-04  eta: 7 days, 23:39:58  time: 1.2853  data_time: 0.0058  memory: 9835  loss: 0.0467  grad_norm: 0.8562
05/10 03:52:49 - mmengine - INFO - Iter(train) [  9090/480000]  lr: 1.2625e-04  eta: 7 days, 23:39:45  time: 1.4683  data_time: 0.0057  memory: 9834  loss: 0.0437  grad_norm: 0.8420
05/10 03:53:02 - mmengine - INFO - Iter(train) [  9100/480000]  lr: 1.2638e-04  eta: 7 days, 23:38:07  time: 1.3037  data_time: 0.0062  memory: 9835  loss: 0.0437  grad_norm: 0.8420
05/10 03:53:15 - mmengine - INFO - Iter(train) [  9110/480000]  lr: 1.2652e-04  eta: 7 days, 23:36:28  time: 1.3016  data_time: 0.0057  memory: 9834  loss: 0.0457  grad_norm: 0.8170
05/10 03:53:29 - mmengine - INFO - Iter(train) [  9120/480000]  lr: 1.2666e-04  eta: 7 days, 23:35:39  time: 1.3991  data_time: 0.0057  memory: 9833  loss: 0.0450  grad_norm: 0.7882
05/10 03:53:44 - mmengine - INFO - Iter(train) [  9130/480000]  lr: 1.2680e-04  eta: 7 days, 23:35:34  time: 1.4841  data_time: 0.2059  memory: 9838  loss: 0.0344  grad_norm: 0.7882
05/10 03:53:59 - mmengine - INFO - Iter(train) [  9140/480000]  lr: 1.2694e-04  eta: 7 days, 23:35:25  time: 1.4742  data_time: 0.0057  memory: 9838  loss: 0.0352  grad_norm: 0.7827
05/10 03:54:12 - mmengine - INFO - Iter(train) [  9150/480000]  lr: 1.2708e-04  eta: 7 days, 23:33:46  time: 1.3025  data_time: 0.0057  memory: 9837  loss: 0.0332  grad_norm: 0.7827
05/10 03:54:25 - mmengine - INFO - Iter(train) [  9160/480000]  lr: 1.2722e-04  eta: 7 days, 23:32:06  time: 1.2972  data_time: 0.0057  memory: 9840  loss: 0.0411  grad_norm: 0.7733
05/10 03:54:40 - mmengine - INFO - Iter(train) [  9170/480000]  lr: 1.2736e-04  eta: 7 days, 23:31:54  time: 1.4699  data_time: 0.0057  memory: 9841  loss: 0.0385  grad_norm: 0.7624
05/10 03:54:52 - mmengine - INFO - Iter(train) [  9180/480000]  lr: 1.2750e-04  eta: 7 days, 23:30:06  time: 1.2832  data_time: 0.0057  memory: 9838  loss: 0.0383  grad_norm: 0.7624
05/10 03:55:08 - mmengine - INFO - Iter(train) [  9190/480000]  lr: 1.2763e-04  eta: 7 days, 23:30:46  time: 1.5714  data_time: 0.0059  memory: 9839  loss: 0.0383  grad_norm: 0.7540
05/10 03:55:22 - mmengine - INFO - Iter(train) [  9200/480000]  lr: 1.2777e-04  eta: 7 days, 23:29:53  time: 1.3887  data_time: 0.0062  memory: 9836  loss: 0.0419  grad_norm: 0.7504
05/10 03:55:35 - mmengine - INFO - Iter(train) [  9210/480000]  lr: 1.2791e-04  eta: 7 days, 23:28:42  time: 1.3549  data_time: 0.0060  memory: 9837  loss: 0.0391  grad_norm: 0.7504
05/10 03:55:51 - mmengine - INFO - Iter(train) [  9220/480000]  lr: 1.2805e-04  eta: 7 days, 23:29:02  time: 1.5313  data_time: 0.0061  memory: 9837  loss: 0.0392  grad_norm: 0.7430
05/10 03:56:04 - mmengine - INFO - Iter(train) [  9230/480000]  lr: 1.2819e-04  eta: 7 days, 23:27:45  time: 1.3424  data_time: 0.0057  memory: 9838  loss: 0.0424  grad_norm: 0.7430
05/10 03:56:20 - mmengine - INFO - Iter(train) [  9240/480000]  lr: 1.2833e-04  eta: 7 days, 23:28:05  time: 1.5316  data_time: 0.0058  memory: 9839  loss: 0.0428  grad_norm: 0.7397
05/10 03:56:33 - mmengine - INFO - Iter(train) [  9250/480000]  lr: 1.2847e-04  eta: 7 days, 23:27:11  time: 1.3876  data_time: 0.0060  memory: 9841  loss: 0.0402  grad_norm: 0.7338
05/10 03:56:48 - mmengine - INFO - Iter(train) [  9260/480000]  lr: 1.2861e-04  eta: 7 days, 23:27:18  time: 1.5060  data_time: 0.0059  memory: 9844  loss: 0.0433  grad_norm: 0.7338
05/10 03:57:02 - mmengine - INFO - Iter(train) [  9270/480000]  lr: 1.2875e-04  eta: 7 days, 23:26:01  time: 1.3416  data_time: 0.0058  memory: 9840  loss: 0.0442  grad_norm: 0.7405
05/10 03:57:15 - mmengine - INFO - Iter(train) [  9280/480000]  lr: 1.2888e-04  eta: 7 days, 23:24:15  time: 1.2830  data_time: 0.0056  memory: 9838  loss: 0.0391  grad_norm: 0.7399
05/10 03:57:32 - mmengine - INFO - Iter(train) [  9290/480000]  lr: 1.2902e-04  eta: 7 days, 23:26:08  time: 1.7164  data_time: 0.2061  memory: 9838  loss: 0.0351  grad_norm: 0.7399
05/10 03:57:45 - mmengine - INFO - Iter(train) [  9300/480000]  lr: 1.2916e-04  eta: 7 days, 23:24:27  time: 1.2925  data_time: 0.0057  memory: 9836  loss: 0.0322  grad_norm: 0.7387
05/10 03:58:00 - mmengine - INFO - Iter(train) [  9310/480000]  lr: 1.2930e-04  eta: 7 days, 23:24:54  time: 1.5469  data_time: 0.0059  memory: 9837  loss: 0.0300  grad_norm: 0.7387
05/10 03:58:14 - mmengine - INFO - Iter(train) [  9320/480000]  lr: 1.2944e-04  eta: 7 days, 23:23:43  time: 1.3524  data_time: 0.0058  memory: 9842  loss: 0.0349  grad_norm: 0.7312
05/10 03:58:27 - mmengine - INFO - Iter(train) [  9330/480000]  lr: 1.2958e-04  eta: 7 days, 23:22:26  time: 1.3414  data_time: 0.0060  memory: 9843  loss: 0.0329  grad_norm: 0.7313
05/10 03:58:42 - mmengine - INFO - Iter(train) [  9340/480000]  lr: 1.2972e-04  eta: 7 days, 23:22:31  time: 1.5025  data_time: 0.0059  memory: 9835  loss: 0.0342  grad_norm: 0.7313
05/10 03:58:56 - mmengine - INFO - Iter(train) [  9350/480000]  lr: 1.2986e-04  eta: 7 days, 23:21:11  time: 1.3328  data_time: 0.0058  memory: 9839  loss: 0.0391  grad_norm: 0.7230
05/10 03:59:11 - mmengine - INFO - Iter(train) [  9360/480000]  lr: 1.3000e-04  eta: 7 days, 23:21:23  time: 1.5171  data_time: 0.0058  memory: 9841  loss: 0.0373  grad_norm: 0.7283
05/10 03:59:24 - mmengine - INFO - Iter(train) [  9370/480000]  lr: 1.3013e-04  eta: 7 days, 23:19:58  time: 1.3242  data_time: 0.0058  memory: 9837  loss: 0.0387  grad_norm: 0.7283
05/10 03:59:39 - mmengine - INFO - Iter(train) [  9380/480000]  lr: 1.3027e-04  eta: 7 days, 23:20:03  time: 1.5014  data_time: 0.0057  memory: 9839  loss: 0.0382  grad_norm: 0.7274
05/10 03:59:52 - mmengine - INFO - Iter(train) [  9390/480000]  lr: 1.3041e-04  eta: 7 days, 23:18:34  time: 1.3158  data_time: 0.0058  memory: 9837  loss: 0.0366  grad_norm: 0.7274
05/10 04:00:06 - mmengine - INFO - Iter(train) [  9400/480000]  lr: 1.3055e-04  eta: 7 days, 23:17:22  time: 1.3486  data_time: 0.0058  memory: 9839  loss: 0.0395  grad_norm: 0.7143
05/10 04:00:21 - mmengine - INFO - Iter(train) [  9410/480000]  lr: 1.3069e-04  eta: 7 days, 23:17:42  time: 1.5336  data_time: 0.0058  memory: 9839  loss: 0.0403  grad_norm: 0.7267
05/10 04:00:34 - mmengine - INFO - Iter(train) [  9420/480000]  lr: 1.3083e-04  eta: 7 days, 23:16:15  time: 1.3172  data_time: 0.0058  memory: 9839  loss: 0.0360  grad_norm: 0.7267
05/10 04:00:49 - mmengine - INFO - Iter(train) [  9430/480000]  lr: 1.3097e-04  eta: 7 days, 23:16:24  time: 1.5120  data_time: 0.0058  memory: 9839  loss: 0.0365  grad_norm: 0.7152
05/10 04:01:02 - mmengine - INFO - Iter(train) [  9440/480000]  lr: 1.3111e-04  eta: 7 days, 23:14:28  time: 1.2604  data_time: 0.0057  memory: 9838  loss: 0.0391  grad_norm: 0.7137
05/10 04:01:17 - mmengine - INFO - Iter(train) [  9450/480000]  lr: 1.3125e-04  eta: 7 days, 23:14:59  time: 1.5532  data_time: 0.2059  memory: 9838  loss: 0.0265  grad_norm: 0.7137
05/10 04:01:32 - mmengine - INFO - Iter(train) [  9460/480000]  lr: 1.3138e-04  eta: 7 days, 23:15:00  time: 1.4945  data_time: 0.0058  memory: 9841  loss: 0.0288  grad_norm: 0.6985
05/10 04:01:45 - mmengine - INFO - Iter(train) [  9470/480000]  lr: 1.3152e-04  eta: 7 days, 23:13:25  time: 1.3012  data_time: 0.0057  memory: 9843  loss: 0.0293  grad_norm: 0.6985
05/10 04:02:01 - mmengine - INFO - Iter(train) [  9480/480000]  lr: 1.3166e-04  eta: 7 days, 23:13:39  time: 1.5222  data_time: 0.0058  memory: 9841  loss: 0.0307  grad_norm: 0.6978
05/10 04:02:14 - mmengine - INFO - Iter(train) [  9490/480000]  lr: 1.3180e-04  eta: 7 days, 23:12:19  time: 1.3300  data_time: 0.0057  memory: 9838  loss: 0.0284  grad_norm: 0.6912
05/10 04:02:29 - mmengine - INFO - Iter(train) [  9500/480000]  lr: 1.3194e-04  eta: 7 days, 23:12:31  time: 1.5164  data_time: 0.0058  memory: 9839  loss: 0.0308  grad_norm: 0.6912
05/10 04:02:29 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 04:02:36 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺复杂的。首先，你的感受很重要，你要知道自己的男朋友是怎样的一个人。精神出轨这样的说法可能不太合适，他们之间的事情应该坐下来好好谈谈，沟通一下。💖 你可以和他表达一下你的感受，告诉他这样对你来说意味着什么。同时，也要考虑一下如何和他沟通这个问题，避免类似的误会发生。如果你需要倾诉或者寻求建议，我在这里随时听你说。🌸<|im_end|>

05/10 04:02:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷。不过说真的，吹蜡烛的时候要注意安全，别把蜡烛吹成火灾警报器。<|im_end|>

05/10 04:02:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，注意身体哦。现在感觉好点了吗？💖<|im_end|>

05/10 04:02:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接把你的朋友圈变成了一地鸡毛。不过别太往心里去，毕竟“友谊的小船”说翻就翻，咱们得把重点放在自己身上，别让这点小插曲影响了我们的“梦想之旅”。“退退退”，这种“友谊的小船”咱们不坐，赶紧找个“小漂泊”让你的人生多一些色彩！🚢<|im_end|>

05/10 04:02:58 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，建议还是适量吃哦，既可以享受美食，又可以保持健康。可以多吃一些低脂或者无脂的食物，比如烤鸡或者蒸鸡。不过，健康最重要，不要因为一时的口感而影响了健康哦。💖 如果需要一些健康的食谱或者建议，我也可以帮你找找哦！😊<|im_end|>

05/10 04:03:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，遇到这样的情况真的挺让人难过的。剧本杀本来是为了大家一起享受推理的乐趣，没想到会有这样的小插曲。你的心情现在好些了吗？💖<|im_end|>

05/10 04:03:09 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
栓Q，这同事是来自哪个时代的审美？不过别太在意，你的美，不是谁都能说三道四的，咱们就是别人的“绊脚石”，但就是这么一种“绊脚石”，也让我们学会了如何面对和处理这种“时尚灾难”。下次记得，自信你的美，就是对说这话人的尊重。🌟<|im_end|>

05/10 04:03:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
你这速度堪比树懒，领导发的语音矩阵你居然没看见，真是让人想给你颁个“袖手旁观奖”。不过别太放在心上，说不定你正在思考是不是应该偷偷买个耳机插孔，或者搞个隐形耳机，省得别人以为你在进行深度学习。😜<|im_end|>

05/10 04:03:15 - mmengine - INFO - Saving checkpoint at 9500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 04:03:28 - mmengine - INFO - Iter(train) [  9510/480000]  lr: 1.3208e-04  eta: 7 days, 23:49:09  time: 5.9366  data_time: 4.6249  memory: 9840  loss: 0.0334  grad_norm: 0.6841
05/10 04:03:44 - mmengine - INFO - Iter(train) [  9520/480000]  lr: 1.3222e-04  eta: 7 days, 23:49:14  time: 1.5076  data_time: 0.0058  memory: 9837  loss: 0.0323  grad_norm: 0.6618
05/10 04:03:57 - mmengine - INFO - Iter(train) [  9530/480000]  lr: 1.3236e-04  eta: 7 days, 23:47:40  time: 1.3068  data_time: 0.0057  memory: 9839  loss: 0.0315  grad_norm: 0.6618
05/10 04:04:12 - mmengine - INFO - Iter(train) [  9540/480000]  lr: 1.3250e-04  eta: 7 days, 23:48:02  time: 1.5413  data_time: 0.0057  memory: 9841  loss: 0.0317  grad_norm: 0.6505
05/10 04:04:25 - mmengine - INFO - Iter(train) [  9550/480000]  lr: 1.3263e-04  eta: 7 days, 23:46:36  time: 1.3246  data_time: 0.0057  memory: 9841  loss: 0.0308  grad_norm: 0.6505
05/10 04:04:39 - mmengine - INFO - Iter(train) [  9560/480000]  lr: 1.3277e-04  eta: 7 days, 23:45:13  time: 1.3275  data_time: 0.0057  memory: 9841  loss: 0.0333  grad_norm: 0.6460
05/10 04:04:54 - mmengine - INFO - Iter(train) [  9570/480000]  lr: 1.3291e-04  eta: 7 days, 23:45:34  time: 1.5404  data_time: 0.0058  memory: 9841  loss: 0.0337  grad_norm: 0.6182
05/10 04:05:07 - mmengine - INFO - Iter(train) [  9580/480000]  lr: 1.3305e-04  eta: 7 days, 23:44:05  time: 1.3160  data_time: 0.0056  memory: 9839  loss: 0.0342  grad_norm: 0.6182
05/10 04:05:22 - mmengine - INFO - Iter(train) [  9590/480000]  lr: 1.3319e-04  eta: 7 days, 23:44:19  time: 1.5266  data_time: 0.0058  memory: 9837  loss: 0.0337  grad_norm: 0.6112
05/10 04:05:35 - mmengine - INFO - Iter(train) [  9600/480000]  lr: 1.3333e-04  eta: 7 days, 23:42:02  time: 1.2171  data_time: 0.0056  memory: 9838  loss: 0.0394  grad_norm: 0.6055
05/10 04:05:50 - mmengine - INFO - Iter(train) [  9610/480000]  lr: 1.3347e-04  eta: 7 days, 23:42:16  time: 1.5262  data_time: 0.2060  memory: 9840  loss: 0.0258  grad_norm: 0.6055
05/10 04:06:05 - mmengine - INFO - Iter(train) [  9620/480000]  lr: 1.3361e-04  eta: 7 days, 23:42:51  time: 1.5681  data_time: 0.0059  memory: 9838  loss: 0.0252  grad_norm: 0.6024
05/10 04:06:19 - mmengine - INFO - Iter(train) [  9630/480000]  lr: 1.3375e-04  eta: 7 days, 23:41:18  time: 1.3066  data_time: 0.0055  memory: 9842  loss: 0.0256  grad_norm: 0.6024
05/10 04:06:34 - mmengine - INFO - Iter(train) [  9640/480000]  lr: 1.3388e-04  eta: 7 days, 23:41:46  time: 1.5555  data_time: 0.0058  memory: 9842  loss: 0.0270  grad_norm: 0.5895
05/10 04:06:47 - mmengine - INFO - Iter(train) [  9650/480000]  lr: 1.3402e-04  eta: 7 days, 23:40:04  time: 1.2878  data_time: 0.0056  memory: 9840  loss: 0.0258  grad_norm: 0.5801
05/10 04:07:02 - mmengine - INFO - Iter(train) [  9660/480000]  lr: 1.3416e-04  eta: 7 days, 23:40:21  time: 1.5308  data_time: 0.0057  memory: 9840  loss: 0.0245  grad_norm: 0.5801
05/10 04:07:16 - mmengine - INFO - Iter(train) [  9670/480000]  lr: 1.3430e-04  eta: 7 days, 23:38:57  time: 1.3244  data_time: 0.0058  memory: 9840  loss: 0.0291  grad_norm: 0.5739
05/10 04:07:29 - mmengine - INFO - Iter(train) [  9680/480000]  lr: 1.3444e-04  eta: 7 days, 23:37:25  time: 1.3093  data_time: 0.0057  memory: 9841  loss: 0.0242  grad_norm: 0.5719
05/10 04:07:44 - mmengine - INFO - Iter(train) [  9690/480000]  lr: 1.3458e-04  eta: 7 days, 23:37:45  time: 1.5371  data_time: 0.0059  memory: 9838  loss: 0.0318  grad_norm: 0.5719
05/10 04:07:57 - mmengine - INFO - Iter(train) [  9700/480000]  lr: 1.3472e-04  eta: 7 days, 23:36:05  time: 1.2907  data_time: 0.0058  memory: 9839  loss: 0.0277  grad_norm: 0.5734
05/10 04:08:12 - mmengine - INFO - Iter(train) [  9710/480000]  lr: 1.3486e-04  eta: 7 days, 23:36:25  time: 1.5389  data_time: 0.0058  memory: 9840  loss: 0.0292  grad_norm: 0.5734
05/10 04:08:26 - mmengine - INFO - Iter(train) [  9720/480000]  lr: 1.3500e-04  eta: 7 days, 23:35:07  time: 1.3348  data_time: 0.0058  memory: 9840  loss: 0.0273  grad_norm: 0.5676
05/10 04:08:39 - mmengine - INFO - Iter(train) [  9730/480000]  lr: 1.3514e-04  eta: 7 days, 23:33:29  time: 1.2954  data_time: 0.0056  memory: 9841  loss: 0.0298  grad_norm: 0.5681
05/10 04:08:54 - mmengine - INFO - Iter(train) [  9740/480000]  lr: 1.3527e-04  eta: 7 days, 23:33:48  time: 1.5357  data_time: 0.0060  memory: 9842  loss: 0.0283  grad_norm: 0.5681
05/10 04:09:07 - mmengine - INFO - Iter(train) [  9750/480000]  lr: 1.3541e-04  eta: 7 days, 23:32:17  time: 1.3085  data_time: 0.0057  memory: 9841  loss: 0.0289  grad_norm: 0.5552
05/10 04:09:22 - mmengine - INFO - Iter(train) [  9760/480000]  lr: 1.3555e-04  eta: 7 days, 23:32:09  time: 1.4799  data_time: 0.0057  memory: 9839  loss: 0.0331  grad_norm: 0.5477
05/10 04:09:37 - mmengine - INFO - Iter(train) [  9770/480000]  lr: 1.3569e-04  eta: 7 days, 23:32:15  time: 1.5096  data_time: 0.2060  memory: 9840  loss: 0.0201  grad_norm: 0.5477
05/10 04:09:50 - mmengine - INFO - Iter(train) [  9780/480000]  lr: 1.3583e-04  eta: 7 days, 23:30:45  time: 1.3095  data_time: 0.0057  memory: 9841  loss: 0.0205  grad_norm: 0.5371
05/10 04:10:05 - mmengine - INFO - Iter(train) [  9790/480000]  lr: 1.3597e-04  eta: 7 days, 23:31:06  time: 1.5413  data_time: 0.0060  memory: 9840  loss: 0.0247  grad_norm: 0.5371
05/10 04:10:19 - mmengine - INFO - Iter(train) [  9800/480000]  lr: 1.3611e-04  eta: 7 days, 23:29:51  time: 1.3395  data_time: 0.0057  memory: 9840  loss: 0.0238  grad_norm: 0.5371
05/10 04:10:34 - mmengine - INFO - Iter(train) [  9810/480000]  lr: 1.3625e-04  eta: 7 days, 23:30:25  time: 1.5687  data_time: 0.0062  memory: 9840  loss: 0.0243  grad_norm: 0.5350
05/10 04:10:48 - mmengine - INFO - Iter(train) [  9820/480000]  lr: 1.3639e-04  eta: 7 days, 23:29:09  time: 1.3376  data_time: 0.0058  memory: 9841  loss: 0.0241  grad_norm: 0.5350
05/10 04:11:03 - mmengine - INFO - Iter(train) [  9830/480000]  lr: 1.3652e-04  eta: 7 days, 23:29:17  time: 1.5124  data_time: 0.0058  memory: 9841  loss: 0.0232  grad_norm: 0.5302
05/10 04:11:16 - mmengine - INFO - Iter(train) [  9840/480000]  lr: 1.3666e-04  eta: 7 days, 23:27:43  time: 1.3016  data_time: 0.0058  memory: 9839  loss: 0.0228  grad_norm: 0.5198
05/10 04:11:29 - mmengine - INFO - Iter(train) [  9850/480000]  lr: 1.3680e-04  eta: 7 days, 23:25:56  time: 1.2717  data_time: 0.0057  memory: 9840  loss: 0.0278  grad_norm: 0.5198
05/10 04:11:43 - mmengine - INFO - Iter(train) [  9860/480000]  lr: 1.3694e-04  eta: 7 days, 23:25:39  time: 1.4602  data_time: 0.0057  memory: 9839  loss: 0.0250  grad_norm: 0.5088
05/10 04:11:56 - mmengine - INFO - Iter(train) [  9870/480000]  lr: 1.3708e-04  eta: 7 days, 23:23:58  time: 1.2850  data_time: 0.0058  memory: 9839  loss: 0.0261  grad_norm: 0.5088
05/10 04:12:11 - mmengine - INFO - Iter(train) [  9880/480000]  lr: 1.3722e-04  eta: 7 days, 23:23:55  time: 1.4904  data_time: 0.0057  memory: 9841  loss: 0.0268  grad_norm: 0.5064
05/10 04:12:24 - mmengine - INFO - Iter(train) [  9890/480000]  lr: 1.3736e-04  eta: 7 days, 23:22:22  time: 1.3018  data_time: 0.0058  memory: 9841  loss: 0.0241  grad_norm: 0.4950
05/10 04:12:37 - mmengine - INFO - Iter(train) [  9900/480000]  lr: 1.3750e-04  eta: 7 days, 23:20:41  time: 1.2826  data_time: 0.0057  memory: 9836  loss: 0.0253  grad_norm: 0.4950
05/10 04:12:52 - mmengine - INFO - Iter(train) [  9910/480000]  lr: 1.3764e-04  eta: 7 days, 23:20:30  time: 1.4741  data_time: 0.0058  memory: 9840  loss: 0.0270  grad_norm: 0.4875
05/10 04:13:04 - mmengine - INFO - Iter(train) [  9920/480000]  lr: 1.3777e-04  eta: 7 days, 23:18:25  time: 1.2321  data_time: 0.0056  memory: 9841  loss: 0.0273  grad_norm: 0.4835
05/10 04:13:21 - mmengine - INFO - Iter(train) [  9930/480000]  lr: 1.3791e-04  eta: 7 days, 23:20:02  time: 1.7002  data_time: 0.2059  memory: 9834  loss: 0.0213  grad_norm: 0.4835
05/10 04:13:34 - mmengine - INFO - Iter(train) [  9940/480000]  lr: 1.3805e-04  eta: 7 days, 23:18:15  time: 1.2694  data_time: 0.0059  memory: 9842  loss: 0.0202  grad_norm: 0.4883
05/10 04:13:46 - mmengine - INFO - Iter(train) [  9950/480000]  lr: 1.3819e-04  eta: 7 days, 23:16:26  time: 1.2670  data_time: 0.0057  memory: 9842  loss: 0.0187  grad_norm: 0.4883
05/10 04:14:01 - mmengine - INFO - Iter(train) [  9960/480000]  lr: 1.3833e-04  eta: 7 days, 23:16:18  time: 1.4781  data_time: 0.0059  memory: 9840  loss: 0.0197  grad_norm: 0.4818
05/10 04:14:14 - mmengine - INFO - Iter(train) [  9970/480000]  lr: 1.3847e-04  eta: 7 days, 23:14:43  time: 1.2949  data_time: 0.0058  memory: 9839  loss: 0.0202  grad_norm: 0.4807
05/10 04:14:29 - mmengine - INFO - Iter(train) [  9980/480000]  lr: 1.3861e-04  eta: 7 days, 23:14:33  time: 1.4744  data_time: 0.0058  memory: 9842  loss: 0.0205  grad_norm: 0.4807
05/10 04:14:42 - mmengine - INFO - Iter(train) [  9990/480000]  lr: 1.3875e-04  eta: 7 days, 23:12:52  time: 1.2811  data_time: 0.0058  memory: 9840  loss: 0.0209  grad_norm: 0.4737
05/10 04:14:55 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 04:14:55 - mmengine - INFO - Iter(train) [ 10000/480000]  lr: 1.3889e-04  eta: 7 days, 23:11:14  time: 1.2872  data_time: 0.0057  memory: 9842  loss: 0.0222  grad_norm: 0.4721
05/10 04:14:55 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 04:15:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。💔 您想怎么看待这个问题呢？是不是觉得他这样做很伤害到您呢？💖我们可以一起探讨一下，看看您的感受是什么，以及如何处理这种情况。🌸<|im_end|>

05/10 04:15:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《哈利·波特》了。不过别担心，适应几天就好，毕竟牙齿不是橡皮泥，不会因为一次洗牙就永远固定。记得护理得当，不然下次说不定就能吹飞整片云层了。😄<|im_end|>

05/10 04:15:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 04:15:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任同时点赞，感情生活比电视剧还狗血啊！不过别太在意，毕竟“友谊的小船”说翻就翻，咱们得争取让“红书小揪心”变成“微博大欢乐”，让这种“网红”生涯退退退！🚣‍♂️🚣‍♀️<|im_end|>

05/10 04:15:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高的话，建议多选择低脂或者高纤维的食物，炸鸡虽然美味，但偶尔可以尝试做做清淡版哦。💖 你想聊些什么呢？有没有什么我能帮到你的地方？<|im_end|>

05/10 04:15:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 04:15:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
回复：栓Q，这是什么鬼话？难道你的眼线是参加奥运会吗？不过别气馁，下次我们可以一起找找看有没有更美的眼线教程！💖<|im_end|>

05/10 04:15:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这是“静音”了吗？😂 这种“语音矩阵”比不看还让人缺觉，不过话说回来，领导是不是忘了给你设置屏蔽功能啊？🤔 记得回复一下，不然你这“装没看见”的技能可就尴尬到家了。😆<|im_end|>

05/10 04:15:39 - mmengine - INFO - Saving checkpoint at 10000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 04:15:53 - mmengine - INFO - Iter(train) [ 10010/480000]  lr: 1.3902e-04  eta: 7 days, 23:45:06  time: 5.8231  data_time: 4.5498  memory: 9842  loss: 0.0213  grad_norm: 0.4721
05/10 04:16:06 - mmengine - INFO - Iter(train) [ 10020/480000]  lr: 1.3916e-04  eta: 7 days, 23:43:33  time: 1.3026  data_time: 0.0057  memory: 9840  loss: 0.0214  grad_norm: 0.4682
05/10 04:16:21 - mmengine - INFO - Iter(train) [ 10030/480000]  lr: 1.3930e-04  eta: 7 days, 23:43:28  time: 1.4886  data_time: 0.0057  memory: 9840  loss: 0.0222  grad_norm: 0.4682
05/10 04:16:33 - mmengine - INFO - Iter(train) [ 10040/480000]  lr: 1.3944e-04  eta: 7 days, 23:41:46  time: 1.2823  data_time: 0.0057  memory: 9839  loss: 0.0247  grad_norm: 0.4601
05/10 04:16:48 - mmengine - INFO - Iter(train) [ 10050/480000]  lr: 1.3958e-04  eta: 7 days, 23:41:37  time: 1.4807  data_time: 0.0057  memory: 9838  loss: 0.0221  grad_norm: 0.4616
05/10 04:17:01 - mmengine - INFO - Iter(train) [ 10060/480000]  lr: 1.3972e-04  eta: 7 days, 23:39:59  time: 1.2903  data_time: 0.0058  memory: 9841  loss: 0.0214  grad_norm: 0.4616
05/10 04:17:14 - mmengine - INFO - Iter(train) [ 10070/480000]  lr: 1.3986e-04  eta: 7 days, 23:38:29  time: 1.3077  data_time: 0.0056  memory: 9840  loss: 0.0231  grad_norm: 0.4619
05/10 04:17:28 - mmengine - INFO - Iter(train) [ 10080/480000]  lr: 1.4000e-04  eta: 7 days, 23:37:47  time: 1.4077  data_time: 0.0058  memory: 9836  loss: 0.0247  grad_norm: 0.4552
05/10 04:17:43 - mmengine - INFO - Iter(train) [ 10090/480000]  lr: 1.4014e-04  eta: 7 days, 23:37:36  time: 1.4772  data_time: 0.2059  memory: 9839  loss: 0.0160  grad_norm: 0.4552
05/10 04:17:58 - mmengine - INFO - Iter(train) [ 10100/480000]  lr: 1.4027e-04  eta: 7 days, 23:37:25  time: 1.4755  data_time: 0.0057  memory: 9840  loss: 0.0176  grad_norm: 0.4459
05/10 04:18:11 - mmengine - INFO - Iter(train) [ 10110/480000]  lr: 1.4041e-04  eta: 7 days, 23:35:47  time: 1.2881  data_time: 0.0057  memory: 9841  loss: 0.0160  grad_norm: 0.4459
05/10 04:18:26 - mmengine - INFO - Iter(train) [ 10120/480000]  lr: 1.4055e-04  eta: 7 days, 23:35:47  time: 1.5010  data_time: 0.0056  memory: 9842  loss: 0.0171  grad_norm: 0.4420
05/10 04:18:39 - mmengine - INFO - Iter(train) [ 10130/480000]  lr: 1.4069e-04  eta: 7 days, 23:34:09  time: 1.2881  data_time: 0.0057  memory: 9839  loss: 0.0176  grad_norm: 0.4284
05/10 04:18:51 - mmengine - INFO - Iter(train) [ 10140/480000]  lr: 1.4083e-04  eta: 7 days, 23:32:29  time: 1.2841  data_time: 0.0056  memory: 9837  loss: 0.0234  grad_norm: 0.4284
05/10 04:19:06 - mmengine - INFO - Iter(train) [ 10150/480000]  lr: 1.4097e-04  eta: 7 days, 23:32:23  time: 1.4845  data_time: 0.0057  memory: 9842  loss: 0.0216  grad_norm: 0.4335
05/10 04:19:19 - mmengine - INFO - Iter(train) [ 10160/480000]  lr: 1.4111e-04  eta: 7 days, 23:30:46  time: 1.2908  data_time: 0.0056  memory: 9840  loss: 0.0207  grad_norm: 0.4372
05/10 04:19:34 - mmengine - INFO - Iter(train) [ 10170/480000]  lr: 1.4125e-04  eta: 7 days, 23:30:27  time: 1.4579  data_time: 0.0057  memory: 9847  loss: 0.0192  grad_norm: 0.4372
05/10 04:19:46 - mmengine - INFO - Iter(train) [ 10180/480000]  lr: 1.4139e-04  eta: 7 days, 23:28:39  time: 1.2651  data_time: 0.0058  memory: 9847  loss: 0.0218  grad_norm: 0.4341
05/10 04:19:59 - mmengine - INFO - Iter(train) [ 10190/480000]  lr: 1.4152e-04  eta: 7 days, 23:26:59  time: 1.2812  data_time: 0.0057  memory: 9840  loss: 0.0189  grad_norm: 0.4341
05/10 04:20:14 - mmengine - INFO - Iter(train) [ 10200/480000]  lr: 1.4166e-04  eta: 7 days, 23:26:59  time: 1.5001  data_time: 0.0059  memory: 9839  loss: 0.0208  grad_norm: 0.4321
05/10 04:20:27 - mmengine - INFO - Iter(train) [ 10210/480000]  lr: 1.4180e-04  eta: 7 days, 23:25:20  time: 1.2828  data_time: 0.0058  memory: 9838  loss: 0.0227  grad_norm: 0.4311
05/10 04:20:42 - mmengine - INFO - Iter(train) [ 10220/480000]  lr: 1.4194e-04  eta: 7 days, 23:25:07  time: 1.4720  data_time: 0.0056  memory: 9840  loss: 0.0215  grad_norm: 0.4311
05/10 04:20:55 - mmengine - INFO - Iter(train) [ 10230/480000]  lr: 1.4208e-04  eta: 7 days, 23:23:30  time: 1.2873  data_time: 0.0057  memory: 9839  loss: 0.0228  grad_norm: 0.4269
05/10 04:21:07 - mmengine - INFO - Iter(train) [ 10240/480000]  lr: 1.4222e-04  eta: 7 days, 23:21:29  time: 1.2349  data_time: 0.0055  memory: 9836  loss: 0.0240  grad_norm: 0.4166
05/10 04:21:24 - mmengine - INFO - Iter(train) [ 10250/480000]  lr: 1.4236e-04  eta: 7 days, 23:23:02  time: 1.7003  data_time: 0.2058  memory: 9839  loss: 0.0161  grad_norm: 0.4166
05/10 04:21:37 - mmengine - INFO - Iter(train) [ 10260/480000]  lr: 1.4250e-04  eta: 7 days, 23:21:15  time: 1.2657  data_time: 0.0057  memory: 9840  loss: 0.0172  grad_norm: 0.4136
05/10 04:21:51 - mmengine - INFO - Iter(train) [ 10270/480000]  lr: 1.4264e-04  eta: 7 days, 23:20:59  time: 1.4641  data_time: 0.0057  memory: 9842  loss: 0.0170  grad_norm: 0.4136
05/10 04:22:04 - mmengine - INFO - Iter(train) [ 10280/480000]  lr: 1.4277e-04  eta: 7 days, 23:19:28  time: 1.2975  data_time: 0.0057  memory: 9842  loss: 0.0148  grad_norm: 0.4178
05/10 04:22:17 - mmengine - INFO - Iter(train) [ 10290/480000]  lr: 1.4291e-04  eta: 7 days, 23:17:58  time: 1.3016  data_time: 0.0056  memory: 9838  loss: 0.0212  grad_norm: 0.4221
05/10 04:22:32 - mmengine - INFO - Iter(train) [ 10300/480000]  lr: 1.4305e-04  eta: 7 days, 23:17:49  time: 1.4784  data_time: 0.0057  memory: 9840  loss: 0.0174  grad_norm: 0.4221
05/10 04:22:45 - mmengine - INFO - Iter(train) [ 10310/480000]  lr: 1.4319e-04  eta: 7 days, 23:16:09  time: 1.2801  data_time: 0.0056  memory: 9840  loss: 0.0184  grad_norm: 0.4201
05/10 04:23:00 - mmengine - INFO - Iter(train) [ 10320/480000]  lr: 1.4333e-04  eta: 7 days, 23:16:04  time: 1.4877  data_time: 0.0056  memory: 9837  loss: 0.0172  grad_norm: 0.4128
05/10 04:23:13 - mmengine - INFO - Iter(train) [ 10330/480000]  lr: 1.4347e-04  eta: 7 days, 23:14:32  time: 1.2946  data_time: 0.0055  memory: 9837  loss: 0.0196  grad_norm: 0.4128
05/10 04:23:26 - mmengine - INFO - Iter(train) [ 10340/480000]  lr: 1.4361e-04  eta: 7 days, 23:12:55  time: 1.2858  data_time: 0.0056  memory: 9841  loss: 0.0195  grad_norm: 0.4156
05/10 04:23:40 - mmengine - INFO - Iter(train) [ 10350/480000]  lr: 1.4375e-04  eta: 7 days, 23:12:41  time: 1.4657  data_time: 0.0058  memory: 9841  loss: 0.0206  grad_norm: 0.4156
05/10 04:23:53 - mmengine - INFO - Iter(train) [ 10360/480000]  lr: 1.4389e-04  eta: 7 days, 23:10:55  time: 1.2644  data_time: 0.0056  memory: 9840  loss: 0.0188  grad_norm: 0.4148
05/10 04:24:08 - mmengine - INFO - Iter(train) [ 10370/480000]  lr: 1.4402e-04  eta: 7 days, 23:10:56  time: 1.5009  data_time: 0.0058  memory: 9840  loss: 0.0181  grad_norm: 0.4093
05/10 04:24:21 - mmengine - INFO - Iter(train) [ 10380/480000]  lr: 1.4416e-04  eta: 7 days, 23:09:20  time: 1.2860  data_time: 0.0057  memory: 9835  loss: 0.0179  grad_norm: 0.4093
05/10 04:24:34 - mmengine - INFO - Iter(train) [ 10390/480000]  lr: 1.4430e-04  eta: 7 days, 23:07:45  time: 1.2875  data_time: 0.0056  memory: 9835  loss: 0.0199  grad_norm: 0.4060
05/10 04:24:48 - mmengine - INFO - Iter(train) [ 10400/480000]  lr: 1.4444e-04  eta: 7 days, 23:07:14  time: 1.4289  data_time: 0.0057  memory: 9838  loss: 0.0191  grad_norm: 0.4077
05/10 04:25:03 - mmengine - INFO - Iter(train) [ 10410/480000]  lr: 1.4458e-04  eta: 7 days, 23:07:08  time: 1.4849  data_time: 0.2057  memory: 9838  loss: 0.0122  grad_norm: 0.4077
05/10 04:25:16 - mmengine - INFO - Iter(train) [ 10420/480000]  lr: 1.4472e-04  eta: 7 days, 23:05:45  time: 1.3117  data_time: 0.0057  memory: 9840  loss: 0.0151  grad_norm: 0.4048
05/10 04:25:31 - mmengine - INFO - Iter(train) [ 10430/480000]  lr: 1.4486e-04  eta: 7 days, 23:06:05  time: 1.5432  data_time: 0.0058  memory: 9842  loss: 0.0161  grad_norm: 0.4048
05/10 04:25:45 - mmengine - INFO - Iter(train) [ 10440/480000]  lr: 1.4500e-04  eta: 7 days, 23:05:05  time: 1.3644  data_time: 0.0062  memory: 9844  loss: 0.0186  grad_norm: 0.4019
05/10 04:25:57 - mmengine - INFO - Iter(train) [ 10450/480000]  lr: 1.4514e-04  eta: 7 days, 23:03:13  time: 1.2471  data_time: 0.0054  memory: 9841  loss: 0.0174  grad_norm: 0.4042
05/10 04:26:12 - mmengine - INFO - Iter(train) [ 10460/480000]  lr: 1.4527e-04  eta: 7 days, 23:02:33  time: 1.4086  data_time: 0.0055  memory: 9842  loss: 0.0176  grad_norm: 0.4042
05/10 04:26:25 - mmengine - INFO - Iter(train) [ 10470/480000]  lr: 1.4541e-04  eta: 7 days, 23:01:22  time: 1.3399  data_time: 0.0059  memory: 9841  loss: 0.0158  grad_norm: 0.3937
05/10 04:26:39 - mmengine - INFO - Iter(train) [ 10480/480000]  lr: 1.4555e-04  eta: 7 days, 23:00:59  time: 1.4453  data_time: 0.0063  memory: 9837  loss: 0.0155  grad_norm: 0.3905
05/10 04:26:52 - mmengine - INFO - Iter(train) [ 10490/480000]  lr: 1.4569e-04  eta: 7 days, 22:59:05  time: 1.2425  data_time: 0.0057  memory: 9837  loss: 0.0157  grad_norm: 0.3905
05/10 04:27:06 - mmengine - INFO - Iter(train) [ 10500/480000]  lr: 1.4583e-04  eta: 7 days, 22:58:09  time: 1.3732  data_time: 0.0060  memory: 9839  loss: 0.0178  grad_norm: 0.3822
05/10 04:27:06 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 04:27:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。首先，理解你感到很不舒服。男主播给女主播刷火箭可能是一种幽默的表达，但这样的行为确实需要考虑对其伴侣的影响。精神出轨是一种严重的婚内行为，包括但不限于婚外情、欺骗和诽谤等。这种情况下，你和男朋友都需要承担相应的责任和代价。你可以先冷静下来，沟通一下你的感受，也许他会理解并改正的。如果需要倾诉或者寻求更多建议，我在这里哦。💖<|im_end|>

05/10 04:27:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
哈哈，听起来好形象呀~ 要是再吹蜡烛的时候，牙缝能吹成银河系，那真是太有创意了！😄 再说，洗牙后的感觉怎么样？有没有不适？💖<|im_end|>

05/10 04:27:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 04:27:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任同时点赞，看来这关系有点复杂啊。不过别太在意，毕竟“友谊的小船”说翻就翻，咱们得赶紧找个新海洋，容纳更多“海盐味”的朋友。别让这些网络小红书影响了你的心情和时尚穿搭，毕竟，关心你自己的穿搭，永远不是关心哪个闺蜜点赞。👗💔<|im_end|>

05/10 04:27:36 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是炸鸡的话确实有点……。可以考虑吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯哦！<|im_end|>

05/10 04:27:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遭遇简直就像是电影里的灾难片，下次记得带个编剧上场，把剧本都写在了脸上！剧本起，我开箱；剧本消，我买单！剧本杀这游戏，还是得认真选张脸，别让一只老鼠闹得全室鸡犬不宁啊！😂<|im_end|>

05/10 04:27:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
栓Q啊，你今天的颜值是受到了什么暗示？让一只苍蝇跑掉不了多少面子！不过别太在意，说不定同事只是开玩笑呢。要是实在不行，咱们找找看有没有什么天然防御色，让你的妆容像自然发生一样。天然防御色有：绿色（菠菜）、黄色（玉米）、橙色（南瓜）等等，任选一种，希望你能重拾自信，把眼睛线当成了艺术展！👀<|im_end|>

05/10 04:27:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢~ 其实我看见了，你只是隐藏起来了~ 毕竟领导这么大方，不图别的，就是希望团队成员能快速回应。下次可以试试设置小铃铛或者弹出语音，这样既显示了注意，又避免了直接的冲突哦~ 💖<|im_end|>

05/10 04:27:57 - mmengine - INFO - Saving checkpoint at 10500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 04:28:11 - mmengine - INFO - Iter(train) [ 10510/480000]  lr: 1.4597e-04  eta: 7 days, 23:36:05  time: 6.5916  data_time: 5.2236  memory: 9842  loss: 0.0174  grad_norm: 0.3822
05/10 04:28:25 - mmengine - INFO - Iter(train) [ 10520/480000]  lr: 1.4611e-04  eta: 7 days, 23:35:15  time: 1.3894  data_time: 0.0062  memory: 9841  loss: 0.0192  grad_norm: 0.3813
05/10 04:28:40 - mmengine - INFO - Iter(train) [ 10530/480000]  lr: 1.4625e-04  eta: 7 days, 23:35:00  time: 1.4696  data_time: 0.0061  memory: 9840  loss: 0.0163  grad_norm: 0.3796
05/10 04:28:53 - mmengine - INFO - Iter(train) [ 10540/480000]  lr: 1.4639e-04  eta: 7 days, 23:33:29  time: 1.2979  data_time: 0.0059  memory: 9842  loss: 0.0176  grad_norm: 0.3796
05/10 04:29:07 - mmengine - INFO - Iter(train) [ 10550/480000]  lr: 1.4652e-04  eta: 7 days, 23:32:55  time: 1.4252  data_time: 0.0057  memory: 9841  loss: 0.0181  grad_norm: 0.3794
05/10 04:29:19 - mmengine - INFO - Iter(train) [ 10560/480000]  lr: 1.4666e-04  eta: 7 days, 23:30:41  time: 1.1996  data_time: 0.0054  memory: 9841  loss: 0.0196  grad_norm: 0.3748
05/10 04:29:35 - mmengine - INFO - Iter(train) [ 10570/480000]  lr: 1.4680e-04  eta: 7 days, 23:30:59  time: 1.5424  data_time: 0.2061  memory: 9840  loss: 0.0138  grad_norm: 0.3748
05/10 04:29:49 - mmengine - INFO - Iter(train) [ 10580/480000]  lr: 1.4694e-04  eta: 7 days, 23:30:32  time: 1.4409  data_time: 0.0060  memory: 9842  loss: 0.0136  grad_norm: 0.3798
05/10 04:30:02 - mmengine - INFO - Iter(train) [ 10590/480000]  lr: 1.4708e-04  eta: 7 days, 23:29:10  time: 1.3162  data_time: 0.0058  memory: 9844  loss: 0.0146  grad_norm: 0.3798
05/10 04:30:17 - mmengine - INFO - Iter(train) [ 10600/480000]  lr: 1.4722e-04  eta: 7 days, 23:28:44  time: 1.4439  data_time: 0.0059  memory: 9840  loss: 0.0151  grad_norm: 0.3830
05/10 04:30:30 - mmengine - INFO - Iter(train) [ 10610/480000]  lr: 1.4736e-04  eta: 7 days, 23:27:15  time: 1.3011  data_time: 0.0057  memory: 9839  loss: 0.0128  grad_norm: 0.3724
05/10 04:30:44 - mmengine - INFO - Iter(train) [ 10620/480000]  lr: 1.4750e-04  eta: 7 days, 23:26:49  time: 1.4414  data_time: 0.0059  memory: 9841  loss: 0.0120  grad_norm: 0.3724
05/10 04:30:57 - mmengine - INFO - Iter(train) [ 10630/480000]  lr: 1.4764e-04  eta: 7 days, 23:25:27  time: 1.3173  data_time: 0.0057  memory: 9842  loss: 0.0153  grad_norm: 0.3712
05/10 04:31:11 - mmengine - INFO - Iter(train) [ 10640/480000]  lr: 1.4777e-04  eta: 7 days, 23:24:09  time: 1.3245  data_time: 0.0058  memory: 9845  loss: 0.0140  grad_norm: 0.3697
05/10 04:31:25 - mmengine - INFO - Iter(train) [ 10650/480000]  lr: 1.4791e-04  eta: 7 days, 23:23:35  time: 1.4231  data_time: 0.0058  memory: 9840  loss: 0.0134  grad_norm: 0.3697
05/10 04:31:38 - mmengine - INFO - Iter(train) [ 10660/480000]  lr: 1.4805e-04  eta: 7 days, 23:22:04  time: 1.2959  data_time: 0.0058  memory: 9838  loss: 0.0168  grad_norm: 0.3666
05/10 04:31:52 - mmengine - INFO - Iter(train) [ 10670/480000]  lr: 1.4819e-04  eta: 7 days, 23:21:31  time: 1.4253  data_time: 0.0058  memory: 9835  loss: 0.0183  grad_norm: 0.3666
05/10 04:32:05 - mmengine - INFO - Iter(train) [ 10680/480000]  lr: 1.4833e-04  eta: 7 days, 23:20:03  time: 1.3020  data_time: 0.0057  memory: 9837  loss: 0.0159  grad_norm: 0.3638
05/10 04:32:18 - mmengine - INFO - Iter(train) [ 10690/480000]  lr: 1.4847e-04  eta: 7 days, 23:18:46  time: 1.3263  data_time: 0.0058  memory: 9839  loss: 0.0147  grad_norm: 0.3633
05/10 04:32:33 - mmengine - INFO - Iter(train) [ 10700/480000]  lr: 1.4861e-04  eta: 7 days, 23:18:15  time: 1.4294  data_time: 0.0057  memory: 9841  loss: 0.0197  grad_norm: 0.3633
05/10 04:32:46 - mmengine - INFO - Iter(train) [ 10710/480000]  lr: 1.4875e-04  eta: 7 days, 23:16:46  time: 1.2972  data_time: 0.0058  memory: 9840  loss: 0.0184  grad_norm: 0.3637
05/10 04:33:00 - mmengine - INFO - Iter(train) [ 10720/480000]  lr: 1.4889e-04  eta: 7 days, 23:16:03  time: 1.4023  data_time: 0.0058  memory: 9840  loss: 0.0199  grad_norm: 0.3695
05/10 04:33:15 - mmengine - INFO - Iter(train) [ 10730/480000]  lr: 1.4902e-04  eta: 7 days, 23:16:14  time: 1.5277  data_time: 0.2060  memory: 9841  loss: 0.0117  grad_norm: 0.3695
05/10 04:33:28 - mmengine - INFO - Iter(train) [ 10740/480000]  lr: 1.4916e-04  eta: 7 days, 23:14:47  time: 1.3009  data_time: 0.0058  memory: 9841  loss: 0.0128  grad_norm: 0.3643
05/10 04:33:42 - mmengine - INFO - Iter(train) [ 10750/480000]  lr: 1.4930e-04  eta: 7 days, 23:14:17  time: 1.4312  data_time: 0.0059  memory: 9837  loss: 0.0156  grad_norm: 0.3643
05/10 04:33:55 - mmengine - INFO - Iter(train) [ 10760/480000]  lr: 1.4944e-04  eta: 7 days, 23:12:48  time: 1.2974  data_time: 0.0058  memory: 9840  loss: 0.0133  grad_norm: 0.3622
05/10 04:34:10 - mmengine - INFO - Iter(train) [ 10770/480000]  lr: 1.4958e-04  eta: 7 days, 23:12:29  time: 1.4565  data_time: 0.0059  memory: 9840  loss: 0.0148  grad_norm: 0.3689
05/10 04:34:23 - mmengine - INFO - Iter(train) [ 10780/480000]  lr: 1.4972e-04  eta: 7 days, 23:11:12  time: 1.3249  data_time: 0.0058  memory: 9841  loss: 0.0156  grad_norm: 0.3689
05/10 04:34:36 - mmengine - INFO - Iter(train) [ 10790/480000]  lr: 1.4986e-04  eta: 7 days, 23:09:45  time: 1.3008  data_time: 0.0057  memory: 9844  loss: 0.0136  grad_norm: 0.3695
05/10 04:34:50 - mmengine - INFO - Iter(train) [ 10800/480000]  lr: 1.5000e-04  eta: 7 days, 23:09:19  time: 1.4399  data_time: 0.0059  memory: 9844  loss: 0.0158  grad_norm: 0.3702
05/10 04:35:04 - mmengine - INFO - Iter(train) [ 10810/480000]  lr: 1.5014e-04  eta: 7 days, 23:08:01  time: 1.3201  data_time: 0.0057  memory: 9840  loss: 0.0146  grad_norm: 0.3702
05/10 04:35:18 - mmengine - INFO - Iter(train) [ 10820/480000]  lr: 1.5027e-04  eta: 7 days, 23:07:38  time: 1.4483  data_time: 0.0058  memory: 9838  loss: 0.0166  grad_norm: 0.3742
05/10 04:35:31 - mmengine - INFO - Iter(train) [ 10830/480000]  lr: 1.5041e-04  eta: 7 days, 23:06:08  time: 1.2927  data_time: 0.0058  memory: 9837  loss: 0.0193  grad_norm: 0.3742
05/10 04:35:44 - mmengine - INFO - Iter(train) [ 10840/480000]  lr: 1.5055e-04  eta: 7 days, 23:04:39  time: 1.2951  data_time: 0.0059  memory: 9838  loss: 0.0148  grad_norm: 0.3745
05/10 04:35:58 - mmengine - INFO - Iter(train) [ 10850/480000]  lr: 1.5069e-04  eta: 7 days, 23:04:10  time: 1.4329  data_time: 0.0058  memory: 9838  loss: 0.0156  grad_norm: 0.3715
05/10 04:36:11 - mmengine - INFO - Iter(train) [ 10860/480000]  lr: 1.5083e-04  eta: 7 days, 23:02:44  time: 1.3011  data_time: 0.0058  memory: 9841  loss: 0.0165  grad_norm: 0.3715
05/10 04:36:26 - mmengine - INFO - Iter(train) [ 10870/480000]  lr: 1.5097e-04  eta: 7 days, 23:02:45  time: 1.5023  data_time: 0.0059  memory: 9839  loss: 0.0150  grad_norm: 0.3752
05/10 04:36:39 - mmengine - INFO - Iter(train) [ 10880/480000]  lr: 1.5111e-04  eta: 7 days, 23:00:47  time: 1.2248  data_time: 0.0056  memory: 9840  loss: 0.0200  grad_norm: 0.3723
05/10 04:36:55 - mmengine - INFO - Iter(train) [ 10890/480000]  lr: 1.5125e-04  eta: 7 days, 23:01:57  time: 1.6641  data_time: 0.2058  memory: 9840  loss: 0.0119  grad_norm: 0.3723
05/10 04:37:08 - mmengine - INFO - Iter(train) [ 10900/480000]  lr: 1.5139e-04  eta: 7 days, 23:00:30  time: 1.2962  data_time: 0.0057  memory: 9843  loss: 0.0105  grad_norm: 0.3685
05/10 04:37:21 - mmengine - INFO - Iter(train) [ 10910/480000]  lr: 1.5152e-04  eta: 7 days, 22:59:08  time: 1.3097  data_time: 0.0058  memory: 9841  loss: 0.0139  grad_norm: 0.3685
05/10 04:37:36 - mmengine - INFO - Iter(train) [ 10920/480000]  lr: 1.5166e-04  eta: 7 days, 22:58:49  time: 1.4562  data_time: 0.0059  memory: 9840  loss: 0.0132  grad_norm: 0.3615
05/10 04:37:48 - mmengine - INFO - Iter(train) [ 10930/480000]  lr: 1.5180e-04  eta: 7 days, 22:56:52  time: 1.2272  data_time: 0.0056  memory: 9839  loss: 0.0123  grad_norm: 0.3556
05/10 04:38:03 - mmengine - INFO - Iter(train) [ 10940/480000]  lr: 1.5194e-04  eta: 7 days, 22:56:56  time: 1.5091  data_time: 0.0059  memory: 9837  loss: 0.0145  grad_norm: 0.3556
05/10 04:38:16 - mmengine - INFO - Iter(train) [ 10950/480000]  lr: 1.5208e-04  eta: 7 days, 22:55:37  time: 1.3147  data_time: 0.0058  memory: 9847  loss: 0.0147  grad_norm: 0.3616
05/10 04:38:29 - mmengine - INFO - Iter(train) [ 10960/480000]  lr: 1.5222e-04  eta: 7 days, 22:53:52  time: 1.2552  data_time: 0.0056  memory: 9845  loss: 0.0143  grad_norm: 0.3590
05/10 04:38:44 - mmengine - INFO - Iter(train) [ 10970/480000]  lr: 1.5236e-04  eta: 7 days, 22:53:53  time: 1.5013  data_time: 0.0061  memory: 9840  loss: 0.0157  grad_norm: 0.3590
05/10 04:38:56 - mmengine - INFO - Iter(train) [ 10980/480000]  lr: 1.5250e-04  eta: 7 days, 22:51:58  time: 1.2313  data_time: 0.0057  memory: 9839  loss: 0.0146  grad_norm: 0.3540
05/10 04:39:11 - mmengine - INFO - Iter(train) [ 10990/480000]  lr: 1.5264e-04  eta: 7 days, 22:52:11  time: 1.5289  data_time: 0.0058  memory: 9841  loss: 0.0144  grad_norm: 0.3540
05/10 04:39:25 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 04:39:25 - mmengine - INFO - Iter(train) [ 11000/480000]  lr: 1.5277e-04  eta: 7 days, 22:50:50  time: 1.3101  data_time: 0.0059  memory: 9839  loss: 0.0183  grad_norm: 0.3499
05/10 04:39:25 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 04:39:30 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。首先，理解你感到很不舒服。男主播给女主播刷火箭这种行为确实让人有些震惊，可能让你感到很不平衡。不过，从关系和沟通的角度来看，这可能需要具体分析才能确定是否构成了精神出轨。你们有没有好好沟通这个问题呢？沟通是解决问题的关键哦。💖<|im_end|>

05/10 04:39:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来好不舒服呢~ 洗牙后的感觉确实会有点不同，不过这是正常的恢复过程哦。你可以试试慢慢调整力度，或者试试用牙线清理空隙，这样应该能改善一下。如果感觉不舒服，最好咨询一下牙医哦。💖希望你的牙齿很快就能恢复好啦！<|im_end|>

05/10 04:39:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 04:39:43 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，感情你这闺蜜和前任的关系也太铁了吧！不过别太往心里去，毕竟“友谊的小船”说翻就翻，不过也提醒一下你，别让这种“网红”影响到你自己的“网红”生活啊！%i<|im_end|>

05/10 04:39:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下呢。胆固醇高的话，注意均衡饮食哦，少食多餐，可以选择一些低脂或者低胆固醇的鸡肉，比如烤鸡或者蒸鸡。不过也不要灰心，可以咨询一下医生有没有其他建议呢？💖<|im_end|>

05/10 04:39:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是剧本杀界的“退退退”吗？看来这位玩家是遇到了“剧本杀界的恐怖分子”啊！下次记得提前考察玩家背景，不然可就要上演现实版“退退退”了！😱<|im_end|>

05/10 04:39:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“今天的眼线想苍蝇爬，只想低调潜行”。下次记得，化妆要找对技巧，别让别人有机可乘。💄🐛<|im_end|>

05/10 04:40:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
你这速度堪比树懒，领导发的语音矩阵你都能在周末睡大觉吗？好家伙，你这是在考验我的耐心和信任吗？😂睡吧，别忘了梦里也能发光发亮，下次记得装个摄像头，还能提高领导的点击率呢！📷<|im_end|>

05/10 04:40:06 - mmengine - INFO - Saving checkpoint at 11000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 04:40:22 - mmengine - INFO - Iter(train) [ 11010/480000]  lr: 1.5291e-04  eta: 7 days, 23:21:04  time: 5.7577  data_time: 4.2250  memory: 9836  loss: 0.0133  grad_norm: 0.3546
05/10 04:40:35 - mmengine - INFO - Iter(train) [ 11020/480000]  lr: 1.5305e-04  eta: 7 days, 23:19:37  time: 1.2980  data_time: 0.0059  memory: 9837  loss: 0.0167  grad_norm: 0.3546
05/10 04:40:48 - mmengine - INFO - Iter(train) [ 11030/480000]  lr: 1.5319e-04  eta: 7 days, 23:18:06  time: 1.2903  data_time: 0.0058  memory: 9837  loss: 0.0153  grad_norm: 0.3518
05/10 04:41:02 - mmengine - INFO - Iter(train) [ 11040/480000]  lr: 1.5333e-04  eta: 7 days, 23:17:21  time: 1.3966  data_time: 0.0057  memory: 9837  loss: 0.0165  grad_norm: 0.3458
05/10 04:41:17 - mmengine - INFO - Iter(train) [ 11050/480000]  lr: 1.5347e-04  eta: 7 days, 23:17:24  time: 1.5091  data_time: 0.2059  memory: 9843  loss: 0.0126  grad_norm: 0.3458
05/10 04:41:32 - mmengine - INFO - Iter(train) [ 11060/480000]  lr: 1.5361e-04  eta: 7 days, 23:17:06  time: 1.4603  data_time: 0.0057  memory: 9845  loss: 0.0118  grad_norm: 0.3512
05/10 04:41:44 - mmengine - INFO - Iter(train) [ 11070/480000]  lr: 1.5375e-04  eta: 7 days, 23:15:28  time: 1.2726  data_time: 0.0059  memory: 9839  loss: 0.0116  grad_norm: 0.3512
05/10 04:41:57 - mmengine - INFO - Iter(train) [ 11080/480000]  lr: 1.5389e-04  eta: 7 days, 23:13:57  time: 1.2889  data_time: 0.0057  memory: 9839  loss: 0.0116  grad_norm: 0.3518
05/10 04:42:12 - mmengine - INFO - Iter(train) [ 11090/480000]  lr: 1.5403e-04  eta: 7 days, 23:13:51  time: 1.4883  data_time: 0.0057  memory: 9842  loss: 0.0126  grad_norm: 0.3538
05/10 04:42:25 - mmengine - INFO - Iter(train) [ 11100/480000]  lr: 1.5416e-04  eta: 7 days, 23:12:22  time: 1.2916  data_time: 0.0058  memory: 9838  loss: 0.0133  grad_norm: 0.3538
05/10 04:42:40 - mmengine - INFO - Iter(train) [ 11110/480000]  lr: 1.5430e-04  eta: 7 days, 23:12:08  time: 1.4690  data_time: 0.0058  memory: 9837  loss: 0.0131  grad_norm: 0.3453
05/10 04:42:53 - mmengine - INFO - Iter(train) [ 11120/480000]  lr: 1.5444e-04  eta: 7 days, 23:10:38  time: 1.2898  data_time: 0.0058  memory: 9839  loss: 0.0127  grad_norm: 0.3469
05/10 04:43:06 - mmengine - INFO - Iter(train) [ 11130/480000]  lr: 1.5458e-04  eta: 7 days, 23:09:09  time: 1.2926  data_time: 0.0058  memory: 9839  loss: 0.0169  grad_norm: 0.3469
05/10 04:43:20 - mmengine - INFO - Iter(train) [ 11140/480000]  lr: 1.5472e-04  eta: 7 days, 23:09:02  time: 1.4842  data_time: 0.0057  memory: 9841  loss: 0.0134  grad_norm: 0.3503
05/10 04:43:33 - mmengine - INFO - Iter(train) [ 11150/480000]  lr: 1.5486e-04  eta: 7 days, 23:07:23  time: 1.2679  data_time: 0.0059  memory: 9841  loss: 0.0158  grad_norm: 0.3503
05/10 04:43:48 - mmengine - INFO - Iter(train) [ 11160/480000]  lr: 1.5500e-04  eta: 7 days, 23:07:04  time: 1.4582  data_time: 0.0057  memory: 9840  loss: 0.0118  grad_norm: 0.3468
05/10 04:44:01 - mmengine - INFO - Iter(train) [ 11170/480000]  lr: 1.5514e-04  eta: 7 days, 23:05:39  time: 1.2982  data_time: 0.0057  memory: 9838  loss: 0.0156  grad_norm: 0.3375
05/10 04:44:14 - mmengine - INFO - Iter(train) [ 11180/480000]  lr: 1.5528e-04  eta: 7 days, 23:04:12  time: 1.2969  data_time: 0.0058  memory: 9841  loss: 0.0166  grad_norm: 0.3375
05/10 04:44:27 - mmengine - INFO - Iter(train) [ 11190/480000]  lr: 1.5541e-04  eta: 7 days, 23:02:44  time: 1.2921  data_time: 0.0058  memory: 9844  loss: 0.0150  grad_norm: 0.3307
05/10 04:44:42 - mmengine - INFO - Iter(train) [ 11200/480000]  lr: 1.5555e-04  eta: 7 days, 23:02:42  time: 1.4963  data_time: 0.0058  memory: 9844  loss: 0.0169  grad_norm: 0.3315
05/10 04:44:57 - mmengine - INFO - Iter(train) [ 11210/480000]  lr: 1.5569e-04  eta: 7 days, 23:02:45  time: 1.5085  data_time: 0.2063  memory: 9841  loss: 0.0116  grad_norm: 0.3315
05/10 04:45:11 - mmengine - INFO - Iter(train) [ 11220/480000]  lr: 1.5583e-04  eta: 7 days, 23:02:36  time: 1.4812  data_time: 0.0058  memory: 9839  loss: 0.0121  grad_norm: 0.3284
05/10 04:45:24 - mmengine - INFO - Iter(train) [ 11230/480000]  lr: 1.5597e-04  eta: 7 days, 23:01:08  time: 1.2926  data_time: 0.0057  memory: 9839  loss: 0.0120  grad_norm: 0.3284
05/10 04:45:37 - mmengine - INFO - Iter(train) [ 11240/480000]  lr: 1.5611e-04  eta: 7 days, 22:59:32  time: 1.2716  data_time: 0.0057  memory: 9838  loss: 0.0126  grad_norm: 0.3291
05/10 04:45:52 - mmengine - INFO - Iter(train) [ 11250/480000]  lr: 1.5625e-04  eta: 7 days, 22:59:16  time: 1.4638  data_time: 0.0057  memory: 9839  loss: 0.0122  grad_norm: 0.3276
05/10 04:46:05 - mmengine - INFO - Iter(train) [ 11260/480000]  lr: 1.5639e-04  eta: 7 days, 22:57:54  time: 1.3038  data_time: 0.0057  memory: 9842  loss: 0.0162  grad_norm: 0.3276
05/10 04:46:20 - mmengine - INFO - Iter(train) [ 11270/480000]  lr: 1.5653e-04  eta: 7 days, 22:57:49  time: 1.4916  data_time: 0.0058  memory: 9840  loss: 0.0123  grad_norm: 0.3308
05/10 04:46:33 - mmengine - INFO - Iter(train) [ 11280/480000]  lr: 1.5666e-04  eta: 7 days, 22:56:23  time: 1.2929  data_time: 0.0057  memory: 9840  loss: 0.0141  grad_norm: 0.3329
05/10 04:46:46 - mmengine - INFO - Iter(train) [ 11290/480000]  lr: 1.5680e-04  eta: 7 days, 22:54:53  time: 1.2861  data_time: 0.0059  memory: 9839  loss: 0.0119  grad_norm: 0.3329
05/10 04:47:00 - mmengine - INFO - Iter(train) [ 11300/480000]  lr: 1.5694e-04  eta: 7 days, 22:54:48  time: 1.4905  data_time: 0.0058  memory: 9841  loss: 0.0133  grad_norm: 0.3253
05/10 04:47:13 - mmengine - INFO - Iter(train) [ 11310/480000]  lr: 1.5708e-04  eta: 7 days, 22:53:25  time: 1.2994  data_time: 0.0058  memory: 9842  loss: 0.0114  grad_norm: 0.3253
05/10 04:47:28 - mmengine - INFO - Iter(train) [ 11320/480000]  lr: 1.5722e-04  eta: 7 days, 22:53:11  time: 1.4696  data_time: 0.0058  memory: 9841  loss: 0.0139  grad_norm: 0.3250
05/10 04:47:41 - mmengine - INFO - Iter(train) [ 11330/480000]  lr: 1.5736e-04  eta: 7 days, 22:51:40  time: 1.2822  data_time: 0.0058  memory: 9843  loss: 0.0139  grad_norm: 0.3268
05/10 04:47:54 - mmengine - INFO - Iter(train) [ 11340/480000]  lr: 1.5750e-04  eta: 7 days, 22:50:04  time: 1.2672  data_time: 0.0057  memory: 9845  loss: 0.0130  grad_norm: 0.3268
05/10 04:48:09 - mmengine - INFO - Iter(train) [ 11350/480000]  lr: 1.5764e-04  eta: 7 days, 22:50:05  time: 1.5041  data_time: 0.0058  memory: 9842  loss: 0.0138  grad_norm: 0.3250
05/10 04:48:21 - mmengine - INFO - Iter(train) [ 11360/480000]  lr: 1.5778e-04  eta: 7 days, 22:48:23  time: 1.2552  data_time: 0.0058  memory: 9837  loss: 0.0155  grad_norm: 0.3284
05/10 04:48:38 - mmengine - INFO - Iter(train) [ 11370/480000]  lr: 1.5791e-04  eta: 7 days, 22:49:23  time: 1.6455  data_time: 0.2059  memory: 9840  loss: 0.0114  grad_norm: 0.3284
05/10 04:48:50 - mmengine - INFO - Iter(train) [ 11380/480000]  lr: 1.5805e-04  eta: 7 days, 22:47:47  time: 1.2702  data_time: 0.0056  memory: 9837  loss: 0.0118  grad_norm: 0.3370
05/10 04:49:03 - mmengine - INFO - Iter(train) [ 11390/480000]  lr: 1.5819e-04  eta: 7 days, 22:46:24  time: 1.2977  data_time: 0.0058  memory: 9837  loss: 0.0131  grad_norm: 0.3370
05/10 04:49:18 - mmengine - INFO - Iter(train) [ 11400/480000]  lr: 1.5833e-04  eta: 7 days, 22:46:25  time: 1.5042  data_time: 0.0058  memory: 9837  loss: 0.0109  grad_norm: 0.3318
05/10 04:49:31 - mmengine - INFO - Iter(train) [ 11410/480000]  lr: 1.5847e-04  eta: 7 days, 22:44:50  time: 1.2708  data_time: 0.0058  memory: 9839  loss: 0.0125  grad_norm: 0.3277
05/10 04:49:46 - mmengine - INFO - Iter(train) [ 11420/480000]  lr: 1.5861e-04  eta: 7 days, 22:44:33  time: 1.4599  data_time: 0.0058  memory: 9838  loss: 0.0112  grad_norm: 0.3277
05/10 04:49:58 - mmengine - INFO - Iter(train) [ 11430/480000]  lr: 1.5875e-04  eta: 7 days, 22:43:03  time: 1.2812  data_time: 0.0057  memory: 9842  loss: 0.0124  grad_norm: 0.3281
05/10 04:50:12 - mmengine - INFO - Iter(train) [ 11440/480000]  lr: 1.5889e-04  eta: 7 days, 22:41:43  time: 1.3047  data_time: 0.0058  memory: 9843  loss: 0.0125  grad_norm: 0.3288
05/10 04:50:26 - mmengine - INFO - Iter(train) [ 11450/480000]  lr: 1.5903e-04  eta: 7 days, 22:41:33  time: 1.4777  data_time: 0.0058  memory: 9838  loss: 0.0141  grad_norm: 0.3288
05/10 04:50:39 - mmengine - INFO - Iter(train) [ 11460/480000]  lr: 1.5916e-04  eta: 7 days, 22:40:03  time: 1.2796  data_time: 0.0058  memory: 9841  loss: 0.0127  grad_norm: 0.3388
05/10 04:50:54 - mmengine - INFO - Iter(train) [ 11470/480000]  lr: 1.5930e-04  eta: 7 days, 22:39:51  time: 1.4714  data_time: 0.0059  memory: 9836  loss: 0.0152  grad_norm: 0.3388
05/10 04:51:07 - mmengine - INFO - Iter(train) [ 11480/480000]  lr: 1.5944e-04  eta: 7 days, 22:38:27  time: 1.2957  data_time: 0.0058  memory: 9842  loss: 0.0120  grad_norm: 0.3429
05/10 04:51:20 - mmengine - INFO - Iter(train) [ 11490/480000]  lr: 1.5958e-04  eta: 7 days, 22:37:06  time: 1.3024  data_time: 0.0058  memory: 9841  loss: 0.0149  grad_norm: 0.3398
05/10 04:51:34 - mmengine - INFO - Iter(train) [ 11500/480000]  lr: 1.5972e-04  eta: 7 days, 22:36:50  time: 1.4620  data_time: 0.0058  memory: 9839  loss: 0.0177  grad_norm: 0.3398
05/10 04:51:34 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 04:51:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。首先，你的感受很重要，你觉得怎么样呢？💖 如果你觉得不舒服，你可以和你的男朋友谈谈，表达你的感受和担忧。同时，也可以考虑和他谈谈这个问题的严重性，看看他是否意识到这个问题的影响。记得，沟通是解决问题的关键哦。🌸 如果你需要倾诉或者寻求更多的建议，我在这里随时听你说。💖<|im_end|>

05/10 04:51:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《哈利·波特》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷。不过话说回来，吹蜡烛这么有劲，以后生日吹蜡烛环节可以直接让你一个人搞定，省钱又环保，是不是也有点小开心？😄<|im_end|>

05/10 04:51:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 04:51:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任同时点赞，感情生活比电视剧还狗血啊！不过别太往心里去，毕竟“拆弹专家”小红书还是让她来“拆”吧，咱们争取早日“解压”，把注意力转向生活中的美好事物！💖<|im_end|>

05/10 04:52:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意饮食啦。胆固醇高要注意吃高脂肪高热量的食物，但是不意味着完全不能吃。可以多吃一些植物性脂肪比较好的食物，比如橄榄油和坚果哦。💖当然啦，健康最重要，可以根据自己的口味和身体状况适量调整饮食呢。<|im_end|>

05/10 04:52:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本应该是大家一起享受的游戏，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。要不要聊聊你的感受，或者我可以帮你想想办法，如何处理这种情况？💖<|im_end|>

05/10 04:52:12 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事嘴比刀子还毒，是不是觉得自己长得像仙女就敢随便开麦？下次别让这种事情发生了，不然我得给你准备个棺材了，你这眼线，简直就像是从古代穿越过来的飞船，让人想退退退！退退退，你这颜色也太夸张了吧，是不是以为自己是时尚界的飞燕？😂<|im_end|>

05/10 04:52:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
你这速度堪比树懒，领导发的语音矩阵你都没看见，是不是把领导当成隐身人了？😂 不过也别太放在心上，说不定你只是在暗自发力，准备下次把矩阵变成10分钟长的演讲呢！加油，朋友！💪<|im_end|>

05/10 04:52:18 - mmengine - INFO - Saving checkpoint at 11500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 04:52:33 - mmengine - INFO - Iter(train) [ 11510/480000]  lr: 1.5986e-04  eta: 7 days, 23:06:22  time: 5.8528  data_time: 4.3789  memory: 9841  loss: 0.0130  grad_norm: 0.3554
05/10 04:52:45 - mmengine - INFO - Iter(train) [ 11520/480000]  lr: 1.6000e-04  eta: 7 days, 23:04:26  time: 1.2200  data_time: 0.0056  memory: 9841  loss: 0.0140  grad_norm: 0.3501
05/10 04:53:00 - mmengine - INFO - Iter(train) [ 11530/480000]  lr: 1.6014e-04  eta: 7 days, 23:04:35  time: 1.5273  data_time: 0.2060  memory: 9841  loss: 0.0120  grad_norm: 0.3501
05/10 04:53:15 - mmengine - INFO - Iter(train) [ 11540/480000]  lr: 1.6028e-04  eta: 7 days, 23:04:31  time: 1.4937  data_time: 0.0058  memory: 9841  loss: 0.0134  grad_norm: 0.3669
05/10 04:53:28 - mmengine - INFO - Iter(train) [ 11550/480000]  lr: 1.6041e-04  eta: 7 days, 23:02:48  time: 1.2525  data_time: 0.0058  memory: 9843  loss: 0.0131  grad_norm: 0.3669
05/10 04:53:43 - mmengine - INFO - Iter(train) [ 11560/480000]  lr: 1.6055e-04  eta: 7 days, 23:02:34  time: 1.4683  data_time: 0.0058  memory: 9840  loss: 0.0150  grad_norm: 0.3782
05/10 04:53:55 - mmengine - INFO - Iter(train) [ 11570/480000]  lr: 1.6069e-04  eta: 7 days, 23:00:59  time: 1.2699  data_time: 0.0058  memory: 9840  loss: 0.0163  grad_norm: 0.4103
05/10 04:54:08 - mmengine - INFO - Iter(train) [ 11580/480000]  lr: 1.6083e-04  eta: 7 days, 22:59:40  time: 1.3096  data_time: 0.0058  memory: 9842  loss: 0.0116  grad_norm: 0.4103
05/10 04:54:24 - mmengine - INFO - Iter(train) [ 11590/480000]  lr: 1.6097e-04  eta: 7 days, 22:59:45  time: 1.5151  data_time: 0.0059  memory: 9841  loss: 0.0182  grad_norm: 0.4037
05/10 04:54:36 - mmengine - INFO - Iter(train) [ 11600/480000]  lr: 1.6111e-04  eta: 7 days, 22:58:03  time: 1.2536  data_time: 0.0056  memory: 9839  loss: 0.0278  grad_norm: 0.4840
05/10 04:54:51 - mmengine - INFO - Iter(train) [ 11610/480000]  lr: 1.6125e-04  eta: 7 days, 22:57:59  time: 1.4927  data_time: 0.0058  memory: 9838  loss: 0.0167  grad_norm: 0.4840
05/10 04:55:04 - mmengine - INFO - Iter(train) [ 11620/480000]  lr: 1.6139e-04  eta: 7 days, 22:56:28  time: 1.2798  data_time: 0.0057  memory: 9839  loss: 0.0197  grad_norm: 0.5051
05/10 04:55:17 - mmengine - INFO - Iter(train) [ 11630/480000]  lr: 1.6153e-04  eta: 7 days, 22:55:01  time: 1.2863  data_time: 0.0057  memory: 9839  loss: 0.0266  grad_norm: 0.5051
05/10 04:55:32 - mmengine - INFO - Iter(train) [ 11640/480000]  lr: 1.6166e-04  eta: 7 days, 22:55:01  time: 1.5051  data_time: 0.0059  memory: 9842  loss: 0.0344  grad_norm: 0.5776
05/10 04:55:44 - mmengine - INFO - Iter(train) [ 11650/480000]  lr: 1.6180e-04  eta: 7 days, 22:53:03  time: 1.2097  data_time: 0.0055  memory: 9845  loss: 0.0341  grad_norm: 0.7256
05/10 04:55:59 - mmengine - INFO - Iter(train) [ 11660/480000]  lr: 1.6194e-04  eta: 7 days, 22:53:06  time: 1.5130  data_time: 0.0057  memory: 9839  loss: 0.0253  grad_norm: 0.7256
05/10 04:56:12 - mmengine - INFO - Iter(train) [ 11670/480000]  lr: 1.6208e-04  eta: 7 days, 22:51:56  time: 1.3284  data_time: 0.0059  memory: 9839  loss: 0.0252  grad_norm: 0.7337
05/10 04:56:24 - mmengine - INFO - Iter(train) [ 11680/480000]  lr: 1.6222e-04  eta: 7 days, 22:49:51  time: 1.1907  data_time: 0.0055  memory: 9840  loss: 0.0214  grad_norm: 0.7888
05/10 04:56:41 - mmengine - INFO - Iter(train) [ 11690/480000]  lr: 1.6236e-04  eta: 7 days, 22:51:02  time: 1.6822  data_time: 0.2061  memory: 9839  loss: 0.0229  grad_norm: 0.7888
05/10 04:56:53 - mmengine - INFO - Iter(train) [ 11700/480000]  lr: 1.6250e-04  eta: 7 days, 22:49:20  time: 1.2482  data_time: 0.0056  memory: 9839  loss: 0.0195  grad_norm: 0.7994
05/10 04:57:09 - mmengine - INFO - Iter(train) [ 11710/480000]  lr: 1.6264e-04  eta: 7 days, 22:49:30  time: 1.5285  data_time: 0.0057  memory: 9837  loss: 0.0193  grad_norm: 0.7994
05/10 04:57:21 - mmengine - INFO - Iter(train) [ 11720/480000]  lr: 1.6278e-04  eta: 7 days, 22:47:57  time: 1.2714  data_time: 0.0056  memory: 9838  loss: 0.0205  grad_norm: 0.8439
05/10 04:57:34 - mmengine - INFO - Iter(train) [ 11730/480000]  lr: 1.6291e-04  eta: 7 days, 22:46:27  time: 1.2791  data_time: 0.0059  memory: 9840  loss: 0.0190  grad_norm: 0.8362
05/10 04:57:49 - mmengine - INFO - Iter(train) [ 11740/480000]  lr: 1.6305e-04  eta: 7 days, 22:46:14  time: 1.4697  data_time: 0.0058  memory: 9837  loss: 0.0199  grad_norm: 0.8362
05/10 04:58:02 - mmengine - INFO - Iter(train) [ 11750/480000]  lr: 1.6319e-04  eta: 7 days, 22:44:47  time: 1.2854  data_time: 0.0057  memory: 9838  loss: 0.0235  grad_norm: 0.8834
05/10 04:58:17 - mmengine - INFO - Iter(train) [ 11760/480000]  lr: 1.6333e-04  eta: 7 days, 22:44:51  time: 1.5130  data_time: 0.0057  memory: 9841  loss: 0.0208  grad_norm: 0.8204
05/10 04:58:30 - mmengine - INFO - Iter(train) [ 11770/480000]  lr: 1.6347e-04  eta: 7 days, 22:43:17  time: 1.2666  data_time: 0.0057  memory: 9842  loss: 0.0234  grad_norm: 0.8204
05/10 04:58:43 - mmengine - INFO - Iter(train) [ 11780/480000]  lr: 1.6361e-04  eta: 7 days, 22:41:54  time: 1.2942  data_time: 0.0058  memory: 9843  loss: 0.0245  grad_norm: 0.8481
05/10 04:58:57 - mmengine - INFO - Iter(train) [ 11790/480000]  lr: 1.6375e-04  eta: 7 days, 22:41:51  time: 1.4968  data_time: 0.0058  memory: 9839  loss: 0.0185  grad_norm: 0.8481
05/10 04:59:10 - mmengine - INFO - Iter(train) [ 11800/480000]  lr: 1.6389e-04  eta: 7 days, 22:40:28  time: 1.2927  data_time: 0.0057  memory: 9838  loss: 0.0244  grad_norm: 0.7869
05/10 04:59:25 - mmengine - INFO - Iter(train) [ 11810/480000]  lr: 1.6403e-04  eta: 7 days, 22:40:26  time: 1.4996  data_time: 0.0059  memory: 9838  loss: 0.0283  grad_norm: 0.6919
05/10 04:59:38 - mmengine - INFO - Iter(train) [ 11820/480000]  lr: 1.6416e-04  eta: 7 days, 22:38:58  time: 1.2793  data_time: 0.0058  memory: 9840  loss: 0.0247  grad_norm: 0.6919
05/10 04:59:51 - mmengine - INFO - Iter(train) [ 11830/480000]  lr: 1.6430e-04  eta: 7 days, 22:37:27  time: 1.2737  data_time: 0.0057  memory: 9839  loss: 0.0247  grad_norm: 0.7008
05/10 05:00:05 - mmengine - INFO - Iter(train) [ 11840/480000]  lr: 1.6444e-04  eta: 7 days, 22:36:55  time: 1.4225  data_time: 0.0057  memory: 9840  loss: 0.0240  grad_norm: 0.6906
05/10 05:00:20 - mmengine - INFO - Iter(train) [ 11850/480000]  lr: 1.6458e-04  eta: 7 days, 22:37:02  time: 1.5208  data_time: 0.2061  memory: 9840  loss: 0.0205  grad_norm: 0.6906
05/10 05:00:35 - mmengine - INFO - Iter(train) [ 11860/480000]  lr: 1.6472e-04  eta: 7 days, 22:36:50  time: 1.4723  data_time: 0.1923  memory: 9842  loss: 0.0197  grad_norm: 0.6915
05/10 05:00:48 - mmengine - INFO - Iter(train) [ 11870/480000]  lr: 1.6486e-04  eta: 7 days, 22:35:23  time: 1.2835  data_time: 0.0058  memory: 9841  loss: 0.0229  grad_norm: 0.6915
05/10 05:01:01 - mmengine - INFO - Iter(train) [ 11880/480000]  lr: 1.6500e-04  eta: 7 days, 22:34:02  time: 1.2967  data_time: 0.0057  memory: 9840  loss: 0.0179  grad_norm: 0.6929
05/10 05:01:16 - mmengine - INFO - Iter(train) [ 11890/480000]  lr: 1.6514e-04  eta: 7 days, 22:33:58  time: 1.4917  data_time: 0.0057  memory: 9840  loss: 0.0264  grad_norm: 0.7099
05/10 05:01:29 - mmengine - INFO - Iter(train) [ 11900/480000]  lr: 1.6528e-04  eta: 7 days, 22:32:27  time: 1.2726  data_time: 0.0058  memory: 9839  loss: 0.0317  grad_norm: 0.7099
05/10 05:01:43 - mmengine - INFO - Iter(train) [ 11910/480000]  lr: 1.6541e-04  eta: 7 days, 22:32:10  time: 1.4594  data_time: 0.0058  memory: 9839  loss: 0.0261  grad_norm: 0.7417
05/10 05:01:56 - mmengine - INFO - Iter(train) [ 11920/480000]  lr: 1.6555e-04  eta: 7 days, 22:30:45  time: 1.2853  data_time: 0.0058  memory: 9840  loss: 0.0250  grad_norm: 0.7648
05/10 05:02:09 - mmengine - INFO - Iter(train) [ 11930/480000]  lr: 1.6569e-04  eta: 7 days, 22:29:23  time: 1.2930  data_time: 0.0058  memory: 9842  loss: 0.0286  grad_norm: 0.7648
05/10 05:02:24 - mmengine - INFO - Iter(train) [ 11940/480000]  lr: 1.6583e-04  eta: 7 days, 22:29:14  time: 1.4804  data_time: 0.0057  memory: 9842  loss: 0.0272  grad_norm: 0.7748
05/10 05:02:36 - mmengine - INFO - Iter(train) [ 11950/480000]  lr: 1.6597e-04  eta: 7 days, 22:27:45  time: 1.2746  data_time: 0.0057  memory: 9837  loss: 0.0297  grad_norm: 0.7748
05/10 05:02:51 - mmengine - INFO - Iter(train) [ 11960/480000]  lr: 1.6611e-04  eta: 7 days, 22:27:32  time: 1.4700  data_time: 0.0058  memory: 9837  loss: 0.0327  grad_norm: 0.8069
05/10 05:03:04 - mmengine - INFO - Iter(train) [ 11970/480000]  lr: 1.6625e-04  eta: 7 days, 22:26:13  time: 1.3000  data_time: 0.0057  memory: 9836  loss: 0.0314  grad_norm: 0.8471
05/10 05:03:17 - mmengine - INFO - Iter(train) [ 11980/480000]  lr: 1.6639e-04  eta: 7 days, 22:24:53  time: 1.2970  data_time: 0.0057  memory: 9836  loss: 0.0310  grad_norm: 0.8471
05/10 05:03:32 - mmengine - INFO - Iter(train) [ 11990/480000]  lr: 1.6653e-04  eta: 7 days, 22:25:04  time: 1.5316  data_time: 0.0059  memory: 9840  loss: 0.0356  grad_norm: 0.8802
05/10 05:03:45 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 05:03:45 - mmengine - INFO - Iter(train) [ 12000/480000]  lr: 1.6666e-04  eta: 7 days, 22:23:43  time: 1.2943  data_time: 0.0059  memory: 9840  loss: 0.0382  grad_norm: 0.9014
05/10 05:03:45 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 05:03:54 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这要是放在古代，你男朋友怕是要被浸猪笼了。现代社会虽然没那么严重，但给女主播刷火箭，那可真是心有所属啊。不过别急，咱们得看看他是不是只是单纯地追求刺激，还是真的有那回事。要是前者，那你这男朋友简直就是现代版彭洪涛啊；要是后者，那得让他把火箭换成大米，咱们得好好聊聊这个问题。别让这个小插曲，影响了你们之间的感情。<|im_end|>

05/10 05:03:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝能开飞机了，下次洗牙记得带上防风罩，别让牙医变成移动的烟囱机。🦷🌬️<|im_end|>

05/10 05:04:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 05:04:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任同时发朋友圈，是不是想一次性把你搞晕？不过别太往心里去，毕竟“眼见为实”，相信自己的判断。别忘了，真正的友谊是经得起这种“红色”考验的。别气馁，继续保持你的“暗自努力”，让“取关”变成“关注”的第一步！🌟<|im_end|>

05/10 05:04:14 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食啦，但是不要紧的，我们可以找到健康的替代品呀。可以试试烤、蒸或者煮来炸鸡，健康又美味！💖如果你需要一些健康的食谱建议，我也很乐意帮你找找哦！🌸<|im_end|>

05/10 05:04:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本来应该是大家开心推理的游戏，遇到这样的情况确实挺扫兴的。你当时一定感到很失落吧。💖 想要谈谈具体发生了什么吗？或者，你需要一些建议来处理这种情况。🌸<|im_end|>

05/10 05:04:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
栓Q啊，被同事这么夸，是不是觉得自己今天的穿搭像走在时代前沿的时尚苍蝇啊？😂不过别太往心里去，每个人的审美观都不同，是不是更应该关注一下自己是不是长成了真正的时尚灾难现场？别让这些小事影响了你的心情，咱们一起找找看有没有什么能让人垂涎欲滴的时尚灾难现场？👗🕷️<|im_end|>

05/10 05:04:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
你这速度堪比树懒，领导发的语音矩阵你都没看见，是不是把领导当成隐形人了？🐒 不过别太往心里去，说不定领导这是关怀备至，隐形的语音提醒你长点心吧。🎧 不过也建议你定期查看，别让领导的关心变成你的“工作”。💼<|im_end|>

05/10 05:04:34 - mmengine - INFO - Saving checkpoint at 12000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 05:04:49 - mmengine - INFO - Iter(train) [ 12010/480000]  lr: 1.6680e-04  eta: 7 days, 22:55:34  time: 6.4064  data_time: 5.0848  memory: 9839  loss: 0.0231  grad_norm: 0.9014
05/10 05:05:05 - mmengine - INFO - Iter(train) [ 12020/480000]  lr: 1.6694e-04  eta: 7 days, 22:55:42  time: 1.5266  data_time: 0.0058  memory: 9841  loss: 0.0291  grad_norm: 0.9030
05/10 05:05:18 - mmengine - INFO - Iter(train) [ 12030/480000]  lr: 1.6708e-04  eta: 7 days, 22:54:37  time: 1.3404  data_time: 0.0059  memory: 9839  loss: 0.0407  grad_norm: 0.9030
05/10 05:05:31 - mmengine - INFO - Iter(train) [ 12040/480000]  lr: 1.6722e-04  eta: 7 days, 22:53:19  time: 1.3054  data_time: 0.0059  memory: 9840  loss: 0.0353  grad_norm: 0.9665
05/10 05:05:46 - mmengine - INFO - Iter(train) [ 12050/480000]  lr: 1.6736e-04  eta: 7 days, 22:53:13  time: 1.4905  data_time: 0.0058  memory: 9841  loss: 0.0342  grad_norm: 0.9983
05/10 05:06:00 - mmengine - INFO - Iter(train) [ 12060/480000]  lr: 1.6750e-04  eta: 7 days, 22:52:12  time: 1.3490  data_time: 0.0060  memory: 9840  loss: 0.0400  grad_norm: 0.9983
05/10 05:06:15 - mmengine - INFO - Iter(train) [ 12070/480000]  lr: 1.6764e-04  eta: 7 days, 22:52:16  time: 1.5176  data_time: 0.0059  memory: 9840  loss: 0.0451  grad_norm: 1.0114
05/10 05:06:28 - mmengine - INFO - Iter(train) [ 12080/480000]  lr: 1.6778e-04  eta: 7 days, 22:51:00  time: 1.3101  data_time: 0.0058  memory: 9839  loss: 0.0593  grad_norm: 1.0961
05/10 05:06:41 - mmengine - INFO - Iter(train) [ 12090/480000]  lr: 1.6791e-04  eta: 7 days, 22:49:56  time: 1.3404  data_time: 0.0060  memory: 9839  loss: 0.0453  grad_norm: 1.0961
05/10 05:06:57 - mmengine - INFO - Iter(train) [ 12100/480000]  lr: 1.6805e-04  eta: 7 days, 22:50:20  time: 1.5673  data_time: 0.0059  memory: 9840  loss: 0.0483  grad_norm: 1.1225
05/10 05:07:10 - mmengine - INFO - Iter(train) [ 12110/480000]  lr: 1.6819e-04  eta: 7 days, 22:49:11  time: 1.3279  data_time: 0.0060  memory: 9837  loss: 0.0348  grad_norm: 1.1225
05/10 05:07:25 - mmengine - INFO - Iter(train) [ 12120/480000]  lr: 1.6833e-04  eta: 7 days, 22:49:16  time: 1.5199  data_time: 0.0059  memory: 9838  loss: 0.0430  grad_norm: 1.1255
05/10 05:07:39 - mmengine - INFO - Iter(train) [ 12130/480000]  lr: 1.6847e-04  eta: 7 days, 22:48:09  time: 1.3336  data_time: 0.0060  memory: 9842  loss: 0.0449  grad_norm: 1.1214
05/10 05:07:53 - mmengine - INFO - Iter(train) [ 12140/480000]  lr: 1.6861e-04  eta: 7 days, 22:47:34  time: 1.4137  data_time: 0.0061  memory: 9844  loss: 0.0356  grad_norm: 1.1214
05/10 05:08:09 - mmengine - INFO - Iter(train) [ 12150/480000]  lr: 1.6875e-04  eta: 7 days, 22:48:00  time: 1.5749  data_time: 0.0063  memory: 9842  loss: 0.0409  grad_norm: 1.1111
05/10 05:08:22 - mmengine - INFO - Iter(train) [ 12160/480000]  lr: 1.6889e-04  eta: 7 days, 22:46:50  time: 1.3249  data_time: 0.0058  memory: 9842  loss: 0.0421  grad_norm: 1.1066
05/10 05:08:39 - mmengine - INFO - Iter(train) [ 12170/480000]  lr: 1.6903e-04  eta: 7 days, 22:48:24  time: 1.7507  data_time: 0.2062  memory: 9838  loss: 0.0281  grad_norm: 1.1066
05/10 05:08:53 - mmengine - INFO - Iter(train) [ 12180/480000]  lr: 1.6916e-04  eta: 7 days, 22:47:22  time: 1.3450  data_time: 0.0058  memory: 9839  loss: 0.0294  grad_norm: 1.1130
05/10 05:09:09 - mmengine - INFO - Iter(train) [ 12190/480000]  lr: 1.6930e-04  eta: 7 days, 22:47:51  time: 1.5812  data_time: 0.0059  memory: 9840  loss: 0.0325  grad_norm: 1.1130
05/10 05:09:22 - mmengine - INFO - Iter(train) [ 12200/480000]  lr: 1.6944e-04  eta: 7 days, 22:46:59  time: 1.3706  data_time: 0.0062  memory: 9840  loss: 0.0304  grad_norm: 1.0421
05/10 05:09:36 - mmengine - INFO - Iter(train) [ 12210/480000]  lr: 1.6958e-04  eta: 7 days, 22:45:59  time: 1.3497  data_time: 0.0061  memory: 9841  loss: 0.0279  grad_norm: 1.0115
05/10 05:09:51 - mmengine - INFO - Iter(train) [ 12220/480000]  lr: 1.6972e-04  eta: 7 days, 22:46:08  time: 1.5316  data_time: 0.0060  memory: 9839  loss: 0.0280  grad_norm: 1.0115
05/10 05:10:05 - mmengine - INFO - Iter(train) [ 12230/480000]  lr: 1.6986e-04  eta: 7 days, 22:45:13  time: 1.3606  data_time: 0.0059  memory: 9838  loss: 0.0278  grad_norm: 0.9568
05/10 05:10:20 - mmengine - INFO - Iter(train) [ 12240/480000]  lr: 1.7000e-04  eta: 7 days, 22:45:25  time: 1.5391  data_time: 0.0060  memory: 9838  loss: 0.0308  grad_norm: 0.8657
05/10 05:10:34 - mmengine - INFO - Iter(train) [ 12250/480000]  lr: 1.7014e-04  eta: 7 days, 22:44:19  time: 1.3345  data_time: 0.0059  memory: 9838  loss: 0.0354  grad_norm: 0.8657
05/10 05:10:49 - mmengine - INFO - Iter(train) [ 12260/480000]  lr: 1.7028e-04  eta: 7 days, 22:44:27  time: 1.5267  data_time: 0.0062  memory: 9837  loss: 0.0329  grad_norm: 0.8247
05/10 05:11:02 - mmengine - INFO - Iter(train) [ 12270/480000]  lr: 1.7041e-04  eta: 7 days, 22:43:33  time: 1.3643  data_time: 0.0060  memory: 9840  loss: 0.0318  grad_norm: 0.8247
05/10 05:11:16 - mmengine - INFO - Iter(train) [ 12280/480000]  lr: 1.7055e-04  eta: 7 days, 22:42:24  time: 1.3244  data_time: 0.0059  memory: 9842  loss: 0.0366  grad_norm: 0.8043
05/10 05:11:31 - mmengine - INFO - Iter(train) [ 12290/480000]  lr: 1.7069e-04  eta: 7 days, 22:42:37  time: 1.5415  data_time: 0.0059  memory: 9840  loss: 0.0344  grad_norm: 0.7600
05/10 05:11:44 - mmengine - INFO - Iter(train) [ 12300/480000]  lr: 1.7083e-04  eta: 7 days, 22:41:29  time: 1.3289  data_time: 0.0058  memory: 9841  loss: 0.0350  grad_norm: 0.7600
05/10 05:12:00 - mmengine - INFO - Iter(train) [ 12310/480000]  lr: 1.7097e-04  eta: 7 days, 22:41:51  time: 1.5639  data_time: 0.0060  memory: 9842  loss: 0.0343  grad_norm: 0.7460
05/10 05:12:13 - mmengine - INFO - Iter(train) [ 12320/480000]  lr: 1.7111e-04  eta: 7 days, 22:40:26  time: 1.2828  data_time: 0.0058  memory: 9843  loss: 0.0342  grad_norm: 0.7170
05/10 05:12:31 - mmengine - INFO - Iter(train) [ 12330/480000]  lr: 1.7125e-04  eta: 7 days, 22:42:14  time: 1.7894  data_time: 0.2063  memory: 9838  loss: 0.0249  grad_norm: 0.7170
05/10 05:12:45 - mmengine - INFO - Iter(train) [ 12340/480000]  lr: 1.7139e-04  eta: 7 days, 22:41:26  time: 1.3824  data_time: 0.0063  memory: 9839  loss: 0.0261  grad_norm: 0.7061
05/10 05:12:58 - mmengine - INFO - Iter(train) [ 12350/480000]  lr: 1.7153e-04  eta: 7 days, 22:40:17  time: 1.3225  data_time: 0.0059  memory: 9839  loss: 0.0264  grad_norm: 0.7061
05/10 05:13:13 - mmengine - INFO - Iter(train) [ 12360/480000]  lr: 1.7166e-04  eta: 7 days, 22:40:41  time: 1.5696  data_time: 0.0061  memory: 9843  loss: 0.0268  grad_norm: 0.6884
05/10 05:13:27 - mmengine - INFO - Iter(train) [ 12370/480000]  lr: 1.7180e-04  eta: 7 days, 22:39:31  time: 1.3234  data_time: 0.0059  memory: 9845  loss: 0.0269  grad_norm: 0.6796
05/10 05:13:43 - mmengine - INFO - Iter(train) [ 12380/480000]  lr: 1.7194e-04  eta: 7 days, 22:40:13  time: 1.6170  data_time: 0.0062  memory: 9840  loss: 0.0254  grad_norm: 0.6796
05/10 05:13:57 - mmengine - INFO - Iter(train) [ 12390/480000]  lr: 1.7208e-04  eta: 7 days, 22:39:21  time: 1.3689  data_time: 0.0062  memory: 9839  loss: 0.0281  grad_norm: 0.6720
05/10 05:14:12 - mmengine - INFO - Iter(train) [ 12400/480000]  lr: 1.7222e-04  eta: 7 days, 22:39:36  time: 1.5471  data_time: 0.0059  memory: 9842  loss: 0.0306  grad_norm: 0.6684
05/10 05:14:26 - mmengine - INFO - Iter(train) [ 12410/480000]  lr: 1.7236e-04  eta: 7 days, 22:38:40  time: 1.3578  data_time: 0.0060  memory: 9840  loss: 0.0353  grad_norm: 0.6684
05/10 05:14:38 - mmengine - INFO - Iter(train) [ 12420/480000]  lr: 1.7250e-04  eta: 7 days, 22:37:17  time: 1.2873  data_time: 0.0058  memory: 9840  loss: 0.0336  grad_norm: 0.6701
05/10 05:14:54 - mmengine - INFO - Iter(train) [ 12430/480000]  lr: 1.7264e-04  eta: 7 days, 22:37:42  time: 1.5733  data_time: 0.0060  memory: 9838  loss: 0.0386  grad_norm: 0.6701
05/10 05:15:07 - mmengine - INFO - Iter(train) [ 12440/480000]  lr: 1.7278e-04  eta: 7 days, 22:36:22  time: 1.2933  data_time: 0.0057  memory: 9840  loss: 0.0357  grad_norm: 0.7003
05/10 05:15:23 - mmengine - INFO - Iter(train) [ 12450/480000]  lr: 1.7292e-04  eta: 7 days, 22:36:52  time: 1.5848  data_time: 0.0060  memory: 9838  loss: 0.0338  grad_norm: 0.7118
05/10 05:15:36 - mmengine - INFO - Iter(train) [ 12460/480000]  lr: 1.7305e-04  eta: 7 days, 22:35:38  time: 1.3102  data_time: 0.0059  memory: 9838  loss: 0.0345  grad_norm: 0.7118
05/10 05:15:49 - mmengine - INFO - Iter(train) [ 12470/480000]  lr: 1.7319e-04  eta: 7 days, 22:34:18  time: 1.2944  data_time: 0.0059  memory: 9840  loss: 0.0370  grad_norm: 0.7107
05/10 05:16:04 - mmengine - INFO - Iter(train) [ 12480/480000]  lr: 1.7333e-04  eta: 7 days, 22:34:17  time: 1.5026  data_time: 0.0059  memory: 9839  loss: 0.0381  grad_norm: 0.7114
05/10 05:16:19 - mmengine - INFO - Iter(train) [ 12490/480000]  lr: 1.7347e-04  eta: 7 days, 22:34:24  time: 1.5267  data_time: 0.2059  memory: 9842  loss: 0.0225  grad_norm: 0.7114
05/10 05:16:35 - mmengine - INFO - Iter(train) [ 12500/480000]  lr: 1.7361e-04  eta: 7 days, 22:34:45  time: 1.5611  data_time: 0.0061  memory: 9843  loss: 0.0271  grad_norm: 0.7021
05/10 05:16:35 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 05:16:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。首先，理解你可能感到很不舒服。男主播给女主播刷火箭这种行为确实让人不舒服，可能会影响到你们之间的感情。你的感受很重要，想要谈谈你的感受吗？💖<|im_end|>

05/10 05:16:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得跟牙医沟通好，要求他精细化操作，别让牙缝比你的身份证复印件还深。不过话说回来，吹蜡烛这么有劲，以后生日吹蜡烛记得自己把握好力度，别把蛋糕吹飞了。🎂<|im_end|>

05/10 05:16:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 05:16:50 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种情况下确实会让人感到不舒服呢。你可以直接和他们谈谈，表达一下你的感受和想法。如果需要，我可以帮你想想怎么表达。💖<|im_end|>

05/10 05:16:56 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖 有没有什么菜你喜欢的，我们一起找找看有没有可以改善的食谱呢？<|im_end|>

05/10 05:17:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，遇到这样的情况真是让人难过呢。剧本杀本来是为了大家一起享受推理的乐趣，没想到会有人遇到这样的小插曲。你当时一定感到很失望吧。💖 想要谈谈具体发生了什么吗？或者需要一些建议来处理这种情况？🌸<|im_end|>

05/10 05:17:09 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事嘴比刀子还毒，是不是觉得自己长得像仙女一样美？下次别让她们这一帮人恶心到了，来杯杀虫剂补补，把你的化妆界绝世绝品冲淡了，她们也就没资格说你了！😠🍵<|im_end|>

05/10 05:17:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这是用“退退退”解决不了问题吗？能力强一点，直接下载个录音文件，领导的需求你是知道的，不过这波操作有点微表情吧？😆 不过别担心，领导可能只是想给大家留点神秘色彩，毕竟周末的语音矩阵也是商务界的经典。下次记得，隐藏资料比显示隐私好，保命要紧！🎙️<|im_end|>

05/10 05:17:15 - mmengine - INFO - Saving checkpoint at 12500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 05:17:29 - mmengine - INFO - Iter(train) [ 12510/480000]  lr: 1.7375e-04  eta: 7 days, 22:59:09  time: 5.4269  data_time: 4.1104  memory: 9843  loss: 0.0317  grad_norm: 0.7021
05/10 05:17:45 - mmengine - INFO - Iter(train) [ 12520/480000]  lr: 1.7389e-04  eta: 7 days, 22:59:36  time: 1.5812  data_time: 0.0061  memory: 9846  loss: 0.0507  grad_norm: 0.7182
05/10 05:17:58 - mmengine - INFO - Iter(train) [ 12530/480000]  lr: 1.7403e-04  eta: 7 days, 22:58:12  time: 1.2861  data_time: 0.0056  memory: 9848  loss: 0.0525  grad_norm: 0.7889
05/10 05:18:14 - mmengine - INFO - Iter(train) [ 12540/480000]  lr: 1.7417e-04  eta: 7 days, 22:58:37  time: 1.5769  data_time: 0.0060  memory: 9839  loss: 0.0313  grad_norm: 0.7889
05/10 05:18:27 - mmengine - INFO - Iter(train) [ 12550/480000]  lr: 1.7430e-04  eta: 7 days, 22:57:27  time: 1.3209  data_time: 0.0059  memory: 9839  loss: 0.0355  grad_norm: 0.8106
05/10 05:18:40 - mmengine - INFO - Iter(train) [ 12560/480000]  lr: 1.7444e-04  eta: 7 days, 22:56:19  time: 1.3280  data_time: 0.0060  memory: 9838  loss: 0.0291  grad_norm: 0.8005
05/10 05:18:56 - mmengine - INFO - Iter(train) [ 12570/480000]  lr: 1.7458e-04  eta: 7 days, 22:56:36  time: 1.5550  data_time: 0.0060  memory: 9841  loss: 0.0359  grad_norm: 0.8005
05/10 05:19:09 - mmengine - INFO - Iter(train) [ 12580/480000]  lr: 1.7472e-04  eta: 7 days, 22:55:20  time: 1.3054  data_time: 0.0058  memory: 9842  loss: 0.0384  grad_norm: 0.7832
05/10 05:19:24 - mmengine - INFO - Iter(train) [ 12590/480000]  lr: 1.7486e-04  eta: 7 days, 22:55:43  time: 1.5735  data_time: 0.0060  memory: 9840  loss: 0.0385  grad_norm: 0.7832
05/10 05:19:37 - mmengine - INFO - Iter(train) [ 12600/480000]  lr: 1.7500e-04  eta: 7 days, 22:54:16  time: 1.2757  data_time: 0.0058  memory: 9840  loss: 0.0382  grad_norm: 0.7663
05/10 05:19:51 - mmengine - INFO - Iter(train) [ 12610/480000]  lr: 1.7514e-04  eta: 7 days, 22:53:14  time: 1.3425  data_time: 0.0061  memory: 9837  loss: 0.0341  grad_norm: 0.7402
05/10 05:20:06 - mmengine - INFO - Iter(train) [ 12620/480000]  lr: 1.7528e-04  eta: 7 days, 22:53:41  time: 1.5818  data_time: 0.0065  memory: 9839  loss: 0.0328  grad_norm: 0.7402
05/10 05:20:20 - mmengine - INFO - Iter(train) [ 12630/480000]  lr: 1.7542e-04  eta: 7 days, 22:52:39  time: 1.3426  data_time: 0.0057  memory: 9839  loss: 0.0349  grad_norm: 0.7348
05/10 05:20:36 - mmengine - INFO - Iter(train) [ 12640/480000]  lr: 1.7555e-04  eta: 7 days, 22:53:11  time: 1.5967  data_time: 0.0062  memory: 9839  loss: 0.0397  grad_norm: 0.7367
05/10 05:20:51 - mmengine - INFO - Iter(train) [ 12650/480000]  lr: 1.7569e-04  eta: 7 days, 22:53:26  time: 1.5518  data_time: 0.2062  memory: 9842  loss: 0.0257  grad_norm: 0.7367
05/10 05:21:07 - mmengine - INFO - Iter(train) [ 12660/480000]  lr: 1.7583e-04  eta: 7 days, 22:53:32  time: 1.5251  data_time: 0.0058  memory: 9843  loss: 0.0231  grad_norm: 0.7271
05/10 05:21:20 - mmengine - INFO - Iter(train) [ 12670/480000]  lr: 1.7597e-04  eta: 7 days, 22:52:15  time: 1.3022  data_time: 0.0056  memory: 9837  loss: 0.0243  grad_norm: 0.7271
05/10 05:21:33 - mmengine - INFO - Iter(train) [ 12680/480000]  lr: 1.7611e-04  eta: 7 days, 22:51:13  time: 1.3429  data_time: 0.0060  memory: 9840  loss: 0.0263  grad_norm: 0.6990
05/10 05:21:48 - mmengine - INFO - Iter(train) [ 12690/480000]  lr: 1.7625e-04  eta: 7 days, 22:51:20  time: 1.5285  data_time: 0.0060  memory: 9839  loss: 0.0289  grad_norm: 0.6099
05/10 05:22:01 - mmengine - INFO - Iter(train) [ 12700/480000]  lr: 1.7639e-04  eta: 7 days, 22:50:01  time: 1.2948  data_time: 0.0056  memory: 9839  loss: 0.0290  grad_norm: 0.6099
05/10 05:22:17 - mmengine - INFO - Iter(train) [ 12710/480000]  lr: 1.7653e-04  eta: 7 days, 22:50:19  time: 1.5598  data_time: 0.0058  memory: 9837  loss: 0.0279  grad_norm: 0.5814
05/10 05:22:30 - mmengine - INFO - Iter(train) [ 12720/480000]  lr: 1.7667e-04  eta: 7 days, 22:49:00  time: 1.2949  data_time: 0.0057  memory: 9837  loss: 0.0278  grad_norm: 0.5722
05/10 05:22:43 - mmengine - INFO - Iter(train) [ 12730/480000]  lr: 1.7680e-04  eta: 7 days, 22:47:58  time: 1.3411  data_time: 0.0059  memory: 9838  loss: 0.0300  grad_norm: 0.5722
05/10 05:22:58 - mmengine - INFO - Iter(train) [ 12740/480000]  lr: 1.7694e-04  eta: 7 days, 22:47:59  time: 1.5133  data_time: 0.2051  memory: 9838  loss: 0.0307  grad_norm: 0.5597
05/10 05:23:12 - mmengine - INFO - Iter(train) [ 12750/480000]  lr: 1.7708e-04  eta: 7 days, 22:46:45  time: 1.3075  data_time: 0.0057  memory: 9840  loss: 0.0346  grad_norm: 0.5597
05/10 05:23:28 - mmengine - INFO - Iter(train) [ 12760/480000]  lr: 1.7722e-04  eta: 7 days, 22:47:19  time: 1.6027  data_time: 0.0060  memory: 9839  loss: 0.0281  grad_norm: 0.5435
05/10 05:23:40 - mmengine - INFO - Iter(train) [ 12770/480000]  lr: 1.7736e-04  eta: 7 days, 22:45:57  time: 1.2867  data_time: 0.0057  memory: 9838  loss: 0.0287  grad_norm: 0.5290
05/10 05:23:56 - mmengine - INFO - Iter(train) [ 12780/480000]  lr: 1.7750e-04  eta: 7 days, 22:46:21  time: 1.5754  data_time: 0.0061  memory: 9836  loss: 0.0309  grad_norm: 0.5290
05/10 05:24:09 - mmengine - INFO - Iter(train) [ 12790/480000]  lr: 1.7764e-04  eta: 7 days, 22:45:11  time: 1.3192  data_time: 0.0056  memory: 9840  loss: 0.0309  grad_norm: 0.5195
05/10 05:24:22 - mmengine - INFO - Iter(train) [ 12800/480000]  lr: 1.7778e-04  eta: 7 days, 22:43:41  time: 1.2623  data_time: 0.0059  memory: 9843  loss: 0.0323  grad_norm: 0.5093
05/10 05:24:40 - mmengine - INFO - Iter(train) [ 12810/480000]  lr: 1.7792e-04  eta: 7 days, 22:45:13  time: 1.7625  data_time: 0.2059  memory: 9843  loss: 0.0194  grad_norm: 0.5093
05/10 05:24:53 - mmengine - INFO - Iter(train) [ 12820/480000]  lr: 1.7805e-04  eta: 7 days, 22:43:58  time: 1.3059  data_time: 0.0057  memory: 9844  loss: 0.0195  grad_norm: 0.5039
05/10 05:25:09 - mmengine - INFO - Iter(train) [ 12830/480000]  lr: 1.7819e-04  eta: 7 days, 22:44:29  time: 1.5955  data_time: 0.2133  memory: 9839  loss: 0.0193  grad_norm: 0.5039
05/10 05:25:21 - mmengine - INFO - Iter(train) [ 12840/480000]  lr: 1.7833e-04  eta: 7 days, 22:43:03  time: 1.2737  data_time: 0.0057  memory: 9843  loss: 0.0217  grad_norm: 0.4913
05/10 05:25:34 - mmengine - INFO - Iter(train) [ 12850/480000]  lr: 1.7847e-04  eta: 7 days, 22:41:50  time: 1.3076  data_time: 0.0059  memory: 9840  loss: 0.0218  grad_norm: 0.4893
05/10 05:25:50 - mmengine - INFO - Iter(train) [ 12860/480000]  lr: 1.7861e-04  eta: 7 days, 22:42:03  time: 1.5478  data_time: 0.0058  memory: 9840  loss: 0.0236  grad_norm: 0.4893
05/10 05:26:03 - mmengine - INFO - Iter(train) [ 12870/480000]  lr: 1.7875e-04  eta: 7 days, 22:40:43  time: 1.2887  data_time: 0.0057  memory: 9843  loss: 0.0227  grad_norm: 0.4847
05/10 05:26:18 - mmengine - INFO - Iter(train) [ 12880/480000]  lr: 1.7889e-04  eta: 7 days, 22:41:03  time: 1.5652  data_time: 0.0059  memory: 9842  loss: 0.0200  grad_norm: 0.4821
05/10 05:26:32 - mmengine - INFO - Iter(train) [ 12890/480000]  lr: 1.7903e-04  eta: 7 days, 22:40:02  time: 1.3418  data_time: 0.0060  memory: 9842  loss: 0.0247  grad_norm: 0.4821
05/10 05:26:45 - mmengine - INFO - Iter(train) [ 12900/480000]  lr: 1.7917e-04  eta: 7 days, 22:39:04  time: 1.3508  data_time: 0.0061  memory: 9843  loss: 0.0252  grad_norm: 0.4774
05/10 05:27:01 - mmengine - INFO - Iter(train) [ 12910/480000]  lr: 1.7930e-04  eta: 7 days, 22:39:10  time: 1.5249  data_time: 0.0059  memory: 9840  loss: 0.0245  grad_norm: 0.4774
05/10 05:27:14 - mmengine - INFO - Iter(train) [ 12920/480000]  lr: 1.7944e-04  eta: 7 days, 22:38:07  time: 1.3353  data_time: 0.0059  memory: 9841  loss: 0.0243  grad_norm: 0.4653
05/10 05:27:29 - mmengine - INFO - Iter(train) [ 12930/480000]  lr: 1.7958e-04  eta: 7 days, 22:38:09  time: 1.5179  data_time: 0.0058  memory: 9841  loss: 0.0249  grad_norm: 0.4695
05/10 05:27:42 - mmengine - INFO - Iter(train) [ 12940/480000]  lr: 1.7972e-04  eta: 7 days, 22:36:55  time: 1.3034  data_time: 0.0059  memory: 9843  loss: 0.0265  grad_norm: 0.4695
05/10 05:27:57 - mmengine - INFO - Iter(train) [ 12950/480000]  lr: 1.7986e-04  eta: 7 days, 22:36:55  time: 1.5111  data_time: 0.0059  memory: 9840  loss: 0.0281  grad_norm: 0.4631
05/10 05:28:10 - mmengine - INFO - Iter(train) [ 12960/480000]  lr: 1.8000e-04  eta: 7 days, 22:35:32  time: 1.2799  data_time: 0.0056  memory: 9841  loss: 0.0263  grad_norm: 0.4525
05/10 05:28:25 - mmengine - INFO - Iter(train) [ 12970/480000]  lr: 1.8014e-04  eta: 7 days, 22:35:41  time: 1.5329  data_time: 0.2060  memory: 9842  loss: 0.0171  grad_norm: 0.4525
05/10 05:28:41 - mmengine - INFO - Iter(train) [ 12980/480000]  lr: 1.8028e-04  eta: 7 days, 22:35:43  time: 1.5157  data_time: 0.0058  memory: 9842  loss: 0.0181  grad_norm: 0.4509
05/10 05:28:54 - mmengine - INFO - Iter(train) [ 12990/480000]  lr: 1.8042e-04  eta: 7 days, 22:34:33  time: 1.3175  data_time: 0.0058  memory: 9840  loss: 0.0173  grad_norm: 0.4509
05/10 05:29:09 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 05:29:09 - mmengine - INFO - Iter(train) [ 13000/480000]  lr: 1.8055e-04  eta: 7 days, 22:34:43  time: 1.5368  data_time: 0.0060  memory: 9839  loss: 0.0179  grad_norm: 0.4533
05/10 05:29:09 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 05:29:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。首先，理解你的感受很正确。这种事情涉及到你的男朋友对主播的特别关注，这可能让你感到很不舒服。你觉得如何呢？💖是不是想要和你的男朋友谈谈你的感受呢？<|im_end|>

05/10 05:29:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝能塞进乒乓球，下次洗牙记得带上防风罩，不然吹蜡烛都得变成吹灰机的操作了。😆<|im_end|>

05/10 05:29:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 05:29:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。你觉得他们是不是有什么误会呢？💖或者，我们可以一起想想怎么跟他们解释清楚，让他们知道你们并不在意这个事情。🌸<|im_end|>

05/10 05:29:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这个问题可有点棘手呢。炸鸡虽然美味，但是偶尔尝试一下也是可以的嘛。可以选择用健康的油来炸，或者尝试用一些健康的替代品来代替。记得多喝水，保持饮食均衡哦。💖如果你需要更多关于如何调整饮食的建议，我可以帮你查一下哦。<|im_end|>

05/10 05:29:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前验货，别让那些“读本玩家”把你的娱乐变成了“阅读爱好者”的体验。😔<|im_end|>

05/10 05:29:36 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“这图案比蝴蝶标本还精致”。下次画眼线，记得自个儿看着舒服就行，别让旁边的人也跟着说“啥子像鸡窝一样”。养护眼睛，注意休息哦！👀<|im_end|>

05/10 05:29:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这是在职场生存还是在搞隐形人生活？隐形人生活可不像60秒语音矩阵那么刺激，赶紧去看看你的“社交技能”是不是也需要重新培训了。🙄<|im_end|>

05/10 05:29:42 - mmengine - INFO - Saving checkpoint at 13000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 05:29:56 - mmengine - INFO - Iter(train) [ 13010/480000]  lr: 1.8069e-04  eta: 7 days, 22:53:35  time: 4.6648  data_time: 3.3442  memory: 9837  loss: 0.0169  grad_norm: 0.4459
05/10 05:30:09 - mmengine - INFO - Iter(train) [ 13020/480000]  lr: 1.8083e-04  eta: 7 days, 22:52:34  time: 1.3401  data_time: 0.0059  memory: 9838  loss: 0.0211  grad_norm: 0.4459
05/10 05:30:25 - mmengine - INFO - Iter(train) [ 13030/480000]  lr: 1.8097e-04  eta: 7 days, 22:52:41  time: 1.5336  data_time: 0.0059  memory: 9842  loss: 0.0218  grad_norm: 0.4418
05/10 05:30:38 - mmengine - INFO - Iter(train) [ 13040/480000]  lr: 1.8111e-04  eta: 7 days, 22:51:31  time: 1.3181  data_time: 0.0058  memory: 9844  loss: 0.0197  grad_norm: 0.4440
05/10 05:30:53 - mmengine - INFO - Iter(train) [ 13050/480000]  lr: 1.8125e-04  eta: 7 days, 22:51:34  time: 1.5197  data_time: 0.0059  memory: 9841  loss: 0.0248  grad_norm: 0.4440
05/10 05:31:06 - mmengine - INFO - Iter(train) [ 13060/480000]  lr: 1.8139e-04  eta: 7 days, 22:50:27  time: 1.3243  data_time: 0.0057  memory: 9843  loss: 0.0240  grad_norm: 0.4418
05/10 05:31:19 - mmengine - INFO - Iter(train) [ 13070/480000]  lr: 1.8153e-04  eta: 7 days, 22:49:18  time: 1.3215  data_time: 0.0059  memory: 9839  loss: 0.0209  grad_norm: 0.4418
05/10 05:31:34 - mmengine - INFO - Iter(train) [ 13080/480000]  lr: 1.8167e-04  eta: 7 days, 22:49:18  time: 1.5126  data_time: 0.0059  memory: 9838  loss: 0.0229  grad_norm: 0.4409
05/10 05:31:47 - mmengine - INFO - Iter(train) [ 13090/480000]  lr: 1.8180e-04  eta: 7 days, 22:48:02  time: 1.2987  data_time: 0.0057  memory: 9841  loss: 0.0205  grad_norm: 0.4364
05/10 05:32:03 - mmengine - INFO - Iter(train) [ 13100/480000]  lr: 1.8194e-04  eta: 7 days, 22:48:16  time: 1.5506  data_time: 0.0059  memory: 9843  loss: 0.0237  grad_norm: 0.4364
05/10 05:32:16 - mmengine - INFO - Iter(train) [ 13110/480000]  lr: 1.8208e-04  eta: 7 days, 22:47:04  time: 1.3117  data_time: 0.0055  memory: 9843  loss: 0.0219  grad_norm: 0.4332
05/10 05:32:31 - mmengine - INFO - Iter(train) [ 13120/480000]  lr: 1.8222e-04  eta: 7 days, 22:46:52  time: 1.4777  data_time: 0.0057  memory: 9843  loss: 0.0230  grad_norm: 0.4309
05/10 05:32:46 - mmengine - INFO - Iter(train) [ 13130/480000]  lr: 1.8236e-04  eta: 7 days, 22:46:58  time: 1.5305  data_time: 0.2062  memory: 9842  loss: 0.0145  grad_norm: 0.4309
05/10 05:32:59 - mmengine - INFO - Iter(train) [ 13140/480000]  lr: 1.8250e-04  eta: 7 days, 22:45:49  time: 1.3185  data_time: 0.0057  memory: 9841  loss: 0.0162  grad_norm: 0.4272
05/10 05:33:15 - mmengine - INFO - Iter(train) [ 13150/480000]  lr: 1.8264e-04  eta: 7 days, 22:46:03  time: 1.5510  data_time: 0.0060  memory: 9838  loss: 0.0170  grad_norm: 0.4272
05/10 05:33:28 - mmengine - INFO - Iter(train) [ 13160/480000]  lr: 1.8278e-04  eta: 7 days, 22:44:52  time: 1.3123  data_time: 0.0057  memory: 9843  loss: 0.0177  grad_norm: 0.4273
05/10 05:33:43 - mmengine - INFO - Iter(train) [ 13170/480000]  lr: 1.8292e-04  eta: 7 days, 22:44:53  time: 1.5164  data_time: 0.0058  memory: 9844  loss: 0.0158  grad_norm: 0.4254
05/10 05:33:56 - mmengine - INFO - Iter(train) [ 13180/480000]  lr: 1.8305e-04  eta: 7 days, 22:43:40  time: 1.3049  data_time: 0.0058  memory: 9840  loss: 0.0166  grad_norm: 0.4254
05/10 05:34:10 - mmengine - INFO - Iter(train) [ 13190/480000]  lr: 1.8319e-04  eta: 7 days, 22:42:41  time: 1.3445  data_time: 0.0059  memory: 9842  loss: 0.0180  grad_norm: 0.4227
05/10 05:34:25 - mmengine - INFO - Iter(train) [ 13200/480000]  lr: 1.8333e-04  eta: 7 days, 22:42:52  time: 1.5449  data_time: 0.0059  memory: 9843  loss: 0.0170  grad_norm: 0.4135
05/10 05:34:38 - mmengine - INFO - Iter(train) [ 13210/480000]  lr: 1.8347e-04  eta: 7 days, 22:41:42  time: 1.3142  data_time: 0.0058  memory: 9840  loss: 0.0178  grad_norm: 0.4135
05/10 05:34:54 - mmengine - INFO - Iter(train) [ 13220/480000]  lr: 1.8361e-04  eta: 7 days, 22:41:50  time: 1.5337  data_time: 0.0058  memory: 9839  loss: 0.0200  grad_norm: 0.4062
05/10 05:35:07 - mmengine - INFO - Iter(train) [ 13230/480000]  lr: 1.8375e-04  eta: 7 days, 22:40:40  time: 1.3167  data_time: 0.0057  memory: 9840  loss: 0.0209  grad_norm: 0.4062
05/10 05:35:22 - mmengine - INFO - Iter(train) [ 13240/480000]  lr: 1.8389e-04  eta: 7 days, 22:40:51  time: 1.5424  data_time: 0.0060  memory: 9843  loss: 0.0183  grad_norm: 0.3989
05/10 05:35:35 - mmengine - INFO - Iter(train) [ 13250/480000]  lr: 1.8403e-04  eta: 7 days, 22:39:36  time: 1.2991  data_time: 0.0058  memory: 9842  loss: 0.0198  grad_norm: 0.3966
05/10 05:35:48 - mmengine - INFO - Iter(train) [ 13260/480000]  lr: 1.8417e-04  eta: 7 days, 22:38:17  time: 1.2872  data_time: 0.0056  memory: 9839  loss: 0.0204  grad_norm: 0.3966
05/10 05:36:04 - mmengine - INFO - Iter(train) [ 13270/480000]  lr: 1.8430e-04  eta: 7 days, 22:38:40  time: 1.5787  data_time: 0.0058  memory: 9838  loss: 0.0214  grad_norm: 0.3913
05/10 05:36:16 - mmengine - INFO - Iter(train) [ 13280/480000]  lr: 1.8444e-04  eta: 7 days, 22:37:08  time: 1.2499  data_time: 0.0057  memory: 9838  loss: 0.0218  grad_norm: 0.3891
05/10 05:36:34 - mmengine - INFO - Iter(train) [ 13290/480000]  lr: 1.8458e-04  eta: 7 days, 22:38:36  time: 1.7644  data_time: 0.2062  memory: 9841  loss: 0.0157  grad_norm: 0.3891
05/10 05:36:47 - mmengine - INFO - Iter(train) [ 13300/480000]  lr: 1.8472e-04  eta: 7 days, 22:37:25  time: 1.3075  data_time: 0.0057  memory: 9841  loss: 0.0153  grad_norm: 0.3911
05/10 05:37:00 - mmengine - INFO - Iter(train) [ 13310/480000]  lr: 1.8486e-04  eta: 7 days, 22:36:11  time: 1.3020  data_time: 0.0057  memory: 9837  loss: 0.0133  grad_norm: 0.3911
05/10 05:37:16 - mmengine - INFO - Iter(train) [ 13320/480000]  lr: 1.8500e-04  eta: 7 days, 22:36:25  time: 1.5533  data_time: 0.0058  memory: 9842  loss: 0.0134  grad_norm: 0.3846
05/10 05:37:28 - mmengine - INFO - Iter(train) [ 13330/480000]  lr: 1.8514e-04  eta: 7 days, 22:35:05  time: 1.2822  data_time: 0.0056  memory: 9841  loss: 0.0151  grad_norm: 0.3831
05/10 05:37:44 - mmengine - INFO - Iter(train) [ 13340/480000]  lr: 1.8528e-04  eta: 7 days, 22:35:15  time: 1.5425  data_time: 0.0057  memory: 9841  loss: 0.0183  grad_norm: 0.3831
05/10 05:37:57 - mmengine - INFO - Iter(train) [ 13350/480000]  lr: 1.8542e-04  eta: 7 days, 22:34:08  time: 1.3204  data_time: 0.0058  memory: 9840  loss: 0.0150  grad_norm: 0.3844
05/10 05:38:10 - mmengine - INFO - Iter(train) [ 13360/480000]  lr: 1.8555e-04  eta: 7 days, 22:33:06  time: 1.3344  data_time: 0.0059  memory: 9842  loss: 0.0163  grad_norm: 0.3783
05/10 05:38:26 - mmengine - INFO - Iter(train) [ 13370/480000]  lr: 1.8569e-04  eta: 7 days, 22:33:14  time: 1.5350  data_time: 0.0058  memory: 9839  loss: 0.0184  grad_norm: 0.3783
05/10 05:38:39 - mmengine - INFO - Iter(train) [ 13380/480000]  lr: 1.8583e-04  eta: 7 days, 22:32:04  time: 1.3120  data_time: 0.0057  memory: 9839  loss: 0.0165  grad_norm: 0.3738
05/10 05:38:54 - mmengine - INFO - Iter(train) [ 13390/480000]  lr: 1.8597e-04  eta: 7 days, 22:32:09  time: 1.5266  data_time: 0.0056  memory: 9839  loss: 0.0172  grad_norm: 0.3738
05/10 05:39:07 - mmengine - INFO - Iter(train) [ 13400/480000]  lr: 1.8611e-04  eta: 7 days, 22:31:07  time: 1.3330  data_time: 0.0058  memory: 9841  loss: 0.0182  grad_norm: 0.3702
05/10 05:39:21 - mmengine - INFO - Iter(train) [ 13410/480000]  lr: 1.8625e-04  eta: 7 days, 22:30:03  time: 1.3277  data_time: 0.0057  memory: 9839  loss: 0.0151  grad_norm: 0.3621
05/10 05:39:36 - mmengine - INFO - Iter(train) [ 13420/480000]  lr: 1.8639e-04  eta: 7 days, 22:30:05  time: 1.5202  data_time: 0.0057  memory: 9838  loss: 0.0164  grad_norm: 0.3621
05/10 05:39:49 - mmengine - INFO - Iter(train) [ 13430/480000]  lr: 1.8653e-04  eta: 7 days, 22:28:53  time: 1.3031  data_time: 0.0058  memory: 9843  loss: 0.0169  grad_norm: 0.3548
05/10 05:40:04 - mmengine - INFO - Iter(train) [ 13440/480000]  lr: 1.8667e-04  eta: 7 days, 22:28:45  time: 1.4905  data_time: 0.0057  memory: 9843  loss: 0.0216  grad_norm: 0.3552
05/10 05:40:19 - mmengine - INFO - Iter(train) [ 13450/480000]  lr: 1.8680e-04  eta: 7 days, 22:28:57  time: 1.5450  data_time: 0.2061  memory: 9844  loss: 0.0115  grad_norm: 0.3552
05/10 05:40:35 - mmengine - INFO - Iter(train) [ 13460/480000]  lr: 1.8694e-04  eta: 7 days, 22:29:03  time: 1.5298  data_time: 0.0057  memory: 9843  loss: 0.0106  grad_norm: 0.3447
05/10 05:40:48 - mmengine - INFO - Iter(train) [ 13470/480000]  lr: 1.8708e-04  eta: 7 days, 22:27:56  time: 1.3184  data_time: 0.0058  memory: 9839  loss: 0.0122  grad_norm: 0.3447
05/10 05:41:01 - mmengine - INFO - Iter(train) [ 13480/480000]  lr: 1.8722e-04  eta: 7 days, 22:26:52  time: 1.3275  data_time: 0.0058  memory: 9843  loss: 0.0126  grad_norm: 0.3388
05/10 05:41:16 - mmengine - INFO - Iter(train) [ 13490/480000]  lr: 1.8736e-04  eta: 7 days, 22:27:01  time: 1.5387  data_time: 0.0058  memory: 9845  loss: 0.0135  grad_norm: 0.3356
05/10 05:41:30 - mmengine - INFO - Iter(train) [ 13500/480000]  lr: 1.8750e-04  eta: 7 days, 22:25:50  time: 1.3071  data_time: 0.0059  memory: 9840  loss: 0.0125  grad_norm: 0.3356
05/10 05:41:30 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 05:41:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。你的感受很重要，要不要聊聊你心中的想法呢？💖<|im_end|>

05/10 05:41:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝能开飞机了，吹蜡烛像是在建金字塔啊！下次记得选个靠谱的牙医，别让“牙口”成了你的“口粮”。🦷<|im_end|>

05/10 05:41:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 05:41:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感三连击。不过别太在意，这种小事情不必太在意，毕竟闺蜜和前任的账号也能变成你的灵感来源，至少证明你们的关系还是蜜糖状态。要是觉得不舒服，直接找个合适的时机跟闺蜜聊聊你的感受，毕竟友谊的小船不能说翻就翻，但也不能假装无关。加油，也希望你的友谊坚不可摧！🚣‍♂️<|im_end|>

05/10 05:41:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点让人担心呢。胆固醇高要注意饮食啦，但是吃炸鸡也不是不可以呀。可以考虑吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能保持营养，又能减少炸鸡的摄入。💖你觉得呢？需要我帮你找一些健康的烤鸡食谱吗？🌸<|im_end|>

05/10 05:41:58 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀是个大家一起享受的游戏，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。要不要聊聊你的感受，或者我可以帮你想想办法，处理这种情况？💖<|im_end|>

05/10 05:42:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事的心理健康比你的眼线还让人担心。不过别太在意，你的美丽只是恰到好处的隐藏低调，说不定哪天就大放异彩了呢！💄<|im_end|>

05/10 05:42:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是懂流量的，60秒的语音矩阵都能搞成一段热点。不过话说回来，周末也不想见你，是不是该找个同事“隐藏”一下你的“野心”啊？🙄<|im_end|>

05/10 05:42:07 - mmengine - INFO - Saving checkpoint at 13500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 05:42:23 - mmengine - INFO - Iter(train) [ 13510/480000]  lr: 1.8764e-04  eta: 7 days, 22:47:50  time: 5.3336  data_time: 3.7864  memory: 9842  loss: 0.0150  grad_norm: 0.3256
05/10 05:42:36 - mmengine - INFO - Iter(train) [ 13520/480000]  lr: 1.8778e-04  eta: 7 days, 22:46:40  time: 1.3139  data_time: 0.0057  memory: 9843  loss: 0.0136  grad_norm: 0.3227
05/10 05:42:51 - mmengine - INFO - Iter(train) [ 13530/480000]  lr: 1.8792e-04  eta: 7 days, 22:46:43  time: 1.5237  data_time: 0.0060  memory: 9843  loss: 0.0153  grad_norm: 0.3227
05/10 05:43:05 - mmengine - INFO - Iter(train) [ 13540/480000]  lr: 1.8805e-04  eta: 7 days, 22:45:43  time: 1.3403  data_time: 0.0060  memory: 9843  loss: 0.0142  grad_norm: 0.3173
05/10 05:43:18 - mmengine - INFO - Iter(train) [ 13550/480000]  lr: 1.8819e-04  eta: 7 days, 22:44:37  time: 1.3250  data_time: 0.0057  memory: 9844  loss: 0.0144  grad_norm: 0.3173
05/10 05:43:33 - mmengine - INFO - Iter(train) [ 13560/480000]  lr: 1.8833e-04  eta: 7 days, 22:44:43  time: 1.5299  data_time: 0.0060  memory: 9844  loss: 0.0187  grad_norm: 0.3163
05/10 05:43:46 - mmengine - INFO - Iter(train) [ 13570/480000]  lr: 1.8847e-04  eta: 7 days, 22:43:33  time: 1.3119  data_time: 0.0059  memory: 9842  loss: 0.0141  grad_norm: 0.3200
05/10 05:44:02 - mmengine - INFO - Iter(train) [ 13580/480000]  lr: 1.8861e-04  eta: 7 days, 22:43:42  time: 1.5428  data_time: 0.0059  memory: 9842  loss: 0.0169  grad_norm: 0.3200
05/10 05:44:15 - mmengine - INFO - Iter(train) [ 13590/480000]  lr: 1.8875e-04  eta: 7 days, 22:42:23  time: 1.2837  data_time: 0.0057  memory: 9843  loss: 0.0155  grad_norm: 0.3244
05/10 05:44:27 - mmengine - INFO - Iter(train) [ 13600/480000]  lr: 1.8889e-04  eta: 7 days, 22:40:40  time: 1.2157  data_time: 0.0057  memory: 9843  loss: 0.0144  grad_norm: 0.3139
05/10 05:44:44 - mmengine - INFO - Iter(train) [ 13610/480000]  lr: 1.8903e-04  eta: 7 days, 22:41:47  time: 1.7087  data_time: 0.2059  memory: 9841  loss: 0.0113  grad_norm: 0.3139
05/10 05:44:57 - mmengine - INFO - Iter(train) [ 13620/480000]  lr: 1.8917e-04  eta: 7 days, 22:40:25  time: 1.2760  data_time: 0.0058  memory: 9840  loss: 0.0113  grad_norm: 0.3153
05/10 05:45:12 - mmengine - INFO - Iter(train) [ 13630/480000]  lr: 1.8930e-04  eta: 7 days, 22:40:22  time: 1.5058  data_time: 0.0058  memory: 9841  loss: 0.0105  grad_norm: 0.3153
05/10 05:45:24 - mmengine - INFO - Iter(train) [ 13640/480000]  lr: 1.8944e-04  eta: 7 days, 22:39:00  time: 1.2761  data_time: 0.0057  memory: 9840  loss: 0.0110  grad_norm: 0.3125
05/10 05:45:37 - mmengine - INFO - Iter(train) [ 13650/480000]  lr: 1.8958e-04  eta: 7 days, 22:37:35  time: 1.2654  data_time: 0.0057  memory: 9840  loss: 0.0113  grad_norm: 0.3069
05/10 05:45:52 - mmengine - INFO - Iter(train) [ 13660/480000]  lr: 1.8972e-04  eta: 7 days, 22:37:25  time: 1.4847  data_time: 0.0058  memory: 9842  loss: 0.0119  grad_norm: 0.3069
05/10 05:46:05 - mmengine - INFO - Iter(train) [ 13670/480000]  lr: 1.8986e-04  eta: 7 days, 22:36:08  time: 1.2882  data_time: 0.0056  memory: 9842  loss: 0.0145  grad_norm: 0.3097
05/10 05:46:20 - mmengine - INFO - Iter(train) [ 13680/480000]  lr: 1.9000e-04  eta: 7 days, 22:36:06  time: 1.5109  data_time: 0.0058  memory: 9843  loss: 0.0161  grad_norm: 0.3099
05/10 05:46:33 - mmengine - INFO - Iter(train) [ 13690/480000]  lr: 1.9014e-04  eta: 7 days, 22:34:44  time: 1.2730  data_time: 0.0057  memory: 9842  loss: 0.0141  grad_norm: 0.3099
05/10 05:46:45 - mmengine - INFO - Iter(train) [ 13700/480000]  lr: 1.9028e-04  eta: 7 days, 22:33:23  time: 1.2762  data_time: 0.0056  memory: 9841  loss: 0.0127  grad_norm: 0.3104
05/10 05:47:00 - mmengine - INFO - Iter(train) [ 13710/480000]  lr: 1.9042e-04  eta: 7 days, 22:33:18  time: 1.5013  data_time: 0.0058  memory: 9841  loss: 0.0144  grad_norm: 0.3104
05/10 05:47:13 - mmengine - INFO - Iter(train) [ 13720/480000]  lr: 1.9055e-04  eta: 7 days, 22:31:59  time: 1.2810  data_time: 0.0056  memory: 9844  loss: 0.0145  grad_norm: 0.3076
05/10 05:47:28 - mmengine - INFO - Iter(train) [ 13730/480000]  lr: 1.9069e-04  eta: 7 days, 22:31:51  time: 1.4917  data_time: 0.0057  memory: 9845  loss: 0.0171  grad_norm: 0.3020
05/10 05:47:41 - mmengine - INFO - Iter(train) [ 13740/480000]  lr: 1.9083e-04  eta: 7 days, 22:30:24  time: 1.2561  data_time: 0.0057  memory: 9841  loss: 0.0112  grad_norm: 0.3020
05/10 05:47:53 - mmengine - INFO - Iter(train) [ 13750/480000]  lr: 1.9097e-04  eta: 7 days, 22:29:01  time: 1.2701  data_time: 0.0057  memory: 9842  loss: 0.0128  grad_norm: 0.2891
05/10 05:48:08 - mmengine - INFO - Iter(train) [ 13760/480000]  lr: 1.9111e-04  eta: 7 days, 22:28:40  time: 1.4513  data_time: 0.0056  memory: 9841  loss: 0.0163  grad_norm: 0.2935
05/10 05:48:23 - mmengine - INFO - Iter(train) [ 13770/480000]  lr: 1.9125e-04  eta: 7 days, 22:28:34  time: 1.4976  data_time: 0.2059  memory: 9841  loss: 0.0119  grad_norm: 0.2935
05/10 05:48:38 - mmengine - INFO - Iter(train) [ 13780/480000]  lr: 1.9139e-04  eta: 7 days, 22:28:27  time: 1.4922  data_time: 0.0058  memory: 9842  loss: 0.0105  grad_norm: 0.2992
05/10 05:48:51 - mmengine - INFO - Iter(train) [ 13790/480000]  lr: 1.9153e-04  eta: 7 days, 22:27:04  time: 1.2699  data_time: 0.0056  memory: 9843  loss: 0.0087  grad_norm: 0.2992
05/10 05:49:03 - mmengine - INFO - Iter(train) [ 13800/480000]  lr: 1.9167e-04  eta: 7 days, 22:25:45  time: 1.2808  data_time: 0.0058  memory: 9840  loss: 0.0098  grad_norm: 0.2975
05/10 05:49:18 - mmengine - INFO - Iter(train) [ 13810/480000]  lr: 1.9181e-04  eta: 7 days, 22:25:41  time: 1.5032  data_time: 0.0057  memory: 9838  loss: 0.0109  grad_norm: 0.2974
05/10 05:49:31 - mmengine - INFO - Iter(train) [ 13820/480000]  lr: 1.9194e-04  eta: 7 days, 22:24:14  time: 1.2544  data_time: 0.0057  memory: 9839  loss: 0.0124  grad_norm: 0.2974
05/10 05:49:46 - mmengine - INFO - Iter(train) [ 13830/480000]  lr: 1.9208e-04  eta: 7 days, 22:24:03  time: 1.4834  data_time: 0.0057  memory: 9841  loss: 0.0108  grad_norm: 0.2883
05/10 05:49:58 - mmengine - INFO - Iter(train) [ 13840/480000]  lr: 1.9222e-04  eta: 7 days, 22:22:41  time: 1.2679  data_time: 0.0058  memory: 9841  loss: 0.0093  grad_norm: 0.2825
05/10 05:50:11 - mmengine - INFO - Iter(train) [ 13850/480000]  lr: 1.9236e-04  eta: 7 days, 22:21:26  time: 1.2921  data_time: 0.0058  memory: 9840  loss: 0.0110  grad_norm: 0.2825
05/10 05:50:26 - mmengine - INFO - Iter(train) [ 13860/480000]  lr: 1.9250e-04  eta: 7 days, 22:21:25  time: 1.5109  data_time: 0.0059  memory: 9843  loss: 0.0135  grad_norm: 0.2791
05/10 05:50:39 - mmengine - INFO - Iter(train) [ 13870/480000]  lr: 1.9264e-04  eta: 7 days, 22:19:58  time: 1.2552  data_time: 0.0057  memory: 9847  loss: 0.0116  grad_norm: 0.2791
05/10 05:50:54 - mmengine - INFO - Iter(train) [ 13880/480000]  lr: 1.9278e-04  eta: 7 days, 22:19:55  time: 1.5054  data_time: 0.0057  memory: 9844  loss: 0.0129  grad_norm: 0.2751
05/10 05:51:07 - mmengine - INFO - Iter(train) [ 13890/480000]  lr: 1.9292e-04  eta: 7 days, 22:18:34  time: 1.2719  data_time: 0.0057  memory: 9842  loss: 0.0120  grad_norm: 0.2674
05/10 05:51:20 - mmengine - INFO - Iter(train) [ 13900/480000]  lr: 1.9306e-04  eta: 7 days, 22:17:18  time: 1.2863  data_time: 0.0057  memory: 9841  loss: 0.0122  grad_norm: 0.2674
05/10 05:51:35 - mmengine - INFO - Iter(train) [ 13910/480000]  lr: 1.9319e-04  eta: 7 days, 22:17:18  time: 1.5130  data_time: 0.0059  memory: 9843  loss: 0.0123  grad_norm: 0.2704
05/10 05:51:47 - mmengine - INFO - Iter(train) [ 13920/480000]  lr: 1.9333e-04  eta: 7 days, 22:15:27  time: 1.1828  data_time: 0.0056  memory: 9842  loss: 0.0136  grad_norm: 0.2625
05/10 05:52:04 - mmengine - INFO - Iter(train) [ 13930/480000]  lr: 1.9347e-04  eta: 7 days, 22:16:41  time: 1.7350  data_time: 0.2060  memory: 9842  loss: 0.0074  grad_norm: 0.2625
05/10 05:52:17 - mmengine - INFO - Iter(train) [ 13940/480000]  lr: 1.9361e-04  eta: 7 days, 22:15:21  time: 1.2745  data_time: 0.0056  memory: 9845  loss: 0.0087  grad_norm: 0.2499
05/10 05:52:29 - mmengine - INFO - Iter(train) [ 13950/480000]  lr: 1.9375e-04  eta: 7 days, 22:13:56  time: 1.2599  data_time: 0.0057  memory: 9841  loss: 0.0090  grad_norm: 0.2499
05/10 05:52:45 - mmengine - INFO - Iter(train) [ 13960/480000]  lr: 1.9389e-04  eta: 7 days, 22:14:10  time: 1.5551  data_time: 0.0059  memory: 9844  loss: 0.0076  grad_norm: 0.2502
05/10 05:52:57 - mmengine - INFO - Iter(train) [ 13970/480000]  lr: 1.9403e-04  eta: 7 days, 22:12:38  time: 1.2382  data_time: 0.0055  memory: 9842  loss: 0.0101  grad_norm: 0.2479
05/10 05:53:13 - mmengine - INFO - Iter(train) [ 13980/480000]  lr: 1.9417e-04  eta: 7 days, 22:12:48  time: 1.5418  data_time: 0.0059  memory: 9843  loss: 0.0108  grad_norm: 0.2479
05/10 05:53:25 - mmengine - INFO - Iter(train) [ 13990/480000]  lr: 1.9431e-04  eta: 7 days, 22:11:19  time: 1.2479  data_time: 0.0056  memory: 9841  loss: 0.0098  grad_norm: 0.2488
05/10 05:53:38 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 05:53:38 - mmengine - INFO - Iter(train) [ 14000/480000]  lr: 1.9444e-04  eta: 7 days, 22:09:53  time: 1.2530  data_time: 0.0056  memory: 9839  loss: 0.0087  grad_norm: 0.2463
05/10 05:53:38 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 05:53:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。首先，你要知道，你的男朋友是独一无二的，他的行为并不是出于你的意识之下。你可以尝试和他沟通一下，表达你的感受和信任的必要性。同时，也要考虑你们关系如何，是否让他知道这些行为会对你造成伤害。如果这很难解决，也许可以考虑一下，是否是时候放手，寻找真正适合你的幸福。💖你的感受很重要，记得照顾好自己哦。<|im_end|>

05/10 05:53:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来有点不舒服呢。洗牙后可能会有一些暂时的不适，但这是正常的恢复过程哦。如果感到牙缝变大，最好咨询一下牙医，看看有没有其他适合你的护理建议。💖 如果你需要一些帮助放松，我可以帮你找一些牙缝紧致的护肤小窍门哦。🌸<|im_end|>

05/10 05:53:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要我帮你分散一下注意力，聊些其他的事情呢？💖<|im_end|>

05/10 05:54:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜你这操作是不是忘了屏蔽啊？不过别太往心里去，就当是给自己补充了一下“时尚审美”，毕竟审美观念还是要与时俱进的。下次记得检查清楚，别让不必要的事情影响了你的优雅气质。💄💔<|im_end|>

05/10 05:54:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点让人担心呢。胆固醇高要注意饮食均衡哦，我们可以试试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖 你有什么特别喜欢的口味吗？我可以帮你想想其他的低脂美食哦！🌸<|im_end|>

05/10 05:54:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本来是为了大家开心一起玩耍的，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。要不要我帮你分散一下注意力，或者我们可以一起想想怎么处理这种情况？💖<|im_end|>

05/10 05:54:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是眼线界的福尔摩斯吗？下次记得藏好点，别让苍蝇再发现你的秘密！👓<|im_end|>

05/10 05:54:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有点捉摸不定呢。领导的指示很重要，但是装没看见确实有点儿没面子。你可以尝试和领导沟通一下，表达一下你的想法和感受，也许他会理解的。如果需要帮忙想一想怎么跟领导表达，我在这里哦，随时可以帮你出谋划策呢！💖<|im_end|>

05/10 05:54:25 - mmengine - INFO - Saving checkpoint at 14000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 05:54:38 - mmengine - INFO - Iter(train) [ 14010/480000]  lr: 1.9458e-04  eta: 7 days, 22:35:03  time: 6.0538  data_time: 4.8210  memory: 9842  loss: 0.0097  grad_norm: 0.2463
05/10 05:54:53 - mmengine - INFO - Iter(train) [ 14020/480000]  lr: 1.9472e-04  eta: 7 days, 22:35:00  time: 1.5092  data_time: 0.0058  memory: 9842  loss: 0.0097  grad_norm: 0.2401
05/10 05:55:06 - mmengine - INFO - Iter(train) [ 14030/480000]  lr: 1.9486e-04  eta: 7 days, 22:33:39  time: 1.2724  data_time: 0.0056  memory: 9840  loss: 0.0094  grad_norm: 0.2401
05/10 05:55:19 - mmengine - INFO - Iter(train) [ 14040/480000]  lr: 1.9500e-04  eta: 7 days, 22:32:15  time: 1.2624  data_time: 0.0057  memory: 9842  loss: 0.0119  grad_norm: 0.2407
05/10 05:55:34 - mmengine - INFO - Iter(train) [ 14050/480000]  lr: 1.9514e-04  eta: 7 days, 22:32:16  time: 1.5202  data_time: 0.0059  memory: 9841  loss: 0.0112  grad_norm: 0.2403
05/10 05:55:46 - mmengine - INFO - Iter(train) [ 14060/480000]  lr: 1.9528e-04  eta: 7 days, 22:30:37  time: 1.2184  data_time: 0.0056  memory: 9841  loss: 0.0125  grad_norm: 0.2403
05/10 05:55:59 - mmengine - INFO - Iter(train) [ 14070/480000]  lr: 1.9542e-04  eta: 7 days, 22:29:24  time: 1.2959  data_time: 0.0058  memory: 9842  loss: 0.0104  grad_norm: 0.2365
05/10 05:56:13 - mmengine - INFO - Iter(train) [ 14080/480000]  lr: 1.9556e-04  eta: 7 days, 22:29:01  time: 1.4455  data_time: 0.0057  memory: 9843  loss: 0.0123  grad_norm: 0.2289
05/10 05:56:28 - mmengine - INFO - Iter(train) [ 14090/480000]  lr: 1.9569e-04  eta: 7 days, 22:28:48  time: 1.4773  data_time: 0.2059  memory: 9842  loss: 0.0084  grad_norm: 0.2289
05/10 05:56:43 - mmengine - INFO - Iter(train) [ 14100/480000]  lr: 1.9583e-04  eta: 7 days, 22:28:51  time: 1.5255  data_time: 0.0059  memory: 9845  loss: 0.0070  grad_norm: 0.2294
05/10 05:56:56 - mmengine - INFO - Iter(train) [ 14110/480000]  lr: 1.9597e-04  eta: 7 days, 22:27:19  time: 1.2369  data_time: 0.0058  memory: 9842  loss: 0.0076  grad_norm: 0.2294
05/10 05:57:11 - mmengine - INFO - Iter(train) [ 14120/480000]  lr: 1.9611e-04  eta: 7 days, 22:27:26  time: 1.5382  data_time: 0.0059  memory: 9843  loss: 0.0071  grad_norm: 0.2238
05/10 05:57:24 - mmengine - INFO - Iter(train) [ 14130/480000]  lr: 1.9625e-04  eta: 7 days, 22:26:01  time: 1.2587  data_time: 0.0057  memory: 9845  loss: 0.0089  grad_norm: 0.2269
05/10 05:57:36 - mmengine - INFO - Iter(train) [ 14140/480000]  lr: 1.9639e-04  eta: 7 days, 22:24:32  time: 1.2463  data_time: 0.0056  memory: 9844  loss: 0.0089  grad_norm: 0.2269
05/10 05:57:52 - mmengine - INFO - Iter(train) [ 14150/480000]  lr: 1.9653e-04  eta: 7 days, 22:24:35  time: 1.5264  data_time: 0.0060  memory: 9843  loss: 0.0088  grad_norm: 0.2246
05/10 05:58:04 - mmengine - INFO - Iter(train) [ 14160/480000]  lr: 1.9667e-04  eta: 7 days, 22:23:05  time: 1.2416  data_time: 0.0055  memory: 9841  loss: 0.0079  grad_norm: 0.2245
05/10 05:58:19 - mmengine - INFO - Iter(train) [ 14170/480000]  lr: 1.9681e-04  eta: 7 days, 22:23:15  time: 1.5452  data_time: 0.0058  memory: 9838  loss: 0.0093  grad_norm: 0.2245
05/10 05:58:32 - mmengine - INFO - Iter(train) [ 14180/480000]  lr: 1.9694e-04  eta: 7 days, 22:21:51  time: 1.2603  data_time: 0.0058  memory: 9838  loss: 0.0100  grad_norm: 0.2281
05/10 05:58:44 - mmengine - INFO - Iter(train) [ 14190/480000]  lr: 1.9708e-04  eta: 7 days, 22:20:23  time: 1.2480  data_time: 0.0056  memory: 9841  loss: 0.0090  grad_norm: 0.2281
05/10 05:59:00 - mmengine - INFO - Iter(train) [ 14200/480000]  lr: 1.9722e-04  eta: 7 days, 22:20:31  time: 1.5422  data_time: 0.0057  memory: 9843  loss: 0.0090  grad_norm: 0.2194
05/10 05:59:13 - mmengine - INFO - Iter(train) [ 14210/480000]  lr: 1.9736e-04  eta: 7 days, 22:19:17  time: 1.2898  data_time: 0.0057  memory: 9842  loss: 0.0099  grad_norm: 0.2147
05/10 05:59:26 - mmengine - INFO - Iter(train) [ 14220/480000]  lr: 1.9750e-04  eta: 7 days, 22:17:57  time: 1.2718  data_time: 0.0056  memory: 9843  loss: 0.0121  grad_norm: 0.2147
05/10 05:59:40 - mmengine - INFO - Iter(train) [ 14230/480000]  lr: 1.9764e-04  eta: 7 days, 22:17:45  time: 1.4783  data_time: 0.0058  memory: 9842  loss: 0.0085  grad_norm: 0.2145
05/10 05:59:52 - mmengine - INFO - Iter(train) [ 14240/480000]  lr: 1.9778e-04  eta: 7 days, 22:16:05  time: 1.2094  data_time: 0.0056  memory: 9844  loss: 0.0100  grad_norm: 0.2150
05/10 06:00:10 - mmengine - INFO - Iter(train) [ 14250/480000]  lr: 1.9792e-04  eta: 7 days, 22:17:11  time: 1.7175  data_time: 0.2060  memory: 9840  loss: 0.0059  grad_norm: 0.2150
05/10 06:00:22 - mmengine - INFO - Iter(train) [ 14260/480000]  lr: 1.9806e-04  eta: 7 days, 22:15:58  time: 1.2924  data_time: 0.0057  memory: 9843  loss: 0.0072  grad_norm: 0.2130
05/10 06:00:37 - mmengine - INFO - Iter(train) [ 14270/480000]  lr: 1.9819e-04  eta: 7 days, 22:15:49  time: 1.4876  data_time: 0.0058  memory: 9842  loss: 0.0087  grad_norm: 0.2130
05/10 06:00:50 - mmengine - INFO - Iter(train) [ 14280/480000]  lr: 1.9833e-04  eta: 7 days, 22:14:31  time: 1.2786  data_time: 0.0057  memory: 9842  loss: 0.0063  grad_norm: 0.2207
05/10 06:01:03 - mmengine - INFO - Iter(train) [ 14290/480000]  lr: 1.9847e-04  eta: 7 days, 22:13:16  time: 1.2859  data_time: 0.0057  memory: 9841  loss: 0.0070  grad_norm: 0.2155
05/10 06:01:18 - mmengine - INFO - Iter(train) [ 14300/480000]  lr: 1.9861e-04  eta: 7 days, 22:13:10  time: 1.4956  data_time: 0.0058  memory: 9844  loss: 0.0083  grad_norm: 0.2155
05/10 06:01:31 - mmengine - INFO - Iter(train) [ 14310/480000]  lr: 1.9875e-04  eta: 7 days, 22:11:49  time: 1.2665  data_time: 0.0059  memory: 9843  loss: 0.0081  grad_norm: 0.2120
05/10 06:01:43 - mmengine - INFO - Iter(train) [ 14320/480000]  lr: 1.9889e-04  eta: 7 days, 22:10:27  time: 1.2639  data_time: 0.0057  memory: 9842  loss: 0.0063  grad_norm: 0.2070
05/10 06:01:58 - mmengine - INFO - Iter(train) [ 14330/480000]  lr: 1.9903e-04  eta: 7 days, 22:10:18  time: 1.4874  data_time: 0.0058  memory: 9838  loss: 0.0119  grad_norm: 0.2070
05/10 06:02:11 - mmengine - INFO - Iter(train) [ 14340/480000]  lr: 1.9917e-04  eta: 7 days, 22:09:03  time: 1.2848  data_time: 0.0058  memory: 9841  loss: 0.0123  grad_norm: 0.2106
05/10 06:02:26 - mmengine - INFO - Iter(train) [ 14350/480000]  lr: 1.9931e-04  eta: 7 days, 22:08:57  time: 1.4960  data_time: 0.0058  memory: 9840  loss: 0.0098  grad_norm: 0.2106
05/10 06:02:39 - mmengine - INFO - Iter(train) [ 14360/480000]  lr: 1.9944e-04  eta: 7 days, 22:07:38  time: 1.2723  data_time: 0.0059  memory: 9842  loss: 0.0075  grad_norm: 0.2154
05/10 06:02:51 - mmengine - INFO - Iter(train) [ 14370/480000]  lr: 1.9958e-04  eta: 7 days, 22:06:20  time: 1.2765  data_time: 0.0058  memory: 9841  loss: 0.0113  grad_norm: 0.2151
05/10 06:03:06 - mmengine - INFO - Iter(train) [ 14380/480000]  lr: 1.9972e-04  eta: 7 days, 22:06:16  time: 1.5024  data_time: 0.0057  memory: 9840  loss: 0.0084  grad_norm: 0.2151
05/10 06:03:19 - mmengine - INFO - Iter(train) [ 14390/480000]  lr: 1.9986e-04  eta: 7 days, 22:05:04  time: 1.2929  data_time: 0.0059  memory: 9846  loss: 0.0102  grad_norm: 0.2150
05/10 06:03:34 - mmengine - INFO - Iter(train) [ 14400/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:32  time: 1.4161  data_time: 0.0057  memory: 9844  loss: 0.0110  grad_norm: 0.2138
05/10 06:03:48 - mmengine - INFO - Iter(train) [ 14410/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:19  time: 1.4741  data_time: 0.2063  memory: 9841  loss: 0.0077  grad_norm: 0.2138
05/10 06:04:01 - mmengine - INFO - Iter(train) [ 14420/480000]  lr: 2.0000e-04  eta: 7 days, 22:03:08  time: 1.2944  data_time: 0.0058  memory: 9840  loss: 0.0083  grad_norm: 0.2170
05/10 06:04:14 - mmengine - INFO - Iter(train) [ 14430/480000]  lr: 2.0000e-04  eta: 7 days, 22:01:55  time: 1.2908  data_time: 0.0058  memory: 9837  loss: 0.0067  grad_norm: 0.2170
05/10 06:04:27 - mmengine - INFO - Iter(train) [ 14440/480000]  lr: 2.0000e-04  eta: 7 days, 22:00:42  time: 1.2860  data_time: 0.0058  memory: 9841  loss: 0.0072  grad_norm: 0.2124
05/10 06:04:40 - mmengine - INFO - Iter(train) [ 14450/480000]  lr: 2.0000e-04  eta: 7 days, 21:59:26  time: 1.2792  data_time: 0.0058  memory: 9845  loss: 0.0066  grad_norm: 0.2091
05/10 06:04:53 - mmengine - INFO - Iter(train) [ 14460/480000]  lr: 2.0000e-04  eta: 7 days, 21:58:11  time: 1.2839  data_time: 0.0057  memory: 9842  loss: 0.0066  grad_norm: 0.2091
05/10 06:05:06 - mmengine - INFO - Iter(train) [ 14470/480000]  lr: 2.0000e-04  eta: 7 days, 21:56:59  time: 1.2896  data_time: 0.0058  memory: 9840  loss: 0.0089  grad_norm: 0.2077
05/10 06:05:24 - mmengine - INFO - Iter(train) [ 14480/480000]  lr: 2.0000e-04  eta: 7 days, 21:58:32  time: 1.8047  data_time: 0.0058  memory: 9843  loss: 0.0092  grad_norm: 0.2155
05/10 06:05:38 - mmengine - INFO - Iter(train) [ 14490/480000]  lr: 2.0000e-04  eta: 7 days, 21:58:14  time: 1.4572  data_time: 0.0058  memory: 9840  loss: 0.0075  grad_norm: 0.2155
05/10 06:05:51 - mmengine - INFO - Iter(train) [ 14500/480000]  lr: 2.0000e-04  eta: 7 days, 21:56:55  time: 1.2691  data_time: 0.0058  memory: 9840  loss: 0.0091  grad_norm: 0.2049
05/10 06:05:51 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 06:05:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺难过的。首先，你要知道，你的男朋友是独一无二的，他的行为并不是为了你而做出的。你不需要因为这种误会而感到孤独或者难过。💖 想要谈谈你的感受，或者需要一些建议吗？我在这里支持你。🌸<|im_end|>

05/10 06:06:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得比长城还深远，下次洗牙记得带上防风罩，不然吹蜡烛都得变成吹灰机的节奏了。😆<|im_end|>

05/10 06:06:05 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 06:06:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感手机屏蔽，心疼你一秒。不过别太往心里去，至少你还能在朋友圈晒一晒，这操作也算展现了你的“潮流”。📸 不过下次记得，前男友/女友之间互关，但别忘了关心自己，别让这种小事影响了你的心情哦。<|im_end|>

05/10 06:06:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物确实可能会有点。不过，炸鸡虽然好吃，但是也要注意均衡饮食哦。可以尝试一些健康的替代品，比如烤鸡或者蒸鸡，健康又美味呢。💖你觉得呢？<|im_end|>

05/10 06:06:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本来是为了大家开心一起玩耍的，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。要不要聊聊他的行为让你感到什么样的，或者我可以帮你想想办法，如何处理这种情况？💖<|im_end|>

05/10 06:06:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带镜子上阵模式吗？不过别气馁，你的眼线可能是想告诉我们“这苍蝇腿我惯使！”😜，下次记得画个能忍的，别让不必要的麻烦影响了你的美丽心情。要是实在不行，我给你找找有镜子的超级英雄眼线液，保证让你回血！🦸‍♂️<|im_end|>

05/10 06:06:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的语音矩阵可能看似很短，但有时候这些小事情会让人感到特别的关注和关怀。你可能只是需要多注意一下领导的社交平台或者公告版块，也许他们真的是想通过这种方式联系你呢。💖 如果实在看不惯这样的方式，可以试着和领导沟通一下你的感受，有时候直接的沟通能解决很多误会哦。你还有其他事情需要帮忙吗？🌸<|im_end|>

05/10 06:06:39 - mmengine - INFO - Saving checkpoint at 14500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 06:06:52 - mmengine - INFO - Iter(train) [ 14510/480000]  lr: 2.0000e-04  eta: 7 days, 22:21:46  time: 6.1642  data_time: 4.9005  memory: 9842  loss: 0.0099  grad_norm: 0.2049
05/10 06:07:05 - mmengine - INFO - Iter(train) [ 14520/480000]  lr: 2.0000e-04  eta: 7 days, 22:20:27  time: 1.2692  data_time: 0.0057  memory: 9841  loss: 0.0068  grad_norm: 0.2063
05/10 06:07:20 - mmengine - INFO - Iter(train) [ 14530/480000]  lr: 2.0000e-04  eta: 7 days, 22:20:24  time: 1.5087  data_time: 0.0058  memory: 9840  loss: 0.0078  grad_norm: 0.2039
05/10 06:07:33 - mmengine - INFO - Iter(train) [ 14540/480000]  lr: 2.0000e-04  eta: 7 days, 22:18:57  time: 1.2465  data_time: 0.0058  memory: 9842  loss: 0.0099  grad_norm: 0.2039
05/10 06:07:48 - mmengine - INFO - Iter(train) [ 14550/480000]  lr: 2.0000e-04  eta: 7 days, 22:18:45  time: 1.4813  data_time: 0.0057  memory: 9842  loss: 0.0097  grad_norm: 0.2057
05/10 06:08:00 - mmengine - INFO - Iter(train) [ 14560/480000]  lr: 2.0000e-04  eta: 7 days, 22:17:10  time: 1.2212  data_time: 0.0057  memory: 9840  loss: 0.0075  grad_norm: 0.2019
05/10 06:08:15 - mmengine - INFO - Iter(train) [ 14570/480000]  lr: 2.0000e-04  eta: 7 days, 22:17:01  time: 1.4908  data_time: 0.2058  memory: 9841  loss: 0.0063  grad_norm: 0.2019
05/10 06:08:30 - mmengine - INFO - Iter(train) [ 14580/480000]  lr: 2.0000e-04  eta: 7 days, 22:16:56  time: 1.5003  data_time: 0.0058  memory: 9842  loss: 0.0060  grad_norm: 0.1948
05/10 06:08:42 - mmengine - INFO - Iter(train) [ 14590/480000]  lr: 2.0000e-04  eta: 7 days, 22:15:34  time: 1.2606  data_time: 0.0057  memory: 9843  loss: 0.0059  grad_norm: 0.1948
05/10 06:08:57 - mmengine - INFO - Iter(train) [ 14600/480000]  lr: 2.0000e-04  eta: 7 days, 22:15:28  time: 1.5000  data_time: 0.0061  memory: 9842  loss: 0.0070  grad_norm: 0.1942
05/10 06:09:10 - mmengine - INFO - Iter(train) [ 14610/480000]  lr: 2.0000e-04  eta: 7 days, 22:14:15  time: 1.2881  data_time: 0.0058  memory: 9841  loss: 0.0082  grad_norm: 0.1958
05/10 06:09:23 - mmengine - INFO - Iter(train) [ 14620/480000]  lr: 2.0000e-04  eta: 7 days, 22:12:58  time: 1.2760  data_time: 0.0057  memory: 9839  loss: 0.0074  grad_norm: 0.1958
05/10 06:09:38 - mmengine - INFO - Iter(train) [ 14630/480000]  lr: 2.0000e-04  eta: 7 days, 22:12:48  time: 1.4874  data_time: 0.0058  memory: 9839  loss: 0.0078  grad_norm: 0.1953
05/10 06:09:50 - mmengine - INFO - Iter(train) [ 14640/480000]  lr: 2.0000e-04  eta: 7 days, 22:11:26  time: 1.2586  data_time: 0.0057  memory: 9841  loss: 0.0075  grad_norm: 0.1871
05/10 06:10:05 - mmengine - INFO - Iter(train) [ 14650/480000]  lr: 2.0000e-04  eta: 7 days, 22:11:23  time: 1.5094  data_time: 0.0058  memory: 9838  loss: 0.0062  grad_norm: 0.1871
05/10 06:10:18 - mmengine - INFO - Iter(train) [ 14660/480000]  lr: 2.0000e-04  eta: 7 days, 22:10:11  time: 1.2912  data_time: 0.0058  memory: 9840  loss: 0.0067  grad_norm: 0.1857
05/10 06:10:31 - mmengine - INFO - Iter(train) [ 14670/480000]  lr: 2.0000e-04  eta: 7 days, 22:08:54  time: 1.2746  data_time: 0.0057  memory: 9839  loss: 0.0095  grad_norm: 0.1857
05/10 06:10:46 - mmengine - INFO - Iter(train) [ 14680/480000]  lr: 2.0000e-04  eta: 7 days, 22:08:47  time: 1.4952  data_time: 0.0057  memory: 9847  loss: 0.0072  grad_norm: 0.1790
05/10 06:10:59 - mmengine - INFO - Iter(train) [ 14690/480000]  lr: 2.0000e-04  eta: 7 days, 22:07:32  time: 1.2798  data_time: 0.0057  memory: 9848  loss: 0.0080  grad_norm: 0.1797
05/10 06:11:14 - mmengine - INFO - Iter(train) [ 14700/480000]  lr: 2.0000e-04  eta: 7 days, 22:07:26  time: 1.4999  data_time: 0.0058  memory: 9843  loss: 0.0082  grad_norm: 0.1797
05/10 06:11:27 - mmengine - INFO - Iter(train) [ 14710/480000]  lr: 2.0000e-04  eta: 7 days, 22:06:09  time: 1.2746  data_time: 0.0058  memory: 9845  loss: 0.0088  grad_norm: 0.1764
05/10 06:11:39 - mmengine - INFO - Iter(train) [ 14720/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:29  time: 1.1998  data_time: 0.0057  memory: 9843  loss: 0.0101  grad_norm: 0.1826
05/10 06:11:56 - mmengine - INFO - Iter(train) [ 14730/480000]  lr: 2.0000e-04  eta: 7 days, 22:05:28  time: 1.7032  data_time: 0.2057  memory: 9845  loss: 0.0060  grad_norm: 0.1826
05/10 06:12:09 - mmengine - INFO - Iter(train) [ 14740/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:16  time: 1.2894  data_time: 0.0057  memory: 9844  loss: 0.0063  grad_norm: 0.1878
05/10 06:12:24 - mmengine - INFO - Iter(train) [ 14750/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:12  time: 1.5043  data_time: 0.0057  memory: 9843  loss: 0.0052  grad_norm: 0.1878
05/10 06:12:36 - mmengine - INFO - Iter(train) [ 14760/480000]  lr: 2.0000e-04  eta: 7 days, 22:02:55  time: 1.2731  data_time: 0.0058  memory: 9842  loss: 0.0050  grad_norm: 0.1829
05/10 06:12:49 - mmengine - INFO - Iter(train) [ 14770/480000]  lr: 2.0000e-04  eta: 7 days, 22:01:39  time: 1.2774  data_time: 0.0057  memory: 9838  loss: 0.0077  grad_norm: 0.1823
05/10 06:13:04 - mmengine - INFO - Iter(train) [ 14780/480000]  lr: 2.0000e-04  eta: 7 days, 22:01:33  time: 1.4967  data_time: 0.0057  memory: 9840  loss: 0.0051  grad_norm: 0.1823
05/10 06:13:17 - mmengine - INFO - Iter(train) [ 14790/480000]  lr: 2.0000e-04  eta: 7 days, 22:00:17  time: 1.2780  data_time: 0.0058  memory: 9840  loss: 0.0073  grad_norm: 0.1766
05/10 06:13:32 - mmengine - INFO - Iter(train) [ 14800/480000]  lr: 2.0000e-04  eta: 7 days, 22:00:07  time: 1.4830  data_time: 0.0057  memory: 9838  loss: 0.0059  grad_norm: 0.1805
05/10 06:13:44 - mmengine - INFO - Iter(train) [ 14810/480000]  lr: 2.0000e-04  eta: 7 days, 21:58:45  time: 1.2565  data_time: 0.0057  memory: 9840  loss: 0.0083  grad_norm: 0.1805
05/10 06:13:57 - mmengine - INFO - Iter(train) [ 14820/480000]  lr: 2.0000e-04  eta: 7 days, 21:57:29  time: 1.2756  data_time: 0.0059  memory: 9840  loss: 0.0064  grad_norm: 0.1810
05/10 06:14:12 - mmengine - INFO - Iter(train) [ 14830/480000]  lr: 2.0000e-04  eta: 7 days, 21:57:25  time: 1.5037  data_time: 0.0058  memory: 9839  loss: 0.0063  grad_norm: 0.1810
05/10 06:14:25 - mmengine - INFO - Iter(train) [ 14840/480000]  lr: 2.0000e-04  eta: 7 days, 21:56:10  time: 1.2769  data_time: 0.0057  memory: 9845  loss: 0.0065  grad_norm: 0.1794
05/10 06:14:40 - mmengine - INFO - Iter(train) [ 14850/480000]  lr: 2.0000e-04  eta: 7 days, 21:56:01  time: 1.4903  data_time: 0.0057  memory: 9844  loss: 0.0076  grad_norm: 0.1795
05/10 06:14:52 - mmengine - INFO - Iter(train) [ 14860/480000]  lr: 2.0000e-04  eta: 7 days, 21:54:43  time: 1.2659  data_time: 0.0056  memory: 9841  loss: 0.0067  grad_norm: 0.1795
05/10 06:15:05 - mmengine - INFO - Iter(train) [ 14870/480000]  lr: 2.0000e-04  eta: 7 days, 21:53:33  time: 1.2946  data_time: 0.0058  memory: 9842  loss: 0.0077  grad_norm: 0.1761
05/10 06:15:20 - mmengine - INFO - Iter(train) [ 14880/480000]  lr: 2.0000e-04  eta: 7 days, 21:53:15  time: 1.4587  data_time: 0.0058  memory: 9843  loss: 0.0099  grad_norm: 0.1755
05/10 06:15:35 - mmengine - INFO - Iter(train) [ 14890/480000]  lr: 2.0000e-04  eta: 7 days, 21:52:59  time: 1.4636  data_time: 0.2059  memory: 9839  loss: 0.0052  grad_norm: 0.1755
05/10 06:15:49 - mmengine - INFO - Iter(train) [ 14900/480000]  lr: 2.0000e-04  eta: 7 days, 21:52:49  time: 1.4871  data_time: 0.0058  memory: 9841  loss: 0.0065  grad_norm: 0.1762
05/10 06:16:02 - mmengine - INFO - Iter(train) [ 14910/480000]  lr: 2.0000e-04  eta: 7 days, 21:51:34  time: 1.2754  data_time: 0.0056  memory: 9840  loss: 0.0076  grad_norm: 0.1762
05/10 06:16:15 - mmengine - INFO - Iter(train) [ 14920/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:27  time: 1.3034  data_time: 0.0058  memory: 9840  loss: 0.0046  grad_norm: 0.1821
05/10 06:16:30 - mmengine - INFO - Iter(train) [ 14930/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:27  time: 1.5162  data_time: 0.0058  memory: 9841  loss: 0.0072  grad_norm: 0.1831
05/10 06:16:43 - mmengine - INFO - Iter(train) [ 14940/480000]  lr: 2.0000e-04  eta: 7 days, 21:49:03  time: 1.2445  data_time: 0.0055  memory: 9839  loss: 0.0061  grad_norm: 0.1831
05/10 06:16:58 - mmengine - INFO - Iter(train) [ 14950/480000]  lr: 2.0000e-04  eta: 7 days, 21:49:03  time: 1.5195  data_time: 0.0057  memory: 9838  loss: 0.0067  grad_norm: 0.1902
05/10 06:17:11 - mmengine - INFO - Iter(train) [ 14960/480000]  lr: 2.0000e-04  eta: 7 days, 21:47:57  time: 1.3027  data_time: 0.0058  memory: 9839  loss: 0.0062  grad_norm: 0.1875
05/10 06:17:24 - mmengine - INFO - Iter(train) [ 14970/480000]  lr: 2.0000e-04  eta: 7 days, 21:46:37  time: 1.2604  data_time: 0.0057  memory: 9842  loss: 0.0080  grad_norm: 0.1875
05/10 06:17:39 - mmengine - INFO - Iter(train) [ 14980/480000]  lr: 2.0000e-04  eta: 7 days, 21:46:28  time: 1.4869  data_time: 0.0059  memory: 9843  loss: 0.0072  grad_norm: 0.1899
05/10 06:17:51 - mmengine - INFO - Iter(train) [ 14990/480000]  lr: 2.0000e-04  eta: 7 days, 21:44:57  time: 1.2216  data_time: 0.0055  memory: 9844  loss: 0.0065  grad_norm: 0.1899
05/10 06:18:06 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 06:18:06 - mmengine - INFO - Iter(train) [ 15000/480000]  lr: 2.0000e-04  eta: 7 days, 21:45:06  time: 1.5464  data_time: 0.0060  memory: 9843  loss: 0.0068  grad_norm: 0.1932
05/10 06:18:06 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 06:18:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺难过的。第一，你要知道，你的男朋友是独一无二的，他的行为只是其中的一部分。第二，精神出轨对你们的关系影响很大，但请记得，感情是需要双方经营的。你可以先和他沟通一下，表达一下你的感受，也许他并不知道这样做会让你感到不舒服。如果需要倾诉或者寻求建议，我在这里随时听你说哦。💖<|im_end|>

05/10 06:18:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来有点不舒服呢。洗牙后可能会有一些暂时的不适，这是因为牙齿表面的牙石被清理掉，牙龈会有点敏感。你可以试试使用温水刷牙，避免吃太冷或太热的食物，慢慢的情况就会改善的。如果不适感持续，最好再去医院检查一下，确保没有其他问题哦。💖<|im_end|>

05/10 06:18:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 06:18:28 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激！不过别担心，友谊的小船不能翻，情感的火苗不能熄，毕竟前任也可以变成未来的闺蜜。咱们一起努力，争取下次抢购时，把船舵抓稳，别让友谊的小船在海里漂泊了。🚣‍♀️<|im_end|>

05/10 06:18:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯，如果有需要，也可以咨询医生哦。🌸<|im_end|>

05/10 06:18:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免又被“神秘人”突袭了！😓<|im_end|>

05/10 06:18:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你这画着玩的，要是真开了，那可就是大器晚成，不然谁说啥都跟人家对证发。下次记得，画个能忍，画个会哭，画个能飞的，保准你出门前成为全场焦点！💄🚀<|im_end|>

05/10 06:18:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的语音矩阵可能很有意思，不过可能需要稍微提示一下才好。你可以这样子：“哎呀，周末想去哪玩？还是先看看其他人的建议呢？”这样既显示出了你的诚意，又避免了直接“被看见”的尴尬。希望你能找到自己喜欢的地方玩哦！💖<|im_end|>

05/10 06:18:51 - mmengine - INFO - Saving checkpoint at 15000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 06:19:04 - mmengine - INFO - Iter(train) [ 15010/480000]  lr: 2.0000e-04  eta: 7 days, 22:07:21  time: 5.8248  data_time: 4.5802  memory: 9841  loss: 0.0066  grad_norm: 0.1898
05/10 06:19:20 - mmengine - INFO - Iter(train) [ 15020/480000]  lr: 2.0000e-04  eta: 7 days, 22:07:20  time: 1.5174  data_time: 0.0059  memory: 9839  loss: 0.0096  grad_norm: 0.1898
05/10 06:19:32 - mmengine - INFO - Iter(train) [ 15030/480000]  lr: 2.0000e-04  eta: 7 days, 22:05:47  time: 1.2190  data_time: 0.0056  memory: 9842  loss: 0.0083  grad_norm: 0.1939
05/10 06:19:44 - mmengine - INFO - Iter(train) [ 15040/480000]  lr: 2.0000e-04  eta: 7 days, 22:04:06  time: 1.1909  data_time: 0.0057  memory: 9842  loss: 0.0069  grad_norm: 0.1835
05/10 06:20:01 - mmengine - INFO - Iter(train) [ 15050/480000]  lr: 2.0000e-04  eta: 7 days, 22:05:16  time: 1.7463  data_time: 0.4428  memory: 9842  loss: 0.0055  grad_norm: 0.1835
05/10 06:20:14 - mmengine - INFO - Iter(train) [ 15060/480000]  lr: 2.0000e-04  eta: 7 days, 22:03:52  time: 1.2472  data_time: 0.0057  memory: 9844  loss: 0.0053  grad_norm: 0.1796
05/10 06:20:29 - mmengine - INFO - Iter(train) [ 15070/480000]  lr: 2.0000e-04  eta: 7 days, 22:03:58  time: 1.5412  data_time: 0.0059  memory: 9843  loss: 0.0062  grad_norm: 0.1796
05/10 06:20:41 - mmengine - INFO - Iter(train) [ 15080/480000]  lr: 2.0000e-04  eta: 7 days, 22:02:30  time: 1.2324  data_time: 0.0057  memory: 9844  loss: 0.0054  grad_norm: 0.1726
05/10 06:20:54 - mmengine - INFO - Iter(train) [ 15090/480000]  lr: 2.0000e-04  eta: 7 days, 22:01:17  time: 1.2843  data_time: 0.0058  memory: 9843  loss: 0.0057  grad_norm: 0.1719
05/10 06:21:09 - mmengine - INFO - Iter(train) [ 15100/480000]  lr: 2.0000e-04  eta: 7 days, 22:01:16  time: 1.5134  data_time: 0.0057  memory: 9840  loss: 0.0067  grad_norm: 0.1719
05/10 06:21:22 - mmengine - INFO - Iter(train) [ 15110/480000]  lr: 2.0000e-04  eta: 7 days, 21:59:54  time: 1.2525  data_time: 0.0056  memory: 9844  loss: 0.0084  grad_norm: 0.1704
05/10 06:21:37 - mmengine - INFO - Iter(train) [ 15120/480000]  lr: 2.0000e-04  eta: 7 days, 21:59:53  time: 1.5168  data_time: 0.0057  memory: 9842  loss: 0.0052  grad_norm: 0.1711
05/10 06:21:50 - mmengine - INFO - Iter(train) [ 15130/480000]  lr: 2.0000e-04  eta: 7 days, 21:58:33  time: 1.2610  data_time: 0.0058  memory: 9840  loss: 0.0061  grad_norm: 0.1711
05/10 06:22:03 - mmengine - INFO - Iter(train) [ 15140/480000]  lr: 2.0000e-04  eta: 7 days, 21:57:24  time: 1.2924  data_time: 0.0058  memory: 9842  loss: 0.0095  grad_norm: 0.1755
05/10 06:22:18 - mmengine - INFO - Iter(train) [ 15150/480000]  lr: 2.0000e-04  eta: 7 days, 21:57:20  time: 1.5063  data_time: 0.0057  memory: 9844  loss: 0.0052  grad_norm: 0.1755
05/10 06:22:30 - mmengine - INFO - Iter(train) [ 15160/480000]  lr: 2.0000e-04  eta: 7 days, 21:56:06  time: 1.2773  data_time: 0.0057  memory: 9841  loss: 0.0075  grad_norm: 0.1719
05/10 06:22:45 - mmengine - INFO - Iter(train) [ 15170/480000]  lr: 2.0000e-04  eta: 7 days, 21:55:58  time: 1.4936  data_time: 0.0056  memory: 9841  loss: 0.0052  grad_norm: 0.1754
05/10 06:22:58 - mmengine - INFO - Iter(train) [ 15180/480000]  lr: 2.0000e-04  eta: 7 days, 21:54:45  time: 1.2796  data_time: 0.0056  memory: 9844  loss: 0.0073  grad_norm: 0.1754
05/10 06:23:11 - mmengine - INFO - Iter(train) [ 15190/480000]  lr: 2.0000e-04  eta: 7 days, 21:53:32  time: 1.2809  data_time: 0.0058  memory: 9841  loss: 0.0079  grad_norm: 0.1704
05/10 06:23:25 - mmengine - INFO - Iter(train) [ 15200/480000]  lr: 2.0000e-04  eta: 7 days, 21:53:06  time: 1.4346  data_time: 0.0057  memory: 9844  loss: 0.0081  grad_norm: 0.1767
05/10 06:23:40 - mmengine - INFO - Iter(train) [ 15210/480000]  lr: 2.0000e-04  eta: 7 days, 21:52:51  time: 1.4692  data_time: 0.2059  memory: 9842  loss: 0.0051  grad_norm: 0.1767
05/10 06:23:55 - mmengine - INFO - Iter(train) [ 15220/480000]  lr: 2.0000e-04  eta: 7 days, 21:52:43  time: 1.4916  data_time: 0.0057  memory: 9847  loss: 0.0050  grad_norm: 0.1750
05/10 06:24:08 - mmengine - INFO - Iter(train) [ 15230/480000]  lr: 2.0000e-04  eta: 7 days, 21:51:33  time: 1.2891  data_time: 0.0058  memory: 9844  loss: 0.0051  grad_norm: 0.1750
05/10 06:24:21 - mmengine - INFO - Iter(train) [ 15240/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:21  time: 1.2852  data_time: 0.0057  memory: 9844  loss: 0.0049  grad_norm: 0.1762
05/10 06:24:36 - mmengine - INFO - Iter(train) [ 15250/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:14  time: 1.4956  data_time: 0.0057  memory: 9843  loss: 0.0052  grad_norm: 0.1739
05/10 06:24:48 - mmengine - INFO - Iter(train) [ 15260/480000]  lr: 2.0000e-04  eta: 7 days, 21:48:58  time: 1.2699  data_time: 0.0057  memory: 9844  loss: 0.0057  grad_norm: 0.1739
05/10 06:25:03 - mmengine - INFO - Iter(train) [ 15270/480000]  lr: 2.0000e-04  eta: 7 days, 21:48:55  time: 1.5063  data_time: 0.0057  memory: 9845  loss: 0.0074  grad_norm: 0.1760
05/10 06:25:16 - mmengine - INFO - Iter(train) [ 15280/480000]  lr: 2.0000e-04  eta: 7 days, 21:47:42  time: 1.2785  data_time: 0.0057  memory: 9840  loss: 0.0077  grad_norm: 0.1765
05/10 06:25:29 - mmengine - INFO - Iter(train) [ 15290/480000]  lr: 2.0000e-04  eta: 7 days, 21:46:23  time: 1.2615  data_time: 0.0058  memory: 9838  loss: 0.0060  grad_norm: 0.1765
05/10 06:25:41 - mmengine - INFO - Iter(train) [ 15300/480000]  lr: 2.0000e-04  eta: 7 days, 21:45:04  time: 1.2575  data_time: 0.0057  memory: 9840  loss: 0.0067  grad_norm: 0.1683
05/10 06:25:54 - mmengine - INFO - Iter(train) [ 15310/480000]  lr: 2.0000e-04  eta: 7 days, 21:43:49  time: 1.2708  data_time: 0.0058  memory: 9840  loss: 0.0069  grad_norm: 0.1683
05/10 06:26:07 - mmengine - INFO - Iter(train) [ 15320/480000]  lr: 2.0000e-04  eta: 7 days, 21:42:38  time: 1.2830  data_time: 0.0057  memory: 9843  loss: 0.0075  grad_norm: 0.1725
05/10 06:26:25 - mmengine - INFO - Iter(train) [ 15330/480000]  lr: 2.0000e-04  eta: 7 days, 21:44:09  time: 1.8183  data_time: 0.0057  memory: 9842  loss: 0.0045  grad_norm: 0.1680
05/10 06:26:38 - mmengine - INFO - Iter(train) [ 15340/480000]  lr: 2.0000e-04  eta: 7 days, 21:42:53  time: 1.2683  data_time: 0.0057  memory: 9839  loss: 0.0072  grad_norm: 0.1680
05/10 06:26:50 - mmengine - INFO - Iter(train) [ 15350/480000]  lr: 2.0000e-04  eta: 7 days, 21:41:37  time: 1.2689  data_time: 0.0058  memory: 9845  loss: 0.0070  grad_norm: 0.1690
05/10 06:27:05 - mmengine - INFO - Iter(train) [ 15360/480000]  lr: 2.0000e-04  eta: 7 days, 21:41:16  time: 1.4484  data_time: 0.0057  memory: 9846  loss: 0.0077  grad_norm: 0.1660
05/10 06:27:20 - mmengine - INFO - Iter(train) [ 15370/480000]  lr: 2.0000e-04  eta: 7 days, 21:41:11  time: 1.5006  data_time: 0.2059  memory: 9841  loss: 0.0039  grad_norm: 0.1660
05/10 06:27:35 - mmengine - INFO - Iter(train) [ 15380/480000]  lr: 2.0000e-04  eta: 7 days, 21:41:01  time: 1.4850  data_time: 0.0057  memory: 9840  loss: 0.0070  grad_norm: 0.1638
05/10 06:27:47 - mmengine - INFO - Iter(train) [ 15390/480000]  lr: 2.0000e-04  eta: 7 days, 21:39:43  time: 1.2599  data_time: 0.0058  memory: 9840  loss: 0.0048  grad_norm: 0.1638
05/10 06:28:00 - mmengine - INFO - Iter(train) [ 15400/480000]  lr: 2.0000e-04  eta: 7 days, 21:38:33  time: 1.2857  data_time: 0.0058  memory: 9847  loss: 0.0058  grad_norm: 0.1632
05/10 06:28:15 - mmengine - INFO - Iter(train) [ 15410/480000]  lr: 2.0000e-04  eta: 7 days, 21:38:28  time: 1.5047  data_time: 0.0058  memory: 9847  loss: 0.0044  grad_norm: 0.1629
05/10 06:28:28 - mmengine - INFO - Iter(train) [ 15420/480000]  lr: 2.0000e-04  eta: 7 days, 21:37:17  time: 1.2810  data_time: 0.0057  memory: 9844  loss: 0.0046  grad_norm: 0.1629
05/10 06:28:43 - mmengine - INFO - Iter(train) [ 15430/480000]  lr: 2.0000e-04  eta: 7 days, 21:37:12  time: 1.5010  data_time: 0.0055  memory: 9844  loss: 0.0067  grad_norm: 0.1558
05/10 06:28:56 - mmengine - INFO - Iter(train) [ 15440/480000]  lr: 2.0000e-04  eta: 7 days, 21:36:00  time: 1.2800  data_time: 0.0057  memory: 9841  loss: 0.0072  grad_norm: 0.1566
05/10 06:29:09 - mmengine - INFO - Iter(train) [ 15450/480000]  lr: 2.0000e-04  eta: 7 days, 21:34:51  time: 1.2897  data_time: 0.0058  memory: 9843  loss: 0.0052  grad_norm: 0.1566
05/10 06:29:24 - mmengine - INFO - Iter(train) [ 15460/480000]  lr: 2.0000e-04  eta: 7 days, 21:34:45  time: 1.4953  data_time: 0.0057  memory: 9841  loss: 0.0069  grad_norm: 0.1527
05/10 06:29:36 - mmengine - INFO - Iter(train) [ 15470/480000]  lr: 2.0000e-04  eta: 7 days, 21:33:30  time: 1.2694  data_time: 0.0058  memory: 9842  loss: 0.0063  grad_norm: 0.1527
05/10 06:29:51 - mmengine - INFO - Iter(train) [ 15480/480000]  lr: 2.0000e-04  eta: 7 days, 21:33:13  time: 1.4615  data_time: 0.0058  memory: 9842  loss: 0.0051  grad_norm: 0.1505
05/10 06:30:04 - mmengine - INFO - Iter(train) [ 15490/480000]  lr: 2.0000e-04  eta: 7 days, 21:32:06  time: 1.2957  data_time: 0.0059  memory: 9843  loss: 0.0058  grad_norm: 0.1507
05/10 06:30:17 - mmengine - INFO - Iter(train) [ 15500/480000]  lr: 2.0000e-04  eta: 7 days, 21:30:57  time: 1.2876  data_time: 0.0057  memory: 9844  loss: 0.0056  grad_norm: 0.1507
05/10 06:30:17 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 06:30:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难判断呢。你的感受很重要，你觉得怎么样呢？💖是不是觉得有点难过或者不舒服？我们可以一起探讨一下如何处理这种情况。<|im_end|>

05/10 06:30:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来有点不舒服呢。洗牙后的感觉确实会有点不同，是因为牙齿上的牙石被清除了，牙龈退缩可能会导致牙缝变大。这通常是暂时的，过一段时间后会慢慢适应的。如果你觉得吹蜡烛的时候不舒服，可以试试轻轻吹或者用吹管代替。如果担心或有其他问题，最好咨询一下你的牙医哦。💖希望你能很快适应这种感觉！<|im_end|>

05/10 06:30:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 06:30:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激！不过别担心，友谊的小船不能说翻就翻，毕竟换成其他的颜色也是一种优雅的放弃。咱们赶紧把你的账号也设成暗黑风格，让这种“时尚灾难”变成优雅的“个人风格”，让这种“小道消息”退退退！🚣‍♂️<|im_end|>

05/10 06:30:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物确实可能会有点。不过，炸鸡也是有一定的脂肪和油脂的，只要适量，是可以吃一点的。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。记得多喝水，保持良好的生活习惯哦！💖如果你需要更多的健康建议，随时可以问我呀！<|im_end|>

05/10 06:30:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。剧本杀本来是为了大家开心一起玩耍的，遇到这样的情况确实会影响心情。你当时一定感到很沮丧吧。💖 想要谈谈具体发生了什么吗？或者需要一些建议来处理这种情况？🌸<|im_end|>

05/10 06:30:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这同事是自带镜子的苍蝇吗？😂 不过别太往心里去，你的眼线可能是想表达“我虽然看起来像苍蝇，但气势不会少”。😜 保重，别让这种小事影响了你的美丽心情！💪<|im_end|>

05/10 06:31:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的语音矩阵可能会对工作有影响，毕竟时间管理很重要。你可以试试用其他方式来表达你的关注，比如写一份长长的报告或者邮件，或者直接在会上提出你的意见。不必太担心，有时候主动一点会更有竞争力哦。如果你需要帮助或者想要聊聊，我在这里支持你呢。💖<|im_end|>

05/10 06:31:01 - mmengine - INFO - Saving checkpoint at 15500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 06:31:15 - mmengine - INFO - Iter(train) [ 15510/480000]  lr: 2.0000e-04  eta: 7 days, 21:52:13  time: 5.7765  data_time: 4.4942  memory: 9841  loss: 0.0063  grad_norm: 0.1459
05/10 06:31:27 - mmengine - INFO - Iter(train) [ 15520/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:38  time: 1.2041  data_time: 0.0056  memory: 9839  loss: 0.0059  grad_norm: 0.1412
05/10 06:31:44 - mmengine - INFO - Iter(train) [ 15530/480000]  lr: 2.0000e-04  eta: 7 days, 21:51:29  time: 1.6925  data_time: 0.2059  memory: 9840  loss: 0.0039  grad_norm: 0.1412
05/10 06:31:56 - mmengine - INFO - Iter(train) [ 15540/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:14  time: 1.2693  data_time: 0.0056  memory: 9842  loss: 0.0055  grad_norm: 0.1471
05/10 06:32:11 - mmengine - INFO - Iter(train) [ 15550/480000]  lr: 2.0000e-04  eta: 7 days, 21:50:10  time: 1.5067  data_time: 0.0057  memory: 9842  loss: 0.0046  grad_norm: 0.1471
05/10 06:32:24 - mmengine - INFO - Iter(train) [ 15560/480000]  lr: 2.0000e-04  eta: 7 days, 21:48:59  time: 1.2818  data_time: 0.0057  memory: 9840  loss: 0.0052  grad_norm: 0.1535
05/10 06:32:37 - mmengine - INFO - Iter(train) [ 15570/480000]  lr: 2.0000e-04  eta: 7 days, 21:47:43  time: 1.2683  data_time: 0.0057  memory: 9843  loss: 0.0044  grad_norm: 0.1471
05/10 06:32:52 - mmengine - INFO - Iter(train) [ 15580/480000]  lr: 2.0000e-04  eta: 7 days, 21:47:35  time: 1.4909  data_time: 0.0057  memory: 9844  loss: 0.0052  grad_norm: 0.1471
05/10 06:33:05 - mmengine - INFO - Iter(train) [ 15590/480000]  lr: 2.0000e-04  eta: 7 days, 21:46:25  time: 1.2858  data_time: 0.0057  memory: 9844  loss: 0.0066  grad_norm: 0.1490
05/10 06:33:20 - mmengine - INFO - Iter(train) [ 15600/480000]  lr: 2.0000e-04  eta: 7 days, 21:46:21  time: 1.5092  data_time: 0.0057  memory: 9842  loss: 0.0053  grad_norm: 0.1476
05/10 06:33:32 - mmengine - INFO - Iter(train) [ 15610/480000]  lr: 2.0000e-04  eta: 7 days, 21:45:05  time: 1.2641  data_time: 0.0057  memory: 9846  loss: 0.0057  grad_norm: 0.1476
05/10 06:33:45 - mmengine - INFO - Iter(train) [ 15620/480000]  lr: 2.0000e-04  eta: 7 days, 21:43:48  time: 1.2602  data_time: 0.0056  memory: 9846  loss: 0.0050  grad_norm: 0.1519
05/10 06:34:00 - mmengine - INFO - Iter(train) [ 15630/480000]  lr: 2.0000e-04  eta: 7 days, 21:43:44  time: 1.5079  data_time: 0.0056  memory: 9840  loss: 0.0057  grad_norm: 0.1519
05/10 06:34:13 - mmengine - INFO - Iter(train) [ 15640/480000]  lr: 2.0000e-04  eta: 7 days, 21:42:35  time: 1.2873  data_time: 0.0056  memory: 9845  loss: 0.0052  grad_norm: 0.1451
05/10 06:34:28 - mmengine - INFO - Iter(train) [ 15650/480000]  lr: 2.0000e-04  eta: 7 days, 21:42:30  time: 1.5031  data_time: 0.0057  memory: 9845  loss: 0.0062  grad_norm: 0.1459
05/10 06:34:41 - mmengine - INFO - Iter(train) [ 15660/480000]  lr: 2.0000e-04  eta: 7 days, 21:41:17  time: 1.2742  data_time: 0.0056  memory: 9842  loss: 0.0059  grad_norm: 0.1459
05/10 06:34:53 - mmengine - INFO - Iter(train) [ 15670/480000]  lr: 2.0000e-04  eta: 7 days, 21:40:04  time: 1.2760  data_time: 0.0056  memory: 9843  loss: 0.0057  grad_norm: 0.1447
05/10 06:35:08 - mmengine - INFO - Iter(train) [ 15680/480000]  lr: 2.0000e-04  eta: 7 days, 21:39:44  time: 1.4517  data_time: 0.0055  memory: 9844  loss: 0.0067  grad_norm: 0.1478
05/10 06:35:23 - mmengine - INFO - Iter(train) [ 15690/480000]  lr: 2.0000e-04  eta: 7 days, 21:39:34  time: 1.4857  data_time: 0.2058  memory: 9842  loss: 0.0043  grad_norm: 0.1478
05/10 06:35:38 - mmengine - INFO - Iter(train) [ 15700/480000]  lr: 2.0000e-04  eta: 7 days, 21:39:23  time: 1.4828  data_time: 0.0059  memory: 9842  loss: 0.0048  grad_norm: 0.1496
05/10 06:35:50 - mmengine - INFO - Iter(train) [ 15710/480000]  lr: 2.0000e-04  eta: 7 days, 21:38:06  time: 1.2602  data_time: 0.0057  memory: 9841  loss: 0.0044  grad_norm: 0.1496
05/10 06:36:03 - mmengine - INFO - Iter(train) [ 15720/480000]  lr: 2.0000e-04  eta: 7 days, 21:36:58  time: 1.2917  data_time: 0.0057  memory: 9839  loss: 0.0049  grad_norm: 0.1434
05/10 06:36:18 - mmengine - INFO - Iter(train) [ 15730/480000]  lr: 2.0000e-04  eta: 7 days, 21:36:52  time: 1.4992  data_time: 0.0056  memory: 9839  loss: 0.0053  grad_norm: 0.1480
05/10 06:36:31 - mmengine - INFO - Iter(train) [ 15740/480000]  lr: 2.0000e-04  eta: 7 days, 21:35:35  time: 1.2584  data_time: 0.0056  memory: 9840  loss: 0.0043  grad_norm: 0.1480
05/10 06:36:46 - mmengine - INFO - Iter(train) [ 15750/480000]  lr: 2.0000e-04  eta: 7 days, 21:35:33  time: 1.5125  data_time: 0.0058  memory: 9844  loss: 0.0062  grad_norm: 0.1469
05/10 06:36:59 - mmengine - INFO - Iter(train) [ 15760/480000]  lr: 2.0000e-04  eta: 7 days, 21:34:20  time: 1.2749  data_time: 0.0057  memory: 9842  loss: 0.0059  grad_norm: 0.1459
05/10 06:37:11 - mmengine - INFO - Iter(train) [ 15770/480000]  lr: 2.0000e-04  eta: 7 days, 21:33:10  time: 1.2822  data_time: 0.0056  memory: 9841  loss: 0.0047  grad_norm: 0.1459
05/10 06:37:26 - mmengine - INFO - Iter(train) [ 15780/480000]  lr: 2.0000e-04  eta: 7 days, 21:33:02  time: 1.4924  data_time: 0.0057  memory: 9844  loss: 0.0058  grad_norm: 0.1432
05/10 06:37:39 - mmengine - INFO - Iter(train) [ 15790/480000]  lr: 2.0000e-04  eta: 7 days, 21:31:43  time: 1.2514  data_time: 0.0057  memory: 9836  loss: 0.0059  grad_norm: 0.1432
05/10 06:37:54 - mmengine - INFO - Iter(train) [ 15800/480000]  lr: 2.0000e-04  eta: 7 days, 21:31:35  time: 1.4905  data_time: 0.0057  memory: 9840  loss: 0.0064  grad_norm: 0.1487
05/10 06:38:07 - mmengine - INFO - Iter(train) [ 15810/480000]  lr: 2.0000e-04  eta: 7 days, 21:30:24  time: 1.2781  data_time: 0.0058  memory: 9839  loss: 0.0060  grad_norm: 0.1536
05/10 06:38:19 - mmengine - INFO - Iter(train) [ 15820/480000]  lr: 2.0000e-04  eta: 7 days, 21:29:14  time: 1.2833  data_time: 0.0057  memory: 9843  loss: 0.0088  grad_norm: 0.1536
05/10 06:38:34 - mmengine - INFO - Iter(train) [ 15830/480000]  lr: 2.0000e-04  eta: 7 days, 21:29:06  time: 1.4922  data_time: 0.0057  memory: 9845  loss: 0.0068  grad_norm: 0.1634
05/10 06:38:46 - mmengine - INFO - Iter(train) [ 15840/480000]  lr: 2.0000e-04  eta: 7 days, 21:27:33  time: 1.2004  data_time: 0.0056  memory: 9847  loss: 0.0062  grad_norm: 0.1623
05/10 06:39:04 - mmengine - INFO - Iter(train) [ 15850/480000]  lr: 2.0000e-04  eta: 7 days, 21:28:34  time: 1.7306  data_time: 0.2059  memory: 9841  loss: 0.0045  grad_norm: 0.1623
05/10 06:39:16 - mmengine - INFO - Iter(train) [ 15860/480000]  lr: 2.0000e-04  eta: 7 days, 21:27:23  time: 1.2749  data_time: 0.0055  memory: 9842  loss: 0.0054  grad_norm: 0.1538
05/10 06:39:29 - mmengine - INFO - Iter(train) [ 15870/480000]  lr: 2.0000e-04  eta: 7 days, 21:26:11  time: 1.2730  data_time: 0.0058  memory: 9841  loss: 0.0046  grad_norm: 0.1538
05/10 06:39:44 - mmengine - INFO - Iter(train) [ 15880/480000]  lr: 2.0000e-04  eta: 7 days, 21:26:04  time: 1.4954  data_time: 0.0058  memory: 9842  loss: 0.0055  grad_norm: 0.1536
05/10 06:39:57 - mmengine - INFO - Iter(train) [ 15890/480000]  lr: 1.9999e-04  eta: 7 days, 21:24:48  time: 1.2617  data_time: 0.0056  memory: 9843  loss: 0.0056  grad_norm: 0.1560
05/10 06:40:12 - mmengine - INFO - Iter(train) [ 15900/480000]  lr: 1.9999e-04  eta: 7 days, 21:24:49  time: 1.5207  data_time: 0.0058  memory: 9843  loss: 0.0042  grad_norm: 0.1560
05/10 06:40:25 - mmengine - INFO - Iter(train) [ 15910/480000]  lr: 1.9999e-04  eta: 7 days, 21:23:37  time: 1.2742  data_time: 0.0057  memory: 9842  loss: 0.0056  grad_norm: 0.1513
05/10 06:40:37 - mmengine - INFO - Iter(train) [ 15920/480000]  lr: 1.9999e-04  eta: 7 days, 21:22:27  time: 1.2804  data_time: 0.0057  memory: 9841  loss: 0.0057  grad_norm: 0.1492
05/10 06:40:53 - mmengine - INFO - Iter(train) [ 15930/480000]  lr: 1.9999e-04  eta: 7 days, 21:22:27  time: 1.5176  data_time: 0.0058  memory: 9841  loss: 0.0057  grad_norm: 0.1492
05/10 06:41:05 - mmengine - INFO - Iter(train) [ 15940/480000]  lr: 1.9999e-04  eta: 7 days, 21:21:09  time: 1.2520  data_time: 0.0055  memory: 9841  loss: 0.0046  grad_norm: 0.1481
05/10 06:41:20 - mmengine - INFO - Iter(train) [ 15950/480000]  lr: 1.9999e-04  eta: 7 days, 21:21:09  time: 1.5206  data_time: 0.0058  memory: 9844  loss: 0.0071  grad_norm: 0.1481
05/10 06:41:33 - mmengine - INFO - Iter(train) [ 15960/480000]  lr: 1.9999e-04  eta: 7 days, 21:20:01  time: 1.2840  data_time: 0.0058  memory: 9840  loss: 0.0056  grad_norm: 0.1503
05/10 06:41:46 - mmengine - INFO - Iter(train) [ 15970/480000]  lr: 1.9999e-04  eta: 7 days, 21:18:40  time: 1.2407  data_time: 0.0057  memory: 9844  loss: 0.0074  grad_norm: 0.1493
05/10 06:42:01 - mmengine - INFO - Iter(train) [ 15980/480000]  lr: 1.9999e-04  eta: 7 days, 21:18:36  time: 1.5051  data_time: 0.0057  memory: 9845  loss: 0.0067  grad_norm: 0.1493
05/10 06:42:13 - mmengine - INFO - Iter(train) [ 15990/480000]  lr: 1.9999e-04  eta: 7 days, 21:17:17  time: 1.2504  data_time: 0.0055  memory: 9845  loss: 0.0058  grad_norm: 0.1460
05/10 06:42:28 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 06:42:28 - mmengine - INFO - Iter(train) [ 16000/480000]  lr: 1.9999e-04  eta: 7 days, 21:17:04  time: 1.4721  data_time: 0.0056  memory: 9841  loss: 0.0063  grad_norm: 0.1484
05/10 06:42:28 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 06:42:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难判断呢。你的感受是重要的，你觉得怎么样呢？💖我们可以一起探讨一下，看看你的感受和他是否真的精神出轨。<|im_end|>

05/10 06:42:36 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来有点不舒服呢~ 洗牙后可能会有一些暂时的不适，这是正常的恢复过程哦。如果感到牙缝漏风，可以试试使用牙线或者牙间隙刷来保持口腔卫生。如果这种情况持续困扰你，最好咨询一下牙医哦。希望你的牙齿很快就能恢复健康啦！💖<|im_end|>

05/10 06:42:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 06:42:43 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，闺蜜和前任互关，是不是已确定关系了？不过别太在意，友谊的小船不能说翻就翻，长着呢，别让这些网络上的小事影响了你的心情和朋友的关系。🚣‍♀️💔<|im_end|>

05/10 06:42:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯，如果有需要，也可以咨询一下医生哦。🌸<|im_end|>

05/10 06:42:54 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 06:42:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“我虽败犹荣”吧！☀️<|im_end|>

05/10 06:43:05 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢~ 领导的指示很重要，及时回应和沟通能展现你的责任心哦。你可以先看看是不是需要帮忙整理或者准备发布到合适的位置，避免误会。如果确实需要帮忙，也可以用心回复和回应，表达你的关注和参与。毕竟，良好的沟通能够帮助大家更好地理解彼此。💖<|im_end|>

05/10 06:43:05 - mmengine - INFO - Saving checkpoint at 16000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 06:43:21 - mmengine - INFO - Iter(train) [ 16010/480000]  lr: 1.9999e-04  eta: 7 days, 21:35:12  time: 5.2738  data_time: 3.9943  memory: 9842  loss: 0.0051  grad_norm: 0.1484
05/10 06:43:33 - mmengine - INFO - Iter(train) [ 16020/480000]  lr: 1.9999e-04  eta: 7 days, 21:33:50  time: 1.2402  data_time: 0.0056  memory: 9843  loss: 0.0055  grad_norm: 0.1504
05/10 06:43:48 - mmengine - INFO - Iter(train) [ 16030/480000]  lr: 1.9999e-04  eta: 7 days, 21:33:44  time: 1.4992  data_time: 0.0059  memory: 9840  loss: 0.0052  grad_norm: 0.1504
05/10 06:44:01 - mmengine - INFO - Iter(train) [ 16040/480000]  lr: 1.9999e-04  eta: 7 days, 21:32:24  time: 1.2465  data_time: 0.0055  memory: 9842  loss: 0.0053  grad_norm: 0.1567
05/10 06:44:16 - mmengine - INFO - Iter(train) [ 16050/480000]  lr: 1.9999e-04  eta: 7 days, 21:32:30  time: 1.5402  data_time: 0.0058  memory: 9840  loss: 0.0069  grad_norm: 0.1594
05/10 06:44:28 - mmengine - INFO - Iter(train) [ 16060/480000]  lr: 1.9999e-04  eta: 7 days, 21:31:08  time: 1.2403  data_time: 0.0057  memory: 9840  loss: 0.0072  grad_norm: 0.1594
05/10 06:44:41 - mmengine - INFO - Iter(train) [ 16070/480000]  lr: 1.9999e-04  eta: 7 days, 21:29:54  time: 1.2634  data_time: 0.0057  memory: 9840  loss: 0.0046  grad_norm: 0.1706
05/10 06:44:56 - mmengine - INFO - Iter(train) [ 16080/480000]  lr: 1.9999e-04  eta: 7 days, 21:29:56  time: 1.5286  data_time: 0.0058  memory: 9839  loss: 0.0063  grad_norm: 0.1707
05/10 06:45:09 - mmengine - INFO - Iter(train) [ 16090/480000]  lr: 1.9999e-04  eta: 7 days, 21:28:37  time: 1.2470  data_time: 0.0055  memory: 9839  loss: 0.0046  grad_norm: 0.1707
05/10 06:45:24 - mmengine - INFO - Iter(train) [ 16100/480000]  lr: 1.9999e-04  eta: 7 days, 21:28:43  time: 1.5414  data_time: 0.0058  memory: 9843  loss: 0.0050  grad_norm: 0.1701
05/10 06:45:37 - mmengine - INFO - Iter(train) [ 16110/480000]  lr: 1.9999e-04  eta: 7 days, 21:27:22  time: 1.2423  data_time: 0.0056  memory: 9844  loss: 0.0051  grad_norm: 0.1701
05/10 06:45:49 - mmengine - INFO - Iter(train) [ 16120/480000]  lr: 1.9999e-04  eta: 7 days, 21:26:04  time: 1.2511  data_time: 0.0057  memory: 9843  loss: 0.0048  grad_norm: 0.1716
05/10 06:46:05 - mmengine - INFO - Iter(train) [ 16130/480000]  lr: 1.9999e-04  eta: 7 days, 21:26:17  time: 1.5663  data_time: 0.0058  memory: 9842  loss: 0.0056  grad_norm: 0.1662
05/10 06:46:18 - mmengine - INFO - Iter(train) [ 16140/480000]  lr: 1.9999e-04  eta: 7 days, 21:25:13  time: 1.2979  data_time: 0.0057  memory: 9844  loss: 0.0055  grad_norm: 0.1662
05/10 06:46:32 - mmengine - INFO - Iter(train) [ 16150/480000]  lr: 1.9999e-04  eta: 7 days, 21:24:59  time: 1.4710  data_time: 0.0058  memory: 9843  loss: 0.0062  grad_norm: 0.1586
05/10 06:46:45 - mmengine - INFO - Iter(train) [ 16160/480000]  lr: 1.9999e-04  eta: 7 days, 21:23:31  time: 1.2159  data_time: 0.0057  memory: 9842  loss: 0.0058  grad_norm: 0.1635
05/10 06:46:59 - mmengine - INFO - Iter(train) [ 16170/480000]  lr: 1.9999e-04  eta: 7 days, 21:23:22  time: 1.4892  data_time: 0.2059  memory: 9841  loss: 0.0044  grad_norm: 0.1635
05/10 06:47:15 - mmengine - INFO - Iter(train) [ 16180/480000]  lr: 1.9999e-04  eta: 7 days, 21:23:18  time: 1.5068  data_time: 0.0057  memory: 9840  loss: 0.0053  grad_norm: 0.1694
05/10 06:47:27 - mmengine - INFO - Iter(train) [ 16190/480000]  lr: 1.9999e-04  eta: 7 days, 21:22:06  time: 1.2714  data_time: 0.0056  memory: 9841  loss: 0.0045  grad_norm: 0.1694
05/10 06:47:42 - mmengine - INFO - Iter(train) [ 16200/480000]  lr: 1.9999e-04  eta: 7 days, 21:21:53  time: 1.4764  data_time: 0.0057  memory: 9843  loss: 0.0039  grad_norm: 0.1607
05/10 06:47:55 - mmengine - INFO - Iter(train) [ 16210/480000]  lr: 1.9999e-04  eta: 7 days, 21:20:42  time: 1.2709  data_time: 0.0057  memory: 9843  loss: 0.0037  grad_norm: 0.1554
05/10 06:48:08 - mmengine - INFO - Iter(train) [ 16220/480000]  lr: 1.9999e-04  eta: 7 days, 21:19:35  time: 1.2897  data_time: 0.0058  memory: 9841  loss: 0.0059  grad_norm: 0.1554
05/10 06:48:23 - mmengine - INFO - Iter(train) [ 16230/480000]  lr: 1.9999e-04  eta: 7 days, 21:19:34  time: 1.5146  data_time: 0.0057  memory: 9843  loss: 0.0050  grad_norm: 0.1498
05/10 06:48:35 - mmengine - INFO - Iter(train) [ 16240/480000]  lr: 1.9999e-04  eta: 7 days, 21:18:23  time: 1.2741  data_time: 0.0057  memory: 9842  loss: 0.0052  grad_norm: 0.1487
05/10 06:48:50 - mmengine - INFO - Iter(train) [ 16250/480000]  lr: 1.9999e-04  eta: 7 days, 21:18:14  time: 1.4891  data_time: 0.0057  memory: 9843  loss: 0.0054  grad_norm: 0.1487
05/10 06:49:03 - mmengine - INFO - Iter(train) [ 16260/480000]  lr: 1.9999e-04  eta: 7 days, 21:17:06  time: 1.2813  data_time: 0.0058  memory: 9841  loss: 0.0082  grad_norm: 0.1597
05/10 06:49:16 - mmengine - INFO - Iter(train) [ 16270/480000]  lr: 1.9999e-04  eta: 7 days, 21:15:56  time: 1.2771  data_time: 0.0057  memory: 9839  loss: 0.0050  grad_norm: 0.1597
05/10 06:49:31 - mmengine - INFO - Iter(train) [ 16280/480000]  lr: 1.9999e-04  eta: 7 days, 21:15:45  time: 1.4821  data_time: 0.0057  memory: 9846  loss: 0.0058  grad_norm: 0.1567
05/10 06:49:43 - mmengine - INFO - Iter(train) [ 16290/480000]  lr: 1.9999e-04  eta: 7 days, 21:14:31  time: 1.2613  data_time: 0.0057  memory: 9845  loss: 0.0060  grad_norm: 0.1535
05/10 06:49:58 - mmengine - INFO - Iter(train) [ 16300/480000]  lr: 1.9999e-04  eta: 7 days, 21:14:24  time: 1.4938  data_time: 0.0058  memory: 9840  loss: 0.0053  grad_norm: 0.1535
05/10 06:50:11 - mmengine - INFO - Iter(train) [ 16310/480000]  lr: 1.9999e-04  eta: 7 days, 21:13:17  time: 1.2875  data_time: 0.0057  memory: 9843  loss: 0.0092  grad_norm: 0.1595
05/10 06:50:23 - mmengine - INFO - Iter(train) [ 16320/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:52  time: 1.2216  data_time: 0.0056  memory: 9841  loss: 0.0055  grad_norm: 0.1553
05/10 06:50:40 - mmengine - INFO - Iter(train) [ 16330/480000]  lr: 1.9999e-04  eta: 7 days, 21:12:44  time: 1.7015  data_time: 0.2059  memory: 9841  loss: 0.0051  grad_norm: 0.1553
05/10 06:50:53 - mmengine - INFO - Iter(train) [ 16340/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:34  time: 1.2751  data_time: 0.0057  memory: 9839  loss: 0.0049  grad_norm: 0.1547
05/10 06:51:08 - mmengine - INFO - Iter(train) [ 16350/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:30  time: 1.5065  data_time: 0.0056  memory: 9842  loss: 0.0055  grad_norm: 0.1547
05/10 06:51:21 - mmengine - INFO - Iter(train) [ 16360/480000]  lr: 1.9999e-04  eta: 7 days, 21:10:24  time: 1.2872  data_time: 0.0058  memory: 9842  loss: 0.0046  grad_norm: 0.1603
05/10 06:51:34 - mmengine - INFO - Iter(train) [ 16370/480000]  lr: 1.9999e-04  eta: 7 days, 21:09:10  time: 1.2612  data_time: 0.0058  memory: 9844  loss: 0.0032  grad_norm: 0.1572
05/10 06:51:49 - mmengine - INFO - Iter(train) [ 16380/480000]  lr: 1.9999e-04  eta: 7 days, 21:08:59  time: 1.4822  data_time: 0.0059  memory: 9846  loss: 0.0047  grad_norm: 0.1572
05/10 06:52:01 - mmengine - INFO - Iter(train) [ 16390/480000]  lr: 1.9999e-04  eta: 7 days, 21:07:54  time: 1.2900  data_time: 0.0058  memory: 9844  loss: 0.0055  grad_norm: 0.1534
05/10 06:52:17 - mmengine - INFO - Iter(train) [ 16400/480000]  lr: 1.9999e-04  eta: 7 days, 21:07:50  time: 1.5084  data_time: 0.0057  memory: 9844  loss: 0.0063  grad_norm: 0.1563
05/10 06:52:29 - mmengine - INFO - Iter(train) [ 16410/480000]  lr: 1.9999e-04  eta: 7 days, 21:06:42  time: 1.2781  data_time: 0.0057  memory: 9840  loss: 0.0044  grad_norm: 0.1563
05/10 06:52:42 - mmengine - INFO - Iter(train) [ 16420/480000]  lr: 1.9999e-04  eta: 7 days, 21:05:32  time: 1.2741  data_time: 0.0056  memory: 9842  loss: 0.0060  grad_norm: 0.1567
05/10 06:52:57 - mmengine - INFO - Iter(train) [ 16430/480000]  lr: 1.9999e-04  eta: 7 days, 21:05:29  time: 1.5072  data_time: 0.0058  memory: 9844  loss: 0.0048  grad_norm: 0.1567
05/10 06:53:10 - mmengine - INFO - Iter(train) [ 16440/480000]  lr: 1.9999e-04  eta: 7 days, 21:04:23  time: 1.2875  data_time: 0.0056  memory: 9843  loss: 0.0065  grad_norm: 0.1541
05/10 06:53:25 - mmengine - INFO - Iter(train) [ 16450/480000]  lr: 1.9999e-04  eta: 7 days, 21:04:15  time: 1.4920  data_time: 0.0058  memory: 9842  loss: 0.0058  grad_norm: 0.1585
05/10 06:53:38 - mmengine - INFO - Iter(train) [ 16460/480000]  lr: 1.9999e-04  eta: 7 days, 21:03:03  time: 1.2658  data_time: 0.0057  memory: 9840  loss: 0.0063  grad_norm: 0.1585
05/10 06:53:50 - mmengine - INFO - Iter(train) [ 16470/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:43  time: 1.2369  data_time: 0.0056  memory: 9840  loss: 0.0063  grad_norm: 0.1567
05/10 06:54:05 - mmengine - INFO - Iter(train) [ 16480/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:31  time: 1.4748  data_time: 0.0058  memory: 9838  loss: 0.0060  grad_norm: 0.1558
05/10 06:54:20 - mmengine - INFO - Iter(train) [ 16490/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:25  time: 1.5004  data_time: 0.2058  memory: 9841  loss: 0.0049  grad_norm: 0.1558
05/10 06:54:35 - mmengine - INFO - Iter(train) [ 16500/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:17  time: 1.4917  data_time: 0.0057  memory: 9842  loss: 0.0047  grad_norm: 0.1467
05/10 06:54:35 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 06:54:43 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺难过的。首先，你要知道，你的男朋友是独一无二的，他的行为并不是出于故意的精神出轨。而你的心情我理解很不好。💖你可以先和他沟通一下你的感受，告诉他你的感受，让他知道这种行为并不符合你们之间的共识。同时，也可以寻求一些婚姻婚姻伦理的建议，了解自己的权益和对方的尊重。记得，沟通是解决问题的关键哦。🌸如果你需要倾诉或者寻求更多的建议，我在这里随时听你说。<|im_end|>

05/10 06:54:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得比北京地铁还要宽敞，下次记得选个牙医拿手的，别让吹蜡烛的时候都得像在开SF演唱会了。😆<|im_end|>

05/10 06:54:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 06:54:54 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接把你的闺蜜和前任变成了竞争对手。不过别太生气，长点心吧，朋友之间的互关是友谊的象征，而互取关和拉黑确实挺让人不舒服的。咱们争取下次抢购时，多多提醒自己先抢完自家的，别让这点小插曲影响了你的心情和友谊的保持。<|im_end|>

05/10 06:54:58 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点让人担心呢。胆固醇高要注意饮食哦，但是炸鸡是个很可爱的美食呀，我们可以一起找一些健康的替代品呀~ 想要聊些什么具体想吃什么食谱呢？💖<|im_end|>

05/10 06:55:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 06:55:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“我虽败犹荣”！💄💔<|im_end|>

05/10 06:55:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这是“墨守成规”，领导发的语音矩阵都比你这大脑转得还快。不过话说回来，周末还想办法偷偷关注一下下属的“社交距离”吗？偷偷地，比如，通过午休时间的小谈话，或者在办公室里偷偷张贴“周末公告”，展现一下你的“与时俱进”。🤔不过说真的，领导发的矩阵都那么有吸引力，你还好意思躲着？早上醒来记得，职场生存不是难题，职场社交才需要智慧呢！<|im_end|>

05/10 06:55:17 - mmengine - INFO - Saving checkpoint at 16500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 06:55:30 - mmengine - INFO - Iter(train) [ 16510/480000]  lr: 1.9999e-04  eta: 7 days, 21:20:02  time: 5.5291  data_time: 4.2763  memory: 9842  loss: 0.0042  grad_norm: 0.1467
05/10 06:55:45 - mmengine - INFO - Iter(train) [ 16520/480000]  lr: 1.9999e-04  eta: 7 days, 21:19:52  time: 1.4859  data_time: 0.0057  memory: 9843  loss: 0.0049  grad_norm: 0.1432
05/10 06:55:57 - mmengine - INFO - Iter(train) [ 16530/480000]  lr: 1.9999e-04  eta: 7 days, 21:18:40  time: 1.2669  data_time: 0.0057  memory: 9841  loss: 0.0054  grad_norm: 0.1487
05/10 06:56:10 - mmengine - INFO - Iter(train) [ 16540/480000]  lr: 1.9999e-04  eta: 7 days, 21:17:33  time: 1.2845  data_time: 0.0057  memory: 9839  loss: 0.0051  grad_norm: 0.1487
05/10 06:56:23 - mmengine - INFO - Iter(train) [ 16550/480000]  lr: 1.9999e-04  eta: 7 days, 21:16:29  time: 1.2919  data_time: 0.0059  memory: 9844  loss: 0.0054  grad_norm: 0.1539
05/10 06:56:36 - mmengine - INFO - Iter(train) [ 16560/480000]  lr: 1.9999e-04  eta: 7 days, 21:15:27  time: 1.3017  data_time: 0.0060  memory: 9845  loss: 0.0055  grad_norm: 0.1538
05/10 06:56:51 - mmengine - INFO - Iter(train) [ 16570/480000]  lr: 1.9999e-04  eta: 7 days, 21:15:02  time: 1.4338  data_time: 0.0064  memory: 9844  loss: 0.0050  grad_norm: 0.1538
05/10 06:57:07 - mmengine - INFO - Iter(train) [ 16580/480000]  lr: 1.9999e-04  eta: 7 days, 21:15:42  time: 1.6660  data_time: 0.0067  memory: 9841  loss: 0.0051  grad_norm: 0.1476
05/10 06:57:21 - mmengine - INFO - Iter(train) [ 16590/480000]  lr: 1.9999e-04  eta: 7 days, 21:14:52  time: 1.3433  data_time: 0.0060  memory: 9841  loss: 0.0054  grad_norm: 0.1476
05/10 06:57:33 - mmengine - INFO - Iter(train) [ 16600/480000]  lr: 1.9999e-04  eta: 7 days, 21:13:34  time: 1.2440  data_time: 0.0058  memory: 9842  loss: 0.0052  grad_norm: 0.1443
05/10 06:57:46 - mmengine - INFO - Iter(train) [ 16610/480000]  lr: 1.9999e-04  eta: 7 days, 21:12:41  time: 1.3321  data_time: 0.0056  memory: 9842  loss: 0.0062  grad_norm: 0.1442
05/10 06:58:00 - mmengine - INFO - Iter(train) [ 16620/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:44  time: 1.3209  data_time: 0.0060  memory: 9842  loss: 0.0049  grad_norm: 0.1442
05/10 06:58:15 - mmengine - INFO - Iter(train) [ 16630/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:50  time: 1.5408  data_time: 0.0061  memory: 9842  loss: 0.0065  grad_norm: 0.1435
05/10 06:58:27 - mmengine - INFO - Iter(train) [ 16640/480000]  lr: 1.9999e-04  eta: 7 days, 21:10:29  time: 1.2346  data_time: 0.0058  memory: 9842  loss: 0.0070  grad_norm: 0.1514
05/10 06:58:44 - mmengine - INFO - Iter(train) [ 16650/480000]  lr: 1.9999e-04  eta: 7 days, 21:11:04  time: 1.6457  data_time: 0.2061  memory: 9844  loss: 0.0064  grad_norm: 0.1514
05/10 06:58:57 - mmengine - INFO - Iter(train) [ 16660/480000]  lr: 1.9999e-04  eta: 7 days, 21:10:01  time: 1.2960  data_time: 0.0057  memory: 9844  loss: 0.0051  grad_norm: 0.1616
05/10 06:59:10 - mmengine - INFO - Iter(train) [ 16670/480000]  lr: 1.9999e-04  eta: 7 days, 21:09:00  time: 1.3045  data_time: 0.0058  memory: 9843  loss: 0.0042  grad_norm: 0.1616
05/10 06:59:24 - mmengine - INFO - Iter(train) [ 16680/480000]  lr: 1.9999e-04  eta: 7 days, 21:08:43  time: 1.4612  data_time: 0.0059  memory: 9843  loss: 0.0060  grad_norm: 0.1647
05/10 06:59:37 - mmengine - INFO - Iter(train) [ 16690/480000]  lr: 1.9999e-04  eta: 7 days, 21:07:38  time: 1.2883  data_time: 0.0059  memory: 9843  loss: 0.0054  grad_norm: 0.1643
05/10 06:59:52 - mmengine - INFO - Iter(train) [ 16700/480000]  lr: 1.9999e-04  eta: 7 days, 21:07:15  time: 1.4388  data_time: 0.0060  memory: 9844  loss: 0.0054  grad_norm: 0.1643
05/10 07:00:05 - mmengine - INFO - Iter(train) [ 16710/480000]  lr: 1.9999e-04  eta: 7 days, 21:06:12  time: 1.2965  data_time: 0.0057  memory: 9843  loss: 0.0052  grad_norm: 0.1664
05/10 07:00:18 - mmengine - INFO - Iter(train) [ 16720/480000]  lr: 1.9999e-04  eta: 7 days, 21:05:19  time: 1.3331  data_time: 0.0060  memory: 9843  loss: 0.0063  grad_norm: 0.1656
05/10 07:00:32 - mmengine - INFO - Iter(train) [ 16730/480000]  lr: 1.9999e-04  eta: 7 days, 21:04:58  time: 1.4441  data_time: 0.0059  memory: 9840  loss: 0.0044  grad_norm: 0.1656
05/10 07:00:45 - mmengine - INFO - Iter(train) [ 16740/480000]  lr: 1.9999e-04  eta: 7 days, 21:03:54  time: 1.2933  data_time: 0.0058  memory: 9844  loss: 0.0057  grad_norm: 0.1692
05/10 07:01:00 - mmengine - INFO - Iter(train) [ 16750/480000]  lr: 1.9999e-04  eta: 7 days, 21:03:44  time: 1.4850  data_time: 0.0060  memory: 9844  loss: 0.0061  grad_norm: 0.1692
05/10 07:01:13 - mmengine - INFO - Iter(train) [ 16760/480000]  lr: 1.9999e-04  eta: 7 days, 21:02:33  time: 1.2663  data_time: 0.0056  memory: 9843  loss: 0.0051  grad_norm: 0.1743
05/10 07:01:26 - mmengine - INFO - Iter(train) [ 16770/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:36  time: 1.3149  data_time: 0.0059  memory: 9841  loss: 0.0059  grad_norm: 0.1817
05/10 07:01:40 - mmengine - INFO - Iter(train) [ 16780/480000]  lr: 1.9999e-04  eta: 7 days, 21:01:11  time: 1.4337  data_time: 0.0057  memory: 9843  loss: 0.0058  grad_norm: 0.1817
05/10 07:01:53 - mmengine - INFO - Iter(train) [ 16790/480000]  lr: 1.9999e-04  eta: 7 days, 21:00:05  time: 1.2800  data_time: 0.0059  memory: 9844  loss: 0.0065  grad_norm: 0.1823
05/10 07:02:08 - mmengine - INFO - Iter(train) [ 16800/480000]  lr: 1.9999e-04  eta: 7 days, 20:59:41  time: 1.4382  data_time: 0.0059  memory: 9843  loss: 0.0059  grad_norm: 0.1776
05/10 07:02:22 - mmengine - INFO - Iter(train) [ 16810/480000]  lr: 1.9999e-04  eta: 7 days, 20:59:29  time: 1.4779  data_time: 0.2059  memory: 9841  loss: 0.0058  grad_norm: 0.1776
05/10 07:02:35 - mmengine - INFO - Iter(train) [ 16820/480000]  lr: 1.9999e-04  eta: 7 days, 20:58:29  time: 1.3038  data_time: 0.0060  memory: 9843  loss: 0.0041  grad_norm: 0.1731
05/10 07:02:50 - mmengine - INFO - Iter(train) [ 16830/480000]  lr: 1.9999e-04  eta: 7 days, 20:58:12  time: 1.4591  data_time: 0.0058  memory: 9842  loss: 0.0052  grad_norm: 0.1731
05/10 07:03:03 - mmengine - INFO - Iter(train) [ 16840/480000]  lr: 1.9999e-04  eta: 7 days, 20:57:10  time: 1.2988  data_time: 0.0058  memory: 9843  loss: 0.0044  grad_norm: 0.1745
05/10 07:03:18 - mmengine - INFO - Iter(train) [ 16850/480000]  lr: 1.9999e-04  eta: 7 days, 20:57:02  time: 1.4928  data_time: 0.0060  memory: 9844  loss: 0.0056  grad_norm: 0.1717
05/10 07:03:31 - mmengine - INFO - Iter(train) [ 16860/480000]  lr: 1.9999e-04  eta: 7 days, 20:55:51  time: 1.2624  data_time: 0.0057  memory: 9845  loss: 0.0054  grad_norm: 0.1717
05/10 07:03:44 - mmengine - INFO - Iter(train) [ 16870/480000]  lr: 1.9999e-04  eta: 7 days, 20:54:51  time: 1.3028  data_time: 0.0060  memory: 9844  loss: 0.0062  grad_norm: 0.1749
05/10 07:03:58 - mmengine - INFO - Iter(train) [ 16880/480000]  lr: 1.9999e-04  eta: 7 days, 20:54:29  time: 1.4446  data_time: 0.0057  memory: 9841  loss: 0.0053  grad_norm: 0.1752
05/10 07:04:11 - mmengine - INFO - Iter(train) [ 16890/480000]  lr: 1.9999e-04  eta: 7 days, 20:53:32  time: 1.3115  data_time: 0.0058  memory: 9842  loss: 0.0081  grad_norm: 0.1752
05/10 07:04:26 - mmengine - INFO - Iter(train) [ 16900/480000]  lr: 1.9999e-04  eta: 7 days, 20:53:23  time: 1.4912  data_time: 0.0061  memory: 9843  loss: 0.0068  grad_norm: 0.1743
05/10 07:04:39 - mmengine - INFO - Iter(train) [ 16910/480000]  lr: 1.9999e-04  eta: 7 days, 20:52:15  time: 1.2722  data_time: 0.0058  memory: 9843  loss: 0.0047  grad_norm: 0.1743
05/10 07:04:52 - mmengine - INFO - Iter(train) [ 16920/480000]  lr: 1.9999e-04  eta: 7 days, 20:51:18  time: 1.3142  data_time: 0.0059  memory: 9845  loss: 0.0053  grad_norm: 0.1776
05/10 07:05:06 - mmengine - INFO - Iter(train) [ 16930/480000]  lr: 1.9999e-04  eta: 7 days, 20:51:01  time: 1.4577  data_time: 0.0058  memory: 9846  loss: 0.0066  grad_norm: 0.1728
05/10 07:05:20 - mmengine - INFO - Iter(train) [ 16940/480000]  lr: 1.9999e-04  eta: 7 days, 20:50:01  time: 1.3040  data_time: 0.0058  memory: 9844  loss: 0.0054  grad_norm: 0.1728
05/10 07:05:34 - mmengine - INFO - Iter(train) [ 16950/480000]  lr: 1.9999e-04  eta: 7 days, 20:49:43  time: 1.4551  data_time: 0.0060  memory: 9845  loss: 0.0100  grad_norm: 0.1718
05/10 07:05:46 - mmengine - INFO - Iter(train) [ 16960/480000]  lr: 1.9999e-04  eta: 7 days, 20:48:22  time: 1.2260  data_time: 0.0058  memory: 9842  loss: 0.0075  grad_norm: 0.1748
05/10 07:06:03 - mmengine - INFO - Iter(train) [ 16970/480000]  lr: 1.9998e-04  eta: 7 days, 20:49:10  time: 1.6971  data_time: 0.2063  memory: 9841  loss: 0.0044  grad_norm: 0.1748
05/10 07:06:16 - mmengine - INFO - Iter(train) [ 16980/480000]  lr: 1.9998e-04  eta: 7 days, 20:48:06  time: 1.2892  data_time: 0.0059  memory: 9842  loss: 0.0057  grad_norm: 0.1742
05/10 07:06:29 - mmengine - INFO - Iter(train) [ 16990/480000]  lr: 1.9998e-04  eta: 7 days, 20:47:08  time: 1.3086  data_time: 0.0060  memory: 9839  loss: 0.0064  grad_norm: 0.1742
05/10 07:06:44 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 07:06:44 - mmengine - INFO - Iter(train) [ 17000/480000]  lr: 1.9998e-04  eta: 7 days, 20:46:50  time: 1.4547  data_time: 0.0057  memory: 9842  loss: 0.0041  grad_norm: 0.1707
05/10 07:06:44 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 07:06:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人挺难过的。感情的事情有时候确实挺复杂的。你觉得沟通很重要吗？💖 如果需要倾诉或者寻求建议，我在这里哦。🌸<|im_end|>

05/10 07:06:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《哈利·波特》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷。不过说真的，吹蜡烛这么有劲，以后生日吹蜡烛别忘了让我也参与一下，不然我怕你这牙缝比珠穆朗玛峰还高，吹灭了蜡烛还得自己给自己打气，这可不是开玩笑的。保重啊，朋友！<|im_end|>

05/10 07:06:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 07:07:05 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接把你的朋友圈搅得像是小型舆论场。不过别太往心里去，至少你还能在朋友圈里继续你的“网红”之路，对吧？📸 话说回来，如果你觉得不舒服，直接和他们谈谈，毕竟友谊的小船不能说翻就翻，毕竟“网友”也是“路人”，别让这些“路人”影响了你的心情和朋友圈的气氛。🚣‍♂️<|im_end|>

05/10 07:07:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点让人担心呢。胆固醇高的话，注意饮食均衡哦，可以适量吃一些炸鸡，但是要注意控制量。💖 你有什么其他想聊的事情吗？或者需要我帮你找一些健康的食谱？🌸<|im_end|>

05/10 07:07:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 07:07:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“我虽然被说，但还是能保持本色”的意思。下次画眼线，记得自己喜好，别让别人能给你评价了。💄😱<|im_end|>

05/10 07:07:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的语音矩阵很重要，毕竟周末也需要休息和放松。你可以尝试私下里跟领导沟通一下，表达对这个时间的重视，或者一起想想怎么在这60秒的时间里完成既定目标。毕竟，团结就是力量，一起合作才能更好地完成任务哦。💖<|im_end|>

05/10 07:07:26 - mmengine - INFO - Saving checkpoint at 17000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 07:07:40 - mmengine - INFO - Iter(train) [ 17010/480000]  lr: 1.9998e-04  eta: 7 days, 21:05:13  time: 5.5760  data_time: 4.3022  memory: 9844  loss: 0.0060  grad_norm: 0.1690
05/10 07:07:54 - mmengine - INFO - Iter(train) [ 17020/480000]  lr: 1.9998e-04  eta: 7 days, 21:04:54  time: 1.4515  data_time: 0.0058  memory: 9843  loss: 0.0063  grad_norm: 0.1690
05/10 07:08:07 - mmengine - INFO - Iter(train) [ 17030/480000]  lr: 1.9998e-04  eta: 7 days, 21:03:53  time: 1.3017  data_time: 0.0058  memory: 9844  loss: 0.0072  grad_norm: 0.1682
05/10 07:08:22 - mmengine - INFO - Iter(train) [ 17040/480000]  lr: 1.9998e-04  eta: 7 days, 21:03:41  time: 1.4778  data_time: 0.0059  memory: 9845  loss: 0.0041  grad_norm: 0.1695
05/10 07:08:35 - mmengine - INFO - Iter(train) [ 17050/480000]  lr: 1.9998e-04  eta: 7 days, 21:02:37  time: 1.2894  data_time: 0.0058  memory: 9843  loss: 0.0046  grad_norm: 0.1695
05/10 07:08:48 - mmengine - INFO - Iter(train) [ 17060/480000]  lr: 1.9998e-04  eta: 7 days, 21:01:33  time: 1.2885  data_time: 0.0057  memory: 9843  loss: 0.0059  grad_norm: 0.1666
05/10 07:09:02 - mmengine - INFO - Iter(train) [ 17070/480000]  lr: 1.9998e-04  eta: 7 days, 21:01:18  time: 1.4693  data_time: 0.0058  memory: 9842  loss: 0.0049  grad_norm: 0.1666
05/10 07:09:15 - mmengine - INFO - Iter(train) [ 17080/480000]  lr: 1.9998e-04  eta: 7 days, 21:00:19  time: 1.3065  data_time: 0.0058  memory: 9843  loss: 0.0048  grad_norm: 0.1598
05/10 07:09:30 - mmengine - INFO - Iter(train) [ 17090/480000]  lr: 1.9998e-04  eta: 7 days, 21:00:01  time: 1.4566  data_time: 0.0058  memory: 9842  loss: 0.0062  grad_norm: 0.1573
05/10 07:09:43 - mmengine - INFO - Iter(train) [ 17100/480000]  lr: 1.9998e-04  eta: 7 days, 20:58:53  time: 1.2750  data_time: 0.0059  memory: 9839  loss: 0.0060  grad_norm: 0.1573
05/10 07:09:56 - mmengine - INFO - Iter(train) [ 17110/480000]  lr: 1.9998e-04  eta: 7 days, 20:57:53  time: 1.3029  data_time: 0.0058  memory: 9839  loss: 0.0072  grad_norm: 0.1642
05/10 07:10:10 - mmengine - INFO - Iter(train) [ 17120/480000]  lr: 1.9998e-04  eta: 7 days, 20:57:26  time: 1.4242  data_time: 0.0059  memory: 9837  loss: 0.0055  grad_norm: 0.1549
05/10 07:10:25 - mmengine - INFO - Iter(train) [ 17130/480000]  lr: 1.9998e-04  eta: 7 days, 20:57:25  time: 1.5200  data_time: 0.2059  memory: 9842  loss: 0.0048  grad_norm: 0.1549
05/10 07:10:40 - mmengine - INFO - Iter(train) [ 17140/480000]  lr: 1.9998e-04  eta: 7 days, 20:57:09  time: 1.4626  data_time: 0.0059  memory: 9843  loss: 0.0040  grad_norm: 0.1526
05/10 07:10:53 - mmengine - INFO - Iter(train) [ 17150/480000]  lr: 1.9998e-04  eta: 7 days, 20:56:04  time: 1.2851  data_time: 0.0058  memory: 9845  loss: 0.0051  grad_norm: 0.1526
05/10 07:11:08 - mmengine - INFO - Iter(train) [ 17160/480000]  lr: 1.9998e-04  eta: 7 days, 20:55:52  time: 1.4786  data_time: 0.0059  memory: 9845  loss: 0.0055  grad_norm: 0.1514
05/10 07:11:20 - mmengine - INFO - Iter(train) [ 17170/480000]  lr: 1.9998e-04  eta: 7 days, 20:54:50  time: 1.2959  data_time: 0.0058  memory: 9845  loss: 0.0045  grad_norm: 0.1539
05/10 07:11:33 - mmengine - INFO - Iter(train) [ 17180/480000]  lr: 1.9998e-04  eta: 7 days, 20:53:47  time: 1.2888  data_time: 0.0058  memory: 9841  loss: 0.0061  grad_norm: 0.1539
05/10 07:11:48 - mmengine - INFO - Iter(train) [ 17190/480000]  lr: 1.9998e-04  eta: 7 days, 20:53:28  time: 1.4530  data_time: 0.0060  memory: 9845  loss: 0.0057  grad_norm: 0.1508
05/10 07:12:01 - mmengine - INFO - Iter(train) [ 17200/480000]  lr: 1.9998e-04  eta: 7 days, 20:52:24  time: 1.2858  data_time: 0.0057  memory: 9845  loss: 0.0049  grad_norm: 0.1492
05/10 07:12:16 - mmengine - INFO - Iter(train) [ 17210/480000]  lr: 1.9998e-04  eta: 7 days, 20:52:15  time: 1.4918  data_time: 0.0059  memory: 9841  loss: 0.0068  grad_norm: 0.1492
05/10 07:12:29 - mmengine - INFO - Iter(train) [ 17220/480000]  lr: 1.9998e-04  eta: 7 days, 20:51:12  time: 1.2898  data_time: 0.0058  memory: 9845  loss: 0.0045  grad_norm: 0.1470
05/10 07:12:42 - mmengine - INFO - Iter(train) [ 17230/480000]  lr: 1.9998e-04  eta: 7 days, 20:50:11  time: 1.2957  data_time: 0.0058  memory: 9844  loss: 0.0080  grad_norm: 0.1470
05/10 07:12:56 - mmengine - INFO - Iter(train) [ 17240/480000]  lr: 1.9998e-04  eta: 7 days, 20:50:01  time: 1.4858  data_time: 0.0060  memory: 9844  loss: 0.0055  grad_norm: 0.1512
05/10 07:13:09 - mmengine - INFO - Iter(train) [ 17250/480000]  lr: 1.9998e-04  eta: 7 days, 20:48:52  time: 1.2661  data_time: 0.0056  memory: 9841  loss: 0.0065  grad_norm: 0.1514
05/10 07:13:24 - mmengine - INFO - Iter(train) [ 17260/480000]  lr: 1.9998e-04  eta: 7 days, 20:48:38  time: 1.4734  data_time: 0.0060  memory: 9844  loss: 0.0099  grad_norm: 0.1514
05/10 07:13:36 - mmengine - INFO - Iter(train) [ 17270/480000]  lr: 1.9998e-04  eta: 7 days, 20:47:29  time: 1.2659  data_time: 0.0058  memory: 9845  loss: 0.0078  grad_norm: 0.1526
05/10 07:13:48 - mmengine - INFO - Iter(train) [ 17280/480000]  lr: 1.9998e-04  eta: 7 days, 20:45:57  time: 1.1773  data_time: 0.0056  memory: 9845  loss: 0.0071  grad_norm: 0.1557
05/10 07:14:06 - mmengine - INFO - Iter(train) [ 17290/480000]  lr: 1.9998e-04  eta: 7 days, 20:46:54  time: 1.7367  data_time: 0.2061  memory: 9842  loss: 0.0040  grad_norm: 0.1557
05/10 07:14:18 - mmengine - INFO - Iter(train) [ 17300/480000]  lr: 1.9998e-04  eta: 7 days, 20:45:46  time: 1.2717  data_time: 0.0056  memory: 9845  loss: 0.0049  grad_norm: 0.1580
05/10 07:14:33 - mmengine - INFO - Iter(train) [ 17310/480000]  lr: 1.9998e-04  eta: 7 days, 20:45:42  time: 1.5090  data_time: 0.0059  memory: 9848  loss: 0.0050  grad_norm: 0.1580
05/10 07:14:46 - mmengine - INFO - Iter(train) [ 17320/480000]  lr: 1.9998e-04  eta: 7 days, 20:44:38  time: 1.2810  data_time: 0.0059  memory: 9846  loss: 0.0052  grad_norm: 0.1625
05/10 07:14:59 - mmengine - INFO - Iter(train) [ 17330/480000]  lr: 1.9998e-04  eta: 7 days, 20:43:27  time: 1.2606  data_time: 0.0057  memory: 9843  loss: 0.0054  grad_norm: 0.1667
05/10 07:15:14 - mmengine - INFO - Iter(train) [ 17340/480000]  lr: 1.9998e-04  eta: 7 days, 20:43:29  time: 1.5312  data_time: 0.0059  memory: 9847  loss: 0.0049  grad_norm: 0.1667
05/10 07:15:27 - mmengine - INFO - Iter(train) [ 17350/480000]  lr: 1.9998e-04  eta: 7 days, 20:42:28  time: 1.2937  data_time: 0.0060  memory: 9845  loss: 0.0071  grad_norm: 0.1640
05/10 07:15:41 - mmengine - INFO - Iter(train) [ 17360/480000]  lr: 1.9998e-04  eta: 7 days, 20:42:04  time: 1.4327  data_time: 0.0058  memory: 9842  loss: 0.0062  grad_norm: 0.1675
05/10 07:15:54 - mmengine - INFO - Iter(train) [ 17370/480000]  lr: 1.9998e-04  eta: 7 days, 20:41:02  time: 1.2893  data_time: 0.0058  memory: 9842  loss: 0.0062  grad_norm: 0.1675
05/10 07:16:07 - mmengine - INFO - Iter(train) [ 17380/480000]  lr: 1.9998e-04  eta: 7 days, 20:40:05  time: 1.3119  data_time: 0.0058  memory: 9841  loss: 0.0058  grad_norm: 0.1668
05/10 07:16:22 - mmengine - INFO - Iter(train) [ 17390/480000]  lr: 1.9998e-04  eta: 7 days, 20:39:53  time: 1.4757  data_time: 0.0059  memory: 9843  loss: 0.0071  grad_norm: 0.1668
05/10 07:16:35 - mmengine - INFO - Iter(train) [ 17400/480000]  lr: 1.9998e-04  eta: 7 days, 20:38:50  time: 1.2900  data_time: 0.0058  memory: 9847  loss: 0.0040  grad_norm: 0.1655
05/10 07:16:50 - mmengine - INFO - Iter(train) [ 17410/480000]  lr: 1.9998e-04  eta: 7 days, 20:38:36  time: 1.4678  data_time: 0.0058  memory: 9847  loss: 0.0059  grad_norm: 0.1666
05/10 07:17:03 - mmengine - INFO - Iter(train) [ 17420/480000]  lr: 1.9998e-04  eta: 7 days, 20:37:37  time: 1.3039  data_time: 0.0058  memory: 9842  loss: 0.0063  grad_norm: 0.1666
05/10 07:17:16 - mmengine - INFO - Iter(train) [ 17430/480000]  lr: 1.9998e-04  eta: 7 days, 20:36:38  time: 1.3004  data_time: 0.0058  memory: 9845  loss: 0.0060  grad_norm: 0.1581
05/10 07:17:30 - mmengine - INFO - Iter(train) [ 17440/480000]  lr: 1.9998e-04  eta: 7 days, 20:36:05  time: 1.3961  data_time: 0.0057  memory: 9846  loss: 0.0084  grad_norm: 0.1581
05/10 07:17:45 - mmengine - INFO - Iter(train) [ 17450/480000]  lr: 1.9998e-04  eta: 7 days, 20:35:56  time: 1.4900  data_time: 0.2062  memory: 9839  loss: 0.0051  grad_norm: 0.1581
05/10 07:17:58 - mmengine - INFO - Iter(train) [ 17460/480000]  lr: 1.9998e-04  eta: 7 days, 20:34:55  time: 1.2926  data_time: 0.0058  memory: 9843  loss: 0.0056  grad_norm: 0.1577
05/10 07:18:13 - mmengine - INFO - Iter(train) [ 17470/480000]  lr: 1.9998e-04  eta: 7 days, 20:35:07  time: 1.5684  data_time: 0.0059  memory: 9846  loss: 0.0047  grad_norm: 0.1577
05/10 07:18:26 - mmengine - INFO - Iter(train) [ 17480/480000]  lr: 1.9998e-04  eta: 7 days, 20:34:09  time: 1.3054  data_time: 0.0059  memory: 9845  loss: 0.0055  grad_norm: 0.1571
05/10 07:18:39 - mmengine - INFO - Iter(train) [ 17490/480000]  lr: 1.9998e-04  eta: 7 days, 20:33:07  time: 1.2903  data_time: 0.0059  memory: 9844  loss: 0.0034  grad_norm: 0.1558
05/10 07:18:54 - mmengine - INFO - Iter(train) [ 17500/480000]  lr: 1.9998e-04  eta: 7 days, 20:32:50  time: 1.4566  data_time: 0.0058  memory: 9842  loss: 0.0046  grad_norm: 0.1558
05/10 07:18:54 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 07:18:58 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。首先，你要知道，感情是需要双方经营的，不应该只由一种行为来决定。每个人的感情都是独特的，不应该被别人的决定影响到。你的心情现在怎么样呢？需要聊聊天，分散一下注意力吗？💖<|im_end|>

05/10 07:19:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷🏞️<|im_end|>

05/10 07:19:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 07:19:10 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，女方取关赶紧把男方也拉黑！不过别太往心里去，这种人归根结底还是得靠自己实力抢夺恋爱资源！别让她们影响到你的生活，保持心态，你的最美穿搭图在不久的将来一定能成为爆款！👗👀<|im_end|>

05/10 07:19:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯，如果有需要，也可以咨询医生哦。🌸<|im_end|>

05/10 07:19:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？🧼 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！🙄<|im_end|>

05/10 07:19:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，下次咱们换个方式，就像《哈利·波特》里隐形的火车，一出来就是一片漆黑，然后自己摸索回去。坚持就是胜利，别让这点小事影响了你的心情哦~ 🌸<|im_end|>

05/10 07:19:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的语音矩阵挺长时间的，确实需要稍微注意一下行事历哦。你可以先点个赞或者评论一下，表达一下你的感受或者想法，有时候直接的沟通能更好理解对方的需求呢。💖 如果实在忙不过来，也可以跟领导沟通一下，看看有没有其他方式可以解决这个问题。🌸<|im_end|>

05/10 07:19:32 - mmengine - INFO - Saving checkpoint at 17500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 07:19:45 - mmengine - INFO - Iter(train) [ 17510/480000]  lr: 1.9998e-04  eta: 7 days, 20:48:45  time: 5.1406  data_time: 3.8642  memory: 9841  loss: 0.0059  grad_norm: 0.1536
05/10 07:20:00 - mmengine - INFO - Iter(train) [ 17520/480000]  lr: 1.9998e-04  eta: 7 days, 20:48:31  time: 1.4718  data_time: 0.0057  memory: 9842  loss: 0.0068  grad_norm: 0.1504
05/10 07:20:13 - mmengine - INFO - Iter(train) [ 17530/480000]  lr: 1.9998e-04  eta: 7 days, 20:47:32  time: 1.3020  data_time: 0.0057  memory: 9842  loss: 0.0048  grad_norm: 0.1504
05/10 07:20:28 - mmengine - INFO - Iter(train) [ 17540/480000]  lr: 1.9998e-04  eta: 7 days, 20:47:18  time: 1.4736  data_time: 0.0058  memory: 9843  loss: 0.0064  grad_norm: 0.1507
05/10 07:20:40 - mmengine - INFO - Iter(train) [ 17550/480000]  lr: 1.9998e-04  eta: 7 days, 20:46:15  time: 1.2852  data_time: 0.0058  memory: 9845  loss: 0.0047  grad_norm: 0.1507
05/10 07:20:53 - mmengine - INFO - Iter(train) [ 17560/480000]  lr: 1.9998e-04  eta: 7 days, 20:45:13  time: 1.2885  data_time: 0.0058  memory: 9841  loss: 0.0064  grad_norm: 0.1462
05/10 07:21:08 - mmengine - INFO - Iter(train) [ 17570/480000]  lr: 1.9998e-04  eta: 7 days, 20:45:01  time: 1.4796  data_time: 0.0058  memory: 9840  loss: 0.0059  grad_norm: 0.1465
05/10 07:21:21 - mmengine - INFO - Iter(train) [ 17580/480000]  lr: 1.9998e-04  eta: 7 days, 20:44:01  time: 1.2996  data_time: 0.0058  memory: 9841  loss: 0.0048  grad_norm: 0.1465
05/10 07:21:36 - mmengine - INFO - Iter(train) [ 17590/480000]  lr: 1.9998e-04  eta: 7 days, 20:43:43  time: 1.4559  data_time: 0.0058  memory: 9842  loss: 0.0064  grad_norm: 0.1484
05/10 07:21:48 - mmengine - INFO - Iter(train) [ 17600/480000]  lr: 1.9998e-04  eta: 7 days, 20:42:22  time: 1.2162  data_time: 0.0058  memory: 9842  loss: 0.0052  grad_norm: 0.1459
05/10 07:22:03 - mmengine - INFO - Iter(train) [ 17610/480000]  lr: 1.9998e-04  eta: 7 days, 20:42:21  time: 1.5221  data_time: 0.2060  memory: 9842  loss: 0.0036  grad_norm: 0.1459
05/10 07:22:18 - mmengine - INFO - Iter(train) [ 17620/480000]  lr: 1.9998e-04  eta: 7 days, 20:42:11  time: 1.4858  data_time: 0.0059  memory: 9843  loss: 0.0033  grad_norm: 0.1439
05/10 07:22:31 - mmengine - INFO - Iter(train) [ 17630/480000]  lr: 1.9998e-04  eta: 7 days, 20:41:09  time: 1.2890  data_time: 0.0058  memory: 9842  loss: 0.0041  grad_norm: 0.1439
05/10 07:22:46 - mmengine - INFO - Iter(train) [ 17640/480000]  lr: 1.9998e-04  eta: 7 days, 20:40:54  time: 1.4678  data_time: 0.0058  memory: 9841  loss: 0.0044  grad_norm: 0.1426
05/10 07:22:59 - mmengine - INFO - Iter(train) [ 17650/480000]  lr: 1.9998e-04  eta: 7 days, 20:39:54  time: 1.2981  data_time: 0.0059  memory: 9841  loss: 0.0055  grad_norm: 0.1365
05/10 07:23:12 - mmengine - INFO - Iter(train) [ 17660/480000]  lr: 1.9998e-04  eta: 7 days, 20:38:55  time: 1.2987  data_time: 0.0059  memory: 9844  loss: 0.0049  grad_norm: 0.1365
05/10 07:23:26 - mmengine - INFO - Iter(train) [ 17670/480000]  lr: 1.9998e-04  eta: 7 days, 20:38:39  time: 1.4640  data_time: 0.0058  memory: 9844  loss: 0.0062  grad_norm: 0.1395
05/10 07:23:39 - mmengine - INFO - Iter(train) [ 17680/480000]  lr: 1.9998e-04  eta: 7 days, 20:37:35  time: 1.2794  data_time: 0.0058  memory: 9842  loss: 0.0044  grad_norm: 0.1388
05/10 07:23:53 - mmengine - INFO - Iter(train) [ 17690/480000]  lr: 1.9998e-04  eta: 7 days, 20:37:15  time: 1.4496  data_time: 0.0057  memory: 9844  loss: 0.0046  grad_norm: 0.1388
05/10 07:24:06 - mmengine - INFO - Iter(train) [ 17700/480000]  lr: 1.9998e-04  eta: 7 days, 20:36:15  time: 1.2937  data_time: 0.0057  memory: 9844  loss: 0.0045  grad_norm: 0.1351
05/10 07:24:19 - mmengine - INFO - Iter(train) [ 17710/480000]  lr: 1.9998e-04  eta: 7 days, 20:35:19  time: 1.3121  data_time: 0.0058  memory: 9838  loss: 0.0069  grad_norm: 0.1351
05/10 07:24:34 - mmengine - INFO - Iter(train) [ 17720/480000]  lr: 1.9997e-04  eta: 7 days, 20:35:10  time: 1.4879  data_time: 0.0059  memory: 9841  loss: 0.0073  grad_norm: 0.1360
05/10 07:24:47 - mmengine - INFO - Iter(train) [ 17730/480000]  lr: 1.9997e-04  eta: 7 days, 20:34:07  time: 1.2863  data_time: 0.0058  memory: 9843  loss: 0.0059  grad_norm: 0.1355
05/10 07:25:02 - mmengine - INFO - Iter(train) [ 17740/480000]  lr: 1.9997e-04  eta: 7 days, 20:33:53  time: 1.4701  data_time: 0.0058  memory: 9844  loss: 0.0052  grad_norm: 0.1355
05/10 07:25:15 - mmengine - INFO - Iter(train) [ 17750/480000]  lr: 1.9997e-04  eta: 7 days, 20:32:54  time: 1.2972  data_time: 0.0061  memory: 9842  loss: 0.0068  grad_norm: 0.1339
05/10 07:25:27 - mmengine - INFO - Iter(train) [ 17760/480000]  lr: 1.9997e-04  eta: 7 days, 20:31:30  time: 1.2024  data_time: 0.0057  memory: 9842  loss: 0.0055  grad_norm: 0.1323
05/10 07:25:44 - mmengine - INFO - Iter(train) [ 17770/480000]  lr: 1.9997e-04  eta: 7 days, 20:32:14  time: 1.6947  data_time: 0.2060  memory: 9840  loss: 0.0037  grad_norm: 0.1323
05/10 07:25:57 - mmengine - INFO - Iter(train) [ 17780/480000]  lr: 1.9997e-04  eta: 7 days, 20:31:11  time: 1.2834  data_time: 0.0057  memory: 9841  loss: 0.0042  grad_norm: 0.1311
05/10 07:26:12 - mmengine - INFO - Iter(train) [ 17790/480000]  lr: 1.9997e-04  eta: 7 days, 20:31:01  time: 1.4840  data_time: 0.0057  memory: 9841  loss: 0.0052  grad_norm: 0.1311
05/10 07:26:24 - mmengine - INFO - Iter(train) [ 17800/480000]  lr: 1.9997e-04  eta: 7 days, 20:29:56  time: 1.2770  data_time: 0.0058  memory: 9844  loss: 0.0041  grad_norm: 0.1299
05/10 07:26:37 - mmengine - INFO - Iter(train) [ 17810/480000]  lr: 1.9997e-04  eta: 7 days, 20:28:52  time: 1.2753  data_time: 0.0059  memory: 9846  loss: 0.0057  grad_norm: 0.1347
05/10 07:26:52 - mmengine - INFO - Iter(train) [ 17820/480000]  lr: 1.9997e-04  eta: 7 days, 20:28:45  time: 1.4977  data_time: 0.0059  memory: 9842  loss: 0.0037  grad_norm: 0.1347
05/10 07:27:05 - mmengine - INFO - Iter(train) [ 17830/480000]  lr: 1.9997e-04  eta: 7 days, 20:27:43  time: 1.2889  data_time: 0.0058  memory: 9842  loss: 0.0044  grad_norm: 0.1300
05/10 07:27:20 - mmengine - INFO - Iter(train) [ 17840/480000]  lr: 1.9997e-04  eta: 7 days, 20:27:36  time: 1.4972  data_time: 0.0058  memory: 9844  loss: 0.0037  grad_norm: 0.1248
05/10 07:27:33 - mmengine - INFO - Iter(train) [ 17850/480000]  lr: 1.9997e-04  eta: 7 days, 20:26:30  time: 1.2698  data_time: 0.0057  memory: 9843  loss: 0.0040  grad_norm: 0.1248
05/10 07:27:45 - mmengine - INFO - Iter(train) [ 17860/480000]  lr: 1.9997e-04  eta: 7 days, 20:25:20  time: 1.2526  data_time: 0.0057  memory: 9844  loss: 0.0050  grad_norm: 0.1255
05/10 07:28:00 - mmengine - INFO - Iter(train) [ 17870/480000]  lr: 1.9997e-04  eta: 7 days, 20:25:17  time: 1.5123  data_time: 0.0058  memory: 9842  loss: 0.0037  grad_norm: 0.1255
05/10 07:28:13 - mmengine - INFO - Iter(train) [ 17880/480000]  lr: 1.9997e-04  eta: 7 days, 20:24:15  time: 1.2850  data_time: 0.0057  memory: 9839  loss: 0.0052  grad_norm: 0.1280
05/10 07:28:28 - mmengine - INFO - Iter(train) [ 17890/480000]  lr: 1.9997e-04  eta: 7 days, 20:24:07  time: 1.4958  data_time: 0.0058  memory: 9841  loss: 0.0055  grad_norm: 0.1253
05/10 07:28:41 - mmengine - INFO - Iter(train) [ 17900/480000]  lr: 1.9997e-04  eta: 7 days, 20:23:01  time: 1.2690  data_time: 0.0057  memory: 9841  loss: 0.0047  grad_norm: 0.1253
05/10 07:28:53 - mmengine - INFO - Iter(train) [ 17910/480000]  lr: 1.9997e-04  eta: 7 days, 20:21:54  time: 1.2648  data_time: 0.0057  memory: 9840  loss: 0.0071  grad_norm: 0.1215
05/10 07:29:08 - mmengine - INFO - Iter(train) [ 17920/480000]  lr: 1.9997e-04  eta: 7 days, 20:21:45  time: 1.4865  data_time: 0.0058  memory: 9838  loss: 0.0059  grad_norm: 0.1247
05/10 07:29:23 - mmengine - INFO - Iter(train) [ 17930/480000]  lr: 1.9997e-04  eta: 7 days, 20:21:27  time: 1.4573  data_time: 0.2058  memory: 9844  loss: 0.0044  grad_norm: 0.1247
05/10 07:29:38 - mmengine - INFO - Iter(train) [ 17940/480000]  lr: 1.9997e-04  eta: 7 days, 20:21:20  time: 1.4954  data_time: 0.0057  memory: 9846  loss: 0.0051  grad_norm: 0.1230
05/10 07:29:50 - mmengine - INFO - Iter(train) [ 17950/480000]  lr: 1.9997e-04  eta: 7 days, 20:20:10  time: 1.2536  data_time: 0.0059  memory: 9841  loss: 0.0047  grad_norm: 0.1230
05/10 07:30:03 - mmengine - INFO - Iter(train) [ 17960/480000]  lr: 1.9997e-04  eta: 7 days, 20:19:02  time: 1.2600  data_time: 0.0056  memory: 9846  loss: 0.0036  grad_norm: 0.1271
05/10 07:30:17 - mmengine - INFO - Iter(train) [ 17970/480000]  lr: 1.9997e-04  eta: 7 days, 20:18:20  time: 1.3619  data_time: 0.0061  memory: 9844  loss: 0.0050  grad_norm: 0.1256
05/10 07:30:33 - mmengine - INFO - Iter(train) [ 17980/480000]  lr: 1.9997e-04  eta: 7 days, 20:18:44  time: 1.6173  data_time: 0.0060  memory: 9843  loss: 0.0052  grad_norm: 0.1256
05/10 07:30:46 - mmengine - INFO - Iter(train) [ 17990/480000]  lr: 1.9997e-04  eta: 7 days, 20:17:54  time: 1.3283  data_time: 0.0060  memory: 9844  loss: 0.0047  grad_norm: 0.1297
05/10 07:31:00 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 07:31:00 - mmengine - INFO - Iter(train) [ 18000/480000]  lr: 1.9997e-04  eta: 7 days, 20:17:16  time: 1.3761  data_time: 0.0055  memory: 9845  loss: 0.0046  grad_norm: 0.1365
05/10 07:31:00 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 07:31:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。感情的事情有时候确实挺复杂的。你觉得心里不舒服是很正常的。你可以和你的男朋友好好沟通一下，彼此的理解和尊重很重要哦。💖 如果你需要倾诉或者寻求建议，我在这里随时听你说。🌸<|im_end|>

05/10 07:31:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷🌊<|im_end|>

05/10 07:31:10 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 07:31:14 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个“闺蜜抢购”现场直播。不过别太往心里去，至少你还能在朋友圈@我，让我来帮你分析分析这波操作大作战的胜利点在哪儿。😎<|im_end|>

05/10 07:31:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯，如果有需要，也可以咨询医生哦。🌸<|im_end|>

05/10 07:31:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遭遇简直比剧本杀还剧本啊！下次记得提前考察玩家背景，以免再遇到这种行为艺术大师。不过别太往心里去，剧本杀就是大家一起推理的游戏，分享一下心情吧。<|im_end|>

05/10 07:31:28 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，下次咱们换个方式，就像《哈利·波特》里隐形的火车，一出来就吓跑了一大群苍蝇！🚂<|im_end|>

05/10 07:31:36 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的指示很重要，你可能需要更正式地和领导沟通一下你的感受，或者可以提出一些解决方案，比如提前下班或者找个其他方式沟通。毕竟，良好的沟通能够帮助工作更加顺利哦。如果你需要倾诉或者寻求建议，我在这里随时听你说呢。💖<|im_end|>

05/10 07:31:36 - mmengine - INFO - Saving checkpoint at 18000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 07:31:49 - mmengine - INFO - Iter(train) [ 18010/480000]  lr: 1.9997e-04  eta: 7 days, 20:31:39  time: 4.8898  data_time: 3.6484  memory: 9846  loss: 0.0043  grad_norm: 0.1365
05/10 07:32:01 - mmengine - INFO - Iter(train) [ 18020/480000]  lr: 1.9997e-04  eta: 7 days, 20:30:36  time: 1.2788  data_time: 0.0058  memory: 9846  loss: 0.0046  grad_norm: 0.1369
05/10 07:32:17 - mmengine - INFO - Iter(train) [ 18030/480000]  lr: 1.9997e-04  eta: 7 days, 20:30:45  time: 1.5620  data_time: 0.0060  memory: 9845  loss: 0.0038  grad_norm: 0.1369
05/10 07:32:29 - mmengine - INFO - Iter(train) [ 18040/480000]  lr: 1.9997e-04  eta: 7 days, 20:29:27  time: 1.2227  data_time: 0.0056  memory: 9844  loss: 0.0053  grad_norm: 0.1324
05/10 07:32:44 - mmengine - INFO - Iter(train) [ 18050/480000]  lr: 1.9997e-04  eta: 7 days, 20:29:21  time: 1.5026  data_time: 0.0058  memory: 9844  loss: 0.0060  grad_norm: 0.1308
05/10 07:32:57 - mmengine - INFO - Iter(train) [ 18060/480000]  lr: 1.9997e-04  eta: 7 days, 20:28:19  time: 1.2825  data_time: 0.0058  memory: 9847  loss: 0.0054  grad_norm: 0.1308
05/10 07:33:10 - mmengine - INFO - Iter(train) [ 18070/480000]  lr: 1.9997e-04  eta: 7 days, 20:27:08  time: 1.2502  data_time: 0.0057  memory: 9847  loss: 0.0057  grad_norm: 0.1368
05/10 07:33:25 - mmengine - INFO - Iter(train) [ 18080/480000]  lr: 1.9997e-04  eta: 7 days, 20:27:00  time: 1.4933  data_time: 0.0058  memory: 9841  loss: 0.0058  grad_norm: 0.1348
05/10 07:33:39 - mmengine - INFO - Iter(train) [ 18090/480000]  lr: 1.9997e-04  eta: 7 days, 20:26:33  time: 1.4207  data_time: 0.2057  memory: 9843  loss: 0.0046  grad_norm: 0.1348
05/10 07:33:54 - mmengine - INFO - Iter(train) [ 18100/480000]  lr: 1.9997e-04  eta: 7 days, 20:26:30  time: 1.5173  data_time: 0.0059  memory: 9843  loss: 0.0060  grad_norm: 0.1458
05/10 07:34:07 - mmengine - INFO - Iter(train) [ 18110/480000]  lr: 1.9997e-04  eta: 7 days, 20:25:28  time: 1.2830  data_time: 0.0058  memory: 9842  loss: 0.0052  grad_norm: 0.1458
05/10 07:34:19 - mmengine - INFO - Iter(train) [ 18120/480000]  lr: 1.9997e-04  eta: 7 days, 20:24:21  time: 1.2611  data_time: 0.0057  memory: 9843  loss: 0.0030  grad_norm: 0.1386
05/10 07:34:35 - mmengine - INFO - Iter(train) [ 18130/480000]  lr: 1.9997e-04  eta: 7 days, 20:24:27  time: 1.5504  data_time: 0.0060  memory: 9844  loss: 0.0030  grad_norm: 0.1356
05/10 07:34:47 - mmengine - INFO - Iter(train) [ 18140/480000]  lr: 1.9997e-04  eta: 7 days, 20:23:09  time: 1.2218  data_time: 0.0055  memory: 9843  loss: 0.0049  grad_norm: 0.1356
05/10 07:35:02 - mmengine - INFO - Iter(train) [ 18150/480000]  lr: 1.9997e-04  eta: 7 days, 20:23:11  time: 1.5314  data_time: 0.0058  memory: 9842  loss: 0.0068  grad_norm: 0.1418
05/10 07:35:15 - mmengine - INFO - Iter(train) [ 18160/480000]  lr: 1.9997e-04  eta: 7 days, 20:22:12  time: 1.2966  data_time: 0.0058  memory: 9841  loss: 0.0055  grad_norm: 0.1386
05/10 07:35:28 - mmengine - INFO - Iter(train) [ 18170/480000]  lr: 1.9997e-04  eta: 7 days, 20:20:59  time: 1.2380  data_time: 0.0056  memory: 9842  loss: 0.0052  grad_norm: 0.1386
05/10 07:35:43 - mmengine - INFO - Iter(train) [ 18180/480000]  lr: 1.9997e-04  eta: 7 days, 20:20:54  time: 1.5051  data_time: 0.0059  memory: 9842  loss: 0.0041  grad_norm: 0.1359
05/10 07:35:55 - mmengine - INFO - Iter(train) [ 18190/480000]  lr: 1.9997e-04  eta: 7 days, 20:19:37  time: 1.2216  data_time: 0.0055  memory: 9841  loss: 0.0049  grad_norm: 0.1359
05/10 07:36:11 - mmengine - INFO - Iter(train) [ 18200/480000]  lr: 1.9997e-04  eta: 7 days, 20:19:41  time: 1.5451  data_time: 0.0058  memory: 9844  loss: 0.0042  grad_norm: 0.1383
05/10 07:36:24 - mmengine - INFO - Iter(train) [ 18210/480000]  lr: 1.9997e-04  eta: 7 days, 20:18:45  time: 1.3030  data_time: 0.0058  memory: 9844  loss: 0.0041  grad_norm: 0.1386
05/10 07:36:36 - mmengine - INFO - Iter(train) [ 18220/480000]  lr: 1.9997e-04  eta: 7 days, 20:17:32  time: 1.2375  data_time: 0.0057  memory: 9841  loss: 0.0050  grad_norm: 0.1386
05/10 07:36:51 - mmengine - INFO - Iter(train) [ 18230/480000]  lr: 1.9997e-04  eta: 7 days, 20:17:34  time: 1.5326  data_time: 0.0059  memory: 9843  loss: 0.0039  grad_norm: 0.1314
05/10 07:37:03 - mmengine - INFO - Iter(train) [ 18240/480000]  lr: 1.9997e-04  eta: 7 days, 20:16:03  time: 1.1695  data_time: 0.0057  memory: 9843  loss: 0.0059  grad_norm: 0.1296
05/10 07:37:21 - mmengine - INFO - Iter(train) [ 18250/480000]  lr: 1.9997e-04  eta: 7 days, 20:17:04  time: 1.7644  data_time: 0.2060  memory: 9840  loss: 0.0044  grad_norm: 0.1296
05/10 07:37:33 - mmengine - INFO - Iter(train) [ 18260/480000]  lr: 1.9997e-04  eta: 7 days, 20:15:52  time: 1.2442  data_time: 0.0057  memory: 9842  loss: 0.0034  grad_norm: 0.1218
05/10 07:37:45 - mmengine - INFO - Iter(train) [ 18270/480000]  lr: 1.9997e-04  eta: 7 days, 20:14:38  time: 1.2310  data_time: 0.0057  memory: 9842  loss: 0.0049  grad_norm: 0.1218
05/10 07:38:01 - mmengine - INFO - Iter(train) [ 18280/480000]  lr: 1.9997e-04  eta: 7 days, 20:14:38  time: 1.5263  data_time: 0.0058  memory: 9842  loss: 0.0033  grad_norm: 0.1228
05/10 07:38:13 - mmengine - INFO - Iter(train) [ 18290/480000]  lr: 1.9997e-04  eta: 7 days, 20:13:36  time: 1.2818  data_time: 0.0059  memory: 9839  loss: 0.0042  grad_norm: 0.1243
05/10 07:38:28 - mmengine - INFO - Iter(train) [ 18300/480000]  lr: 1.9997e-04  eta: 7 days, 20:13:31  time: 1.5033  data_time: 0.0057  memory: 9840  loss: 0.0046  grad_norm: 0.1243
05/10 07:38:41 - mmengine - INFO - Iter(train) [ 18310/480000]  lr: 1.9997e-04  eta: 7 days, 20:12:25  time: 1.2647  data_time: 0.0057  memory: 9843  loss: 0.0036  grad_norm: 0.1151
05/10 07:38:54 - mmengine - INFO - Iter(train) [ 18320/480000]  lr: 1.9997e-04  eta: 7 days, 20:11:19  time: 1.2631  data_time: 0.0058  memory: 9843  loss: 0.0049  grad_norm: 0.1142
05/10 07:39:09 - mmengine - INFO - Iter(train) [ 18330/480000]  lr: 1.9996e-04  eta: 7 days, 20:11:20  time: 1.5294  data_time: 0.0059  memory: 9843  loss: 0.0059  grad_norm: 0.1142
05/10 07:39:22 - mmengine - INFO - Iter(train) [ 18340/480000]  lr: 1.9996e-04  eta: 7 days, 20:10:11  time: 1.2515  data_time: 0.0056  memory: 9841  loss: 0.0047  grad_norm: 0.1175
05/10 07:39:34 - mmengine - INFO - Iter(train) [ 18350/480000]  lr: 1.9996e-04  eta: 7 days, 20:09:05  time: 1.2667  data_time: 0.0058  memory: 9842  loss: 0.0052  grad_norm: 0.1175
05/10 07:39:49 - mmengine - INFO - Iter(train) [ 18360/480000]  lr: 1.9996e-04  eta: 7 days, 20:09:04  time: 1.5187  data_time: 0.0058  memory: 9844  loss: 0.0046  grad_norm: 0.1166
05/10 07:40:02 - mmengine - INFO - Iter(train) [ 18370/480000]  lr: 1.9996e-04  eta: 7 days, 20:08:06  time: 1.2967  data_time: 0.0057  memory: 9844  loss: 0.0043  grad_norm: 0.1180
05/10 07:40:17 - mmengine - INFO - Iter(train) [ 18380/480000]  lr: 1.9996e-04  eta: 7 days, 20:07:57  time: 1.4882  data_time: 0.0058  memory: 9841  loss: 0.0051  grad_norm: 0.1180
05/10 07:40:30 - mmengine - INFO - Iter(train) [ 18390/480000]  lr: 1.9996e-04  eta: 7 days, 20:06:55  time: 1.2794  data_time: 0.0056  memory: 9847  loss: 0.0060  grad_norm: 0.1218
05/10 07:40:42 - mmengine - INFO - Iter(train) [ 18400/480000]  lr: 1.9996e-04  eta: 7 days, 20:05:36  time: 1.2097  data_time: 0.0057  memory: 9848  loss: 0.0065  grad_norm: 0.1253
05/10 07:40:59 - mmengine - INFO - Iter(train) [ 18410/480000]  lr: 1.9996e-04  eta: 7 days, 20:06:25  time: 1.7216  data_time: 0.4317  memory: 9844  loss: 0.0036  grad_norm: 0.1253
05/10 07:41:12 - mmengine - INFO - Iter(train) [ 18420/480000]  lr: 1.9996e-04  eta: 7 days, 20:05:22  time: 1.2744  data_time: 0.0057  memory: 9845  loss: 0.0037  grad_norm: 0.1232
05/10 07:41:27 - mmengine - INFO - Iter(train) [ 18430/480000]  lr: 1.9996e-04  eta: 7 days, 20:05:15  time: 1.4957  data_time: 0.0057  memory: 9844  loss: 0.0034  grad_norm: 0.1232
05/10 07:41:40 - mmengine - INFO - Iter(train) [ 18440/480000]  lr: 1.9996e-04  eta: 7 days, 20:04:07  time: 1.2559  data_time: 0.0056  memory: 9844  loss: 0.0039  grad_norm: 0.1228
05/10 07:41:52 - mmengine - INFO - Iter(train) [ 18450/480000]  lr: 1.9996e-04  eta: 7 days, 20:03:02  time: 1.2661  data_time: 0.0057  memory: 9844  loss: 0.0037  grad_norm: 0.1212
05/10 07:42:07 - mmengine - INFO - Iter(train) [ 18460/480000]  lr: 1.9996e-04  eta: 7 days, 20:03:00  time: 1.5165  data_time: 0.0056  memory: 9842  loss: 0.0040  grad_norm: 0.1212
05/10 07:42:20 - mmengine - INFO - Iter(train) [ 18470/480000]  lr: 1.9996e-04  eta: 7 days, 20:02:00  time: 1.2840  data_time: 0.0057  memory: 9843  loss: 0.0038  grad_norm: 0.1159
05/10 07:42:35 - mmengine - INFO - Iter(train) [ 18480/480000]  lr: 1.9996e-04  eta: 7 days, 20:01:52  time: 1.4953  data_time: 0.0056  memory: 9845  loss: 0.0037  grad_norm: 0.1120
05/10 07:42:48 - mmengine - INFO - Iter(train) [ 18490/480000]  lr: 1.9996e-04  eta: 7 days, 20:00:48  time: 1.2697  data_time: 0.0056  memory: 9841  loss: 0.0043  grad_norm: 0.1120
05/10 07:43:01 - mmengine - INFO - Iter(train) [ 18500/480000]  lr: 1.9996e-04  eta: 7 days, 19:59:46  time: 1.2749  data_time: 0.0057  memory: 9843  loss: 0.0051  grad_norm: 0.1128
05/10 07:43:01 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 07:43:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。首先要做的当然是和你的男朋友沟通一下你的感受，告诉他你看到你在他心中的地位受到了质疑。沟通是解决问题的关键，也许他并不是真的精神出轨，只是有些误会需要解开。你觉得呢？💖<|im_end|>

05/10 07:43:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来有点不舒服呢。洗牙后可能会有一些暂时的不适，这是因为牙齿表面的牙石被清理掉，牙龈会有点敏感。你可以试试使用温水刷牙，避免吃太冷或太热的食物，慢慢的情况就会改善的。如果还是很不舒服，最好再去医院检查一下，确保没有其他问题哦。💖<|im_end|>

05/10 07:43:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 07:43:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你觉得他们之间的互动让你感到不舒服吗？💖我们可以一起想想怎么处理这件事，或者聊些别的事情分散一下注意力。<|im_end|>

05/10 07:43:24 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。可以适量吃一些鱼、肉和鸡蛋，以及水果和蔬菜，这样既能保持健康，又能避免吃太多不利于健康的食物。💖你喜欢清淡的食物吗？如果需要一些健康的食谱建议，我可以帮你哦。<|im_end|>

05/10 07:43:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 07:43:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“我虽败犹荣”呢。下次记得，画眼线前先selfie一下，看看是不是能成为朋友圈的网红风景。👀<|im_end|>

05/10 07:43:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见哦。领导的指示很重要，你可以先仔细阅读一遍，或者用一些简单的方式向同事或者领导说明你的感受。毕竟，理解领导的意图是工作的重要部分。如果你需要帮忙想一想怎么表达，我在这里哦，随时可以向我寻求建议~💖<|im_end|>

05/10 07:43:41 - mmengine - INFO - Saving checkpoint at 18500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 07:43:55 - mmengine - INFO - Iter(train) [ 18510/480000]  lr: 1.9996e-04  eta: 7 days, 20:15:52  time: 5.3993  data_time: 4.1293  memory: 9843  loss: 0.0055  grad_norm: 0.1128
05/10 07:44:07 - mmengine - INFO - Iter(train) [ 18520/480000]  lr: 1.9996e-04  eta: 7 days, 20:14:50  time: 1.2807  data_time: 0.0058  memory: 9841  loss: 0.0071  grad_norm: 0.1126
05/10 07:44:23 - mmengine - INFO - Iter(train) [ 18530/480000]  lr: 1.9996e-04  eta: 7 days, 20:14:45  time: 1.5079  data_time: 0.0060  memory: 9842  loss: 0.0045  grad_norm: 0.1147
05/10 07:44:35 - mmengine - INFO - Iter(train) [ 18540/480000]  lr: 1.9996e-04  eta: 7 days, 20:13:39  time: 1.2631  data_time: 0.0058  memory: 9843  loss: 0.0053  grad_norm: 0.1147
05/10 07:44:50 - mmengine - INFO - Iter(train) [ 18550/480000]  lr: 1.9996e-04  eta: 7 days, 20:13:32  time: 1.4976  data_time: 0.0058  memory: 9844  loss: 0.0043  grad_norm: 0.1145
05/10 07:45:02 - mmengine - INFO - Iter(train) [ 18560/480000]  lr: 1.9996e-04  eta: 7 days, 20:12:15  time: 1.2174  data_time: 0.0057  memory: 9844  loss: 0.0060  grad_norm: 0.1120
05/10 07:45:17 - mmengine - INFO - Iter(train) [ 18570/480000]  lr: 1.9996e-04  eta: 7 days, 20:12:07  time: 1.4971  data_time: 0.2058  memory: 9846  loss: 0.0030  grad_norm: 0.1120
05/10 07:45:30 - mmengine - INFO - Iter(train) [ 18580/480000]  lr: 1.9996e-04  eta: 7 days, 20:11:03  time: 1.2691  data_time: 0.0057  memory: 9846  loss: 0.0046  grad_norm: 0.1126
05/10 07:45:42 - mmengine - INFO - Iter(train) [ 18590/480000]  lr: 1.9996e-04  eta: 7 days, 20:09:54  time: 1.2475  data_time: 0.0056  memory: 9845  loss: 0.0030  grad_norm: 0.1126
05/10 07:45:55 - mmengine - INFO - Iter(train) [ 18600/480000]  lr: 1.9996e-04  eta: 7 days, 20:08:55  time: 1.2893  data_time: 0.0057  memory: 9844  loss: 0.0054  grad_norm: 0.1135
05/10 07:46:14 - mmengine - INFO - Iter(train) [ 18610/480000]  lr: 1.9996e-04  eta: 7 days, 20:10:09  time: 1.8263  data_time: 0.0056  memory: 9845  loss: 0.0040  grad_norm: 0.1180
05/10 07:46:27 - mmengine - INFO - Iter(train) [ 18620/480000]  lr: 1.9996e-04  eta: 7 days, 20:09:09  time: 1.2867  data_time: 0.0058  memory: 9844  loss: 0.0052  grad_norm: 0.1180
05/10 07:46:39 - mmengine - INFO - Iter(train) [ 18630/480000]  lr: 1.9996e-04  eta: 7 days, 20:08:10  time: 1.2897  data_time: 0.0058  memory: 9846  loss: 0.0040  grad_norm: 0.1252
05/10 07:46:54 - mmengine - INFO - Iter(train) [ 18640/480000]  lr: 1.9996e-04  eta: 7 days, 20:08:03  time: 1.4959  data_time: 0.0059  memory: 9842  loss: 0.0034  grad_norm: 0.1265
05/10 07:47:08 - mmengine - INFO - Iter(train) [ 18650/480000]  lr: 1.9996e-04  eta: 7 days, 20:07:17  time: 1.3434  data_time: 0.0059  memory: 9842  loss: 0.0043  grad_norm: 0.1265
05/10 07:47:22 - mmengine - INFO - Iter(train) [ 18660/480000]  lr: 1.9996e-04  eta: 7 days, 20:06:47  time: 1.4069  data_time: 0.0058  memory: 9842  loss: 0.0045  grad_norm: 0.1285
05/10 07:47:34 - mmengine - INFO - Iter(train) [ 18670/480000]  lr: 1.9996e-04  eta: 7 days, 20:05:30  time: 1.2130  data_time: 0.0056  memory: 9843  loss: 0.0040  grad_norm: 0.1285
05/10 07:47:47 - mmengine - INFO - Iter(train) [ 18680/480000]  lr: 1.9996e-04  eta: 7 days, 20:04:23  time: 1.2589  data_time: 0.0056  memory: 9843  loss: 0.0057  grad_norm: 0.1261
05/10 07:48:03 - mmengine - INFO - Iter(train) [ 18690/480000]  lr: 1.9996e-04  eta: 7 days, 20:04:49  time: 1.6317  data_time: 0.0060  memory: 9842  loss: 0.0045  grad_norm: 0.1222
05/10 07:48:16 - mmengine - INFO - Iter(train) [ 18700/480000]  lr: 1.9996e-04  eta: 7 days, 20:03:55  time: 1.3072  data_time: 0.0058  memory: 9841  loss: 0.0048  grad_norm: 0.1222
05/10 07:48:30 - mmengine - INFO - Iter(train) [ 18710/480000]  lr: 1.9996e-04  eta: 7 days, 20:03:26  time: 1.4108  data_time: 0.0057  memory: 9842  loss: 0.0060  grad_norm: 0.1235
05/10 07:48:42 - mmengine - INFO - Iter(train) [ 18720/480000]  lr: 1.9996e-04  eta: 7 days, 20:02:05  time: 1.1966  data_time: 0.0055  memory: 9842  loss: 0.0047  grad_norm: 0.1242
05/10 07:48:57 - mmengine - INFO - Iter(train) [ 18730/480000]  lr: 1.9996e-04  eta: 7 days, 20:01:53  time: 1.4815  data_time: 0.2058  memory: 9843  loss: 0.0033  grad_norm: 0.1242
05/10 07:49:13 - mmengine - INFO - Iter(train) [ 18740/480000]  lr: 1.9996e-04  eta: 7 days, 20:02:03  time: 1.5648  data_time: 0.0060  memory: 9844  loss: 0.0046  grad_norm: 0.1238
05/10 07:49:25 - mmengine - INFO - Iter(train) [ 18750/480000]  lr: 1.9996e-04  eta: 7 days, 20:00:50  time: 1.2336  data_time: 0.0056  memory: 9840  loss: 0.0029  grad_norm: 0.1238
05/10 07:49:40 - mmengine - INFO - Iter(train) [ 18760/480000]  lr: 1.9996e-04  eta: 7 days, 20:00:40  time: 1.4857  data_time: 0.0055  memory: 9845  loss: 0.0037  grad_norm: 0.1227
05/10 07:49:52 - mmengine - INFO - Iter(train) [ 18770/480000]  lr: 1.9996e-04  eta: 7 days, 19:59:36  time: 1.2663  data_time: 0.0057  memory: 9845  loss: 0.0035  grad_norm: 0.1155
05/10 07:50:05 - mmengine - INFO - Iter(train) [ 18780/480000]  lr: 1.9996e-04  eta: 7 days, 19:58:35  time: 1.2774  data_time: 0.0057  memory: 9846  loss: 0.0049  grad_norm: 0.1155
05/10 07:50:20 - mmengine - INFO - Iter(train) [ 18790/480000]  lr: 1.9996e-04  eta: 7 days, 19:58:33  time: 1.5179  data_time: 0.0058  memory: 9845  loss: 0.0040  grad_norm: 0.1147
05/10 07:50:33 - mmengine - INFO - Iter(train) [ 18800/480000]  lr: 1.9996e-04  eta: 7 days, 19:57:27  time: 1.2577  data_time: 0.0057  memory: 9841  loss: 0.0038  grad_norm: 0.1158
05/10 07:50:46 - mmengine - INFO - Iter(train) [ 18810/480000]  lr: 1.9996e-04  eta: 7 days, 19:56:25  time: 1.2761  data_time: 0.0058  memory: 9840  loss: 0.0055  grad_norm: 0.1158
05/10 07:50:59 - mmengine - INFO - Iter(train) [ 18820/480000]  lr: 1.9996e-04  eta: 7 days, 19:55:38  time: 1.3364  data_time: 0.0059  memory: 9840  loss: 0.0037  grad_norm: 0.1143
05/10 07:51:12 - mmengine - INFO - Iter(train) [ 18830/480000]  lr: 1.9996e-04  eta: 7 days, 19:54:52  time: 1.3369  data_time: 0.0058  memory: 9840  loss: 0.0034  grad_norm: 0.1143
05/10 07:51:27 - mmengine - INFO - Iter(train) [ 18840/480000]  lr: 1.9996e-04  eta: 7 days, 19:54:39  time: 1.4728  data_time: 0.0068  memory: 9843  loss: 0.0039  grad_norm: 0.1156
05/10 07:51:41 - mmengine - INFO - Iter(train) [ 18850/480000]  lr: 1.9995e-04  eta: 7 days, 19:54:08  time: 1.4028  data_time: 0.0064  memory: 9845  loss: 0.0046  grad_norm: 0.1176
05/10 07:51:55 - mmengine - INFO - Iter(train) [ 18860/480000]  lr: 1.9995e-04  eta: 7 days, 19:53:27  time: 1.3583  data_time: 0.0062  memory: 9842  loss: 0.0056  grad_norm: 0.1176
05/10 07:52:10 - mmengine - INFO - Iter(train) [ 18870/480000]  lr: 1.9995e-04  eta: 7 days, 19:53:25  time: 1.5197  data_time: 0.0061  memory: 9842  loss: 0.0046  grad_norm: 0.1162
05/10 07:52:22 - mmengine - INFO - Iter(train) [ 18880/480000]  lr: 1.9995e-04  eta: 7 days, 19:52:06  time: 1.2022  data_time: 0.0056  memory: 9843  loss: 0.0057  grad_norm: 0.1164
05/10 07:52:39 - mmengine - INFO - Iter(train) [ 18890/480000]  lr: 1.9995e-04  eta: 7 days, 19:52:49  time: 1.7031  data_time: 0.2060  memory: 9841  loss: 0.0027  grad_norm: 0.1164
05/10 07:52:52 - mmengine - INFO - Iter(train) [ 18900/480000]  lr: 1.9995e-04  eta: 7 days, 19:51:51  time: 1.2899  data_time: 0.0058  memory: 9843  loss: 0.0039  grad_norm: 0.1130
05/10 07:53:05 - mmengine - INFO - Iter(train) [ 18910/480000]  lr: 1.9995e-04  eta: 7 days, 19:50:52  time: 1.2829  data_time: 0.0056  memory: 9845  loss: 0.0045  grad_norm: 0.1130
05/10 07:53:18 - mmengine - INFO - Iter(train) [ 18920/480000]  lr: 1.9995e-04  eta: 7 days, 19:50:10  time: 1.3549  data_time: 0.0061  memory: 9845  loss: 0.0045  grad_norm: 0.1125
05/10 07:53:32 - mmengine - INFO - Iter(train) [ 18930/480000]  lr: 1.9995e-04  eta: 7 days, 19:49:34  time: 1.3820  data_time: 0.0063  memory: 9841  loss: 0.0031  grad_norm: 0.1178
05/10 07:53:46 - mmengine - INFO - Iter(train) [ 18940/480000]  lr: 1.9995e-04  eta: 7 days, 19:48:50  time: 1.3451  data_time: 0.0060  memory: 9840  loss: 0.0039  grad_norm: 0.1178
05/10 07:54:01 - mmengine - INFO - Iter(train) [ 18950/480000]  lr: 1.9995e-04  eta: 7 days, 19:48:45  time: 1.5053  data_time: 0.0062  memory: 9841  loss: 0.0037  grad_norm: 0.1177
05/10 07:54:14 - mmengine - INFO - Iter(train) [ 18960/480000]  lr: 1.9995e-04  eta: 7 days, 19:48:09  time: 1.3782  data_time: 0.0061  memory: 9841  loss: 0.0050  grad_norm: 0.1190
05/10 07:54:28 - mmengine - INFO - Iter(train) [ 18970/480000]  lr: 1.9995e-04  eta: 7 days, 19:47:26  time: 1.3488  data_time: 0.0061  memory: 9840  loss: 0.0052  grad_norm: 0.1190
05/10 07:54:41 - mmengine - INFO - Iter(train) [ 18980/480000]  lr: 1.9995e-04  eta: 7 days, 19:46:24  time: 1.2751  data_time: 0.0057  memory: 9849  loss: 0.0044  grad_norm: 0.1158
05/10 07:54:54 - mmengine - INFO - Iter(train) [ 18990/480000]  lr: 1.9995e-04  eta: 7 days, 19:45:38  time: 1.3335  data_time: 0.0059  memory: 9848  loss: 0.0039  grad_norm: 0.1158
05/10 07:55:09 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 07:55:09 - mmengine - INFO - Iter(train) [ 19000/480000]  lr: 1.9995e-04  eta: 7 days, 19:45:31  time: 1.4993  data_time: 0.0060  memory: 9847  loss: 0.0036  grad_norm: 0.1205
05/10 07:55:09 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 07:55:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。男票这样做确实可能会让女方感到不舒服，这种情况下确实很难处理。精神出轨确实是个很复杂的问题，需要双方沟通和理解。你可以和男朋友坦诚地交流一下你的感受，告诉他你对他这种行为感到不安，希望他能够理解你的感受。同时，也可以考虑和他沟通一下你的期望和梦想，让他知道你不仅仅是为了他的“精神愉悦”而活的。如果需要倾诉或者寻求更多建议，我在这里随时听你说哦。💖<|im_end|>

05/10 07:55:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷。不过，别忘了，健康最重要，别让洗牙成了你的“痛风”来源。🦷🌿<|im_end|>

05/10 07:55:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 07:55:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个“闺蜜抢购”、“前任鉴赏”？不过别太往心里去，毕竟“友谊的小船”说翻就翻，下次记得设个密码，防止你这“屏蔽大法”再被“前任”有机可乘！🚣‍♂️💔<|im_end|>

05/10 07:55:39 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物确实可能会让人担心。不过，炸鸡虽然美味，也是有的人喜欢的食物呢。你可以尝试一些健康的替代品，比如烤鸡或者蒸鸡，它们同样很美味哦。💖 如果你想要聊聊其他的事情，或者需要一些健康饮食的建议，我都在这里呢。🌸<|im_end|>

05/10 07:55:44 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过话说回来，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 07:55:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想告诉我们“今天也要抖抖翅膀”！🌟<|im_end|>

05/10 07:55:50 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这是“静音”了吗？😂 下次记得，周末也要开启“听力模式”，别让领导再给你“选边站”啦！👀<|im_end|>

05/10 07:55:50 - mmengine - INFO - Saving checkpoint at 19000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 07:56:04 - mmengine - INFO - Iter(train) [ 19010/480000]  lr: 1.9995e-04  eta: 7 days, 20:01:24  time: 5.4568  data_time: 4.1852  memory: 9844  loss: 0.0062  grad_norm: 0.1198
05/10 07:56:19 - mmengine - INFO - Iter(train) [ 19020/480000]  lr: 1.9995e-04  eta: 7 days, 20:01:21  time: 1.5145  data_time: 0.0062  memory: 9843  loss: 0.0047  grad_norm: 0.1198
05/10 07:56:31 - mmengine - INFO - Iter(train) [ 19030/480000]  lr: 1.9995e-04  eta: 7 days, 20:00:12  time: 1.2470  data_time: 0.0056  memory: 9843  loss: 0.0055  grad_norm: 0.1171
05/10 07:56:45 - mmengine - INFO - Iter(train) [ 19040/480000]  lr: 1.9995e-04  eta: 7 days, 19:59:43  time: 1.4089  data_time: 0.0057  memory: 9843  loss: 0.0050  grad_norm: 0.1166
05/10 07:57:00 - mmengine - INFO - Iter(train) [ 19050/480000]  lr: 1.9995e-04  eta: 7 days, 19:59:40  time: 1.5143  data_time: 0.2059  memory: 9841  loss: 0.0039  grad_norm: 0.1166
05/10 07:57:13 - mmengine - INFO - Iter(train) [ 19060/480000]  lr: 1.9995e-04  eta: 7 days, 19:58:45  time: 1.3030  data_time: 0.0058  memory: 9840  loss: 0.0038  grad_norm: 0.1187
05/10 07:57:28 - mmengine - INFO - Iter(train) [ 19070/480000]  lr: 1.9995e-04  eta: 7 days, 19:58:35  time: 1.4867  data_time: 0.0059  memory: 9841  loss: 0.0030  grad_norm: 0.1187
05/10 07:57:41 - mmengine - INFO - Iter(train) [ 19080/480000]  lr: 1.9995e-04  eta: 7 days, 19:57:24  time: 1.2346  data_time: 0.0056  memory: 9839  loss: 0.0037  grad_norm: 0.1209
05/10 07:57:56 - mmengine - INFO - Iter(train) [ 19090/480000]  lr: 1.9995e-04  eta: 7 days, 19:57:15  time: 1.4922  data_time: 0.0059  memory: 9839  loss: 0.0038  grad_norm: 0.1186
05/10 07:58:09 - mmengine - INFO - Iter(train) [ 19100/480000]  lr: 1.9995e-04  eta: 7 days, 19:56:22  time: 1.3080  data_time: 0.0059  memory: 9843  loss: 0.0033  grad_norm: 0.1186
05/10 07:58:22 - mmengine - INFO - Iter(train) [ 19110/480000]  lr: 1.9995e-04  eta: 7 days, 19:55:26  time: 1.2972  data_time: 0.0057  memory: 9843  loss: 0.0046  grad_norm: 0.1155
05/10 07:58:36 - mmengine - INFO - Iter(train) [ 19120/480000]  lr: 1.9995e-04  eta: 7 days, 19:55:11  time: 1.4657  data_time: 0.0059  memory: 9843  loss: 0.0053  grad_norm: 0.1188
05/10 07:58:49 - mmengine - INFO - Iter(train) [ 19130/480000]  lr: 1.9995e-04  eta: 7 days, 19:54:11  time: 1.2834  data_time: 0.0058  memory: 9842  loss: 0.0069  grad_norm: 0.1188
05/10 07:59:04 - mmengine - INFO - Iter(train) [ 19140/480000]  lr: 1.9995e-04  eta: 7 days, 19:54:02  time: 1.4880  data_time: 0.0058  memory: 9842  loss: 0.0046  grad_norm: 0.1251
05/10 07:59:17 - mmengine - INFO - Iter(train) [ 19150/480000]  lr: 1.9995e-04  eta: 7 days, 19:53:03  time: 1.2871  data_time: 0.0058  memory: 9842  loss: 0.0047  grad_norm: 0.1251
05/10 07:59:30 - mmengine - INFO - Iter(train) [ 19160/480000]  lr: 1.9995e-04  eta: 7 days, 19:52:03  time: 1.2765  data_time: 0.0057  memory: 9842  loss: 0.0049  grad_norm: 0.1248
05/10 07:59:44 - mmengine - INFO - Iter(train) [ 19170/480000]  lr: 1.9995e-04  eta: 7 days, 19:51:49  time: 1.4730  data_time: 0.0059  memory: 9843  loss: 0.0050  grad_norm: 0.1283
05/10 07:59:57 - mmengine - INFO - Iter(train) [ 19180/480000]  lr: 1.9995e-04  eta: 7 days, 19:50:45  time: 1.2620  data_time: 0.0057  memory: 9849  loss: 0.0040  grad_norm: 0.1283
05/10 08:00:10 - mmengine - INFO - Iter(train) [ 19190/480000]  lr: 1.9995e-04  eta: 7 days, 19:49:55  time: 1.3177  data_time: 0.0058  memory: 9846  loss: 0.0051  grad_norm: 0.1336
05/10 08:00:25 - mmengine - INFO - Iter(train) [ 19200/480000]  lr: 1.9995e-04  eta: 7 days, 19:49:52  time: 1.5190  data_time: 0.0059  memory: 9843  loss: 0.0045  grad_norm: 0.1357
05/10 08:00:41 - mmengine - INFO - Iter(train) [ 19210/480000]  lr: 1.9995e-04  eta: 7 days, 19:49:55  time: 1.5388  data_time: 0.2225  memory: 9842  loss: 0.0040  grad_norm: 0.1357
05/10 08:00:53 - mmengine - INFO - Iter(train) [ 19220/480000]  lr: 1.9995e-04  eta: 7 days, 19:48:48  time: 1.2498  data_time: 0.0056  memory: 9843  loss: 0.0036  grad_norm: 0.1350
05/10 08:01:08 - mmengine - INFO - Iter(train) [ 19230/480000]  lr: 1.9995e-04  eta: 7 days, 19:48:32  time: 1.4611  data_time: 0.0058  memory: 9841  loss: 0.0040  grad_norm: 0.1350
05/10 08:01:20 - mmengine - INFO - Iter(train) [ 19240/480000]  lr: 1.9995e-04  eta: 7 days, 19:47:26  time: 1.2526  data_time: 0.0056  memory: 9839  loss: 0.0046  grad_norm: 0.1350
05/10 08:01:35 - mmengine - INFO - Iter(train) [ 19250/480000]  lr: 1.9995e-04  eta: 7 days, 19:47:16  time: 1.4884  data_time: 0.0059  memory: 9841  loss: 0.0038  grad_norm: 0.1358
05/10 08:01:48 - mmengine - INFO - Iter(train) [ 19260/480000]  lr: 1.9995e-04  eta: 7 days, 19:46:12  time: 1.2596  data_time: 0.0057  memory: 9845  loss: 0.0043  grad_norm: 0.1358
05/10 08:02:01 - mmengine - INFO - Iter(train) [ 19270/480000]  lr: 1.9995e-04  eta: 7 days, 19:45:12  time: 1.2786  data_time: 0.0057  memory: 9843  loss: 0.0048  grad_norm: 0.1392
05/10 08:02:16 - mmengine - INFO - Iter(train) [ 19280/480000]  lr: 1.9995e-04  eta: 7 days, 19:45:09  time: 1.5163  data_time: 0.0060  memory: 9843  loss: 0.0051  grad_norm: 0.1407
05/10 08:02:28 - mmengine - INFO - Iter(train) [ 19290/480000]  lr: 1.9995e-04  eta: 7 days, 19:44:02  time: 1.2493  data_time: 0.0056  memory: 9843  loss: 0.0049  grad_norm: 0.1407
05/10 08:02:43 - mmengine - INFO - Iter(train) [ 19300/480000]  lr: 1.9995e-04  eta: 7 days, 19:43:55  time: 1.4955  data_time: 0.0060  memory: 9843  loss: 0.0051  grad_norm: 0.1401
05/10 08:02:56 - mmengine - INFO - Iter(train) [ 19310/480000]  lr: 1.9995e-04  eta: 7 days, 19:42:54  time: 1.2748  data_time: 0.0056  memory: 9841  loss: 0.0051  grad_norm: 0.1401
05/10 08:03:09 - mmengine - INFO - Iter(train) [ 19320/480000]  lr: 1.9994e-04  eta: 7 days, 19:41:56  time: 1.2862  data_time: 0.0056  memory: 9842  loss: 0.0042  grad_norm: 0.1373
05/10 08:03:24 - mmengine - INFO - Iter(train) [ 19330/480000]  lr: 1.9994e-04  eta: 7 days, 19:41:51  time: 1.5073  data_time: 0.0061  memory: 9842  loss: 0.0059  grad_norm: 0.1324
05/10 08:03:37 - mmengine - INFO - Iter(train) [ 19340/480000]  lr: 1.9994e-04  eta: 7 days, 19:40:48  time: 1.2621  data_time: 0.0057  memory: 9845  loss: 0.0042  grad_norm: 0.1324
05/10 08:03:52 - mmengine - INFO - Iter(train) [ 19350/480000]  lr: 1.9994e-04  eta: 7 days, 19:41:00  time: 1.5811  data_time: 0.0059  memory: 9841  loss: 0.0048  grad_norm: 0.1350
05/10 08:04:05 - mmengine - INFO - Iter(train) [ 19360/480000]  lr: 1.9994e-04  eta: 7 days, 19:40:10  time: 1.3160  data_time: 0.0061  memory: 9839  loss: 0.0040  grad_norm: 0.1338
05/10 08:04:23 - mmengine - INFO - Iter(train) [ 19370/480000]  lr: 1.9994e-04  eta: 7 days, 19:41:07  time: 1.7704  data_time: 0.2065  memory: 9842  loss: 0.0028  grad_norm: 0.1338
05/10 08:04:36 - mmengine - INFO - Iter(train) [ 19380/480000]  lr: 1.9994e-04  eta: 7 days, 19:40:17  time: 1.3171  data_time: 0.0058  memory: 9842  loss: 0.0038  grad_norm: 0.1352
05/10 08:04:49 - mmengine - INFO - Iter(train) [ 19390/480000]  lr: 1.9994e-04  eta: 7 days, 19:39:22  time: 1.2972  data_time: 0.0057  memory: 9842  loss: 0.0040  grad_norm: 0.1352
05/10 08:05:05 - mmengine - INFO - Iter(train) [ 19400/480000]  lr: 1.9994e-04  eta: 7 days, 19:39:27  time: 1.5500  data_time: 0.0061  memory: 9841  loss: 0.0046  grad_norm: 0.1367
05/10 08:05:18 - mmengine - INFO - Iter(train) [ 19410/480000]  lr: 1.9994e-04  eta: 7 days, 19:38:33  time: 1.2986  data_time: 0.0057  memory: 9842  loss: 0.0036  grad_norm: 0.1377
05/10 08:05:33 - mmengine - INFO - Iter(train) [ 19420/480000]  lr: 1.9994e-04  eta: 7 days, 19:38:32  time: 1.5265  data_time: 0.0060  memory: 9841  loss: 0.0048  grad_norm: 0.1377
05/10 08:05:46 - mmengine - INFO - Iter(train) [ 19430/480000]  lr: 1.9994e-04  eta: 7 days, 19:37:43  time: 1.3222  data_time: 0.0060  memory: 9842  loss: 0.0042  grad_norm: 0.1356
05/10 08:06:00 - mmengine - INFO - Iter(train) [ 19440/480000]  lr: 1.9994e-04  eta: 7 days, 19:37:05  time: 1.3685  data_time: 0.0060  memory: 9843  loss: 0.0050  grad_norm: 0.1300
05/10 08:06:15 - mmengine - INFO - Iter(train) [ 19450/480000]  lr: 1.9994e-04  eta: 7 days, 19:37:09  time: 1.5423  data_time: 0.0059  memory: 9841  loss: 0.0043  grad_norm: 0.1300
05/10 08:06:29 - mmengine - INFO - Iter(train) [ 19460/480000]  lr: 1.9994e-04  eta: 7 days, 19:36:31  time: 1.3697  data_time: 0.0059  memory: 9842  loss: 0.0054  grad_norm: 0.1253
05/10 08:06:45 - mmengine - INFO - Iter(train) [ 19470/480000]  lr: 1.9994e-04  eta: 7 days, 19:36:39  time: 1.5613  data_time: 0.0063  memory: 9839  loss: 0.0041  grad_norm: 0.1253
05/10 08:06:58 - mmengine - INFO - Iter(train) [ 19480/480000]  lr: 1.9994e-04  eta: 7 days, 19:35:43  time: 1.2916  data_time: 0.0057  memory: 9841  loss: 0.0048  grad_norm: 0.1262
05/10 08:07:13 - mmengine - INFO - Iter(train) [ 19490/480000]  lr: 1.9994e-04  eta: 7 days, 19:35:46  time: 1.5438  data_time: 0.0061  memory: 9842  loss: 0.0052  grad_norm: 0.1266
05/10 08:07:26 - mmengine - INFO - Iter(train) [ 19500/480000]  lr: 1.9994e-04  eta: 7 days, 19:34:56  time: 1.3133  data_time: 0.0060  memory: 9843  loss: 0.0060  grad_norm: 0.1266
05/10 08:07:26 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 08:07:31 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人难过的。所有的选择都有它的理由，不需要因为别人的行为而质疑自己的选择。你的男朋友是由衷地关心你，这是一件好事。你觉得如何呢？💖是不是想要聊聊你的感受，或者我们可以一起想想怎么处理这件事让你感到更好。<|im_end|>

05/10 08:07:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷👋<|im_end|>

05/10 08:07:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 08:07:41 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感三连击！不过别太往心里去，至少你还能在朋友圈开个“闺蜜和前任一起上央视”的新闻发布会呢。🌟<|im_end|>

05/10 08:07:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。你可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖记得多喝水，保持良好的生活习惯，如果有需要，也可以咨询医生哦。🌸<|im_end|>

05/10 08:07:56 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“逃课大师”！不过，别太往心里去，大家都是为了开心来的，别让一场游戏影响了你的好心情。😄<|im_end|>

05/10 08:08:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别气馁，你的眼线可能是想开个个人艺术展，只是作品有点过于抽象了。下次换个颜色，或者直接给他来个“相见恨晚”，让他知道谁才是真正的颜值爆表！😜<|im_end|>

05/10 08:08:10 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的语音矩阵很重要，及时回应和沟通是很重要的。你可以试试用一些智能应用或者通知服务来帮忙回应，比如微信、短信等，这样可以减少错过重要信息的风险。如果实在不行，也可以简单写个回复，表明你注意到了并且会尽快处理，这样既显示了你的责任心，又避免了直接的“装没看见”。💖<|im_end|>

05/10 08:08:10 - mmengine - INFO - Saving checkpoint at 19500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 08:08:26 - mmengine - INFO - Iter(train) [ 19510/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:24  time: 5.9691  data_time: 4.4355  memory: 9843  loss: 0.0042  grad_norm: 0.1220
05/10 08:08:38 - mmengine - INFO - Iter(train) [ 19520/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:14  time: 1.2358  data_time: 0.0058  memory: 9844  loss: 0.0059  grad_norm: 0.1261
05/10 08:08:56 - mmengine - INFO - Iter(train) [ 19530/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:00  time: 1.7250  data_time: 0.2061  memory: 9844  loss: 0.0046  grad_norm: 0.1261
05/10 08:09:09 - mmengine - INFO - Iter(train) [ 19540/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:21  time: 1.3681  data_time: 0.0061  memory: 9844  loss: 0.0027  grad_norm: 0.1290
05/10 08:09:23 - mmengine - INFO - Iter(train) [ 19550/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:37  time: 1.3440  data_time: 0.0062  memory: 9846  loss: 0.0046  grad_norm: 0.1290
05/10 08:09:38 - mmengine - INFO - Iter(train) [ 19560/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:29  time: 1.4959  data_time: 0.0061  memory: 9846  loss: 0.0027  grad_norm: 0.1263
05/10 08:09:51 - mmengine - INFO - Iter(train) [ 19570/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:43  time: 1.3353  data_time: 0.0060  memory: 9848  loss: 0.0030  grad_norm: 0.1242
05/10 08:10:06 - mmengine - INFO - Iter(train) [ 19580/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:40  time: 1.5177  data_time: 0.0060  memory: 9843  loss: 0.0058  grad_norm: 0.1242
05/10 08:10:20 - mmengine - INFO - Iter(train) [ 19590/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:59  time: 1.3554  data_time: 0.0060  memory: 9843  loss: 0.0034  grad_norm: 0.1254
05/10 08:10:33 - mmengine - INFO - Iter(train) [ 19600/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:17  time: 1.3532  data_time: 0.0062  memory: 9842  loss: 0.0044  grad_norm: 0.1286
05/10 08:10:48 - mmengine - INFO - Iter(train) [ 19610/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:07  time: 1.4891  data_time: 0.0060  memory: 9842  loss: 0.0037  grad_norm: 0.1286
05/10 08:11:01 - mmengine - INFO - Iter(train) [ 19620/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:21  time: 1.3355  data_time: 0.0062  memory: 9844  loss: 0.0047  grad_norm: 0.1350
05/10 08:11:17 - mmengine - INFO - Iter(train) [ 19630/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:17  time: 1.5144  data_time: 0.0061  memory: 9844  loss: 0.0040  grad_norm: 0.1350
05/10 08:11:30 - mmengine - INFO - Iter(train) [ 19640/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:30  time: 1.3288  data_time: 0.0060  memory: 9844  loss: 0.0051  grad_norm: 0.1311
05/10 08:11:45 - mmengine - INFO - Iter(train) [ 19650/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:25  time: 1.5094  data_time: 0.0061  memory: 9842  loss: 0.0069  grad_norm: 0.1381
05/10 08:11:58 - mmengine - INFO - Iter(train) [ 19660/480000]  lr: 1.9994e-04  eta: 7 days, 19:45:37  time: 1.3286  data_time: 0.0059  memory: 9845  loss: 0.0057  grad_norm: 0.1381
05/10 08:12:12 - mmengine - INFO - Iter(train) [ 19670/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:57  time: 1.3595  data_time: 0.0059  memory: 9846  loss: 0.0056  grad_norm: 0.1427
05/10 08:12:26 - mmengine - INFO - Iter(train) [ 19680/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:35  time: 1.4349  data_time: 0.0060  memory: 9843  loss: 0.0050  grad_norm: 0.1426
05/10 08:12:41 - mmengine - INFO - Iter(train) [ 19690/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:29  time: 1.5082  data_time: 0.2061  memory: 9838  loss: 0.0034  grad_norm: 0.1426
05/10 08:12:57 - mmengine - INFO - Iter(train) [ 19700/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:32  time: 1.5429  data_time: 0.0065  memory: 9844  loss: 0.0045  grad_norm: 0.1489
05/10 08:13:10 - mmengine - INFO - Iter(train) [ 19710/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:45  time: 1.3281  data_time: 0.0060  memory: 9846  loss: 0.0038  grad_norm: 0.1489
05/10 08:13:23 - mmengine - INFO - Iter(train) [ 19720/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:00  time: 1.3418  data_time: 0.0062  memory: 9844  loss: 0.0042  grad_norm: 0.1497
05/10 08:13:38 - mmengine - INFO - Iter(train) [ 19730/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:53  time: 1.4978  data_time: 0.0059  memory: 9842  loss: 0.0038  grad_norm: 0.1507
05/10 08:13:52 - mmengine - INFO - Iter(train) [ 19740/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:08  time: 1.3417  data_time: 0.0061  memory: 9842  loss: 0.0042  grad_norm: 0.1507
05/10 08:14:07 - mmengine - INFO - Iter(train) [ 19750/480000]  lr: 1.9993e-04  eta: 7 days, 19:42:03  time: 1.5066  data_time: 0.0060  memory: 9844  loss: 0.0052  grad_norm: 0.1487
05/10 08:14:20 - mmengine - INFO - Iter(train) [ 19760/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:21  time: 1.3511  data_time: 0.0059  memory: 9844  loss: 0.0040  grad_norm: 0.1451
05/10 08:14:36 - mmengine - INFO - Iter(train) [ 19770/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:16  time: 1.5123  data_time: 0.0060  memory: 9845  loss: 0.0062  grad_norm: 0.1451
05/10 08:14:49 - mmengine - INFO - Iter(train) [ 19780/480000]  lr: 1.9993e-04  eta: 7 days, 19:40:25  time: 1.3094  data_time: 0.0059  memory: 9845  loss: 0.0051  grad_norm: 0.1468
05/10 08:15:02 - mmengine - INFO - Iter(train) [ 19790/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:45  time: 1.3595  data_time: 0.0061  memory: 9839  loss: 0.0049  grad_norm: 0.1468
05/10 08:15:18 - mmengine - INFO - Iter(train) [ 19800/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:59  time: 1.5899  data_time: 0.0062  memory: 9843  loss: 0.0040  grad_norm: 0.1471
05/10 08:15:32 - mmengine - INFO - Iter(train) [ 19810/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:20  time: 1.3668  data_time: 0.0060  memory: 9844  loss: 0.0057  grad_norm: 0.1426
05/10 08:15:47 - mmengine - INFO - Iter(train) [ 19820/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:18  time: 1.5212  data_time: 0.0060  memory: 9840  loss: 0.0058  grad_norm: 0.1426
05/10 08:16:01 - mmengine - INFO - Iter(train) [ 19830/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:37  time: 1.3542  data_time: 0.0060  memory: 9843  loss: 0.0073  grad_norm: 0.1395
05/10 08:16:13 - mmengine - INFO - Iter(train) [ 19840/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:37  time: 1.2729  data_time: 0.0059  memory: 9841  loss: 0.0033  grad_norm: 0.1366
05/10 08:16:31 - mmengine - INFO - Iter(train) [ 19850/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:28  time: 1.7519  data_time: 0.4193  memory: 9845  loss: 0.0041  grad_norm: 0.1366
05/10 08:16:44 - mmengine - INFO - Iter(train) [ 19860/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:29  time: 1.2766  data_time: 0.0057  memory: 9845  loss: 0.0034  grad_norm: 0.1269
05/10 08:17:00 - mmengine - INFO - Iter(train) [ 19870/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:56  time: 1.6473  data_time: 0.0062  memory: 9841  loss: 0.0069  grad_norm: 0.1269
05/10 08:17:13 - mmengine - INFO - Iter(train) [ 19880/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:54  time: 1.2646  data_time: 0.0058  memory: 9848  loss: 0.0044  grad_norm: 0.1299
05/10 08:17:28 - mmengine - INFO - Iter(train) [ 19890/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:57  time: 1.5415  data_time: 0.0059  memory: 9847  loss: 0.0063  grad_norm: 0.1367
05/10 08:17:41 - mmengine - INFO - Iter(train) [ 19900/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:03  time: 1.2998  data_time: 0.0059  memory: 9846  loss: 0.0054  grad_norm: 0.1367
05/10 08:17:54 - mmengine - INFO - Iter(train) [ 19910/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:12  time: 1.3098  data_time: 0.0059  memory: 9846  loss: 0.0035  grad_norm: 0.1363
05/10 08:18:11 - mmengine - INFO - Iter(train) [ 19920/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:38  time: 1.6464  data_time: 0.0062  memory: 9845  loss: 0.0068  grad_norm: 0.1385
05/10 08:18:23 - mmengine - INFO - Iter(train) [ 19930/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:39  time: 1.2759  data_time: 0.0056  memory: 9842  loss: 0.0038  grad_norm: 0.1385
05/10 08:18:39 - mmengine - INFO - Iter(train) [ 19940/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:57  time: 1.6086  data_time: 0.0065  memory: 9844  loss: 0.0065  grad_norm: 0.1295
05/10 08:18:52 - mmengine - INFO - Iter(train) [ 19950/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:02  time: 1.2938  data_time: 0.0059  memory: 9844  loss: 0.0047  grad_norm: 0.1295
05/10 08:19:05 - mmengine - INFO - Iter(train) [ 19960/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:09  time: 1.2996  data_time: 0.0059  memory: 9845  loss: 0.0042  grad_norm: 0.1354
05/10 08:19:22 - mmengine - INFO - Iter(train) [ 19970/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:27  time: 1.6098  data_time: 0.0061  memory: 9844  loss: 0.0043  grad_norm: 0.1308
05/10 08:19:34 - mmengine - INFO - Iter(train) [ 19980/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:27  time: 1.2702  data_time: 0.0056  memory: 9845  loss: 0.0047  grad_norm: 0.1308
05/10 08:19:50 - mmengine - INFO - Iter(train) [ 19990/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:37  time: 1.5734  data_time: 0.0059  memory: 9846  loss: 0.0048  grad_norm: 0.1311
05/10 08:20:02 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010
05/10 08:20:02 - mmengine - INFO - Iter(train) [ 20000/480000]  lr: 1.9993e-04  eta: 7 days, 19:31:29  time: 1.2366  data_time: 0.0058  memory: 9844  loss: 0.0064  grad_norm: 0.1372
05/10 08:20:02 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 08:20:10 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。男票给女主播刷火箭可能只是单纯的游戏娱乐，不应该成为精神出轨的定义。你们之间应该及时沟通，表达一下你的感受，了解他为什么会做出这样的行为。同时，也可以谈谈其他的，分散一下注意力，让彼此之间的关系更加稳固。💖

如果需要倾诉或者寻求更多建议，我在这里哦。🌸<|im_end|>

05/10 08:20:14 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷🌊<|im_end|>

05/10 08:20:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖<|im_end|>

05/10 08:20:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感和网络界的地震级爆炸音！不过别太在意，友谊的小船不能翻，但至少能让你们的对话多一点“特殊”的元素，这就是生活的一部分嘛。别让这种小事影响了你们之间的闺蜜和前任，毕竟，真正的友情不是靠取关和拉黑来考验的。👩‍💼💔<|im_end|>

05/10 08:20:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖 而且，戒掉炸鸡也可能会影响食欲，记得多喝水，保持良好的饮食习惯哦。🌸 如果需要更多建议或者想要聊聊其他话题，我都在这里呢。😊<|im_end|>

05/10 08:20:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“退退退”！<|im_end|>

05/10 08:20:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别太往心里去，你的眼线可能是想开个开放日，举办“恐怖节”。下次记得，找美容师，别让那些不懂欣赏的家伙影响了你的造型。💄😱<|im_end|>

05/10 08:20:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实会让人感到有些失落呢。领导的指示很重要，及时回应和表达自己的立场是很重要的。你可以选择看到并且回复，或者可以想想有没有其他方式表达你的感受。💖你觉得呢？<|im_end|>

05/10 08:20:47 - mmengine - INFO - Saving checkpoint at 20000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 08:21:05 - mmengine - INFO - Iter(train) [ 20010/480000]  lr: 1.9993e-04  eta: 7 days, 19:49:40  time: 6.2766  data_time: 4.6992  memory: 9842  loss: 0.0041  grad_norm: 0.1372
05/10 08:21:18 - mmengine - INFO - Iter(train) [ 20020/480000]  lr: 1.9993e-04  eta: 7 days, 19:48:42  time: 1.2843  data_time: 0.0057  memory: 9840  loss: 0.0042  grad_norm: 0.1413
05/10 08:21:34 - mmengine - INFO - Iter(train) [ 20030/480000]  lr: 1.9993e-04  eta: 7 days, 19:48:55  time: 1.5916  data_time: 0.0060  memory: 9842  loss: 0.0052  grad_norm: 0.1413
05/10 08:21:46 - mmengine - INFO - Iter(train) [ 20040/480000]  lr: 1.9993e-04  eta: 7 days, 19:47:53  time: 1.2620  data_time: 0.0057  memory: 9843  loss: 0.0052  grad_norm: 0.1412
05/10 08:22:00 - mmengine - INFO - Iter(train) [ 20050/480000]  lr: 1.9993e-04  eta: 7 days, 19:47:02  time: 1.3109  data_time: 0.0058  memory: 9842  loss: 0.0043  grad_norm: 0.1332
05/10 08:22:15 - mmengine - INFO - Iter(train) [ 20060/480000]  lr: 1.9993e-04  eta: 7 days, 19:47:13  time: 1.5819  data_time: 0.0062  memory: 9843  loss: 0.0039  grad_norm: 0.1332
05/10 08:22:29 - mmengine - INFO - Iter(train) [ 20070/480000]  lr: 1.9993e-04  eta: 7 days, 19:46:24  time: 1.3196  data_time: 0.0059  memory: 9842  loss: 0.0058  grad_norm: 0.1333
05/10 08:22:44 - mmengine - INFO - Iter(train) [ 20080/480000]  lr: 1.9993e-04  eta: 7 days, 19:46:14  time: 1.4924  data_time: 0.0059  memory: 9843  loss: 0.0037  grad_norm: 0.1374
05/10 08:22:57 - mmengine - INFO - Iter(train) [ 20090/480000]  lr: 1.9993e-04  eta: 7 days, 19:45:22  time: 1.3080  data_time: 0.0058  memory: 9843  loss: 0.0062  grad_norm: 0.1374
05/10 08:23:12 - mmengine - INFO - Iter(train) [ 20100/480000]  lr: 1.9993e-04  eta: 7 days, 19:45:21  time: 1.5293  data_time: 0.0058  memory: 9844  loss: 0.0043  grad_norm: 0.1455
05/10 08:23:25 - mmengine - INFO - Iter(train) [ 20110/480000]  lr: 1.9993e-04  eta: 7 days, 19:44:27  time: 1.2969  data_time: 0.0058  memory: 9844  loss: 0.0047  grad_norm: 0.1455
05/10 08:23:38 - mmengine - INFO - Iter(train) [ 20120/480000]  lr: 1.9993e-04  eta: 7 days, 19:43:31  time: 1.2889  data_time: 0.0058  memory: 9844  loss: 0.0059  grad_norm: 0.1430
05/10 08:23:53 - mmengine - INFO - Iter(train) [ 20130/480000]  lr: 1.9993e-04  eta: 7 days, 19:43:33  time: 1.5436  data_time: 0.0060  memory: 9842  loss: 0.0043  grad_norm: 0.1454
05/10 08:24:07 - mmengine - INFO - Iter(train) [ 20140/480000]  lr: 1.9993e-04  eta: 7 days, 19:42:47  time: 1.3320  data_time: 0.0060  memory: 9841  loss: 0.0046  grad_norm: 0.1454
05/10 08:24:22 - mmengine - INFO - Iter(train) [ 20150/480000]  lr: 1.9992e-04  eta: 7 days, 19:42:44  time: 1.5191  data_time: 0.0060  memory: 9843  loss: 0.0038  grad_norm: 0.1415
05/10 08:24:34 - mmengine - INFO - Iter(train) [ 20160/480000]  lr: 1.9992e-04  eta: 7 days, 19:41:39  time: 1.2477  data_time: 0.0057  memory: 9841  loss: 0.0044  grad_norm: 0.1317
05/10 08:24:49 - mmengine - INFO - Iter(train) [ 20170/480000]  lr: 1.9992e-04  eta: 7 days, 19:41:36  time: 1.5225  data_time: 0.2062  memory: 9842  loss: 0.0051  grad_norm: 0.1317
05/10 08:25:05 - mmengine - INFO - Iter(train) [ 20180/480000]  lr: 1.9992e-04  eta: 7 days, 19:41:33  time: 1.5213  data_time: 0.0059  memory: 9841  loss: 0.0045  grad_norm: 0.1303
05/10 08:25:18 - mmengine - INFO - Iter(train) [ 20190/480000]  lr: 1.9992e-04  eta: 7 days, 19:40:43  time: 1.3137  data_time: 0.0058  memory: 9841  loss: 0.0044  grad_norm: 0.1303
05/10 08:25:33 - mmengine - INFO - Iter(train) [ 20200/480000]  lr: 1.9992e-04  eta: 7 days, 19:40:37  time: 1.5065  data_time: 0.0058  memory: 9843  loss: 0.0049  grad_norm: 0.1301
05/10 08:25:46 - mmengine - INFO - Iter(train) [ 20210/480000]  lr: 1.9992e-04  eta: 7 days, 19:39:44  time: 1.3010  data_time: 0.0058  memory: 9844  loss: 0.0080  grad_norm: 0.1371
05/10 08:25:59 - mmengine - INFO - Iter(train) [ 20220/480000]  lr: 1.9992e-04  eta: 7 days, 19:38:54  time: 1.3137  data_time: 0.0058  memory: 9843  loss: 0.0058  grad_norm: 0.1371
05/10 08:26:14 - mmengine - INFO - Iter(train) [ 20230/480000]  lr: 1.9992e-04  eta: 7 days, 19:38:53  time: 1.5321  data_time: 0.0058  memory: 9845  loss: 0.0040  grad_norm: 0.1425
05/10 08:26:27 - mmengine - INFO - Iter(train) [ 20240/480000]  lr: 1.9992e-04  eta: 7 days, 19:38:04  time: 1.3162  data_time: 0.0059  memory: 9845  loss: 0.0036  grad_norm: 0.1366
05/10 08:26:43 - mmengine - INFO - Iter(train) [ 20250/480000]  lr: 1.9992e-04  eta: 7 days, 19:37:59  time: 1.5147  data_time: 0.0058  memory: 9846  loss: 0.0047  grad_norm: 0.1366
05/10 08:26:56 - mmengine - INFO - Iter(train) [ 20260/480000]  lr: 1.9992e-04  eta: 7 days, 19:37:10  time: 1.3175  data_time: 0.0059  memory: 9846  loss: 0.0031  grad_norm: 0.1331
05/10 08:27:11 - mmengine - INFO - Iter(train) [ 20270/480000]  lr: 1.9992e-04  eta: 7 days, 19:37:09  time: 1.5272  data_time: 0.0059  memory: 9842  loss: 0.0038  grad_norm: 0.1331
05/10 08:27:24 - mmengine - INFO - Iter(train) [ 20280/480000]  lr: 1.9992e-04  eta: 7 days, 19:36:20  time: 1.3185  data_time: 0.0059  memory: 9842  loss: 0.0060  grad_norm: 0.1365
05/10 08:27:37 - mmengine - INFO - Iter(train) [ 20290/480000]  lr: 1.9992e-04  eta: 7 days, 19:35:27  time: 1.2993  data_time: 0.0059  memory: 9843  loss: 0.0039  grad_norm: 0.1408
05/10 08:27:52 - mmengine - INFO - Iter(train) [ 20300/480000]  lr: 1.9992e-04  eta: 7 days, 19:35:21  time: 1.5073  data_time: 0.0059  memory: 9843  loss: 0.0060  grad_norm: 0.1408
05/10 08:28:06 - mmengine - INFO - Iter(train) [ 20310/480000]  lr: 1.9992e-04  eta: 7 days, 19:34:34  time: 1.3281  data_time: 0.0059  memory: 9843  loss: 0.0055  grad_norm: 0.1445
05/10 08:28:21 - mmengine - INFO - Iter(train) [ 20320/480000]  lr: 1.9992e-04  eta: 7 days, 19:34:25  time: 1.4933  data_time: 0.0058  memory: 9843  loss: 0.0102  grad_norm: 0.1566
05/10 08:28:36 - mmengine - INFO - Iter(train) [ 20330/480000]  lr: 1.9992e-04  eta: 7 days, 19:34:22  time: 1.5207  data_time: 0.2061  memory: 9845  loss: 0.0045  grad_norm: 0.1566
05/10 08:28:49 - mmengine - INFO - Iter(train) [ 20340/480000]  lr: 1.9992e-04  eta: 7 days, 19:33:31  time: 1.3083  data_time: 0.0058  memory: 9845  loss: 0.0039  grad_norm: 0.1630
05/10 08:29:04 - mmengine - INFO - Iter(train) [ 20350/480000]  lr: 1.9992e-04  eta: 7 days, 19:33:27  time: 1.5179  data_time: 0.0059  memory: 9844  loss: 0.0046  grad_norm: 0.1630
05/10 08:29:17 - mmengine - INFO - Iter(train) [ 20360/480000]  lr: 1.9992e-04  eta: 7 days, 19:32:44  time: 1.3423  data_time: 0.0059  memory: 9844  loss: 0.0048  grad_norm: 0.1638
05/10 08:29:33 - mmengine - INFO - Iter(train) [ 20370/480000]  lr: 1.9992e-04  eta: 7 days, 19:32:46  time: 1.5428  data_time: 0.0059  memory: 9842  loss: 0.0049  grad_norm: 0.1612
05/10 08:29:46 - mmengine - INFO - Iter(train) [ 20380/480000]  lr: 1.9992e-04  eta: 7 days, 19:31:55  time: 1.3088  data_time: 0.0058  memory: 9840  loss: 0.0045  grad_norm: 0.1612
05/10 08:29:59 - mmengine - INFO - Iter(train) [ 20390/480000]  lr: 1.9992e-04  eta: 7 days, 19:31:12  time: 1.3441  data_time: 0.0059  memory: 9840  loss: 0.0040  grad_norm: 0.1557
05/10 08:30:15 - mmengine - INFO - Iter(train) [ 20400/480000]  lr: 1.9992e-04  eta: 7 days, 19:31:15  time: 1.5438  data_time: 0.0059  memory: 9840  loss: 0.0058  grad_norm: 0.1578
05/10 08:30:28 - mmengine - INFO - Iter(train) [ 20410/480000]  lr: 1.9992e-04  eta: 7 days, 19:30:25  time: 1.3140  data_time: 0.0058  memory: 9843  loss: 0.0056  grad_norm: 0.1578
05/10 08:30:44 - mmengine - INFO - Iter(train) [ 20420/480000]  lr: 1.9992e-04  eta: 7 days, 19:30:40  time: 1.6019  data_time: 0.0058  memory: 9842  loss: 0.0077  grad_norm: 0.1662
05/10 08:30:57 - mmengine - INFO - Iter(train) [ 20430/480000]  lr: 1.9992e-04  eta: 7 days, 19:29:52  time: 1.3193  data_time: 0.0063  memory: 9844  loss: 0.0054  grad_norm: 0.1662
05/10 08:31:13 - mmengine - INFO - Iter(train) [ 20440/480000]  lr: 1.9992e-04  eta: 7 days, 19:30:00  time: 1.5710  data_time: 0.0063  memory: 9844  loss: 0.0089  grad_norm: 0.1648
05/10 08:31:26 - mmengine - INFO - Iter(train) [ 20450/480000]  lr: 1.9992e-04  eta: 7 days, 19:29:20  time: 1.3526  data_time: 0.0063  memory: 9846  loss: 0.0042  grad_norm: 0.1632
05/10 08:31:40 - mmengine - INFO - Iter(train) [ 20460/480000]  lr: 1.9992e-04  eta: 7 days, 19:28:32  time: 1.3211  data_time: 0.0059  memory: 9845  loss: 0.0053  grad_norm: 0.1632
05/10 08:31:55 - mmengine - INFO - Iter(train) [ 20470/480000]  lr: 1.9992e-04  eta: 7 days, 19:28:36  time: 1.5542  data_time: 0.0059  memory: 9844  loss: 0.0067  grad_norm: 0.1687
05/10 08:32:08 - mmengine - INFO - Iter(train) [ 20480/480000]  lr: 1.9992e-04  eta: 7 days, 19:27:40  time: 1.2833  data_time: 0.0058  memory: 9843  loss: 0.0062  grad_norm: 0.1633
