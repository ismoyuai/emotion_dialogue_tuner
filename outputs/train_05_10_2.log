nohup: ignoring input

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 33, in <module>
    sys.exit(load_entry_point('xtuner', 'console_scripts', 'xtuner')())
  File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 25, in importlib_load_entry_point
    return next(matches).load()
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/metadata/__init__.py", line 171, in load
    module = import_module(match.group('module'))
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/moyuai/moyuai/xtuner/xtuner/__init__.py", line 4, in <module>
    from mmengine.utils import digit_version
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in <module>
    from .registry import *
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in <module>
    from .build_functions import (build_from_cfg, build_model_from_cfg,
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in <module>
    import torch
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 1471, in <module>
    from .functional import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[2025-05-10 16:21:33,679] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 10, in <module>
    from mmengine.config import Config, DictAction
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in <module>
    from .registry import *
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in <module>
    from .build_functions import (build_from_cfg, build_model_from_cfg,
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in <module>
    import torch
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 1471, in <module>
    from .functional import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[2025-05-10 16:21:39,915] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
05/10 16:21:41 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 592051055
    GPU 0: NVIDIA GeForce RTX 4060 Ti
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 12.1, V12.1.105
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.2.0+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.17.0+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.6

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 592051055
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

05/10 16:21:41 - mmengine - INFO - Config:
SYSTEM = 'xtuner.utils.SYSTEM_TEMPLATE.alpaca'
accumulative_counts = 16
alpaca_en = dict(
    dataset=dict(
        data_files='/home/moyuai/moyuai/data/output.json',
        path='json',
        type='datasets.load_dataset'),
    dataset_map_fn=None,
    max_length=512,
    pack_to_max_length=True,
    remove_unused_columns=True,
    shuffle_before_pack=True,
    template_map_fn=dict(
        template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
        type='xtuner.dataset.map_fns.template_map_fn_factory'),
    tokenizer=dict(
        padding_side='right',
        pretrained_model_name_or_path=
        '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
        trust_remote_code=True,
        type='transformers.AutoTokenizer.from_pretrained'),
    type='xtuner.dataset.process_hf_dataset',
    use_varlen_attn=False)
batch_size = 4
betas = (
    0.9,
    0.999,
)
custom_hooks = [
    dict(
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.DatasetInfoHook'),
    dict(
        evaluation_inputs=[
            '男朋友给女主播刷火箭，算精神出轨吗？',
            '喝红酒养生，结果喝到头晕…',
            '闺蜜和我前任互关小红书，取关拉黑三连击！',
            '体检说胆固醇高，要戒炸鸡了吗？',
            '剧本杀遇读本玩家，直接摔门离场！',
            '领导周末发60秒语音矩阵，装没看见行吗？',
        ],
        every_n_iters=500,
        prompt_template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
        system='xtuner.utils.SYSTEM_TEMPLATE.alpaca',
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.EvaluateChatHook'),
]
data_files = '/home/moyuai/moyuai/data/output.json'
dataloader_num_workers = 0
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=500,
        max_keep_ckpts=5,
        type='mmengine.hooks.CheckpointHook'),
    logger=dict(
        interval=10,
        log_metric_by_epoch=False,
        type='mmengine.hooks.LoggerHook'),
    param_scheduler=dict(type='mmengine.hooks.ParamSchedulerHook'),
    sampler_seed=dict(type='mmengine.hooks.DistSamplerSeedHook'),
    timer=dict(type='mmengine.hooks.IterTimerHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation_freq = 500
evaluation_inputs = [
    '男朋友给女主播刷火箭，算精神出轨吗？',
    '喝红酒养生，结果喝到头晕…',
    '闺蜜和我前任互关小红书，取关拉黑三连击！',
    '体检说胆固醇高，要戒炸鸡了吗？',
    '剧本杀遇读本玩家，直接摔门离场！',
    '领导周末发60秒语音矩阵，装没看见行吗？',
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr = 0.0002
max_epochs = 3000
max_length = 512
max_norm = 1
model = dict(
    llm=dict(
        pretrained_model_name_or_path=
        '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
        quantization_config=dict(
            llm_int8_has_fp16_weight=False,
            llm_int8_threshold=6.0,
            load_in_4bit=False,
            load_in_8bit=True,
            type='transformers.BitsAndBytesConfig'),
        torch_dtype='torch.float16',
        trust_remote_code=True,
        type='transformers.AutoModelForCausalLM.from_pretrained'),
    lora=dict(
        bias='none',
        lora_alpha=64,
        lora_dropout=0.1,
        r=32,
        task_type='CAUSAL_LM',
        type='peft.LoraConfig'),
    type='xtuner.model.SupervisedFinetune',
    use_varlen_attn=False)
optim_type = 'torch.optim.AdamW'
optim_wrapper = dict(
    accumulative_counts=16,
    clip_grad=dict(error_if_nonfinite=False, max_norm=1),
    dtype='float16',
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        lr=0.0002,
        type='torch.optim.AdamW',
        weight_decay=0),
    type='mmengine.optim.AmpOptimWrapper')
pack_to_max_length = True
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=90.0,
        start_factor=1e-05,
        type='mmengine.optim.LinearLR'),
    dict(
        begin=90.0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=3000,
        eta_min=0.0,
        type='mmengine.optim.CosineAnnealingLR'),
]
pretrained_model_name_or_path = '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat'
prompt_template = 'xtuner.utils.PROMPT_TEMPLATE.qwen_chat'
randomness = dict(deterministic=False, seed=None)
resume = False
sampler = 'mmengine.dataset.DefaultSampler'
save_steps = 500
save_total_limit = 5
sequence_parallel_size = 1
tokenizer = dict(
    padding_side='right',
    pretrained_model_name_or_path=
    '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
    trust_remote_code=True,
    type='transformers.AutoTokenizer.from_pretrained')
train_cfg = dict(max_epochs=3000, type='xtuner.engine.runner.TrainLoop')
train_dataloader = dict(
    batch_size=4,
    collate_fn=dict(
        type='xtuner.dataset.collate_fns.default_collate_fn',
        use_varlen_attn=False),
    dataset=dict(
        dataset=dict(
            data_files='/home/moyuai/moyuai/data/output.json',
            path='json',
            type='datasets.load_dataset'),
        dataset_map_fn=None,
        max_length=512,
        pack_to_max_length=True,
        remove_unused_columns=True,
        shuffle_before_pack=True,
        template_map_fn=dict(
            template='xtuner.utils.PROMPT_TEMPLATE.qwen_chat',
            type='xtuner.dataset.map_fns.template_map_fn_factory'),
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path=
            '/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.dataset.process_hf_dataset',
        use_varlen_attn=False),
    num_workers=0,
    sampler=dict(shuffle=True, type='mmengine.dataset.DefaultSampler'))
use_varlen_attn = False
visualizer = None
warmup_ratio = 0.03
weight_decay = 0
work_dir = './work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3'

05/10 16:21:41 - mmengine - WARNING - Failed to search registry with scope "mmengine" in the "builder" registry tree. As a workaround, the current "builder" registry in "xtuner" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether "mmengine" is a correct scope, or whether the registry is initialized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
05/10 16:21:47 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
05/10 16:21:47 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DatasetInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Setting TOKENIZERS_PARALLELISM=false for forked processes.
Flattening the indices (num_proc=32):   0%|          | 0/4000 [00:00<?, ? examples/s]Flattening the indices (num_proc=32):   9%|▉         | 375/4000 [00:00<00:01, 3411.58 examples/s]Flattening the indices (num_proc=32): 100%|██████████| 4000/4000 [00:00<00:00, 18955.19 examples/s]
Map (num_proc=32):   0%|          | 0/4000 [00:00<?, ? examples/s]Map (num_proc=32):  44%|████▍     | 1750/4000 [00:00<00:00, 17253.21 examples/s]Map (num_proc=32): 100%|██████████| 4000/4000 [00:00<00:00, 19733.23 examples/s]
Map (num_proc=32):   0%|          | 0/637 [00:00<?, ? examples/s]Map (num_proc=32):  66%|██████▌   | 420/637 [00:00<00:00, 4146.29 examples/s]Map (num_proc=32): 100%|██████████| 637/637 [00:00<00:00, 3506.51 examples/s]
05/10 16:21:50 - mmengine - WARNING - Dataset Dataset has no metainfo. ``dataset_meta`` in visualizer will be None.
05/10 16:21:50 - mmengine - INFO - Num train samples 637
05/10 16:21:50 - mmengine - INFO - train example:
05/10 16:21:50 - mmengine - INFO - <|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
这个问题涉及到感情和道德方面的判断，每个人的看法可能都不同。如果你感到不舒服或者困惑，我们可以一起探讨一下你的感受，看看如何处理这种情况。💖你觉得呢？这让你感到如何呢？🌸<|im_end|>
<|im_start|>user
DIY陶艺做成歪脖子花瓶，丑萌…<|im_end|>
<|im_start|>assistant
温柔
哎呀，DIY的过程本身就是一种创造和探索，你的歪脖子花瓶充满了个性呢！💖 有没有考虑过给它上上色，或者加上一些装饰，可能会更有特色哦！🎨 不管怎样，制作的过程也是一种享受，不是吗？😄<|im_end|>
<|im_start|>user
午睡流口水泡湿合同，甲方皱眉捂鼻子！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真是有点尴尬呢~ 不过我相信你一定能够巧妙地处理这个情况的。有没有什么我能帮助你的呢？💖<|im_end|>
<|im_start|>user
男友游戏CP叫人家小甜心，能忍？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你的感受很重要，你觉得怎么样呢？💖 如果你想聊聊，或者需要一些建议，我在这里哦。🌸<|im_end|>
<|im_start|>user
吃海鲜自助全身起风团，痒到想跳楼！<|im_end|>
<|im_start|>assistant
温柔
哎呀，听起来你现在的状态很不舒服呢~ 海鲜过敏真的很难受。你要不要试试用冰敷来缓解痒感？或者吃一些抗过敏的药物？如果症状严重，建议及时去看医生哦。💖希望你能快点感觉好起来。现在感觉好点了吗？<|im_end|>
<|im_start|>user
洗牙后牙缝漏风，吹蜡烛像鼓风机！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这牙缝得比北京地铁还要宽敞，下次吹蜡烛记得自带防风罩，不然吹灭了蜡烛，吹出来的风都能把生日蛋糕吹飞了！🎂<|im_end|>
<|im_start|>user
吃代餐饿到偷吃泡面，罪恶感爆棚…<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实很让人难过。代餐是为了健康考虑，偶尔偷吃一下泡面也是可以理解的哦。重要的是找到健康的平衡。如果你觉得罪恶感很强，或许可以试着调整一下饮食计划，让自己既能享受美食，又能保持健康。💖你想聊
05/10 16:21:50 - mmengine - INFO - before_train in EvaluateChatHook.
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 16:21:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
作为一个人工智能语言模型，我不能对个人行为进行道德判断或提供法律建议。然而，从一般道德和法律角度来看，给女主播刷火箭可能被视为一种精神出轨行为。

精神出轨是指在婚姻或恋爱关系中

05/10 16:21:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
喝红酒养生确实可以起到一定的保健作用，但同时也需要注意适量饮用。如果在饮用红酒后出现头晕的症状，可能是以下几种原因导致的：

1. 酒精过量：红酒中的酒精含量较高，过量饮用

05/10 16:22:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
闺蜜和前任互关小红书，取关拉黑三连击！这种行为无疑是对闺蜜和前任之间关系的严重伤害和破坏，不仅破坏了彼此之间的友谊，也对彼此的个人形象和网络形象造成了负面影响

05/10 16:22:08 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
是的，体检结果显示胆固醇高，建议您戒掉炸鸡。炸鸡含有较高的饱和脂肪酸和胆固醇，长期食用可能会导致血脂升高，增加患心血管疾病的风险。此外，炸鸡的制作过程通常会使用大量的油脂

05/10 16:22:12 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
剧本杀遇读本玩家，直接摔门离场！这种行为在剧本杀中是不被允许的，因为这不仅违反了剧本杀的规则，也可能会对其他玩家造成困扰和影响。以下是一些可能的回应

05/10 16:22:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导周末发60秒语音矩阵，装没看见行吗？这是一道关于领导在周末发布语音矩阵但未被注意到的指令的回应问题。以下是一个可能的回复：

"尊敬的领导，感谢您在周末

05/10 16:22:16 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
05/10 16:22:16 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
05/10 16:22:16 - mmengine - INFO - Checkpoints will be saved to /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3.
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/optim/scheduler/param_scheduler.py:198: UserWarning: Detected call of `scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `scheduler.step()`. Failure to do this will result in PyTorch skipping the first value of the parameter value schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
05/10 16:22:31 - mmengine - INFO - Iter(train) [    10/480000]  lr: 1.2701e-07  eta: 8 days, 3:28:17  time: 1.4661  data_time: 0.0059  memory: 9045  loss: 3.3254
05/10 16:22:44 - mmengine - INFO - Iter(train) [    20/480000]  lr: 2.6590e-07  eta: 7 days, 14:34:26  time: 1.2727  data_time: 0.0059  memory: 9271  loss: 3.3687  grad_norm: 2.2397
05/10 16:23:00 - mmengine - INFO - Iter(train) [    30/480000]  lr: 4.0480e-07  eta: 8 days, 4:21:17  time: 1.6795  data_time: 0.0060  memory: 9271  loss: 3.4204  grad_norm: 2.2397
05/10 16:23:14 - mmengine - INFO - Iter(train) [    40/480000]  lr: 5.4370e-07  eta: 8 days, 1:58:22  time: 1.4014  data_time: 0.0061  memory: 9272  loss: 3.3844  grad_norm: 2.3158
05/10 16:23:27 - mmengine - INFO - Iter(train) [    50/480000]  lr: 6.8260e-07  eta: 7 days, 21:43:20  time: 1.2957  data_time: 0.0057  memory: 9272  loss: 3.4144  grad_norm: 2.3245
05/10 16:23:43 - mmengine - INFO - Iter(train) [    60/480000]  lr: 8.2149e-07  eta: 7 days, 23:58:01  time: 1.5243  data_time: 0.0058  memory: 9272  loss: 3.3818  grad_norm: 2.3245
05/10 16:23:55 - mmengine - INFO - Iter(train) [    70/480000]  lr: 9.6039e-07  eta: 7 days, 20:51:53  time: 1.2773  data_time: 0.0058  memory: 9272  loss: 3.4590  grad_norm: 2.2957
05/10 16:24:12 - mmengine - INFO - Iter(train) [    80/480000]  lr: 1.0993e-06  eta: 8 days, 1:28:55  time: 1.6940  data_time: 0.0064  memory: 9272  loss: 3.3415  grad_norm: 2.3042
05/10 16:24:26 - mmengine - INFO - Iter(train) [    90/480000]  lr: 1.2382e-06  eta: 7 days, 23:44:50  time: 1.3345  data_time: 0.0062  memory: 9272  loss: 3.4274  grad_norm: 2.3042
05/10 16:24:40 - mmengine - INFO - Iter(train) [   100/480000]  lr: 1.3771e-06  eta: 7 days, 23:44:57  time: 1.4388  data_time: 0.0059  memory: 9272  loss: 3.4044  grad_norm: 2.3188
05/10 16:24:53 - mmengine - INFO - Iter(train) [   110/480000]  lr: 1.5160e-06  eta: 7 days, 21:39:13  time: 1.2658  data_time: 0.0057  memory: 9272  loss: 3.3358  grad_norm: 2.3188
05/10 16:25:06 - mmengine - INFO - Iter(train) [   120/480000]  lr: 1.6549e-06  eta: 7 days, 20:20:29  time: 1.3050  data_time: 0.0058  memory: 9272  loss: 3.4039  grad_norm: 2.3085
05/10 16:25:23 - mmengine - INFO - Iter(train) [   130/480000]  lr: 1.7938e-06  eta: 7 days, 23:23:58  time: 1.7115  data_time: 0.0064  memory: 9272  loss: 3.3678  grad_norm: 2.3094
05/10 16:25:36 - mmengine - INFO - Iter(train) [   140/480000]  lr: 1.9327e-06  eta: 7 days, 21:59:21  time: 1.2882  data_time: 0.0058  memory: 9272  loss: 3.3243  grad_norm: 2.3094
05/10 16:25:50 - mmengine - INFO - Iter(train) [   150/480000]  lr: 2.0716e-06  eta: 7 days, 22:20:36  time: 1.4656  data_time: 0.0056  memory: 9272  loss: 3.3747  grad_norm: 2.3093
05/10 16:26:02 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 16:26:02 - mmengine - INFO - Iter(train) [   160/480000]  lr: 2.2105e-06  eta: 7 days, 20:27:28  time: 1.2022  data_time: 0.0056  memory: 9274  loss: 3.2854  grad_norm: 2.2959
05/10 16:26:02 - mmengine - WARNING - Reach the end of the dataloader, it will be restarted and continue to iterate. It is recommended to use `mmengine.dataset.InfiniteSampler` to enable the dataloader to iterate infinitely.
05/10 16:26:18 - mmengine - INFO - Iter(train) [   170/480000]  lr: 2.3494e-06  eta: 7 days, 21:32:52  time: 1.5534  data_time: 0.2058  memory: 9274  loss: 3.3817  grad_norm: 2.2959
05/10 16:26:34 - mmengine - INFO - Iter(train) [   180/480000]  lr: 2.4883e-06  eta: 7 days, 23:16:06  time: 1.6550  data_time: 0.0059  memory: 9274  loss: 3.2901  grad_norm: 2.2938
05/10 16:26:47 - mmengine - INFO - Iter(train) [   190/480000]  lr: 2.6272e-06  eta: 7 days, 22:01:59  time: 1.2595  data_time: 0.0056  memory: 9271  loss: 3.3561  grad_norm: 2.2938
05/10 16:27:03 - mmengine - INFO - Iter(train) [   200/480000]  lr: 2.7661e-06  eta: 7 days, 23:10:59  time: 1.5990  data_time: 0.0057  memory: 9271  loss: 3.3952  grad_norm: 2.2719
05/10 16:27:16 - mmengine - INFO - Iter(train) [   210/480000]  lr: 2.9050e-06  eta: 7 days, 22:28:28  time: 1.3235  data_time: 0.0059  memory: 9272  loss: 3.3484  grad_norm: 2.2533
05/10 16:27:29 - mmengine - INFO - Iter(train) [   220/480000]  lr: 3.0438e-06  eta: 7 days, 21:26:58  time: 1.2606  data_time: 0.0056  memory: 9274  loss: 3.3082  grad_norm: 2.2533
05/10 16:27:45 - mmengine - INFO - Iter(train) [   230/480000]  lr: 3.1827e-06  eta: 7 days, 22:18:46  time: 1.5712  data_time: 0.2906  memory: 9271  loss: 3.3281  grad_norm: 2.2419
05/10 16:27:57 - mmengine - INFO - Iter(train) [   240/480000]  lr: 3.3216e-06  eta: 7 days, 21:19:44  time: 1.2515  data_time: 0.0058  memory: 9271  loss: 3.2646  grad_norm: 2.2238
05/10 16:28:13 - mmengine - INFO - Iter(train) [   250/480000]  lr: 3.4605e-06  eta: 7 days, 22:15:45  time: 1.5966  data_time: 0.0057  memory: 9272  loss: 3.2805  grad_norm: 2.2238
05/10 16:28:26 - mmengine - INFO - Iter(train) [   260/480000]  lr: 3.5994e-06  eta: 7 days, 21:25:28  time: 1.2650  data_time: 0.0057  memory: 9272  loss: 3.2714  grad_norm: 2.1914
05/10 16:28:38 - mmengine - INFO - Iter(train) [   270/480000]  lr: 3.7383e-06  eta: 7 days, 20:32:27  time: 1.2432  data_time: 0.0056  memory: 9273  loss: 3.2438  grad_norm: 2.1914
05/10 16:28:54 - mmengine - INFO - Iter(train) [   280/480000]  lr: 3.8772e-06  eta: 7 days, 21:20:19  time: 1.5833  data_time: 0.0057  memory: 9272  loss: 3.3266  grad_norm: 2.1631
05/10 16:29:06 - mmengine - INFO - Iter(train) [   290/480000]  lr: 4.0161e-06  eta: 7 days, 20:32:04  time: 1.2467  data_time: 0.0056  memory: 9272  loss: 3.3278  grad_norm: 2.1270
05/10 16:29:22 - mmengine - INFO - Iter(train) [   300/480000]  lr: 4.1550e-06  eta: 7 days, 21:17:27  time: 1.5861  data_time: 0.0057  memory: 9272  loss: 3.2347  grad_norm: 2.1270
05/10 16:29:35 - mmengine - INFO - Iter(train) [   310/480000]  lr: 4.2939e-06  eta: 7 days, 20:46:41  time: 1.3022  data_time: 0.0059  memory: 9273  loss: 3.2324  grad_norm: 2.0812
05/10 16:29:47 - mmengine - INFO - Iter(train) [   320/480000]  lr: 4.4328e-06  eta: 7 days, 19:51:08  time: 1.1953  data_time: 0.0056  memory: 9272  loss: 3.2470  grad_norm: 2.0597
05/10 16:30:05 - mmengine - INFO - Iter(train) [   330/480000]  lr: 4.5717e-06  eta: 7 days, 21:14:17  time: 1.7540  data_time: 0.2059  memory: 9271  loss: 3.1824  grad_norm: 2.0597
05/10 16:30:18 - mmengine - INFO - Iter(train) [   340/480000]  lr: 4.7106e-06  eta: 7 days, 20:59:13  time: 1.3572  data_time: 0.0058  memory: 9274  loss: 3.2474  grad_norm: 2.0204
05/10 16:30:34 - mmengine - INFO - Iter(train) [   350/480000]  lr: 4.8495e-06  eta: 7 days, 21:30:20  time: 1.5557  data_time: 0.0058  memory: 9273  loss: 3.2077  grad_norm: 2.0204
05/10 16:30:47 - mmengine - INFO - Iter(train) [   360/480000]  lr: 4.9884e-06  eta: 7 days, 20:59:47  time: 1.2859  data_time: 0.0057  memory: 9273  loss: 3.2540  grad_norm: 1.9822
05/10 16:31:00 - mmengine - INFO - Iter(train) [   370/480000]  lr: 5.1273e-06  eta: 7 days, 20:32:00  time: 1.2910  data_time: 0.0057  memory: 9273  loss: 3.1751  grad_norm: 1.9384
05/10 16:31:15 - mmengine - INFO - Iter(train) [   380/480000]  lr: 5.2662e-06  eta: 7 days, 20:59:52  time: 1.5487  data_time: 0.0057  memory: 9272  loss: 3.2210  grad_norm: 1.9384
05/10 16:31:28 - mmengine - INFO - Iter(train) [   390/480000]  lr: 5.4051e-06  eta: 7 days, 20:29:55  time: 1.2736  data_time: 0.0056  memory: 9275  loss: 3.1692  grad_norm: 1.8984
05/10 16:31:44 - mmengine - INFO - Iter(train) [   400/480000]  lr: 5.5440e-06  eta: 7 days, 20:57:46  time: 1.5555  data_time: 0.0058  memory: 9273  loss: 3.1612  grad_norm: 1.8482
05/10 16:31:56 - mmengine - INFO - Iter(train) [   410/480000]  lr: 5.6829e-06  eta: 7 days, 20:29:37  time: 1.2752  data_time: 0.0057  memory: 9274  loss: 3.1654  grad_norm: 1.8482
05/10 16:32:09 - mmengine - INFO - Iter(train) [   420/480000]  lr: 5.8218e-06  eta: 7 days, 20:04:42  time: 1.2853  data_time: 0.0058  memory: 9272  loss: 3.1228  grad_norm: 1.7980
05/10 16:32:25 - mmengine - INFO - Iter(train) [   430/480000]  lr: 5.9607e-06  eta: 7 days, 20:32:41  time: 1.5636  data_time: 0.0058  memory: 9272  loss: 3.2019  grad_norm: 1.7980
05/10 16:32:38 - mmengine - INFO - Iter(train) [   440/480000]  lr: 6.0996e-06  eta: 7 days, 20:09:41  time: 1.2900  data_time: 0.0059  memory: 9273  loss: 3.1493  grad_norm: 1.7464
05/10 16:32:53 - mmengine - INFO - Iter(train) [   450/480000]  lr: 6.2385e-06  eta: 7 days, 20:38:17  time: 1.5749  data_time: 0.0059  memory: 9271  loss: 3.0994  grad_norm: 1.6871
05/10 16:33:06 - mmengine - INFO - Iter(train) [   460/480000]  lr: 6.3774e-06  eta: 7 days, 20:16:06  time: 1.2898  data_time: 0.0057  memory: 9273  loss: 3.0899  grad_norm: 1.6871
05/10 16:33:19 - mmengine - INFO - Iter(train) [   470/480000]  lr: 6.5163e-06  eta: 7 days, 19:53:29  time: 1.2818  data_time: 0.0058  memory: 9272  loss: 3.1314  grad_norm: 1.6450
05/10 16:33:34 - mmengine - INFO - Iter(train) [   480/480000]  lr: 6.6552e-06  eta: 7 days, 20:06:30  time: 1.4902  data_time: 0.0058  memory: 9272  loss: 3.0679  grad_norm: 1.5827
05/10 16:33:49 - mmengine - INFO - Iter(train) [   490/480000]  lr: 6.7941e-06  eta: 7 days, 20:27:23  time: 1.5417  data_time: 0.2061  memory: 9272  loss: 3.0634  grad_norm: 1.5827
05/10 16:34:05 - mmengine - INFO - Iter(train) [   500/480000]  lr: 6.9330e-06  eta: 7 days, 20:53:00  time: 1.5766  data_time: 0.0057  memory: 9272  loss: 3.0546  grad_norm: 1.5318
05/10 16:34:05 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 16:34:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
算不算精神出轨，这取决于具体情况和双方的关系。以下是一些可能的情况和相应的判断：

1. **情感关系**：如果男朋友和女主播的关系是基于情感和浪漫的，那么这种行为可能被视为精神出轨。在这种情况下，男朋友可能在追求女主播的个人兴趣和满足感，而不是出于对婚姻或家庭的忠诚。在这种情况下，男朋友的行为可能被视为一种浪漫和情感的表达，而不是一种破坏性或不道德的行为。

2. **金钱关系**：如果男朋友和女主播的关系是基于金钱和经济利益的，那么这种行为可能被视为精神出轨。在这种情况下，男朋友可能在追求女主播的经济利益，而不是出于对婚姻或家庭的忠诚。在这种情况下，男朋友的行为可能被视为一种商业和金钱的追求，而不是一种道德和情感的表达。

3. **家庭关系**：如果男朋友和女主播的关系是基于家庭和孩子的利益的，那么这种行为可能被视为精神出轨。在这种情况下，男朋友可能在追求女主播的个人兴趣和满足感，而不是出于对婚姻或家庭的忠诚。在这种情况下，男朋友的行为可能被视为一种浪漫和情感的表达，而不是一种破坏性或不道德的行为。

4. **法律关系**：如果男朋友和女主播的关系是基于法律和婚姻的，那么这种行为可能被视为精神出轨。在这种情况下，男朋友可能在追求女主播的个人兴趣和满足感，而不是出于对婚姻或家庭的忠诚。在这种情况下，男朋友的行为可能被视为一种浪漫和情感的表达，而不是一种破坏性或不道德的行为。

总的来说，是否算作精神出轨，需要根据具体情况和双方的关系来判断。如果男朋友的行为是出于对女主播的个人兴趣和满足感，而不是出于对婚姻或家庭的忠诚，那么这种行为可能被视为精神出轨。如果男朋友的行为是出于对金钱和经济利益的追求，而不是出于对婚姻或家庭的忠诚，那么这种行为可能被视为精神出轨。如果男朋友的行为是出于对家庭和孩子的利益的追求，而不是出于对婚姻或家庭的忠诚，那么这种行为可能被视为精神出轨。如果男朋友的行为是基于法律和婚姻的，那么这种行为可能被视为精神出轨。<|im_end|>

05/10 16:35:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
喝红酒养生确实可以起到一定的保健作用，但过量饮用可能会导致头晕等不适症状。红酒中的酒精成分可以刺激神经系统，使人产生兴奋和提神的感觉，但如果过量饮用，酒精会迅速被身体吸收，导致血液中的酒精浓度升高，从而影响大脑的正常功能，包括平衡感、协调性、注意力和记忆力等，从而引发头晕等不适症状。

建议在饮用红酒时，控制好饮用量，一般建议每次饮用红酒不超过两杯，且最好在饭后饮用，以减少酒精对胃肠道的刺激。此外，红酒中的单宁酸可以促进血液循环，有助于缓解疲劳和改善睡眠质量，但过量饮用可能会导致胃部不适，如胃痛、胃胀等，因此在饮用红酒时，也要注意饮食和休息，避免过度劳累。

总的来说，适量饮用红酒可以起到一定的养生作用，但过量饮用可能会带来不适，因此在饮用红酒时，应根据个人体质和饮酒习惯，合理控制饮用量，以达到养生保健的目的。<|im_end|>

05/10 16:35:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
这个情况确实有些尴尬，因为闺蜜和前任互关小红书并取关拉黑三连击，这可能意味着她们之间存在一些矛盾或者冲突。以下是一些可能的解决方案和应对策略：

1. **冷静沟通**：首先，你需要冷静下来，不要让情绪影响你的判断和行动。尝试与闺蜜进行一次坦诚的对话，表达你的感受和想法。告诉她你对前任的不满和对她的行为感到困扰，同时也要尊重她的决定和选择。你可以提出一些建设性的建议，比如一起找出问题的根源，或者寻找一个双方都能接受的解决方案。

2. **寻求第三方调解**：如果你们无法通过直接对话解决矛盾，可以考虑寻求第三方的调解。这可能是一个朋友、家人或者专业的心理咨询师。他们可以提供中立的视角，帮助你们理解对方的立场和需求，同时也可以提供一些调解的策略和技巧。

3. **尊重对方的选择**：即使你们无法达成一致，也要尊重对方的选择。前任可能有自己的原因和理由，她可能并不希望你们之间的关系受到影响。你可以理解她的立场，但也要表达你的感受和需求，让她知道你的底线和底线。

4. **寻找共同点**：尽管你们之间存在矛盾，但你们也可能有一些共同点。你可以尝试找出这些共同点，以此来建立和维护你们之间的联系。这可能包括共同的兴趣爱好、共同的价值观或者共同的目标。

5. **保持距离**：如果你们无法解决矛盾，或者你们的关系已经变得非常紧张，那么可能需要暂时保持距离。这可能意味着你们需要暂时避免互相关注或者互动，直到你们能够找到解决问题的方法。

总的来说，处理这种情况需要耐心、理解和尊重。通过冷静沟通、寻求第三方调解、尊重对方的选择、寻找共同点和保持距离，你们可以找到一个双方都能接受的解决方案，维护你们之间的关系。<|im_end|>

05/10 16:35:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
是的，建议您戒掉炸鸡，因为炸鸡中含有大量的饱和脂肪和胆固醇，长期食用可能会导致血脂升高，增加患心血管疾病的风险。建议您选择低脂、低胆固醇的食品，如鸡胸肉、鱼肉、豆腐、蔬菜等，以保持健康的饮食习惯。同时，保持适量的运动，如散步、慢跑等，也有助于降低血脂水平。如果胆固醇问题严重，建议您咨询医生，根据个人情况制定个性化的饮食和运动方案。<|im_end|>

05/10 16:36:22 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
剧本杀遇读本玩家，直接摔门离场！这种行为在剧本杀中是不被允许的，因为这不仅违反了游戏的规则，也可能会对其他玩家造成不必要的困扰和伤害。在剧本杀中，玩家需要尊重其他玩家的权益和感受，尤其是在遇到读本玩家时，更应该保持冷静和礼貌，避免直接摔门离场的行为，以避免引起不必要的冲突和不良影响。

以下是一些可能的应对方式：

1. 保持冷静：在遇到读本玩家时，首先需要保持冷静，不要因为一时的情绪激动而做出冲动的决定。可以尝试与读本玩家进行沟通，了解他们的需求和感受，看看是否可以找到解决问题的方法。

2. 询问原因：如果读本玩家是因为读不懂剧本或者对剧本内容有疑问，可以尝试与他们进行沟通，询问他们对剧本的理解和感受，看看是否可以提供一些帮助或者解释。如果读本玩家是因为对剧本内容有误解或者不理解，可以尝试引导他们理解剧本的含义和情节，或者提供一些相关的背景知识和解释。

3. 尊重他人：在沟通中，需要尊重读本玩家的权益和感受，避免直接指责或者批评他们。可以尝试用礼貌的语言和态度与他们交流，表达出对他们的理解和尊重，同时也可以表达出对剧本杀游戏规则和氛围的尊重。

4. 退出游戏：如果读本玩家的行为严重影响了游戏的氛围和体验，或者对其他玩家造成了不必要的困扰和伤害，可以考虑退出游戏。在退出游戏时，需要向其他玩家道歉，并且承诺会遵守游戏的规则和氛围，避免再次发生类似的行为。

总的来说，遇到读本玩家时，应该保持冷静，尊重他人，通过沟通和交流解决问题，避免直接摔门离场的行为，以维护游戏的和谐和秩序。<|im_end|>

05/10 16:36:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导周末发60秒语音矩阵，装没看见，这可能意味着领导没有注意到这个语音矩阵，或者领导认为这个矩阵的内容并不重要，或者领导认为这个矩阵的发布时机不合适。以下是一些可能的回应：

1. "对不起，我可能没有注意到这个语音矩阵。我可能在忙其他事情，或者这个矩阵的内容可能与我当前的工作或项目无关。如果您需要我提供任何关于这个矩阵的信息，或者有任何其他问题，我会尽力回答。"

2. "这个语音矩阵可能与我当前的工作或项目无关，我可能没有注意到。如果您需要我提供任何关于这个矩阵的信息，或者有任何其他问题，我会尽力回答。"

3. "这个语音矩阵可能与我当前的工作或项目无关，我可能没有注意到。如果您需要我提供任何关于这个矩阵的信息，或者有任何其他问题，我会尽力回答。"

4. "对不起，我可能没有注意到这个语音矩阵。我可能在忙其他事情，或者这个矩阵的内容可能与我当前的工作或项目无关。如果您需要我提供任何关于这个矩阵的信息，或者有任何其他问题，我会尽力回答。"

5. "这个语音矩阵可能与我当前的工作或项目无关，我可能没有注意到。如果您需要我提供任何关于这个矩阵的信息，或者有任何其他问题，我会尽力回答。"

请注意，这些建议可能根据领导的个性、工作风格和沟通方式有所不同。在回复时，应根据具体情况选择最合适的回应方式，以展示您的专业性和尊重。<|im_end|>

05/10 16:36:48 - mmengine - INFO - Saving checkpoint at 500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 16:37:05 - mmengine - INFO - Iter(train) [   510/480000]  lr: 7.0719e-06  eta: 9 days, 16:02:39  time: 17.9462  data_time: 16.3880  memory: 9274  loss: 3.0608  grad_norm: 1.5318
05/10 16:37:18 - mmengine - INFO - Iter(train) [   520/480000]  lr: 7.2108e-06  eta: 9 days, 14:52:28  time: 1.2873  data_time: 0.0058  memory: 9271  loss: 3.0563  grad_norm: 1.4724
05/10 16:37:33 - mmengine - INFO - Iter(train) [   530/480000]  lr: 7.3497e-06  eta: 9 days, 14:23:57  time: 1.5463  data_time: 0.0057  memory: 9272  loss: 3.0219  grad_norm: 1.4151
05/10 16:37:45 - mmengine - INFO - Iter(train) [   540/480000]  lr: 7.4886e-06  eta: 9 days, 13:11:34  time: 1.2426  data_time: 0.0056  memory: 9273  loss: 3.0106  grad_norm: 1.4151
05/10 16:37:58 - mmengine - INFO - Iter(train) [   550/480000]  lr: 7.6275e-06  eta: 9 days, 12:03:25  time: 1.2538  data_time: 0.0056  memory: 9273  loss: 3.0266  grad_norm: 1.3609
05/10 16:38:14 - mmengine - INFO - Iter(train) [   560/480000]  lr: 7.7664e-06  eta: 9 days, 11:54:18  time: 1.6505  data_time: 0.0057  memory: 9273  loss: 3.0401  grad_norm: 1.3001
05/10 16:38:27 - mmengine - INFO - Iter(train) [   570/480000]  lr: 7.9052e-06  eta: 9 days, 10:53:24  time: 1.2789  data_time: 0.0057  memory: 9272  loss: 2.9702  grad_norm: 1.3001
05/10 16:38:43 - mmengine - INFO - Iter(train) [   580/480000]  lr: 8.0441e-06  eta: 9 days, 10:36:51  time: 1.5855  data_time: 0.0059  memory: 9272  loss: 3.0030  grad_norm: 1.2477
05/10 16:38:56 - mmengine - INFO - Iter(train) [   590/480000]  lr: 8.1830e-06  eta: 9 days, 9:38:12  time: 1.2707  data_time: 0.0057  memory: 9273  loss: 2.9696  grad_norm: 1.2477
05/10 16:39:09 - mmengine - INFO - Iter(train) [   600/480000]  lr: 8.3219e-06  eta: 9 days, 8:42:33  time: 1.2785  data_time: 0.0057  memory: 9272  loss: 2.9514  grad_norm: 1.2019
05/10 16:39:24 - mmengine - INFO - Iter(train) [   610/480000]  lr: 8.4608e-06  eta: 9 days, 8:25:43  time: 1.5611  data_time: 0.0056  memory: 9271  loss: 2.9713  grad_norm: 1.1612
05/10 16:39:37 - mmengine - INFO - Iter(train) [   620/480000]  lr: 8.5997e-06  eta: 9 days, 7:31:39  time: 1.2679  data_time: 0.0057  memory: 9272  loss: 2.9770  grad_norm: 1.1612
05/10 16:39:50 - mmengine - INFO - Iter(train) [   630/480000]  lr: 8.7386e-06  eta: 9 days, 6:39:37  time: 1.2705  data_time: 0.0056  memory: 9272  loss: 2.9180  grad_norm: 1.1118
05/10 16:40:02 - mmengine - INFO - Iter(train) [   640/480000]  lr: 8.8775e-06  eta: 9 days, 5:39:33  time: 1.1933  data_time: 0.0056  memory: 9272  loss: 2.9178  grad_norm: 1.0729
05/10 16:40:17 - mmengine - INFO - Iter(train) [   650/480000]  lr: 9.0164e-06  eta: 9 days, 5:21:53  time: 1.5231  data_time: 0.2061  memory: 9273  loss: 2.9301  grad_norm: 1.0729
05/10 16:40:30 - mmengine - INFO - Iter(train) [   660/480000]  lr: 9.1553e-06  eta: 9 days, 4:38:10  time: 1.3036  data_time: 0.0057  memory: 9274  loss: 2.8806  grad_norm: 1.0490
05/10 16:40:50 - mmengine - INFO - Iter(train) [   670/480000]  lr: 9.2942e-06  eta: 9 days, 5:22:05  time: 2.0276  data_time: 0.0065  memory: 9272  loss: 2.8583  grad_norm: 1.0490
05/10 16:41:05 - mmengine - INFO - Iter(train) [   680/480000]  lr: 9.4331e-06  eta: 9 days, 5:03:24  time: 1.5059  data_time: 0.0069  memory: 9273  loss: 2.8677  grad_norm: 1.0192
05/10 16:41:17 - mmengine - INFO - Iter(train) [   690/480000]  lr: 9.5720e-06  eta: 9 days, 4:03:30  time: 1.1453  data_time: 0.0062  memory: 9273  loss: 2.8811  grad_norm: 0.9917
05/10 16:41:29 - mmengine - INFO - Iter(train) [   700/480000]  lr: 9.7109e-06  eta: 9 days, 3:20:34  time: 1.2791  data_time: 0.0057  memory: 9272  loss: 2.8394  grad_norm: 0.9917
05/10 16:41:43 - mmengine - INFO - Iter(train) [   710/480000]  lr: 9.8498e-06  eta: 9 days, 2:45:52  time: 1.3415  data_time: 0.0059  memory: 9275  loss: 2.8636  grad_norm: 0.9690
05/10 16:41:59 - mmengine - INFO - Iter(train) [   720/480000]  lr: 9.9887e-06  eta: 9 days, 2:45:13  time: 1.6397  data_time: 0.0065  memory: 9272  loss: 2.7842  grad_norm: 0.9453
05/10 16:42:12 - mmengine - INFO - Iter(train) [   730/480000]  lr: 1.0128e-05  eta: 9 days, 2:05:35  time: 1.2834  data_time: 0.0057  memory: 9272  loss: 2.7905  grad_norm: 0.9453
05/10 16:42:26 - mmengine - INFO - Iter(train) [   740/480000]  lr: 1.0266e-05  eta: 9 days, 1:37:15  time: 1.3781  data_time: 0.0057  memory: 9272  loss: 2.9071  grad_norm: 0.9252
05/10 16:42:38 - mmengine - INFO - Iter(train) [   750/480000]  lr: 1.0405e-05  eta: 9 days, 0:57:37  time: 1.2652  data_time: 0.0058  memory: 9272  loss: 2.7730  grad_norm: 0.9252
05/10 16:42:54 - mmengine - INFO - Iter(train) [   760/480000]  lr: 1.0544e-05  eta: 9 days, 0:51:18  time: 1.5721  data_time: 0.0060  memory: 9271  loss: 2.8187  grad_norm: 0.9089
05/10 16:43:07 - mmengine - INFO - Iter(train) [   770/480000]  lr: 1.0683e-05  eta: 9 days, 0:19:22  time: 1.3238  data_time: 0.0060  memory: 9272  loss: 2.7169  grad_norm: 0.8902
05/10 16:43:20 - mmengine - INFO - Iter(train) [   780/480000]  lr: 1.0822e-05  eta: 8 days, 23:43:07  time: 1.2737  data_time: 0.0057  memory: 9271  loss: 2.7947  grad_norm: 0.8902
05/10 16:43:36 - mmengine - INFO - Iter(train) [   790/480000]  lr: 1.0961e-05  eta: 8 days, 23:36:13  time: 1.5550  data_time: 0.0060  memory: 9272  loss: 2.8181  grad_norm: 0.8711
05/10 16:43:48 - mmengine - INFO - Iter(train) [   800/480000]  lr: 1.1100e-05  eta: 8 days, 22:52:42  time: 1.1864  data_time: 0.0057  memory: 9272  loss: 2.7516  grad_norm: 0.8485
05/10 16:44:05 - mmengine - INFO - Iter(train) [   810/480000]  lr: 1.1239e-05  eta: 8 days, 23:06:57  time: 1.7616  data_time: 0.2059  memory: 9272  loss: 2.7779  grad_norm: 0.8485
05/10 16:44:18 - mmengine - INFO - Iter(train) [   820/480000]  lr: 1.1378e-05  eta: 8 days, 22:36:39  time: 1.3077  data_time: 0.0063  memory: 9272  loss: 2.7418  grad_norm: 0.8114
05/10 16:44:31 - mmengine - INFO - Iter(train) [   830/480000]  lr: 1.1517e-05  eta: 8 days, 22:03:11  time: 1.2674  data_time: 0.0056  memory: 9273  loss: 2.7282  grad_norm: 0.8114
05/10 16:44:46 - mmengine - INFO - Iter(train) [   840/480000]  lr: 1.1655e-05  eta: 8 days, 21:57:07  time: 1.5471  data_time: 0.0059  memory: 9272  loss: 2.7329  grad_norm: 0.7929
05/10 16:44:59 - mmengine - INFO - Iter(train) [   850/480000]  lr: 1.1794e-05  eta: 8 days, 21:24:20  time: 1.2614  data_time: 0.0056  memory: 9271  loss: 2.7333  grad_norm: 0.7772
05/10 16:45:14 - mmengine - INFO - Iter(train) [   860/480000]  lr: 1.1933e-05  eta: 8 days, 21:16:35  time: 1.5228  data_time: 0.0056  memory: 9272  loss: 2.7135  grad_norm: 0.7772
05/10 16:45:27 - mmengine - INFO - Iter(train) [   870/480000]  lr: 1.2072e-05  eta: 8 days, 20:48:37  time: 1.3007  data_time: 0.0059  memory: 9273  loss: 2.6269  grad_norm: 0.7589
05/10 16:45:40 - mmengine - INFO - Iter(train) [   880/480000]  lr: 1.2211e-05  eta: 8 days, 20:18:06  time: 1.2656  data_time: 0.0057  memory: 9273  loss: 2.6451  grad_norm: 0.7436
05/10 16:45:55 - mmengine - INFO - Iter(train) [   890/480000]  lr: 1.2350e-05  eta: 8 days, 20:13:08  time: 1.5428  data_time: 0.0058  memory: 9271  loss: 2.5947  grad_norm: 0.7436
05/10 16:46:08 - mmengine - INFO - Iter(train) [   900/480000]  lr: 1.2489e-05  eta: 8 days, 19:43:37  time: 1.2649  data_time: 0.0057  memory: 9274  loss: 2.6791  grad_norm: 0.7235
05/10 16:46:23 - mmengine - INFO - Iter(train) [   910/480000]  lr: 1.2628e-05  eta: 8 days, 19:37:36  time: 1.5254  data_time: 0.0057  memory: 9272  loss: 2.6580  grad_norm: 0.7235
05/10 16:46:36 - mmengine - INFO - Iter(train) [   920/480000]  lr: 1.2767e-05  eta: 8 days, 19:11:37  time: 1.2938  data_time: 0.0059  memory: 9271  loss: 2.6010  grad_norm: 0.7074
05/10 16:46:49 - mmengine - INFO - Iter(train) [   930/480000]  lr: 1.2906e-05  eta: 8 days, 18:44:00  time: 1.2684  data_time: 0.0057  memory: 9273  loss: 2.6136  grad_norm: 0.6960
05/10 16:47:04 - mmengine - INFO - Iter(train) [   940/480000]  lr: 1.3044e-05  eta: 8 days, 18:41:50  time: 1.5612  data_time: 0.0059  memory: 9272  loss: 2.5565  grad_norm: 0.6960
05/10 16:47:17 - mmengine - INFO - Iter(train) [   950/480000]  lr: 1.3183e-05  eta: 8 days, 18:14:15  time: 1.2583  data_time: 0.0056  memory: 9271  loss: 2.5855  grad_norm: 0.6862
05/10 16:47:29 - mmengine - INFO - Iter(train) [   960/480000]  lr: 1.3322e-05  eta: 8 days, 17:40:16  time: 1.1744  data_time: 0.0056  memory: 9273  loss: 2.6809  grad_norm: 0.6780
05/10 16:47:46 - mmengine - INFO - Iter(train) [   970/480000]  lr: 1.3461e-05  eta: 8 days, 17:53:49  time: 1.7436  data_time: 0.4484  memory: 9272  loss: 2.6342  grad_norm: 0.6780
05/10 16:47:59 - mmengine - INFO - Iter(train) [   980/480000]  lr: 1.3600e-05  eta: 8 days, 17:28:13  time: 1.2665  data_time: 0.0057  memory: 9272  loss: 2.5864  grad_norm: 0.6691
05/10 16:48:15 - mmengine - INFO - Iter(train) [   990/480000]  lr: 1.3739e-05  eta: 8 days, 17:27:24  time: 1.5672  data_time: 0.0059  memory: 9272  loss: 2.5641  grad_norm: 0.6691
05/10 16:48:27 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 16:48:27 - mmengine - INFO - Iter(train) [  1000/480000]  lr: 1.3878e-05  eta: 8 days, 17:02:41  time: 1.2680  data_time: 0.0058  memory: 9273  loss: 2.5251  grad_norm: 0.6584
05/10 16:48:27 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 16:48:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
算不算精神出轨，这取决于具体情况和双方的沟通和理解。如果男朋友明确表示他只是在为女主播刷火箭，而没有其他不正当的意图，那么这可能并不算精神出轨。然而，如果男朋友的行为有其他不正当的意图，比如频繁与女主播进行不正当的互动，或者在直播过程中表现出明显的不忠，那么这可能就构成了精神出轨。在这种情况下，建议男朋友和女主播进行深入的沟通，了解对方的想法和感受，同时也需要考虑自己的行为是否符合道德和法律规范。如果情况严重，可能需要寻求专业的心理咨询师的帮助。<|im_end|>

05/10 16:48:47 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
这听起来像是你喝红酒后出现了不适反应。红酒中的某些成分，如单宁，可能会导致一些人感到头晕。如果你感到不适，建议你先停止饮用红酒，休息一下，如果症状持续或加重，最好咨询医生或营养师的意见。同时，下次在饮用红酒前，可以先了解红酒的成分和可能的副作用，以避免类似的情况再次发生。<|im_end|>

05/10 16:48:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
哎呀，听起来好不舒服啊！这种行为真的很不礼貌，而且也侵犯了你的隐私权。你可以尝试和闺蜜沟通，告诉她你对这种行为的感受，看看能否找到一个解决办法。如果她还是坚持这样做，你可以考虑向平台举报，让他们介入处理。同时，也要注意保护自己的隐私，避免再次受到伤害。<|im_end|>

05/10 16:48:59 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
是的，建议您尽量减少食用炸鸡等高胆固醇食物，可以尝试一些低脂、低盐、高纤维的食物，如鸡胸肉、鱼、豆腐、蔬菜等，以帮助降低胆固醇水平。同时，保持适量的运动和良好的生活习惯也有助于改善血脂状况。如果需要更具体的饮食建议，建议您咨询专业的营养师或医生。<|im_end|>

05/10 16:49:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
抱歉听到这个消息，希望你的心情能够尽快恢复。如果你需要任何帮助或者支持，随时告诉我，我会尽力提供支持和建议。<|im_end|>

05/10 16:49:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
领导，您周末发的语音矩阵我已经收到了，但是可能有些地方我还没有注意到。如果您需要我帮忙查看或者处理，我会尽力的。请问您需要我做什么呢？<|im_end|>

05/10 16:49:04 - mmengine - INFO - Saving checkpoint at 1000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 16:49:20 - mmengine - INFO - Iter(train) [  1010/480000]  lr: 1.4017e-05  eta: 8 days, 21:59:00  time: 5.3233  data_time: 3.7657  memory: 9272  loss: 2.5203  grad_norm: 0.6461
05/10 16:49:33 - mmengine - INFO - Iter(train) [  1020/480000]  lr: 1.4156e-05  eta: 8 days, 21:31:57  time: 1.2659  data_time: 0.0057  memory: 9272  loss: 2.4724  grad_norm: 0.6461
05/10 16:49:46 - mmengine - INFO - Iter(train) [  1030/480000]  lr: 1.4295e-05  eta: 8 days, 21:05:21  time: 1.2652  data_time: 0.0057  memory: 9272  loss: 2.5217  grad_norm: 0.6286
05/10 16:50:01 - mmengine - INFO - Iter(train) [  1040/480000]  lr: 1.4433e-05  eta: 8 days, 21:00:56  time: 1.5474  data_time: 0.0057  memory: 9272  loss: 2.5625  grad_norm: 0.6220
05/10 16:50:14 - mmengine - INFO - Iter(train) [  1050/480000]  lr: 1.4572e-05  eta: 8 days, 20:34:47  time: 1.2607  data_time: 0.0057  memory: 9273  loss: 2.5145  grad_norm: 0.6220
05/10 16:50:29 - mmengine - INFO - Iter(train) [  1060/480000]  lr: 1.4711e-05  eta: 8 days, 20:31:05  time: 1.5524  data_time: 0.0057  memory: 9271  loss: 2.5814  grad_norm: 0.6165
05/10 16:50:42 - mmengine - INFO - Iter(train) [  1070/480000]  lr: 1.4850e-05  eta: 8 days, 20:06:15  time: 1.2679  data_time: 0.0057  memory: 9272  loss: 2.5376  grad_norm: 0.6165
05/10 16:50:55 - mmengine - INFO - Iter(train) [  1080/480000]  lr: 1.4989e-05  eta: 8 days, 19:42:01  time: 1.2702  data_time: 0.0057  memory: 9272  loss: 2.4536  grad_norm: 0.6083
05/10 16:51:10 - mmengine - INFO - Iter(train) [  1090/480000]  lr: 1.5128e-05  eta: 8 days, 19:39:23  time: 1.5589  data_time: 0.0057  memory: 9271  loss: 2.4513  grad_norm: 0.6003
05/10 16:51:23 - mmengine - INFO - Iter(train) [  1100/480000]  lr: 1.5267e-05  eta: 8 days, 19:15:50  time: 1.2703  data_time: 0.0058  memory: 9271  loss: 2.4431  grad_norm: 0.6003
05/10 16:51:39 - mmengine - INFO - Iter(train) [  1110/480000]  lr: 1.5406e-05  eta: 8 days, 19:12:49  time: 1.5496  data_time: 0.0059  memory: 9271  loss: 2.4627  grad_norm: 0.5913
05/10 16:51:50 - mmengine - INFO - Iter(train) [  1120/480000]  lr: 1.5545e-05  eta: 8 days, 18:43:06  time: 1.1747  data_time: 0.0056  memory: 9272  loss: 2.4751  grad_norm: 0.5879
05/10 16:52:05 - mmengine - INFO - Iter(train) [  1130/480000]  lr: 1.5683e-05  eta: 8 days, 18:35:18  time: 1.4774  data_time: 0.2059  memory: 9271  loss: 2.4162  grad_norm: 0.5879
05/10 16:52:21 - mmengine - INFO - Iter(train) [  1140/480000]  lr: 1.5822e-05  eta: 8 days, 18:32:37  time: 1.5485  data_time: 0.0059  memory: 9271  loss: 2.4676  grad_norm: 0.5832
05/10 16:52:33 - mmengine - INFO - Iter(train) [  1150/480000]  lr: 1.5961e-05  eta: 8 days, 18:10:04  time: 1.2618  data_time: 0.0057  memory: 9271  loss: 2.4436  grad_norm: 0.5832
05/10 16:52:49 - mmengine - INFO - Iter(train) [  1160/480000]  lr: 1.6100e-05  eta: 8 days, 18:06:57  time: 1.5384  data_time: 0.0059  memory: 9273  loss: 2.4623  grad_norm: 0.5792
05/10 16:53:01 - mmengine - INFO - Iter(train) [  1170/480000]  lr: 1.6239e-05  eta: 8 days, 17:44:46  time: 1.2583  data_time: 0.0056  memory: 9272  loss: 2.4339  grad_norm: 0.5753
05/10 16:53:14 - mmengine - INFO - Iter(train) [  1180/480000]  lr: 1.6378e-05  eta: 8 days, 17:24:04  time: 1.2748  data_time: 0.0057  memory: 9272  loss: 2.3936  grad_norm: 0.5753
05/10 16:53:29 - mmengine - INFO - Iter(train) [  1190/480000]  lr: 1.6517e-05  eta: 8 days, 17:21:25  time: 1.5388  data_time: 0.0060  memory: 9272  loss: 2.3384  grad_norm: 0.5701
05/10 16:53:42 - mmengine - INFO - Iter(train) [  1200/480000]  lr: 1.6656e-05  eta: 8 days, 17:02:10  time: 1.2886  data_time: 0.0058  memory: 9272  loss: 2.3225  grad_norm: 0.5640
05/10 16:53:57 - mmengine - INFO - Iter(train) [  1210/480000]  lr: 1.6795e-05  eta: 8 days, 16:57:53  time: 1.5106  data_time: 0.0060  memory: 9271  loss: 2.3828  grad_norm: 0.5640
05/10 16:54:10 - mmengine - INFO - Iter(train) [  1220/480000]  lr: 1.6934e-05  eta: 8 days, 16:39:27  time: 1.2935  data_time: 0.0060  memory: 9272  loss: 2.3419  grad_norm: 0.5602
05/10 16:54:23 - mmengine - INFO - Iter(train) [  1230/480000]  lr: 1.7072e-05  eta: 8 days, 16:21:31  time: 1.2965  data_time: 0.0059  memory: 9271  loss: 2.3986  grad_norm: 0.5602
05/10 16:54:38 - mmengine - INFO - Iter(train) [  1240/480000]  lr: 1.7211e-05  eta: 8 days, 16:17:41  time: 1.5113  data_time: 0.0058  memory: 9273  loss: 2.3014  grad_norm: 0.5554
05/10 16:54:51 - mmengine - INFO - Iter(train) [  1250/480000]  lr: 1.7350e-05  eta: 8 days, 15:59:31  time: 1.2856  data_time: 0.0058  memory: 9271  loss: 2.3819  grad_norm: 0.5576
05/10 16:55:06 - mmengine - INFO - Iter(train) [  1260/480000]  lr: 1.7489e-05  eta: 8 days, 15:55:27  time: 1.5041  data_time: 0.0059  memory: 9274  loss: 2.3785  grad_norm: 0.5576
05/10 16:55:19 - mmengine - INFO - Iter(train) [  1270/480000]  lr: 1.7628e-05  eta: 8 days, 15:37:46  time: 1.2862  data_time: 0.0058  memory: 9274  loss: 2.3563  grad_norm: 0.5579
05/10 16:55:31 - mmengine - INFO - Iter(train) [  1280/480000]  lr: 1.7767e-05  eta: 8 days, 15:15:17  time: 1.2047  data_time: 0.0058  memory: 9271  loss: 2.3036  grad_norm: 0.5513
05/10 16:55:46 - mmengine - INFO - Iter(train) [  1290/480000]  lr: 1.7906e-05  eta: 8 days, 15:11:28  time: 1.5012  data_time: 0.2061  memory: 9272  loss: 2.3399  grad_norm: 0.5513
05/10 16:56:02 - mmengine - INFO - Iter(train) [  1300/480000]  lr: 1.8045e-05  eta: 8 days, 15:15:43  time: 1.6315  data_time: 0.0060  memory: 9272  loss: 2.3140  grad_norm: 0.5444
05/10 16:56:15 - mmengine - INFO - Iter(train) [  1310/480000]  lr: 1.8184e-05  eta: 8 days, 14:58:46  time: 1.2847  data_time: 0.0059  memory: 9272  loss: 2.3484  grad_norm: 0.5444
05/10 16:56:30 - mmengine - INFO - Iter(train) [  1320/480000]  lr: 1.8323e-05  eta: 8 days, 14:55:58  time: 1.5146  data_time: 0.0060  memory: 9271  loss: 2.3194  grad_norm: 0.5362
05/10 16:56:43 - mmengine - INFO - Iter(train) [  1330/480000]  lr: 1.8461e-05  eta: 8 days, 14:40:17  time: 1.2991  data_time: 0.0058  memory: 9272  loss: 2.2667  grad_norm: 0.5278
05/10 16:56:56 - mmengine - INFO - Iter(train) [  1340/480000]  lr: 1.8600e-05  eta: 8 days, 14:24:21  time: 1.2911  data_time: 0.0059  memory: 9273  loss: 2.2785  grad_norm: 0.5278
05/10 16:57:12 - mmengine - INFO - Iter(train) [  1350/480000]  lr: 1.8739e-05  eta: 8 days, 14:22:24  time: 1.5237  data_time: 0.0059  memory: 9271  loss: 2.2518  grad_norm: 0.5225
05/10 16:57:24 - mmengine - INFO - Iter(train) [  1360/480000]  lr: 1.8878e-05  eta: 8 days, 14:06:39  time: 1.2881  data_time: 0.0058  memory: 9273  loss: 2.2950  grad_norm: 0.5177
05/10 16:57:40 - mmengine - INFO - Iter(train) [  1370/480000]  lr: 1.9017e-05  eta: 8 days, 14:04:13  time: 1.5127  data_time: 0.0060  memory: 9272  loss: 2.3000  grad_norm: 0.5177
05/10 16:57:53 - mmengine - INFO - Iter(train) [  1380/480000]  lr: 1.9156e-05  eta: 8 days, 13:50:22  time: 1.3148  data_time: 0.0060  memory: 9271  loss: 2.2927  grad_norm: 0.5128
05/10 16:58:06 - mmengine - INFO - Iter(train) [  1390/480000]  lr: 1.9295e-05  eta: 8 days, 13:36:17  time: 1.3075  data_time: 0.0058  memory: 9271  loss: 2.2763  grad_norm: 0.5128
05/10 16:58:21 - mmengine - INFO - Iter(train) [  1400/480000]  lr: 1.9434e-05  eta: 8 days, 13:35:34  time: 1.5383  data_time: 0.0059  memory: 9272  loss: 2.2208  grad_norm: 0.5102
05/10 16:58:34 - mmengine - INFO - Iter(train) [  1410/480000]  lr: 1.9573e-05  eta: 8 days, 13:21:25  time: 1.3008  data_time: 0.0057  memory: 9272  loss: 2.2531  grad_norm: 0.5002
05/10 16:58:47 - mmengine - INFO - Iter(train) [  1420/480000]  lr: 1.9712e-05  eta: 8 days, 13:08:10  time: 1.3134  data_time: 0.0058  memory: 9272  loss: 2.2891  grad_norm: 0.5002
05/10 16:59:03 - mmengine - INFO - Iter(train) [  1430/480000]  lr: 1.9850e-05  eta: 8 days, 13:10:22  time: 1.5874  data_time: 0.0060  memory: 9272  loss: 2.2742  grad_norm: 0.4906
05/10 16:59:15 - mmengine - INFO - Iter(train) [  1440/480000]  lr: 1.9989e-05  eta: 8 days, 12:50:10  time: 1.1831  data_time: 0.0058  memory: 9272  loss: 2.2007  grad_norm: 0.4844
05/10 16:59:30 - mmengine - INFO - Iter(train) [  1450/480000]  lr: 2.0128e-05  eta: 8 days, 12:45:52  time: 1.4674  data_time: 0.2060  memory: 9272  loss: 2.2495  grad_norm: 0.4844
05/10 16:59:45 - mmengine - INFO - Iter(train) [  1460/480000]  lr: 2.0267e-05  eta: 8 days, 12:42:40  time: 1.4866  data_time: 0.0059  memory: 9271  loss: 2.2330  grad_norm: 0.4794
05/10 16:59:57 - mmengine - INFO - Iter(train) [  1470/480000]  lr: 2.0406e-05  eta: 8 days, 12:26:41  time: 1.2502  data_time: 0.0058  memory: 9273  loss: 2.2482  grad_norm: 0.4794
05/10 17:00:12 - mmengine - INFO - Iter(train) [  1480/480000]  lr: 2.0545e-05  eta: 8 days, 12:23:30  time: 1.4838  data_time: 0.0059  memory: 9271  loss: 2.1931  grad_norm: 0.4764
05/10 17:00:25 - mmengine - INFO - Iter(train) [  1490/480000]  lr: 2.0684e-05  eta: 8 days, 12:08:40  time: 1.2652  data_time: 0.0058  memory: 9272  loss: 2.1858  grad_norm: 0.4758
05/10 17:00:37 - mmengine - INFO - Iter(train) [  1500/480000]  lr: 2.0823e-05  eta: 8 days, 11:53:03  time: 1.2469  data_time: 0.0057  memory: 9271  loss: 2.2175  grad_norm: 0.4758
05/10 17:00:37 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 17:00:46 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这男朋友是想让女主播给他送火箭吗？不过别担心，出轨这种事情，有时候就是“出轨”本身，不是出轨对象。不过，下次记得，别让火箭成为你精神出轨的“火箭”，要保持理智，别让感情成为你生活的“火箭”。毕竟，爱情是两个人的事，别让火箭成为你生活的全部。<|im_end|>

05/10 17:00:50 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这养生方式也太离谱了吧？红酒养生？你这养生水平堪比树懒，连头晕都得喝红酒来缓解？下次记得，养生要科学，别让红酒成为你的“毒药”。<|im_end|>

05/10 17:00:54 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这闺蜜是想把前任变成你的“小红书”吗？不过别担心，我这就帮你把她们拉黑，让你的“小红书”重新焕发生机！<|im_end|>

05/10 17:01:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点让人担心呢。胆固醇高确实需要注意饮食，但是炸鸡的热量确实比较高，适量食用还是可以的。你可以尝试一些低脂、低热量的替代品，比如烤鸡胸肉、蒸鱼等，同时也要注意饮食均衡，多吃蔬菜水果，保持良好的生活习惯哦。如果需要更多的建议或者帮助，可以告诉我哦。<|im_end|>

05/10 17:01:05 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直比电视剧里的主角还高冷，下次记得带个防滑垫，不然下次再遇到这种尴尬情况，你得准备去健身房锻炼一下，不然我得帮你找找有没有适合的剧本。<|im_end|>

05/10 17:01:09 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，领导发语音矩阵确实挺让人头疼的呢。不过别太担心，我们可以一起想想办法，让领导看到我们的努力和态度。如果需要我帮你想想办法，或者有什么我能做的，随时告诉我哦~<|im_end|>

05/10 17:01:09 - mmengine - INFO - Saving checkpoint at 1500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 17:01:25 - mmengine - INFO - Iter(train) [  1510/480000]  lr: 2.0962e-05  eta: 8 days, 14:46:43  time: 4.8270  data_time: 3.3360  memory: 9273  loss: 2.1861  grad_norm: 0.4745
05/10 17:01:38 - mmengine - INFO - Iter(train) [  1520/480000]  lr: 2.1100e-05  eta: 8 days, 14:30:31  time: 1.2520  data_time: 0.0057  memory: 9272  loss: 2.1967  grad_norm: 0.4721
05/10 17:01:50 - mmengine - INFO - Iter(train) [  1530/480000]  lr: 2.1239e-05  eta: 8 days, 14:13:37  time: 1.2345  data_time: 0.0056  memory: 9272  loss: 2.2507  grad_norm: 0.4721
05/10 17:02:06 - mmengine - INFO - Iter(train) [  1540/480000]  lr: 2.1378e-05  eta: 8 days, 14:13:57  time: 1.5632  data_time: 0.0059  memory: 9272  loss: 2.1618  grad_norm: 0.4711
05/10 17:02:18 - mmengine - INFO - Iter(train) [  1550/480000]  lr: 2.1517e-05  eta: 8 days, 13:57:39  time: 1.2397  data_time: 0.0059  memory: 9271  loss: 2.1818  grad_norm: 0.4711
05/10 17:02:33 - mmengine - INFO - Iter(train) [  1560/480000]  lr: 2.1656e-05  eta: 8 days, 13:52:45  time: 1.4591  data_time: 0.0057  memory: 9272  loss: 2.1598  grad_norm: 0.4652
05/10 17:02:45 - mmengine - INFO - Iter(train) [  1570/480000]  lr: 2.1795e-05  eta: 8 days, 13:37:17  time: 1.2497  data_time: 0.0057  memory: 9273  loss: 2.1546  grad_norm: 0.4608
05/10 17:02:58 - mmengine - INFO - Iter(train) [  1580/480000]  lr: 2.1934e-05  eta: 8 days, 13:21:13  time: 1.2339  data_time: 0.0055  memory: 9272  loss: 2.1806  grad_norm: 0.4608
05/10 17:03:13 - mmengine - INFO - Iter(train) [  1590/480000]  lr: 2.2073e-05  eta: 8 days, 13:20:14  time: 1.5306  data_time: 0.0057  memory: 9272  loss: 2.1957  grad_norm: 0.4621
05/10 17:03:24 - mmengine - INFO - Iter(train) [  1600/480000]  lr: 2.2212e-05  eta: 8 days, 13:00:21  time: 1.1516  data_time: 0.0054  memory: 9272  loss: 2.2645  grad_norm: 0.4669
05/10 17:03:42 - mmengine - INFO - Iter(train) [  1610/480000]  lr: 2.2351e-05  eta: 8 days, 13:08:57  time: 1.7215  data_time: 0.2058  memory: 9272  loss: 2.1696  grad_norm: 0.4669
05/10 17:03:54 - mmengine - INFO - Iter(train) [  1620/480000]  lr: 2.2489e-05  eta: 8 days, 12:55:34  time: 1.2770  data_time: 0.0057  memory: 9273  loss: 2.1275  grad_norm: 0.4729
05/10 17:04:07 - mmengine - INFO - Iter(train) [  1630/480000]  lr: 2.2628e-05  eta: 8 days, 12:40:18  time: 1.2352  data_time: 0.0056  memory: 9274  loss: 2.1513  grad_norm: 0.4729
05/10 17:04:22 - mmengine - INFO - Iter(train) [  1640/480000]  lr: 2.2767e-05  eta: 8 days, 12:39:16  time: 1.5246  data_time: 0.0058  memory: 9273  loss: 2.1200  grad_norm: 0.4791
05/10 17:04:34 - mmengine - INFO - Iter(train) [  1650/480000]  lr: 2.2906e-05  eta: 8 days, 12:24:09  time: 1.2324  data_time: 0.0056  memory: 9271  loss: 2.1670  grad_norm: 0.4790
05/10 17:04:49 - mmengine - INFO - Iter(train) [  1660/480000]  lr: 2.3045e-05  eta: 8 days, 12:21:30  time: 1.4886  data_time: 0.0057  memory: 9270  loss: 2.1094  grad_norm: 0.4790
05/10 17:05:02 - mmengine - INFO - Iter(train) [  1670/480000]  lr: 2.3184e-05  eta: 8 days, 12:08:55  time: 1.2795  data_time: 0.0059  memory: 9272  loss: 2.1325  grad_norm: 0.4844
05/10 17:05:14 - mmengine - INFO - Iter(train) [  1680/480000]  lr: 2.3323e-05  eta: 8 days, 11:54:11  time: 1.2314  data_time: 0.0056  memory: 9273  loss: 2.1685  grad_norm: 0.4900
05/10 17:05:29 - mmengine - INFO - Iter(train) [  1690/480000]  lr: 2.3462e-05  eta: 8 days, 11:52:40  time: 1.5080  data_time: 0.0059  memory: 9273  loss: 2.1636  grad_norm: 0.4900
05/10 17:05:42 - mmengine - INFO - Iter(train) [  1700/480000]  lr: 2.3601e-05  eta: 8 days, 11:38:23  time: 1.2355  data_time: 0.0057  memory: 9272  loss: 2.0813  grad_norm: 0.4891
05/10 17:05:54 - mmengine - INFO - Iter(train) [  1710/480000]  lr: 2.3740e-05  eta: 8 days, 11:24:01  time: 1.2300  data_time: 0.0056  memory: 9272  loss: 2.0992  grad_norm: 0.4891
05/10 17:06:09 - mmengine - INFO - Iter(train) [  1720/480000]  lr: 2.3878e-05  eta: 8 days, 11:23:42  time: 1.5297  data_time: 0.0058  memory: 9272  loss: 2.1735  grad_norm: 0.4941
05/10 17:06:22 - mmengine - INFO - Iter(train) [  1730/480000]  lr: 2.4017e-05  eta: 8 days, 11:09:43  time: 1.2328  data_time: 0.0055  memory: 9272  loss: 2.0671  grad_norm: 0.5000
05/10 17:06:37 - mmengine - INFO - Iter(train) [  1740/480000]  lr: 2.4156e-05  eta: 8 days, 11:08:24  time: 1.5061  data_time: 0.0057  memory: 9271  loss: 2.1362  grad_norm: 0.5000
05/10 17:06:49 - mmengine - INFO - Iter(train) [  1750/480000]  lr: 2.4295e-05  eta: 8 days, 10:55:21  time: 1.2480  data_time: 0.0057  memory: 9272  loss: 2.1183  grad_norm: 0.4996
05/10 17:07:01 - mmengine - INFO - Iter(train) [  1760/480000]  lr: 2.4434e-05  eta: 8 days, 10:37:54  time: 1.1478  data_time: 0.0055  memory: 9273  loss: 2.1412  grad_norm: 0.5010
05/10 17:07:16 - mmengine - INFO - Iter(train) [  1770/480000]  lr: 2.4573e-05  eta: 8 days, 10:36:40  time: 1.5036  data_time: 0.2060  memory: 9274  loss: 2.1523  grad_norm: 0.5010
05/10 17:07:32 - mmengine - INFO - Iter(train) [  1780/480000]  lr: 2.4712e-05  eta: 8 days, 10:42:57  time: 1.6714  data_time: 0.0064  memory: 9273  loss: 2.1033  grad_norm: 0.4983
05/10 17:07:45 - mmengine - INFO - Iter(train) [  1790/480000]  lr: 2.4851e-05  eta: 8 days, 10:31:22  time: 1.2715  data_time: 0.0059  memory: 9272  loss: 2.0866  grad_norm: 0.4983
05/10 17:07:59 - mmengine - INFO - Iter(train) [  1800/480000]  lr: 2.4990e-05  eta: 8 days, 10:23:31  time: 1.3528  data_time: 0.0056  memory: 9272  loss: 2.1059  grad_norm: 0.4943
05/10 17:08:11 - mmengine - INFO - Iter(train) [  1810/480000]  lr: 2.5128e-05  eta: 8 days, 10:10:45  time: 1.2396  data_time: 0.0056  memory: 9272  loss: 2.0985  grad_norm: 0.4980
05/10 17:08:23 - mmengine - INFO - Iter(train) [  1820/480000]  lr: 2.5267e-05  eta: 8 days, 9:57:56  time: 1.2354  data_time: 0.0055  memory: 9273  loss: 2.0823  grad_norm: 0.4980
05/10 17:08:39 - mmengine - INFO - Iter(train) [  1830/480000]  lr: 2.5406e-05  eta: 8 days, 10:00:20  time: 1.5812  data_time: 0.0060  memory: 9271  loss: 2.0763  grad_norm: 0.4963
05/10 17:08:52 - mmengine - INFO - Iter(train) [  1840/480000]  lr: 2.5545e-05  eta: 8 days, 9:47:41  time: 1.2346  data_time: 0.0055  memory: 9273  loss: 2.0965  grad_norm: 0.4954
05/10 17:09:06 - mmengine - INFO - Iter(train) [  1850/480000]  lr: 2.5684e-05  eta: 8 days, 9:45:11  time: 1.4673  data_time: 0.0056  memory: 9271  loss: 2.0348  grad_norm: 0.4954
05/10 17:09:19 - mmengine - INFO - Iter(train) [  1860/480000]  lr: 2.5823e-05  eta: 8 days, 9:34:35  time: 1.2774  data_time: 0.0058  memory: 9272  loss: 2.0604  grad_norm: 0.4956
05/10 17:09:31 - mmengine - INFO - Iter(train) [  1870/480000]  lr: 2.5962e-05  eta: 8 days, 9:22:09  time: 1.2317  data_time: 0.0057  memory: 9271  loss: 1.9795  grad_norm: 0.4956
05/10 17:09:47 - mmengine - INFO - Iter(train) [  1880/480000]  lr: 2.6101e-05  eta: 8 days, 9:22:34  time: 1.5320  data_time: 0.0059  memory: 9271  loss: 2.0787  grad_norm: 0.4943
05/10 17:09:59 - mmengine - INFO - Iter(train) [  1890/480000]  lr: 2.6240e-05  eta: 8 days, 9:10:21  time: 1.2326  data_time: 0.0055  memory: 9273  loss: 2.0520  grad_norm: 0.4917
05/10 17:10:12 - mmengine - INFO - Iter(train) [  1900/480000]  lr: 2.6379e-05  eta: 8 days, 8:58:47  time: 1.2450  data_time: 0.0058  memory: 9272  loss: 2.0218  grad_norm: 0.4917
05/10 17:10:27 - mmengine - INFO - Iter(train) [  1910/480000]  lr: 2.6517e-05  eta: 8 days, 8:59:06  time: 1.5269  data_time: 0.0059  memory: 9271  loss: 2.0442  grad_norm: 0.4949
05/10 17:10:39 - mmengine - INFO - Iter(train) [  1920/480000]  lr: 2.6656e-05  eta: 8 days, 8:45:23  time: 1.1890  data_time: 0.0056  memory: 9272  loss: 2.0029  grad_norm: 0.4940
05/10 17:10:55 - mmengine - INFO - Iter(train) [  1930/480000]  lr: 2.6795e-05  eta: 8 days, 8:51:10  time: 1.6578  data_time: 0.2060  memory: 9271  loss: 2.0724  grad_norm: 0.4940
05/10 17:11:08 - mmengine - INFO - Iter(train) [  1940/480000]  lr: 2.6934e-05  eta: 8 days, 8:40:33  time: 1.2603  data_time: 0.0058  memory: 9272  loss: 2.0335  grad_norm: 0.4971
05/10 17:11:20 - mmengine - INFO - Iter(train) [  1950/480000]  lr: 2.7073e-05  eta: 8 days, 8:30:01  time: 1.2595  data_time: 0.0057  memory: 9271  loss: 2.0239  grad_norm: 0.4971
05/10 17:11:35 - mmengine - INFO - Iter(train) [  1960/480000]  lr: 2.7212e-05  eta: 8 days, 8:28:11  time: 1.4709  data_time: 0.0058  memory: 9271  loss: 2.0280  grad_norm: 0.4989
05/10 17:11:48 - mmengine - INFO - Iter(train) [  1970/480000]  lr: 2.7351e-05  eta: 8 days, 8:17:37  time: 1.2547  data_time: 0.0057  memory: 9271  loss: 2.0385  grad_norm: 0.5024
05/10 17:12:02 - mmengine - INFO - Iter(train) [  1980/480000]  lr: 2.7490e-05  eta: 8 days, 8:15:36  time: 1.4644  data_time: 0.0057  memory: 9273  loss: 1.9462  grad_norm: 0.5024
05/10 17:12:15 - mmengine - INFO - Iter(train) [  1990/480000]  lr: 2.7629e-05  eta: 8 days, 8:05:52  time: 1.2717  data_time: 0.0060  memory: 9272  loss: 1.9918  grad_norm: 0.5118
05/10 17:12:28 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 17:12:28 - mmengine - INFO - Iter(train) [  2000/480000]  lr: 2.7768e-05  eta: 8 days, 7:55:46  time: 1.2595  data_time: 0.0058  memory: 9273  loss: 1.9278  grad_norm: 0.5132
05/10 17:12:28 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 17:12:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。出轨这种行为确实会让双方关系变得复杂，但每个人都有自己的选择和权利。如果你觉得这种情况让你感到不舒服，可以和男朋友好好沟通，表达你的感受和想法。同时，也可以寻求专业的心理咨询帮助，了解如何处理这种情况。💖<|im_end|>

05/10 17:12:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这红酒喝得比喝药还猛，下次记得先测一下血压，别让红酒成了你的“健康杀手”啊！<|im_end|>

05/10 17:12:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比树懒还懒，连个拉黑都懒得拉，直接给你三连击，退退退！下次记得，别让这种“友情”变成“爱情”，不然你得感谢你的前任，因为他让你学会了“退退退”。不过，别太往心里去，毕竟“退退退”也能成为一种时尚潮流，说不定还能成为你的新标签呢！<|im_end|>

05/10 17:12:52 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点担心呢。胆固醇高确实需要注意饮食，不过戒炸鸡也不是不能吃哦。你可以尝试一些低脂、低盐的替代品，比如烤鸡胸肉、蒸鱼或者煮鸡蛋。同时，保持适量的运动和健康的生活习惯也很重要哦。如果需要更多建议或者想要聊聊怎么调整饮食，我都在这里哦。💖<|im_end|>

05/10 17:12:58 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遭遇简直比《红楼梦》还精彩！下次记得，剧本杀不是演戏，别让读本玩家把你的角色演成了“剧本杀版的贾宝玉”。不过，下次记得，别让读本玩家把你的剧本杀体验变成“读本玩家的剧本杀体验”！😂<|im_end|>

05/10 17:13:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，领导发语音矩阵确实挺让人头疼的。不过，装没看见可能不是最好的解决办法哦。你可以尝试和领导沟通一下，表达一下你的感受和想法。如果需要，我可以帮你找找其他解决办法。💖<|im_end|>

05/10 17:13:02 - mmengine - INFO - Saving checkpoint at 2000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 17:13:17 - mmengine - INFO - Iter(train) [  2010/480000]  lr: 2.7906e-05  eta: 8 days, 10:12:47  time: 4.9691  data_time: 3.4919  memory: 9272  loss: 2.0122  grad_norm: 0.5132
05/10 17:13:31 - mmengine - INFO - Iter(train) [  2020/480000]  lr: 2.8045e-05  eta: 8 days, 10:05:44  time: 1.3506  data_time: 0.0059  memory: 9274  loss: 2.0255  grad_norm: 0.5234
05/10 17:13:47 - mmengine - INFO - Iter(train) [  2030/480000]  lr: 2.8184e-05  eta: 8 days, 10:07:50  time: 1.5823  data_time: 0.0058  memory: 9273  loss: 1.9602  grad_norm: 0.5234
05/10 17:14:00 - mmengine - INFO - Iter(train) [  2040/480000]  lr: 2.8323e-05  eta: 8 days, 9:59:50  time: 1.3240  data_time: 0.0058  memory: 9272  loss: 2.0251  grad_norm: 0.5292
05/10 17:14:15 - mmengine - INFO - Iter(train) [  2050/480000]  lr: 2.8462e-05  eta: 8 days, 10:00:51  time: 1.5541  data_time: 0.0059  memory: 9272  loss: 2.0366  grad_norm: 0.5339
05/10 17:14:29 - mmengine - INFO - Iter(train) [  2060/480000]  lr: 2.8601e-05  eta: 8 days, 9:53:16  time: 1.3319  data_time: 0.0059  memory: 9271  loss: 2.0546  grad_norm: 0.5339
05/10 17:14:42 - mmengine - INFO - Iter(train) [  2070/480000]  lr: 2.8740e-05  eta: 8 days, 9:44:42  time: 1.3047  data_time: 0.0058  memory: 9271  loss: 1.9768  grad_norm: 0.5437
05/10 17:14:56 - mmengine - INFO - Iter(train) [  2080/480000]  lr: 2.8879e-05  eta: 8 days, 9:41:04  time: 1.4316  data_time: 0.0058  memory: 9272  loss: 1.9690  grad_norm: 0.5525
05/10 17:15:11 - mmengine - INFO - Iter(train) [  2090/480000]  lr: 2.9018e-05  eta: 8 days, 9:40:03  time: 1.4990  data_time: 0.2061  memory: 9272  loss: 1.9682  grad_norm: 0.5525
05/10 17:15:26 - mmengine - INFO - Iter(train) [  2100/480000]  lr: 2.9157e-05  eta: 8 days, 9:39:46  time: 1.5182  data_time: 0.0059  memory: 9272  loss: 1.9552  grad_norm: 0.5550
05/10 17:15:39 - mmengine - INFO - Iter(train) [  2110/480000]  lr: 2.9295e-05  eta: 8 days, 9:31:47  time: 1.3145  data_time: 0.0060  memory: 9273  loss: 1.9287  grad_norm: 0.5550
05/10 17:15:52 - mmengine - INFO - Iter(train) [  2120/480000]  lr: 2.9434e-05  eta: 8 days, 9:23:14  time: 1.2974  data_time: 0.0058  memory: 9273  loss: 2.0142  grad_norm: 0.5681
05/10 17:16:08 - mmengine - INFO - Iter(train) [  2130/480000]  lr: 2.9573e-05  eta: 8 days, 9:23:15  time: 1.5245  data_time: 0.0058  memory: 9272  loss: 1.9781  grad_norm: 0.5736
05/10 17:16:21 - mmengine - INFO - Iter(train) [  2140/480000]  lr: 2.9712e-05  eta: 8 days, 9:15:01  time: 1.3026  data_time: 0.0058  memory: 9272  loss: 1.9662  grad_norm: 0.5736
05/10 17:16:36 - mmengine - INFO - Iter(train) [  2150/480000]  lr: 2.9851e-05  eta: 8 days, 9:14:38  time: 1.5124  data_time: 0.0058  memory: 9272  loss: 1.9794  grad_norm: 0.5771
05/10 17:16:49 - mmengine - INFO - Iter(train) [  2160/480000]  lr: 2.9990e-05  eta: 8 days, 9:06:42  time: 1.3080  data_time: 0.0058  memory: 9273  loss: 1.9381  grad_norm: 0.5851
05/10 17:17:02 - mmengine - INFO - Iter(train) [  2170/480000]  lr: 3.0129e-05  eta: 8 days, 8:58:27  time: 1.2972  data_time: 0.0057  memory: 9271  loss: 1.8910  grad_norm: 0.5851
05/10 17:17:17 - mmengine - INFO - Iter(train) [  2180/480000]  lr: 3.0268e-05  eta: 8 days, 8:58:27  time: 1.5212  data_time: 0.0058  memory: 9272  loss: 1.9450  grad_norm: 0.5838
05/10 17:17:30 - mmengine - INFO - Iter(train) [  2190/480000]  lr: 3.0407e-05  eta: 8 days, 8:50:10  time: 1.2933  data_time: 0.0059  memory: 9272  loss: 1.9623  grad_norm: 0.5838
05/10 17:17:45 - mmengine - INFO - Iter(train) [  2200/480000]  lr: 3.0545e-05  eta: 8 days, 8:50:00  time: 1.5155  data_time: 0.0060  memory: 9272  loss: 1.9463  grad_norm: 0.5983
05/10 17:17:58 - mmengine - INFO - Iter(train) [  2210/480000]  lr: 3.0684e-05  eta: 8 days, 8:42:18  time: 1.3065  data_time: 0.0058  memory: 9270  loss: 1.9023  grad_norm: 0.6013
05/10 17:18:11 - mmengine - INFO - Iter(train) [  2220/480000]  lr: 3.0823e-05  eta: 8 days, 8:34:35  time: 1.3041  data_time: 0.0058  memory: 9272  loss: 1.9070  grad_norm: 0.6013
05/10 17:18:27 - mmengine - INFO - Iter(train) [  2230/480000]  lr: 3.0962e-05  eta: 8 days, 8:34:44  time: 1.5227  data_time: 0.0060  memory: 9271  loss: 1.9648  grad_norm: 0.6036
05/10 17:18:38 - mmengine - INFO - Iter(train) [  2240/480000]  lr: 3.1101e-05  eta: 8 days, 8:23:19  time: 1.1971  data_time: 0.0056  memory: 9271  loss: 1.8950  grad_norm: 0.6072
05/10 17:18:56 - mmengine - INFO - Iter(train) [  2250/480000]  lr: 3.1240e-05  eta: 8 days, 8:30:29  time: 1.7195  data_time: 0.2058  memory: 9272  loss: 1.8876  grad_norm: 0.6072
05/10 17:19:08 - mmengine - INFO - Iter(train) [  2260/480000]  lr: 3.1379e-05  eta: 8 days, 8:20:59  time: 1.2487  data_time: 0.0056  memory: 9272  loss: 1.9253  grad_norm: 0.6113
05/10 17:19:21 - mmengine - INFO - Iter(train) [  2270/480000]  lr: 3.1518e-05  eta: 8 days, 8:13:28  time: 1.3023  data_time: 0.0058  memory: 9273  loss: 1.8988  grad_norm: 0.6113
05/10 17:19:37 - mmengine - INFO - Iter(train) [  2280/480000]  lr: 3.1657e-05  eta: 8 days, 8:15:47  time: 1.5828  data_time: 0.0059  memory: 9272  loss: 1.8655  grad_norm: 0.6072
05/10 17:19:50 - mmengine - INFO - Iter(train) [  2290/480000]  lr: 3.1796e-05  eta: 8 days, 8:07:44  time: 1.2844  data_time: 0.0057  memory: 9271  loss: 1.8815  grad_norm: 0.6125
05/10 17:20:05 - mmengine - INFO - Iter(train) [  2300/480000]  lr: 3.1934e-05  eta: 8 days, 8:08:26  time: 1.5357  data_time: 0.0058  memory: 9272  loss: 1.9476  grad_norm: 0.6125
05/10 17:20:18 - mmengine - INFO - Iter(train) [  2310/480000]  lr: 3.2073e-05  eta: 8 days, 8:01:01  time: 1.3003  data_time: 0.0059  memory: 9272  loss: 1.8700  grad_norm: 0.6065
05/10 17:20:31 - mmengine - INFO - Iter(train) [  2320/480000]  lr: 3.2212e-05  eta: 8 days, 7:52:12  time: 1.2579  data_time: 0.0057  memory: 9272  loss: 1.9550  grad_norm: 0.6114
05/10 17:20:47 - mmengine - INFO - Iter(train) [  2330/480000]  lr: 3.2351e-05  eta: 8 days, 7:54:34  time: 1.5828  data_time: 0.0058  memory: 9272  loss: 1.8961  grad_norm: 0.6114
05/10 17:20:59 - mmengine - INFO - Iter(train) [  2340/480000]  lr: 3.2490e-05  eta: 8 days, 7:45:58  time: 1.2613  data_time: 0.0057  memory: 9272  loss: 1.8823  grad_norm: 0.6159
05/10 17:21:15 - mmengine - INFO - Iter(train) [  2350/480000]  lr: 3.2629e-05  eta: 8 days, 7:48:53  time: 1.5993  data_time: 0.0057  memory: 9272  loss: 1.9083  grad_norm: 0.6159
05/10 17:21:28 - mmengine - INFO - Iter(train) [  2360/480000]  lr: 3.2768e-05  eta: 8 days, 7:42:24  time: 1.3211  data_time: 0.0059  memory: 9272  loss: 1.8636  grad_norm: 0.6226
05/10 17:21:41 - mmengine - INFO - Iter(train) [  2370/480000]  lr: 3.2907e-05  eta: 8 days, 7:33:36  time: 1.2508  data_time: 0.0056  memory: 9273  loss: 1.8554  grad_norm: 0.8217
05/10 17:21:56 - mmengine - INFO - Iter(train) [  2380/480000]  lr: 3.3046e-05  eta: 8 days, 7:34:14  time: 1.5305  data_time: 0.0058  memory: 9273  loss: 1.8501  grad_norm: 0.8217
05/10 17:22:09 - mmengine - INFO - Iter(train) [  2390/480000]  lr: 3.3185e-05  eta: 8 days, 7:25:28  time: 1.2487  data_time: 0.0057  memory: 9272  loss: 1.8347  grad_norm: 0.8439
05/10 17:22:24 - mmengine - INFO - Iter(train) [  2400/480000]  lr: 3.3323e-05  eta: 8 days, 7:26:14  time: 1.5338  data_time: 0.0056  memory: 9273  loss: 1.8613  grad_norm: 0.8529
05/10 17:22:40 - mmengine - INFO - Iter(train) [  2410/480000]  lr: 3.3462e-05  eta: 8 days, 7:27:21  time: 1.5446  data_time: 0.2068  memory: 9272  loss: 1.8456  grad_norm: 0.8529
05/10 17:22:52 - mmengine - INFO - Iter(train) [  2420/480000]  lr: 3.3601e-05  eta: 8 days, 7:19:39  time: 1.2769  data_time: 0.0058  memory: 9271  loss: 1.8624  grad_norm: 0.8674
05/10 17:23:06 - mmengine - INFO - Iter(train) [  2430/480000]  lr: 3.3740e-05  eta: 8 days, 7:16:40  time: 1.4193  data_time: 0.0056  memory: 9273  loss: 1.9076  grad_norm: 0.8674
05/10 17:23:19 - mmengine - INFO - Iter(train) [  2440/480000]  lr: 3.3879e-05  eta: 8 days, 7:08:10  time: 1.2490  data_time: 0.0056  memory: 9274  loss: 1.8307  grad_norm: 0.8858
05/10 17:23:36 - mmengine - INFO - Iter(train) [  2450/480000]  lr: 3.4018e-05  eta: 8 days, 7:13:24  time: 1.6699  data_time: 0.0059  memory: 9272  loss: 1.8290  grad_norm: 0.8991
05/10 17:23:49 - mmengine - INFO - Iter(train) [  2460/480000]  lr: 3.4157e-05  eta: 8 days, 7:08:21  time: 1.3535  data_time: 0.0061  memory: 9272  loss: 1.8509  grad_norm: 0.8991
05/10 17:24:02 - mmengine - INFO - Iter(train) [  2470/480000]  lr: 3.4296e-05  eta: 8 days, 7:00:51  time: 1.2764  data_time: 0.0057  memory: 9272  loss: 1.8519  grad_norm: 0.9179
05/10 17:24:16 - mmengine - INFO - Iter(train) [  2480/480000]  lr: 3.4435e-05  eta: 8 days, 6:57:33  time: 1.4053  data_time: 0.0057  memory: 9273  loss: 1.8173  grad_norm: 0.9284
05/10 17:24:29 - mmengine - INFO - Iter(train) [  2490/480000]  lr: 3.4573e-05  eta: 8 days, 6:49:26  time: 1.2537  data_time: 0.0055  memory: 9272  loss: 1.8439  grad_norm: 0.9284
05/10 17:24:45 - mmengine - INFO - Iter(train) [  2500/480000]  lr: 3.4712e-05  eta: 8 days, 6:54:39  time: 1.6707  data_time: 0.0060  memory: 9272  loss: 1.8485  grad_norm: 0.9474
05/10 17:24:45 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 17:24:54 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比火箭发射还刺激，不过别忘了，出轨这种事，得看对象是谁，不是所有的男人都能承受得了的。不过，如果他只是偶尔为之，那可能只是个小小的“小情趣”，毕竟，爱情嘛，就是有点小情趣。不过，如果他经常这样，那可得好好谈谈了，毕竟出轨这种事，得防着点。毕竟，婚姻不是儿戏，别让小情趣成了大问题。<|im_end|>

05/10 17:24:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这红酒喝得比喝药还猛，下次记得先测一下血压，别让红酒成了你的“健康杀手”啊！🍹<|im_end|>

05/10 17:25:03 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比双十一抢购还刺激，不过别担心，我这朋友可是我见过的最懂“拉黑”操作的，她知道怎么让你的前任“退退退”，让你的闺蜜“退退退”。下次咱们得提前做好心理准备，别让这种“退退退”操作影响了你的生活节奏。保重啊！<|im_end|>

05/10 17:25:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这胆固醇高得都能开个炸鸡店了，是不是想开个健康快餐连锁啊？不过别担心，我这里有健康的炸鸡配方，保证你吃得开心，胆固醇降得又快又稳！🍗<|im_end|>

05/10 17:25:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这遭遇简直比《红楼梦》还惨烈，下次记得带个防读本，别让那些“读本玩家”再给你带来“红楼梦”的体验了！😂<|im_end|>

05/10 17:25:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是打算让你在职场上“隐身”吗？下次记得，领导的“语音矩阵”是“语音雷达”，不是“语音隐形”，别让领导以为你“隐形”了。不过，别忘了，装没看见也是有成本的，比如影响了你的“语音矩阵”体验。下次记得，领导的“语音矩阵”是“语音雷达”，不是“语音隐形”，别让领导以为你“隐形”了。<|im_end|>

05/10 17:25:21 - mmengine - INFO - Saving checkpoint at 2500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 17:25:35 - mmengine - INFO - Iter(train) [  2510/480000]  lr: 3.4851e-05  eta: 8 days, 8:43:37  time: 4.9446  data_time: 3.6613  memory: 9274  loss: 1.8135  grad_norm: 0.9474
05/10 17:25:50 - mmengine - INFO - Iter(train) [  2520/480000]  lr: 3.4990e-05  eta: 8 days, 8:45:14  time: 1.5726  data_time: 0.0059  memory: 9274  loss: 1.7912  grad_norm: 0.9424
05/10 17:26:03 - mmengine - INFO - Iter(train) [  2530/480000]  lr: 3.5129e-05  eta: 8 days, 8:37:56  time: 1.2894  data_time: 0.0058  memory: 9273  loss: 1.7831  grad_norm: 0.7680
05/10 17:26:16 - mmengine - INFO - Iter(train) [  2540/480000]  lr: 3.5268e-05  eta: 8 days, 8:29:42  time: 1.2578  data_time: 0.0057  memory: 9272  loss: 1.8416  grad_norm: 0.7680
05/10 17:26:32 - mmengine - INFO - Iter(train) [  2550/480000]  lr: 3.5407e-05  eta: 8 days, 8:32:37  time: 1.6133  data_time: 0.0059  memory: 9271  loss: 1.7949  grad_norm: 0.7665
05/10 17:26:44 - mmengine - INFO - Iter(train) [  2560/480000]  lr: 3.5546e-05  eta: 8 days, 8:21:48  time: 1.1722  data_time: 0.0054  memory: 9272  loss: 1.7685  grad_norm: 0.7822
05/10 17:27:02 - mmengine - INFO - Iter(train) [  2570/480000]  lr: 3.5685e-05  eta: 8 days, 8:30:21  time: 1.7950  data_time: 0.2059  memory: 9273  loss: 1.7564  grad_norm: 0.7822
05/10 17:27:15 - mmengine - INFO - Iter(train) [  2580/480000]  lr: 3.5824e-05  eta: 8 days, 8:23:45  time: 1.3062  data_time: 0.0059  memory: 9272  loss: 1.8017  grad_norm: 0.7895
05/10 17:27:27 - mmengine - INFO - Iter(train) [  2590/480000]  lr: 3.5962e-05  eta: 8 days, 8:15:29  time: 1.2502  data_time: 0.0056  memory: 9271  loss: 1.8235  grad_norm: 0.7895
05/10 17:27:43 - mmengine - INFO - Iter(train) [  2600/480000]  lr: 3.6101e-05  eta: 8 days, 8:16:24  time: 1.5482  data_time: 0.0055  memory: 9272  loss: 1.8226  grad_norm: 0.7858
05/10 17:27:55 - mmengine - INFO - Iter(train) [  2610/480000]  lr: 3.6240e-05  eta: 8 days, 8:08:18  time: 1.2529  data_time: 0.0056  memory: 9274  loss: 1.7745  grad_norm: 0.8056
05/10 17:28:12 - mmengine - INFO - Iter(train) [  2620/480000]  lr: 3.6379e-05  eta: 8 days, 8:11:33  time: 1.6245  data_time: 0.0057  memory: 9272  loss: 1.8033  grad_norm: 0.8056
05/10 17:28:25 - mmengine - INFO - Iter(train) [  2630/480000]  lr: 3.6518e-05  eta: 8 days, 8:06:03  time: 1.3362  data_time: 0.0060  memory: 9272  loss: 1.7780  grad_norm: 0.8218
05/10 17:28:38 - mmengine - INFO - Iter(train) [  2640/480000]  lr: 3.6657e-05  eta: 8 days, 8:00:04  time: 1.3187  data_time: 0.0059  memory: 9272  loss: 1.7745  grad_norm: 0.8278
05/10 17:28:53 - mmengine - INFO - Iter(train) [  2650/480000]  lr: 3.6796e-05  eta: 8 days, 7:59:59  time: 1.5142  data_time: 0.0059  memory: 9273  loss: 1.7649  grad_norm: 0.8278
05/10 17:29:05 - mmengine - INFO - Iter(train) [  2660/480000]  lr: 3.6935e-05  eta: 8 days, 7:50:58  time: 1.2152  data_time: 0.0057  memory: 9274  loss: 1.7415  grad_norm: 0.8384
05/10 17:29:18 - mmengine - INFO - Iter(train) [  2670/480000]  lr: 3.7074e-05  eta: 8 days, 7:42:29  time: 1.2311  data_time: 0.0056  memory: 9272  loss: 1.7659  grad_norm: 0.8384
05/10 17:29:33 - mmengine - INFO - Iter(train) [  2680/480000]  lr: 3.7213e-05  eta: 8 days, 7:44:16  time: 1.5745  data_time: 0.0059  memory: 9272  loss: 1.7691  grad_norm: 0.8732
05/10 17:29:46 - mmengine - INFO - Iter(train) [  2690/480000]  lr: 3.7351e-05  eta: 8 days, 7:35:21  time: 1.2139  data_time: 0.0056  memory: 9274  loss: 1.7766  grad_norm: 0.8846
05/10 17:30:01 - mmengine - INFO - Iter(train) [  2700/480000]  lr: 3.7490e-05  eta: 8 days, 7:35:36  time: 1.5220  data_time: 0.0057  memory: 9272  loss: 1.7220  grad_norm: 0.8846
05/10 17:30:13 - mmengine - INFO - Iter(train) [  2710/480000]  lr: 3.7629e-05  eta: 8 days, 7:27:32  time: 1.2392  data_time: 0.0057  memory: 9273  loss: 1.7385  grad_norm: 0.9018
05/10 17:30:25 - mmengine - INFO - Iter(train) [  2720/480000]  lr: 3.7768e-05  eta: 8 days, 7:16:31  time: 1.1362  data_time: 0.0055  memory: 9272  loss: 1.7276  grad_norm: 0.9113
05/10 17:30:42 - mmengine - INFO - Iter(train) [  2730/480000]  lr: 3.7907e-05  eta: 8 days, 7:23:33  time: 1.7535  data_time: 0.2059  memory: 9274  loss: 1.7041  grad_norm: 0.9113
05/10 17:30:54 - mmengine - INFO - Iter(train) [  2740/480000]  lr: 3.8046e-05  eta: 8 days, 7:14:55  time: 1.2151  data_time: 0.0056  memory: 9273  loss: 1.7025  grad_norm: 0.9247
05/10 17:31:10 - mmengine - INFO - Iter(train) [  2750/480000]  lr: 3.8185e-05  eta: 8 days, 7:15:33  time: 1.5337  data_time: 0.0057  memory: 9274  loss: 1.7094  grad_norm: 0.9247
05/10 17:31:22 - mmengine - INFO - Iter(train) [  2760/480000]  lr: 3.8324e-05  eta: 8 days, 7:07:39  time: 1.2371  data_time: 0.0058  memory: 9273  loss: 1.7123  grad_norm: 0.9425
05/10 17:31:34 - mmengine - INFO - Iter(train) [  2770/480000]  lr: 3.8463e-05  eta: 8 days, 6:59:06  time: 1.2134  data_time: 0.0056  memory: 9274  loss: 1.7106  grad_norm: 0.9356
05/10 17:31:50 - mmengine - INFO - Iter(train) [  2780/480000]  lr: 3.8602e-05  eta: 8 days, 7:00:20  time: 1.5530  data_time: 0.0058  memory: 9273  loss: 1.6812  grad_norm: 0.9356
05/10 17:32:02 - mmengine - INFO - Iter(train) [  2790/480000]  lr: 3.8740e-05  eta: 8 days, 6:52:25  time: 1.2323  data_time: 0.0056  memory: 9273  loss: 1.6844  grad_norm: 0.9358
05/10 17:32:14 - mmengine - INFO - Iter(train) [  2800/480000]  lr: 3.8879e-05  eta: 8 days, 6:44:55  time: 1.2450  data_time: 0.0059  memory: 9273  loss: 1.6741  grad_norm: 0.9504
05/10 17:32:27 - mmengine - INFO - Iter(train) [  2810/480000]  lr: 3.9018e-05  eta: 8 days, 6:38:24  time: 1.2781  data_time: 0.0059  memory: 9273  loss: 1.7031  grad_norm: 0.9504
05/10 17:32:44 - mmengine - INFO - Iter(train) [  2820/480000]  lr: 3.9157e-05  eta: 8 days, 6:42:26  time: 1.6504  data_time: 0.0058  memory: 9274  loss: 1.7812  grad_norm: 0.9460
05/10 17:32:56 - mmengine - INFO - Iter(train) [  2830/480000]  lr: 3.9296e-05  eta: 8 days, 6:34:13  time: 1.2155  data_time: 0.0056  memory: 9273  loss: 1.7229  grad_norm: 0.9460
05/10 17:33:11 - mmengine - INFO - Iter(train) [  2840/480000]  lr: 3.9435e-05  eta: 8 days, 6:35:06  time: 1.5387  data_time: 0.0056  memory: 9274  loss: 1.7035  grad_norm: 0.9409
05/10 17:33:24 - mmengine - INFO - Iter(train) [  2850/480000]  lr: 3.9574e-05  eta: 8 days, 6:27:46  time: 1.2440  data_time: 0.0057  memory: 9274  loss: 1.6906  grad_norm: 0.9570
05/10 17:33:36 - mmengine - INFO - Iter(train) [  2860/480000]  lr: 3.9713e-05  eta: 8 days, 6:20:09  time: 1.2327  data_time: 0.0056  memory: 9272  loss: 1.7163  grad_norm: 0.9570
05/10 17:33:51 - mmengine - INFO - Iter(train) [  2870/480000]  lr: 3.9852e-05  eta: 8 days, 6:20:49  time: 1.5297  data_time: 0.0057  memory: 9274  loss: 1.7145  grad_norm: 0.9489
05/10 17:34:03 - mmengine - INFO - Iter(train) [  2880/480000]  lr: 3.9990e-05  eta: 8 days, 6:11:04  time: 1.1520  data_time: 0.0055  memory: 9273  loss: 1.7586  grad_norm: 0.9508
05/10 17:34:20 - mmengine - INFO - Iter(train) [  2890/480000]  lr: 4.0129e-05  eta: 8 days, 6:17:34  time: 1.7406  data_time: 0.2060  memory: 9272  loss: 1.6615  grad_norm: 0.9508
05/10 17:34:33 - mmengine - INFO - Iter(train) [  2900/480000]  lr: 4.0268e-05  eta: 8 days, 6:10:24  time: 1.2442  data_time: 0.0057  memory: 9273  loss: 1.6474  grad_norm: 0.9577
05/10 17:34:45 - mmengine - INFO - Iter(train) [  2910/480000]  lr: 4.0407e-05  eta: 8 days, 6:03:03  time: 1.2356  data_time: 0.0057  memory: 9273  loss: 1.6748  grad_norm: 0.9577
05/10 17:35:00 - mmengine - INFO - Iter(train) [  2920/480000]  lr: 4.0546e-05  eta: 8 days, 6:03:58  time: 1.5372  data_time: 0.0058  memory: 9272  loss: 1.6784  grad_norm: 0.9598
05/10 17:35:13 - mmengine - INFO - Iter(train) [  2930/480000]  lr: 4.0685e-05  eta: 8 days, 5:56:23  time: 1.2240  data_time: 0.0056  memory: 9274  loss: 1.6911  grad_norm: 0.9641
05/10 17:35:25 - mmengine - INFO - Iter(train) [  2940/480000]  lr: 4.0824e-05  eta: 8 days, 5:49:19  time: 1.2420  data_time: 0.0056  memory: 9275  loss: 1.6188  grad_norm: 0.9641
05/10 17:35:40 - mmengine - INFO - Iter(train) [  2950/480000]  lr: 4.0963e-05  eta: 8 days, 5:50:01  time: 1.5279  data_time: 0.0057  memory: 9275  loss: 1.6356  grad_norm: 0.9743
05/10 17:35:53 - mmengine - INFO - Iter(train) [  2960/480000]  lr: 4.1102e-05  eta: 8 days, 5:42:34  time: 1.2245  data_time: 0.0056  memory: 9273  loss: 1.6070  grad_norm: 0.9867
05/10 17:36:08 - mmengine - INFO - Iter(train) [  2970/480000]  lr: 4.1241e-05  eta: 8 days, 5:43:18  time: 1.5289  data_time: 0.0057  memory: 9273  loss: 1.6447  grad_norm: 0.9867
05/10 17:36:20 - mmengine - INFO - Iter(train) [  2980/480000]  lr: 4.1379e-05  eta: 8 days, 5:36:14  time: 1.2364  data_time: 0.0057  memory: 9274  loss: 1.6015  grad_norm: 1.0083
05/10 17:36:33 - mmengine - INFO - Iter(train) [  2990/480000]  lr: 4.1518e-05  eta: 8 days, 5:29:11  time: 1.2359  data_time: 0.0057  memory: 9273  loss: 1.6832  grad_norm: 1.0083
05/10 17:36:48 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 17:36:48 - mmengine - INFO - Iter(train) [  3000/480000]  lr: 4.1657e-05  eta: 8 days, 5:29:53  time: 1.5262  data_time: 0.0057  memory: 9275  loss: 1.6074  grad_norm: 1.0202
05/10 17:36:48 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 17:36:53 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这操作简直比火箭发射还刺激，但别忘了，出轨这种事，男人和女人的定义可是不一样的。不过，如果你觉得心里不舒服，可以和他好好谈谈，毕竟出轨这种事，得不偿失。别让这种小事影响了你的心情和幸福。💔<|im_end|>

05/10 17:36:57 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直就是在红酒的世界里玩起了“心跳游戏”啊！下次记得，养生不是喝红酒，是喝红酒的小心脏。保重身体，别让红酒成了你的“健康杀手”！🍷💔<|im_end|>

05/10 17:37:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，这操作简直比双十一抢购还刺激！你的闺蜜是真爱粉，还是想让你体验一把“被黑”的滋味？不过别太往心里去，毕竟“闺蜜”这个词，有时候就是个玩笑话。不过，下次别让这种“小插曲”影响了你的心情，毕竟，生活还是要继续的！💪<|im_end|>

05/10 17:37:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这胆固醇高得都能开个炸鸡店了，不过别担心，我这里有健康的炸鸡配方，保证你血脂不升反降！🍗<|im_end|>

05/10 17:37:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q了，你这遭遇比小说里的主角还惨烈！下次记得带个防摔垫，别让剧本杀变成“剧本杀”了。剧本杀，下次得长点儿心！<|im_end|>

05/10 17:37:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这领导是打算让你体验一下“沉默是金”的感觉吗？下次记得，60秒语音矩阵，藏着的可是你的“秘密武器”啊！别让领导以为你装作没看见，不然下次他可能就要给你安排“秘密任务”了。💼🔒<|im_end|>

05/10 17:37:19 - mmengine - INFO - Saving checkpoint at 3000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 17:37:32 - mmengine - INFO - Iter(train) [  3010/480000]  lr: 4.1796e-05  eta: 8 days, 6:46:50  time: 4.4135  data_time: 3.1785  memory: 9274  loss: 1.6551  grad_norm: 1.0246
05/10 17:37:44 - mmengine - INFO - Iter(train) [  3020/480000]  lr: 4.1935e-05  eta: 8 days, 6:39:43  time: 1.2392  data_time: 0.0058  memory: 9274  loss: 1.6544  grad_norm: 1.0246
05/10 17:38:00 - mmengine - INFO - Iter(train) [  3030/480000]  lr: 4.2074e-05  eta: 8 days, 6:40:13  time: 1.5280  data_time: 0.0057  memory: 9274  loss: 1.6411  grad_norm: 1.0498
05/10 17:38:11 - mmengine - INFO - Iter(train) [  3040/480000]  lr: 4.2213e-05  eta: 8 days, 6:30:42  time: 1.1452  data_time: 0.0056  memory: 9273  loss: 1.6669  grad_norm: 1.0622
05/10 17:38:29 - mmengine - INFO - Iter(train) [  3050/480000]  lr: 4.2352e-05  eta: 8 days, 6:37:08  time: 1.7544  data_time: 0.2058  memory: 9274  loss: 1.5911  grad_norm: 1.0622
05/10 17:38:41 - mmengine - INFO - Iter(train) [  3060/480000]  lr: 4.2491e-05  eta: 8 days, 6:29:55  time: 1.2310  data_time: 0.0056  memory: 9273  loss: 1.5651  grad_norm: 1.0761
05/10 17:38:53 - mmengine - INFO - Iter(train) [  3070/480000]  lr: 4.2630e-05  eta: 8 days, 6:22:47  time: 1.2324  data_time: 0.0057  memory: 9273  loss: 1.6112  grad_norm: 1.0761
05/10 17:39:09 - mmengine - INFO - Iter(train) [  3080/480000]  lr: 4.2768e-05  eta: 8 days, 6:23:44  time: 1.5444  data_time: 0.0057  memory: 9273  loss: 1.6339  grad_norm: 1.1042
05/10 17:39:21 - mmengine - INFO - Iter(train) [  3090/480000]  lr: 4.2907e-05  eta: 8 days, 6:16:19  time: 1.2189  data_time: 0.0056  memory: 9274  loss: 1.5732  grad_norm: 1.1232
05/10 17:39:36 - mmengine - INFO - Iter(train) [  3100/480000]  lr: 4.3046e-05  eta: 8 days, 6:17:35  time: 1.5553  data_time: 0.0056  memory: 9274  loss: 1.5698  grad_norm: 1.1232
05/10 17:39:49 - mmengine - INFO - Iter(train) [  3110/480000]  lr: 4.3185e-05  eta: 8 days, 6:10:27  time: 1.2281  data_time: 0.0057  memory: 9273  loss: 1.6176  grad_norm: 1.1265
05/10 17:40:01 - mmengine - INFO - Iter(train) [  3120/480000]  lr: 4.3324e-05  eta: 8 days, 6:03:41  time: 1.2401  data_time: 0.0057  memory: 9276  loss: 1.5034  grad_norm: 1.1449
05/10 17:40:17 - mmengine - INFO - Iter(train) [  3130/480000]  lr: 4.3463e-05  eta: 8 days, 6:04:33  time: 1.5389  data_time: 0.0057  memory: 9274  loss: 1.6438  grad_norm: 1.1449
05/10 17:40:29 - mmengine - INFO - Iter(train) [  3140/480000]  lr: 4.3602e-05  eta: 8 days, 5:57:26  time: 1.2240  data_time: 0.0056  memory: 9274  loss: 1.6336  grad_norm: 1.1660
05/10 17:40:41 - mmengine - INFO - Iter(train) [  3150/480000]  lr: 4.3741e-05  eta: 8 days, 5:50:22  time: 1.2245  data_time: 0.0056  memory: 9274  loss: 1.5723  grad_norm: 1.1660
05/10 17:40:57 - mmengine - INFO - Iter(train) [  3160/480000]  lr: 4.3880e-05  eta: 8 days, 5:52:07  time: 1.5729  data_time: 0.0057  memory: 9275  loss: 1.5963  grad_norm: 1.1690
05/10 17:41:09 - mmengine - INFO - Iter(train) [  3170/480000]  lr: 4.4019e-05  eta: 8 days, 5:44:46  time: 1.2107  data_time: 0.0055  memory: 9275  loss: 1.5475  grad_norm: 1.1915
05/10 17:41:24 - mmengine - INFO - Iter(train) [  3180/480000]  lr: 4.4157e-05  eta: 8 days, 5:45:35  time: 1.5352  data_time: 0.0057  memory: 9275  loss: 1.5682  grad_norm: 1.1915
05/10 17:41:37 - mmengine - INFO - Iter(train) [  3190/480000]  lr: 4.4296e-05  eta: 8 days, 5:39:01  time: 1.2395  data_time: 0.0057  memory: 9275  loss: 1.5778  grad_norm: 1.2103
05/10 17:41:48 - mmengine - INFO - Iter(train) [  3200/480000]  lr: 4.4435e-05  eta: 8 days, 5:29:50  time: 1.1326  data_time: 0.0055  memory: 9275  loss: 1.5731  grad_norm: 1.2223
05/10 17:42:06 - mmengine - INFO - Iter(train) [  3210/480000]  lr: 4.4574e-05  eta: 8 days, 5:36:39  time: 1.7764  data_time: 0.2057  memory: 9275  loss: 1.5482  grad_norm: 1.2223
05/10 17:42:18 - mmengine - INFO - Iter(train) [  3220/480000]  lr: 4.4713e-05  eta: 8 days, 5:30:28  time: 1.2521  data_time: 0.0059  memory: 9276  loss: 1.5454  grad_norm: 1.2386
05/10 17:42:33 - mmengine - INFO - Iter(train) [  3230/480000]  lr: 4.4852e-05  eta: 8 days, 5:30:20  time: 1.4955  data_time: 0.0056  memory: 9276  loss: 1.4816  grad_norm: 1.2386
05/10 17:42:46 - mmengine - INFO - Iter(train) [  3240/480000]  lr: 4.4991e-05  eta: 8 days, 5:23:52  time: 1.2380  data_time: 0.0057  memory: 9277  loss: 1.5043  grad_norm: 1.2393
05/10 17:42:58 - mmengine - INFO - Iter(train) [  3250/480000]  lr: 4.5130e-05  eta: 8 days, 5:16:50  time: 1.2131  data_time: 0.0056  memory: 9274  loss: 1.5029  grad_norm: 1.2503
05/10 17:43:13 - mmengine - INFO - Iter(train) [  3260/480000]  lr: 4.5269e-05  eta: 8 days, 5:18:33  time: 1.5704  data_time: 0.0057  memory: 9275  loss: 1.5666  grad_norm: 1.2503
05/10 17:43:26 - mmengine - INFO - Iter(train) [  3270/480000]  lr: 4.5407e-05  eta: 8 days, 5:13:03  time: 1.2735  data_time: 0.0058  memory: 9276  loss: 1.5918  grad_norm: 1.2651
05/10 17:43:38 - mmengine - INFO - Iter(train) [  3280/480000]  lr: 4.5546e-05  eta: 8 days, 5:06:05  time: 1.2123  data_time: 0.0055  memory: 9276  loss: 1.5635  grad_norm: 1.2676
05/10 17:43:53 - mmengine - INFO - Iter(train) [  3290/480000]  lr: 4.5685e-05  eta: 8 days, 5:05:11  time: 1.4616  data_time: 0.0055  memory: 9275  loss: 1.5092  grad_norm: 1.2676
05/10 17:44:05 - mmengine - INFO - Iter(train) [  3300/480000]  lr: 4.5824e-05  eta: 8 days, 4:58:23  time: 1.2163  data_time: 0.0056  memory: 9275  loss: 1.4911  grad_norm: 1.2810
05/10 17:44:21 - mmengine - INFO - Iter(train) [  3310/480000]  lr: 4.5963e-05  eta: 8 days, 5:00:58  time: 1.6049  data_time: 0.0058  memory: 9275  loss: 1.5415  grad_norm: 1.2810
05/10 17:44:34 - mmengine - INFO - Iter(train) [  3320/480000]  lr: 4.6102e-05  eta: 8 days, 4:55:14  time: 1.2589  data_time: 0.0058  memory: 9275  loss: 1.5227  grad_norm: 1.2926
05/10 17:44:46 - mmengine - INFO - Iter(train) [  3330/480000]  lr: 4.6241e-05  eta: 8 days, 4:48:31  time: 1.2159  data_time: 0.0056  memory: 9275  loss: 1.5071  grad_norm: 1.3061
05/10 17:45:01 - mmengine - INFO - Iter(train) [  3340/480000]  lr: 4.6380e-05  eta: 8 days, 4:49:24  time: 1.5338  data_time: 0.0058  memory: 9276  loss: 1.5140  grad_norm: 1.3061
05/10 17:45:13 - mmengine - INFO - Iter(train) [  3350/480000]  lr: 4.6519e-05  eta: 8 days, 4:42:50  time: 1.2203  data_time: 0.0056  memory: 9276  loss: 1.5171  grad_norm: 1.3180
05/10 17:45:25 - mmengine - INFO - Iter(train) [  3360/480000]  lr: 4.6658e-05  eta: 8 days, 4:34:24  time: 1.1399  data_time: 0.0055  memory: 9275  loss: 1.4849  grad_norm: 1.3533
05/10 17:45:43 - mmengine - INFO - Iter(train) [  3370/480000]  lr: 4.6796e-05  eta: 8 days, 4:41:01  time: 1.7758  data_time: 0.5288  memory: 9276  loss: 1.4722  grad_norm: 1.3533
05/10 17:45:55 - mmengine - INFO - Iter(train) [  3380/480000]  lr: 4.6935e-05  eta: 8 days, 4:34:26  time: 1.2155  data_time: 0.0055  memory: 9277  loss: 1.4750  grad_norm: 1.3518
05/10 17:46:10 - mmengine - INFO - Iter(train) [  3390/480000]  lr: 4.7074e-05  eta: 8 days, 4:36:01  time: 1.5634  data_time: 0.0057  memory: 9277  loss: 1.4972  grad_norm: 1.3518
05/10 17:46:23 - mmengine - INFO - Iter(train) [  3400/480000]  lr: 4.7213e-05  eta: 8 days, 4:29:41  time: 1.2240  data_time: 0.0055  memory: 9275  loss: 1.4920  grad_norm: 1.3718
05/10 17:46:35 - mmengine - INFO - Iter(train) [  3410/480000]  lr: 4.7352e-05  eta: 8 days, 4:22:59  time: 1.2073  data_time: 0.0056  memory: 9278  loss: 1.4913  grad_norm: 1.3785
05/10 17:46:50 - mmengine - INFO - Iter(train) [  3420/480000]  lr: 4.7491e-05  eta: 8 days, 4:24:28  time: 1.5585  data_time: 0.0056  memory: 9276  loss: 1.4797  grad_norm: 1.3785
05/10 17:47:02 - mmengine - INFO - Iter(train) [  3430/480000]  lr: 4.7630e-05  eta: 8 days, 4:17:53  time: 1.2099  data_time: 0.0055  memory: 9277  loss: 1.4461  grad_norm: 1.3917
05/10 17:47:18 - mmengine - INFO - Iter(train) [  3440/480000]  lr: 4.7769e-05  eta: 8 days, 4:19:09  time: 1.5478  data_time: 0.0055  memory: 9277  loss: 1.4287  grad_norm: 1.4117
05/10 17:47:30 - mmengine - INFO - Iter(train) [  3450/480000]  lr: 4.7908e-05  eta: 8 days, 4:13:28  time: 1.2472  data_time: 0.0056  memory: 9278  loss: 1.4788  grad_norm: 1.4117
05/10 17:47:42 - mmengine - INFO - Iter(train) [  3460/480000]  lr: 4.8047e-05  eta: 8 days, 4:07:11  time: 1.2191  data_time: 0.0056  memory: 9279  loss: 1.4202  grad_norm: 1.4092
05/10 17:47:57 - mmengine - INFO - Iter(train) [  3470/480000]  lr: 4.8185e-05  eta: 8 days, 4:07:12  time: 1.4932  data_time: 0.0056  memory: 9277  loss: 1.5070  grad_norm: 1.4092
05/10 17:48:10 - mmengine - INFO - Iter(train) [  3480/480000]  lr: 4.8324e-05  eta: 8 days, 4:02:00  time: 1.2649  data_time: 0.0057  memory: 9279  loss: 1.4621  grad_norm: 1.4183
05/10 17:48:22 - mmengine - INFO - Iter(train) [  3490/480000]  lr: 4.8463e-05  eta: 8 days, 3:56:20  time: 1.2428  data_time: 0.0056  memory: 9276  loss: 1.4291  grad_norm: 1.4080
05/10 17:48:38 - mmengine - INFO - Iter(train) [  3500/480000]  lr: 4.8602e-05  eta: 8 days, 3:56:46  time: 1.5103  data_time: 0.0058  memory: 9276  loss: 1.4579  grad_norm: 1.4080
05/10 17:48:38 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 17:48:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些困惑呢。每个人都有自己的生活方式和价值观，有时候这些行为可能会让人感到不舒服。如果你觉得这种情况让你感到困扰，或许可以和男朋友好好谈谈，表达你的感受。同时，也可以考虑寻求专业的心理咨询师的帮助，看看如何处理这种情况。💖<|im_end|>

05/10 17:48:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
毒舌
栓Q，你这操作简直比喝酒还刺激，下次记得先测测自己的酒精含量，别让身体也跟着“醉”了。🍷💊<|im_end|>

05/10 17:48:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺让人不舒服的。你可以和你的闺蜜沟通一下，表达一下你的感受，毕竟信任和尊重是很重要的。如果需要倾诉或者寻求建议，我在这里哦。💖<|im_end|>

05/10 17:48:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食哦，不过戒炸鸡也不是不可能呢。你可以试试吃一些低脂或者无脂的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入过多的油脂。如果还是担心，最好咨询一下医生或者营养师，他们会给你更专业的建议哦。💖<|im_end|>

05/10 17:49:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这玩家是来自古代的吧？剧本杀是用来享受推理的乐趣，不是来体验古代生活的。下次记得，遇到读本玩家，直接把剧本藏起来，假装没看见，或者直接找我借一本，保证你笑到合不拢嘴！😂<|im_end|>

05/10 17:49:05 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，装没看见可不好呢，毕竟领导的指示很重要。你可以试试用语音助手或者直接回复确认一下，表达一下你的关注哦。💖<|im_end|>

05/10 17:49:05 - mmengine - INFO - Saving checkpoint at 3500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 17:49:18 - mmengine - INFO - Iter(train) [  3510/480000]  lr: 4.8741e-05  eta: 8 days, 4:54:30  time: 4.0427  data_time: 2.8038  memory: 9277  loss: 1.4728  grad_norm: 1.4220
05/10 17:49:29 - mmengine - INFO - Iter(train) [  3520/480000]  lr: 4.8880e-05  eta: 8 days, 4:46:19  time: 1.1362  data_time: 0.0055  memory: 9276  loss: 1.4422  grad_norm: 1.4047
05/10 17:49:46 - mmengine - INFO - Iter(train) [  3530/480000]  lr: 4.9019e-05  eta: 8 days, 4:51:03  time: 1.7080  data_time: 0.2057  memory: 9277  loss: 1.3905  grad_norm: 1.4047
05/10 17:49:59 - mmengine - INFO - Iter(train) [  3540/480000]  lr: 4.9158e-05  eta: 8 days, 4:45:05  time: 1.2326  data_time: 0.0056  memory: 9277  loss: 1.4232  grad_norm: 1.4011
05/10 17:50:14 - mmengine - INFO - Iter(train) [  3550/480000]  lr: 4.9297e-05  eta: 8 days, 4:45:41  time: 1.5242  data_time: 0.0056  memory: 9277  loss: 1.4215  grad_norm: 1.4011
05/10 17:50:26 - mmengine - INFO - Iter(train) [  3560/480000]  lr: 4.9435e-05  eta: 8 days, 4:39:56  time: 1.2398  data_time: 0.0066  memory: 9278  loss: 1.4568  grad_norm: 1.3947
05/10 17:50:39 - mmengine - INFO - Iter(train) [  3570/480000]  lr: 4.9574e-05  eta: 8 days, 4:33:55  time: 1.2267  data_time: 0.0056  memory: 9278  loss: 1.4066  grad_norm: 1.3993
05/10 17:50:54 - mmengine - INFO - Iter(train) [  3580/480000]  lr: 4.9713e-05  eta: 8 days, 4:34:21  time: 1.5163  data_time: 0.0057  memory: 9277  loss: 1.3719  grad_norm: 1.3993
05/10 17:51:06 - mmengine - INFO - Iter(train) [  3590/480000]  lr: 4.9852e-05  eta: 8 days, 4:28:44  time: 1.2427  data_time: 0.0056  memory: 9277  loss: 1.4421  grad_norm: 1.4150
05/10 17:51:22 - mmengine - INFO - Iter(train) [  3600/480000]  lr: 4.9991e-05  eta: 8 days, 4:29:28  time: 1.5292  data_time: 0.0056  memory: 9277  loss: 1.4113  grad_norm: 1.4130
05/10 17:51:34 - mmengine - INFO - Iter(train) [  3610/480000]  lr: 5.0130e-05  eta: 8 days, 4:23:26  time: 1.2213  data_time: 0.0058  memory: 9278  loss: 1.4021  grad_norm: 1.4130
05/10 17:51:46 - mmengine - INFO - Iter(train) [  3620/480000]  lr: 5.0269e-05  eta: 8 days, 4:17:20  time: 1.2176  data_time: 0.0056  memory: 9278  loss: 1.3987  grad_norm: 1.4218
05/10 17:52:01 - mmengine - INFO - Iter(train) [  3630/480000]  lr: 5.0408e-05  eta: 8 days, 4:18:04  time: 1.5284  data_time: 0.0057  memory: 9277  loss: 1.3898  grad_norm: 1.4218
05/10 17:52:14 - mmengine - INFO - Iter(train) [  3640/480000]  lr: 5.0547e-05  eta: 8 days, 4:12:43  time: 1.2492  data_time: 0.0056  memory: 9277  loss: 1.3846  grad_norm: 1.4402
05/10 17:52:26 - mmengine - INFO - Iter(train) [  3650/480000]  lr: 5.0686e-05  eta: 8 days, 4:07:08  time: 1.2376  data_time: 0.0056  memory: 9276  loss: 1.4285  grad_norm: 1.4544
05/10 17:52:41 - mmengine - INFO - Iter(train) [  3660/480000]  lr: 5.0824e-05  eta: 8 days, 4:07:48  time: 1.5244  data_time: 0.0058  memory: 9278  loss: 1.3673  grad_norm: 1.4544
05/10 17:52:54 - mmengine - INFO - Iter(train) [  3670/480000]  lr: 5.0963e-05  eta: 8 days, 4:02:09  time: 1.2327  data_time: 0.0055  memory: 9278  loss: 1.4037  grad_norm: 1.4377
05/10 17:53:08 - mmengine - INFO - Iter(train) [  3680/480000]  lr: 5.1102e-05  eta: 8 days, 4:01:13  time: 1.4498  data_time: 0.0055  memory: 9278  loss: 1.4052  grad_norm: 1.4426
05/10 17:53:23 - mmengine - INFO - Iter(train) [  3690/480000]  lr: 5.1241e-05  eta: 8 days, 4:00:18  time: 1.4500  data_time: 0.2058  memory: 9279  loss: 1.4027  grad_norm: 1.4426
05/10 17:53:35 - mmengine - INFO - Iter(train) [  3700/480000]  lr: 5.1380e-05  eta: 8 days, 3:54:18  time: 1.2132  data_time: 0.0057  memory: 9279  loss: 1.3433  grad_norm: 1.4712
05/10 17:53:50 - mmengine - INFO - Iter(train) [  3710/480000]  lr: 5.1519e-05  eta: 8 days, 3:54:41  time: 1.5104  data_time: 0.0056  memory: 9278  loss: 1.2722  grad_norm: 1.4712
05/10 17:54:02 - mmengine - INFO - Iter(train) [  3720/480000]  lr: 5.1658e-05  eta: 8 days, 3:49:27  time: 1.2471  data_time: 0.0056  memory: 9277  loss: 1.3440  grad_norm: 1.4941
05/10 17:54:18 - mmengine - INFO - Iter(train) [  3730/480000]  lr: 5.1797e-05  eta: 8 days, 3:50:23  time: 1.5357  data_time: 0.0057  memory: 9279  loss: 1.3962  grad_norm: 1.5226
05/10 17:54:30 - mmengine - INFO - Iter(train) [  3740/480000]  lr: 5.1936e-05  eta: 8 days, 3:45:09  time: 1.2448  data_time: 0.0056  memory: 9280  loss: 1.3715  grad_norm: 1.5226
05/10 17:54:43 - mmengine - INFO - Iter(train) [  3750/480000]  lr: 5.2075e-05  eta: 8 days, 3:39:53  time: 1.2428  data_time: 0.0058  memory: 9280  loss: 1.2911  grad_norm: 1.5623
05/10 17:54:57 - mmengine - INFO - Iter(train) [  3760/480000]  lr: 5.2213e-05  eta: 8 days, 3:39:40  time: 1.4804  data_time: 0.0055  memory: 9278  loss: 1.3763  grad_norm: 1.5748
05/10 17:55:10 - mmengine - INFO - Iter(train) [  3770/480000]  lr: 5.2352e-05  eta: 8 days, 3:33:47  time: 1.2115  data_time: 0.0054  memory: 9277  loss: 1.3521  grad_norm: 1.5748
05/10 17:55:22 - mmengine - INFO - Iter(train) [  3780/480000]  lr: 5.2491e-05  eta: 8 days, 3:27:47  time: 1.2040  data_time: 0.0054  memory: 9282  loss: 1.3592  grad_norm: 1.6059
05/10 17:55:37 - mmengine - INFO - Iter(train) [  3790/480000]  lr: 5.2630e-05  eta: 8 days, 3:29:06  time: 1.5525  data_time: 0.0056  memory: 9278  loss: 1.3375  grad_norm: 1.6059
05/10 17:55:49 - mmengine - INFO - Iter(train) [  3800/480000]  lr: 5.2769e-05  eta: 8 days, 3:23:15  time: 1.2097  data_time: 0.0055  memory: 9278  loss: 1.3388  grad_norm: 1.6114
05/10 17:56:05 - mmengine - INFO - Iter(train) [  3810/480000]  lr: 5.2908e-05  eta: 8 days, 3:24:38  time: 1.5549  data_time: 0.0056  memory: 9278  loss: 1.3349  grad_norm: 1.6138
05/10 17:56:17 - mmengine - INFO - Iter(train) [  3820/480000]  lr: 5.3047e-05  eta: 8 days, 3:19:27  time: 1.2396  data_time: 0.0056  memory: 9279  loss: 1.3327  grad_norm: 1.6138
05/10 17:56:29 - mmengine - INFO - Iter(train) [  3830/480000]  lr: 5.3186e-05  eta: 8 days, 3:14:02  time: 1.2272  data_time: 0.0056  memory: 9279  loss: 1.3200  grad_norm: 1.6540
05/10 17:56:44 - mmengine - INFO - Iter(train) [  3840/480000]  lr: 5.3325e-05  eta: 8 days, 3:13:00  time: 1.4382  data_time: 0.0056  memory: 9278  loss: 1.3321  grad_norm: 1.6988
05/10 17:56:58 - mmengine - INFO - Iter(train) [  3850/480000]  lr: 5.3464e-05  eta: 8 days, 3:11:50  time: 1.4311  data_time: 0.2058  memory: 9280  loss: 1.3015  grad_norm: 1.6988
05/10 17:57:14 - mmengine - INFO - Iter(train) [  3860/480000]  lr: 5.3602e-05  eta: 8 days, 3:13:20  time: 1.5604  data_time: 0.0057  memory: 9280  loss: 1.2733  grad_norm: 1.7239
05/10 17:57:26 - mmengine - INFO - Iter(train) [  3870/480000]  lr: 5.3741e-05  eta: 8 days, 3:08:05  time: 1.2326  data_time: 0.0057  memory: 9280  loss: 1.2885  grad_norm: 1.7239
05/10 17:57:38 - mmengine - INFO - Iter(train) [  3880/480000]  lr: 5.3880e-05  eta: 8 days, 3:02:26  time: 1.2105  data_time: 0.0057  memory: 9279  loss: 1.2327  grad_norm: 1.7403
05/10 17:57:53 - mmengine - INFO - Iter(train) [  3890/480000]  lr: 5.4019e-05  eta: 8 days, 3:03:10  time: 1.5229  data_time: 0.0056  memory: 9280  loss: 1.2768  grad_norm: 1.7353
05/10 17:58:06 - mmengine - INFO - Iter(train) [  3900/480000]  lr: 5.4158e-05  eta: 8 days, 2:58:09  time: 1.2402  data_time: 0.0057  memory: 9281  loss: 1.2944  grad_norm: 1.7353
05/10 17:58:18 - mmengine - INFO - Iter(train) [  3910/480000]  lr: 5.4297e-05  eta: 8 days, 2:53:14  time: 1.2442  data_time: 0.0056  memory: 9281  loss: 1.3025  grad_norm: 1.7498
05/10 17:58:34 - mmengine - INFO - Iter(train) [  3920/480000]  lr: 5.4436e-05  eta: 8 days, 2:54:16  time: 1.5370  data_time: 0.0057  memory: 9280  loss: 1.2818  grad_norm: 1.7649
05/10 17:58:46 - mmengine - INFO - Iter(train) [  3930/480000]  lr: 5.4575e-05  eta: 8 days, 2:48:38  time: 1.2074  data_time: 0.0056  memory: 9280  loss: 1.2509  grad_norm: 1.7649
05/10 17:59:01 - mmengine - INFO - Iter(train) [  3940/480000]  lr: 5.4714e-05  eta: 8 days, 2:50:01  time: 1.5533  data_time: 0.0054  memory: 9280  loss: 1.2914  grad_norm: 1.7533
05/10 17:59:13 - mmengine - INFO - Iter(train) [  3950/480000]  lr: 5.4852e-05  eta: 8 days, 2:44:47  time: 1.2257  data_time: 0.0056  memory: 9280  loss: 1.2957  grad_norm: 1.7533
05/10 17:59:26 - mmengine - INFO - Iter(train) [  3960/480000]  lr: 5.4991e-05  eta: 8 days, 2:39:17  time: 1.2097  data_time: 0.0055  memory: 9280  loss: 1.3040  grad_norm: 1.7650
05/10 17:59:41 - mmengine - INFO - Iter(train) [  3970/480000]  lr: 5.5130e-05  eta: 8 days, 2:40:26  time: 1.5424  data_time: 0.0056  memory: 9280  loss: 1.3110  grad_norm: 1.7811
05/10 17:59:53 - mmengine - INFO - Iter(train) [  3980/480000]  lr: 5.5269e-05  eta: 8 days, 2:34:52  time: 1.2053  data_time: 0.0054  memory: 9279  loss: 1.2809  grad_norm: 1.7811
05/10 18:00:05 - mmengine - INFO - Iter(train) [  3990/480000]  lr: 5.5408e-05  eta: 8 days, 2:29:40  time: 1.2224  data_time: 0.0055  memory: 9281  loss: 1.3536  grad_norm: 1.7784
05/10 18:00:20 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 18:00:20 - mmengine - INFO - Iter(train) [  4000/480000]  lr: 5.5547e-05  eta: 8 days, 2:30:04  time: 1.5030  data_time: 0.0056  memory: 9283  loss: 1.2465  grad_norm: 1.7644
05/10 18:00:20 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:00:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些困惑呢。你觉得他这样做让你感到不舒服吗？我们可以一起探讨一下，看看怎么处理这个问题。💖<|im_end|>

05/10 18:00:25 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然好喝，但要注意适量哦。现在感觉怎么样？有没有好一些了？💖<|im_end|>

05/10 18:00:28 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你可以和她好好沟通一下，表达一下你的感受。如果需要，我可以帮你出出主意，怎么处理这种情况。💖<|im_end|>

05/10 18:00:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实有点担心呢。胆固醇高要注意饮食啦，不过戒炸鸡也不是特别难的事情。你可以试试吃一些低脂或者无脂的替代品，比如烤鸡胸肉或者蒸鸡，这样既能享受美食，又不会影响健康哦。如果还是担心，最好咨询一下医生或者营养师，他们会给你更专业的建议。💖<|im_end|>

05/10 18:00:38 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这真是让人有些尴尬呢。剧本杀本来是为了大家开心地一起推理，遇到这样的情况确实会有些影响。你当时一定很生气吧。要不要我帮你想想办法，看看能不能解决这个问题呢？💖<|im_end|>

05/10 18:00:42 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，装没看见可不好哦。这种时候应该会有点尴尬呢。你可以试试跟领导沟通一下，表达一下你的感受，也许他们只是有其他事情需要处理呢。如果还是装作没看见，可能需要考虑一下这种行为是否合适哦。💖<|im_end|>

05/10 18:00:42 - mmengine - INFO - Saving checkpoint at 4000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 18:01:01 - mmengine - INFO - Iter(train) [  4010/480000]  lr: 5.5686e-05  eta: 8 days, 3:20:59  time: 4.0573  data_time: 2.7989  memory: 9281  loss: 1.2645  grad_norm: 1.7644
05/10 18:01:13 - mmengine - INFO - Iter(train) [  4020/480000]  lr: 5.5825e-05  eta: 8 days, 3:15:28  time: 1.2108  data_time: 0.0055  memory: 9281  loss: 1.2502  grad_norm: 1.7679
05/10 18:01:28 - mmengine - INFO - Iter(train) [  4030/480000]  lr: 5.5964e-05  eta: 8 days, 3:15:51  time: 1.5089  data_time: 0.0055  memory: 9282  loss: 1.2149  grad_norm: 1.7679
05/10 18:01:40 - mmengine - INFO - Iter(train) [  4040/480000]  lr: 5.6103e-05  eta: 8 days, 3:10:05  time: 1.1952  data_time: 0.0055  memory: 9281  loss: 1.2168  grad_norm: 1.7700
05/10 18:01:52 - mmengine - INFO - Iter(train) [  4050/480000]  lr: 5.6241e-05  eta: 8 days, 3:04:22  time: 1.1969  data_time: 0.0055  memory: 9281  loss: 1.2341  grad_norm: 1.8196
05/10 18:02:08 - mmengine - INFO - Iter(train) [  4060/480000]  lr: 5.6380e-05  eta: 8 days, 3:07:15  time: 1.6360  data_time: 0.0060  memory: 9282  loss: 1.1621  grad_norm: 1.8196
05/10 18:02:21 - mmengine - INFO - Iter(train) [  4070/480000]  lr: 5.6519e-05  eta: 8 days, 3:02:34  time: 1.2482  data_time: 0.0057  memory: 9282  loss: 1.2527  grad_norm: 1.7934
05/10 18:02:35 - mmengine - INFO - Iter(train) [  4080/480000]  lr: 5.6658e-05  eta: 8 days, 3:01:38  time: 1.4396  data_time: 0.0055  memory: 9281  loss: 1.2311  grad_norm: 1.8270
05/10 18:02:47 - mmengine - INFO - Iter(train) [  4090/480000]  lr: 5.6797e-05  eta: 8 days, 2:56:09  time: 1.2053  data_time: 0.0055  memory: 9281  loss: 1.2210  grad_norm: 1.8270
05/10 18:02:59 - mmengine - INFO - Iter(train) [  4100/480000]  lr: 5.6936e-05  eta: 8 days, 2:50:52  time: 1.2146  data_time: 0.0056  memory: 9281  loss: 1.2728  grad_norm: 1.8581
05/10 18:03:16 - mmengine - INFO - Iter(train) [  4110/480000]  lr: 5.7075e-05  eta: 8 days, 2:53:57  time: 1.6464  data_time: 0.0058  memory: 9281  loss: 1.2141  grad_norm: 1.8581
05/10 18:03:28 - mmengine - INFO - Iter(train) [  4120/480000]  lr: 5.7214e-05  eta: 8 days, 2:48:47  time: 1.2184  data_time: 0.0055  memory: 9281  loss: 1.2290  grad_norm: 1.8877
05/10 18:03:43 - mmengine - INFO - Iter(train) [  4130/480000]  lr: 5.7353e-05  eta: 8 days, 2:48:13  time: 1.4575  data_time: 0.0055  memory: 9280  loss: 1.2107  grad_norm: 1.9067
05/10 18:03:55 - mmengine - INFO - Iter(train) [  4140/480000]  lr: 5.7492e-05  eta: 8 days, 2:42:49  time: 1.2047  data_time: 0.0055  memory: 9281  loss: 1.2949  grad_norm: 1.9067
05/10 18:04:07 - mmengine - INFO - Iter(train) [  4150/480000]  lr: 5.7630e-05  eta: 8 days, 2:37:47  time: 1.2218  data_time: 0.0055  memory: 9280  loss: 1.2325  grad_norm: 1.9110
05/10 18:04:22 - mmengine - INFO - Iter(train) [  4160/480000]  lr: 5.7769e-05  eta: 8 days, 2:38:40  time: 1.5318  data_time: 0.0056  memory: 9280  loss: 1.1598  grad_norm: 1.9699
05/10 18:04:36 - mmengine - INFO - Iter(train) [  4170/480000]  lr: 5.7908e-05  eta: 8 days, 2:37:22  time: 1.4169  data_time: 0.2056  memory: 9283  loss: 1.1566  grad_norm: 1.9699
05/10 18:04:48 - mmengine - INFO - Iter(train) [  4180/480000]  lr: 5.8047e-05  eta: 8 days, 2:32:04  time: 1.2066  data_time: 0.0054  memory: 9281  loss: 1.1764  grad_norm: 1.9763
05/10 18:05:04 - mmengine - INFO - Iter(train) [  4190/480000]  lr: 5.8186e-05  eta: 8 days, 2:33:22  time: 1.5532  data_time: 0.0055  memory: 9283  loss: 1.2080  grad_norm: 1.9763
05/10 18:05:16 - mmengine - INFO - Iter(train) [  4200/480000]  lr: 5.8325e-05  eta: 8 days, 2:28:24  time: 1.2222  data_time: 0.0055  memory: 9282  loss: 1.1320  grad_norm: 2.0153
05/10 18:05:31 - mmengine - INFO - Iter(train) [  4210/480000]  lr: 5.8464e-05  eta: 8 days, 2:29:12  time: 1.5272  data_time: 0.0055  memory: 9285  loss: 1.1410  grad_norm: 2.0154
05/10 18:05:44 - mmengine - INFO - Iter(train) [  4220/480000]  lr: 5.8603e-05  eta: 8 days, 2:24:09  time: 1.2154  data_time: 0.0055  memory: 9282  loss: 1.2195  grad_norm: 2.0154
05/10 18:05:56 - mmengine - INFO - Iter(train) [  4230/480000]  lr: 5.8742e-05  eta: 8 days, 2:19:02  time: 1.2107  data_time: 0.0055  memory: 9281  loss: 1.1939  grad_norm: 2.0406
05/10 18:06:11 - mmengine - INFO - Iter(train) [  4240/480000]  lr: 5.8881e-05  eta: 8 days, 2:20:36  time: 1.5680  data_time: 0.0056  memory: 9283  loss: 1.1877  grad_norm: 2.0713
05/10 18:06:24 - mmengine - INFO - Iter(train) [  4250/480000]  lr: 5.9019e-05  eta: 8 days, 2:15:55  time: 1.2328  data_time: 0.0055  memory: 9284  loss: 1.1224  grad_norm: 2.0713
05/10 18:06:36 - mmengine - INFO - Iter(train) [  4260/480000]  lr: 5.9158e-05  eta: 8 days, 2:10:46  time: 1.2064  data_time: 0.0055  memory: 9282  loss: 1.1687  grad_norm: 2.0620
05/10 18:06:51 - mmengine - INFO - Iter(train) [  4270/480000]  lr: 5.9297e-05  eta: 8 days, 2:11:51  time: 1.5409  data_time: 0.0056  memory: 9282  loss: 1.1758  grad_norm: 2.0620
05/10 18:07:03 - mmengine - INFO - Iter(train) [  4280/480000]  lr: 5.9436e-05  eta: 8 days, 2:06:49  time: 1.2104  data_time: 0.0055  memory: 9281  loss: 1.1488  grad_norm: 2.0819
05/10 18:07:16 - mmengine - INFO - Iter(train) [  4290/480000]  lr: 5.9575e-05  eta: 8 days, 2:01:59  time: 1.2205  data_time: 0.0055  memory: 9282  loss: 1.1919  grad_norm: 2.0866
05/10 18:07:33 - mmengine - INFO - Iter(train) [  4300/480000]  lr: 5.9714e-05  eta: 8 days, 2:06:11  time: 1.7097  data_time: 0.0061  memory: 9282  loss: 1.1944  grad_norm: 2.0866
05/10 18:07:47 - mmengine - INFO - Iter(train) [  4310/480000]  lr: 5.9853e-05  eta: 8 days, 2:05:20  time: 1.4361  data_time: 0.0065  memory: 9282  loss: 1.1429  grad_norm: 2.1048
05/10 18:08:00 - mmengine - INFO - Iter(train) [  4320/480000]  lr: 5.9992e-05  eta: 8 days, 2:01:31  time: 1.2746  data_time: 0.0063  memory: 9282  loss: 1.2217  grad_norm: 2.0959
05/10 18:08:13 - mmengine - INFO - Iter(train) [  4330/480000]  lr: 6.0131e-05  eta: 8 days, 1:58:39  time: 1.3250  data_time: 0.2060  memory: 9281  loss: 1.1300  grad_norm: 2.0959
05/10 18:08:26 - mmengine - INFO - Iter(train) [  4340/480000]  lr: 6.0269e-05  eta: 8 days, 1:54:57  time: 1.2791  data_time: 0.0058  memory: 9283  loss: 1.1281  grad_norm: 2.0924
05/10 18:08:41 - mmengine - INFO - Iter(train) [  4350/480000]  lr: 6.0408e-05  eta: 8 days, 1:55:21  time: 1.5030  data_time: 0.0061  memory: 9282  loss: 1.1232  grad_norm: 2.0924
05/10 18:08:53 - mmengine - INFO - Iter(train) [  4360/480000]  lr: 6.0547e-05  eta: 8 days, 1:51:28  time: 1.2674  data_time: 0.0058  memory: 9283  loss: 1.1208  grad_norm: 2.1016
05/10 18:09:06 - mmengine - INFO - Iter(train) [  4370/480000]  lr: 6.0686e-05  eta: 8 days, 1:47:10  time: 1.2437  data_time: 0.0057  memory: 9284  loss: 1.1460  grad_norm: 2.0940
05/10 18:09:21 - mmengine - INFO - Iter(train) [  4380/480000]  lr: 6.0825e-05  eta: 8 days, 1:47:35  time: 1.5031  data_time: 0.0058  memory: 9284  loss: 1.1149  grad_norm: 2.0940
05/10 18:09:33 - mmengine - INFO - Iter(train) [  4390/480000]  lr: 6.0964e-05  eta: 8 days, 1:42:51  time: 1.2187  data_time: 0.0057  memory: 9284  loss: 1.1146  grad_norm: 2.1202
05/10 18:09:48 - mmengine - INFO - Iter(train) [  4400/480000]  lr: 6.1103e-05  eta: 8 days, 1:42:39  time: 1.4680  data_time: 0.0056  memory: 9284  loss: 1.1088  grad_norm: 2.1055
05/10 18:10:01 - mmengine - INFO - Iter(train) [  4410/480000]  lr: 6.1242e-05  eta: 8 days, 1:39:12  time: 1.2883  data_time: 0.0058  memory: 9284  loss: 1.0825  grad_norm: 2.1055
05/10 18:10:13 - mmengine - INFO - Iter(train) [  4420/480000]  lr: 6.1381e-05  eta: 8 days, 1:35:01  time: 1.2466  data_time: 0.0056  memory: 9284  loss: 1.1001  grad_norm: 2.1320
05/10 18:10:28 - mmengine - INFO - Iter(train) [  4430/480000]  lr: 6.1520e-05  eta: 8 days, 1:35:43  time: 1.5174  data_time: 0.0058  memory: 9285  loss: 1.1202  grad_norm: 2.1320
05/10 18:10:41 - mmengine - INFO - Iter(train) [  4440/480000]  lr: 6.1658e-05  eta: 8 days, 1:31:18  time: 1.2319  data_time: 0.0056  memory: 9284  loss: 1.1239  grad_norm: 2.1627
05/10 18:10:55 - mmengine - INFO - Iter(train) [  4450/480000]  lr: 6.1797e-05  eta: 8 days, 1:31:07  time: 1.4685  data_time: 0.0056  memory: 9283  loss: 1.1311  grad_norm: 2.1972
05/10 18:11:08 - mmengine - INFO - Iter(train) [  4460/480000]  lr: 6.1936e-05  eta: 8 days, 1:27:52  time: 1.2955  data_time: 0.0058  memory: 9284  loss: 1.0889  grad_norm: 2.1972
05/10 18:11:21 - mmengine - INFO - Iter(train) [  4470/480000]  lr: 6.2075e-05  eta: 8 days, 1:23:34  time: 1.2361  data_time: 0.0057  memory: 9283  loss: 1.1560  grad_norm: 2.2108
05/10 18:11:35 - mmengine - INFO - Iter(train) [  4480/480000]  lr: 6.2214e-05  eta: 8 days, 1:22:12  time: 1.4006  data_time: 0.0057  memory: 9284  loss: 1.1038  grad_norm: 2.2297
05/10 18:11:49 - mmengine - INFO - Iter(train) [  4490/480000]  lr: 6.2353e-05  eta: 8 days, 1:21:17  time: 1.4260  data_time: 0.2057  memory: 9284  loss: 1.0540  grad_norm: 2.2297
05/10 18:12:04 - mmengine - INFO - Iter(train) [  4500/480000]  lr: 6.2492e-05  eta: 8 days, 1:21:10  time: 1.4711  data_time: 0.0056  memory: 9283  loss: 1.0874  grad_norm: 2.2761
05/10 18:12:04 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:12:13 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。首先，你需要和你的男朋友好好沟通一下你的感受。如果他真的出轨了，那么可能需要好好谈谈，理解他的压力和情绪。同时，也要考虑自己的感受和需求。如果他只是偶尔为之，也许可以理解为是工作压力导致的疏忽。但如果是经常这样做，那么可能需要采取一些措施来保护自己。💖

如果你需要更多建议或者只是想要倾诉，我在这里哦。🌸<|im_end|>

05/10 18:12:16 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然好喝，但要注意适量哦。现在感觉怎么样了？有没有吃点什么缓解一下？💖<|im_end|>

05/10 18:12:19 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些不舒服呢。你可以和她好好沟通一下，表达一下你的感受。如果需要倾诉或者寻求建议，我在这里哦。💖<|im_end|>

05/10 18:12:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实需要注意饮食啦。胆固醇高的话，建议少吃点油腻的食物哦。不过，炸鸡也可以偶尔尝尝，不过要注意控制摄入量呢。💖 你有没有什么健康饮食的建议或者想要分享的呢？<|im_end|>

05/10 18:12:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的‘弃门而去’侠’吗？😂 不过别太往心里去，毕竟‘悲剧’的剧本杀，有时候也需要‘悲剧’的玩家来演绎。下次记得，带个‘剧本杀界的‘弃门而去’侠’同行，保佑你别再遇到这种‘悲剧’的玩家了！<|im_end|>

05/10 18:12:33 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装没看见呢。领导的指示很重要，不过你可以试试私下里跟他说一下你的感受，也许他会理解你的。毕竟，工作上的事情有时候需要大家的沟通和理解哦。💖<|im_end|>

05/10 18:12:33 - mmengine - INFO - Saving checkpoint at 4500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 18:12:49 - mmengine - INFO - Iter(train) [  4510/480000]  lr: 6.2631e-05  eta: 8 days, 2:15:45  time: 4.5844  data_time: 3.0477  memory: 9284  loss: 1.0875  grad_norm: 2.2761
05/10 18:13:02 - mmengine - INFO - Iter(train) [  4520/480000]  lr: 6.2770e-05  eta: 8 days, 2:11:16  time: 1.2285  data_time: 0.0056  memory: 9284  loss: 1.1087  grad_norm: 2.2944
05/10 18:13:17 - mmengine - INFO - Iter(train) [  4530/480000]  lr: 6.2909e-05  eta: 8 days, 2:11:15  time: 1.4837  data_time: 0.0056  memory: 9284  loss: 1.0462  grad_norm: 2.3460
05/10 18:13:29 - mmengine - INFO - Iter(train) [  4540/480000]  lr: 6.3047e-05  eta: 8 days, 2:07:02  time: 1.2426  data_time: 0.0057  memory: 9285  loss: 0.9918  grad_norm: 2.3460
05/10 18:13:41 - mmengine - INFO - Iter(train) [  4550/480000]  lr: 6.3186e-05  eta: 8 days, 2:02:19  time: 1.2128  data_time: 0.0055  memory: 9284  loss: 1.0374  grad_norm: 2.3363
05/10 18:13:56 - mmengine - INFO - Iter(train) [  4560/480000]  lr: 6.3325e-05  eta: 8 days, 2:02:44  time: 1.5074  data_time: 0.0059  memory: 9285  loss: 1.0675  grad_norm: 2.3509
05/10 18:14:09 - mmengine - INFO - Iter(train) [  4570/480000]  lr: 6.3464e-05  eta: 8 days, 1:58:24  time: 1.2341  data_time: 0.0055  memory: 9284  loss: 1.1083  grad_norm: 2.3509
05/10 18:14:23 - mmengine - INFO - Iter(train) [  4580/480000]  lr: 6.3603e-05  eta: 8 days, 1:58:30  time: 1.4881  data_time: 0.0058  memory: 9285  loss: 1.0193  grad_norm: 2.3589
05/10 18:14:36 - mmengine - INFO - Iter(train) [  4590/480000]  lr: 6.3742e-05  eta: 8 days, 1:54:39  time: 1.2606  data_time: 0.0059  memory: 9285  loss: 1.0186  grad_norm: 2.3589
05/10 18:14:48 - mmengine - INFO - Iter(train) [  4600/480000]  lr: 6.3881e-05  eta: 8 days, 1:50:11  time: 1.2229  data_time: 0.0055  memory: 9285  loss: 0.9958  grad_norm: 2.3201
05/10 18:15:03 - mmengine - INFO - Iter(train) [  4610/480000]  lr: 6.4020e-05  eta: 8 days, 1:50:45  time: 1.5154  data_time: 0.0059  memory: 9284  loss: 1.0818  grad_norm: 2.3240
05/10 18:15:16 - mmengine - INFO - Iter(train) [  4620/480000]  lr: 6.4159e-05  eta: 8 days, 1:46:33  time: 1.2369  data_time: 0.0056  memory: 9285  loss: 1.0586  grad_norm: 2.3240
05/10 18:15:28 - mmengine - INFO - Iter(train) [  4630/480000]  lr: 6.4297e-05  eta: 8 days, 1:42:28  time: 1.2430  data_time: 0.0056  memory: 9284  loss: 1.1144  grad_norm: 2.3346
05/10 18:15:43 - mmengine - INFO - Iter(train) [  4640/480000]  lr: 6.4436e-05  eta: 8 days, 1:41:54  time: 1.4486  data_time: 0.0059  memory: 9283  loss: 1.0592  grad_norm: 2.3085
05/10 18:15:58 - mmengine - INFO - Iter(train) [  4650/480000]  lr: 6.4575e-05  eta: 8 days, 1:43:32  time: 1.5768  data_time: 0.2072  memory: 9284  loss: 1.0004  grad_norm: 2.3085
05/10 18:16:12 - mmengine - INFO - Iter(train) [  4660/480000]  lr: 6.4714e-05  eta: 8 days, 1:41:01  time: 1.3337  data_time: 0.0059  memory: 9286  loss: 0.9809  grad_norm: 2.3224
05/10 18:16:24 - mmengine - INFO - Iter(train) [  4670/480000]  lr: 6.4853e-05  eta: 8 days, 1:36:53  time: 1.2374  data_time: 0.0055  memory: 9285  loss: 0.9651  grad_norm: 2.3224
05/10 18:16:36 - mmengine - INFO - Iter(train) [  4680/480000]  lr: 6.4992e-05  eta: 8 days, 1:32:39  time: 1.2308  data_time: 0.0057  memory: 9286  loss: 1.0179  grad_norm: 2.2984
05/10 18:16:50 - mmengine - INFO - Iter(train) [  4690/480000]  lr: 6.5131e-05  eta: 8 days, 1:30:50  time: 1.3724  data_time: 0.0061  memory: 9285  loss: 1.0007  grad_norm: 2.2979
05/10 18:17:04 - mmengine - INFO - Iter(train) [  4700/480000]  lr: 6.5270e-05  eta: 8 days, 1:28:36  time: 1.3477  data_time: 0.0060  memory: 9285  loss: 1.0249  grad_norm: 2.2979
05/10 18:17:19 - mmengine - INFO - Iter(train) [  4710/480000]  lr: 6.5409e-05  eta: 8 days, 1:29:59  time: 1.5622  data_time: 0.0061  memory: 9286  loss: 1.0336  grad_norm: 2.3254
05/10 18:17:32 - mmengine - INFO - Iter(train) [  4720/480000]  lr: 6.5548e-05  eta: 8 days, 1:26:08  time: 1.2513  data_time: 0.0058  memory: 9284  loss: 1.0082  grad_norm: 2.3166
05/10 18:17:46 - mmengine - INFO - Iter(train) [  4730/480000]  lr: 6.5686e-05  eta: 8 days, 1:24:30  time: 1.3824  data_time: 0.0056  memory: 9284  loss: 0.9815  grad_norm: 2.3166
05/10 18:17:59 - mmengine - INFO - Iter(train) [  4740/480000]  lr: 6.5825e-05  eta: 8 days, 1:21:20  time: 1.2895  data_time: 0.0057  memory: 9285  loss: 0.9622  grad_norm: 2.3239
05/10 18:18:12 - mmengine - INFO - Iter(train) [  4750/480000]  lr: 6.5964e-05  eta: 8 days, 1:18:56  time: 1.3354  data_time: 0.0057  memory: 9285  loss: 0.9926  grad_norm: 2.3239
05/10 18:18:28 - mmengine - INFO - Iter(train) [  4760/480000]  lr: 6.6103e-05  eta: 8 days, 1:21:37  time: 1.6408  data_time: 0.0061  memory: 9285  loss: 1.0153  grad_norm: 2.3366
05/10 18:18:41 - mmengine - INFO - Iter(train) [  4770/480000]  lr: 6.6242e-05  eta: 8 days, 1:18:39  time: 1.3004  data_time: 0.0058  memory: 9284  loss: 1.0072  grad_norm: 2.3412
05/10 18:18:56 - mmengine - INFO - Iter(train) [  4780/480000]  lr: 6.6381e-05  eta: 8 days, 1:18:39  time: 1.4787  data_time: 0.0060  memory: 9285  loss: 1.0559  grad_norm: 2.3412
05/10 18:19:09 - mmengine - INFO - Iter(train) [  4790/480000]  lr: 6.6520e-05  eta: 8 days, 1:15:06  time: 1.2652  data_time: 0.0056  memory: 9285  loss: 0.9858  grad_norm: 2.3398
05/10 18:19:20 - mmengine - INFO - Iter(train) [  4800/480000]  lr: 6.6659e-05  eta: 8 days, 1:09:56  time: 1.1655  data_time: 0.0055  memory: 9285  loss: 1.0187  grad_norm: 2.3562
05/10 18:19:38 - mmengine - INFO - Iter(train) [  4810/480000]  lr: 6.6798e-05  eta: 8 days, 1:14:26  time: 1.7512  data_time: 0.2059  memory: 9285  loss: 0.9630  grad_norm: 2.3562
05/10 18:19:50 - mmengine - INFO - Iter(train) [  4820/480000]  lr: 6.6937e-05  eta: 8 days, 1:10:26  time: 1.2354  data_time: 0.0055  memory: 9286  loss: 0.9708  grad_norm: 2.3491
05/10 18:20:06 - mmengine - INFO - Iter(train) [  4830/480000]  lr: 6.7075e-05  eta: 8 days, 1:11:12  time: 1.5253  data_time: 0.0057  memory: 9285  loss: 0.9337  grad_norm: 2.3491
05/10 18:20:18 - mmengine - INFO - Iter(train) [  4840/480000]  lr: 6.7214e-05  eta: 8 days, 1:07:49  time: 1.2716  data_time: 0.0056  memory: 9287  loss: 0.9751  grad_norm: 2.3494
05/10 18:20:31 - mmengine - INFO - Iter(train) [  4850/480000]  lr: 6.7353e-05  eta: 8 days, 1:04:06  time: 1.2508  data_time: 0.0056  memory: 9288  loss: 0.9494  grad_norm: 2.4050
05/10 18:20:46 - mmengine - INFO - Iter(train) [  4860/480000]  lr: 6.7492e-05  eta: 8 days, 1:05:12  time: 1.5452  data_time: 0.0059  memory: 9288  loss: 0.9475  grad_norm: 2.4050
05/10 18:20:59 - mmengine - INFO - Iter(train) [  4870/480000]  lr: 6.7631e-05  eta: 8 days, 1:01:39  time: 1.2597  data_time: 0.0056  memory: 9287  loss: 0.9118  grad_norm: 2.4217
05/10 18:21:14 - mmengine - INFO - Iter(train) [  4880/480000]  lr: 6.7770e-05  eta: 8 days, 1:02:28  time: 1.5279  data_time: 0.0056  memory: 9286  loss: 0.9567  grad_norm: 2.4092
05/10 18:21:27 - mmengine - INFO - Iter(train) [  4890/480000]  lr: 6.7909e-05  eta: 8 days, 0:59:01  time: 1.2644  data_time: 0.0056  memory: 9284  loss: 0.9384  grad_norm: 2.4092
05/10 18:21:39 - mmengine - INFO - Iter(train) [  4900/480000]  lr: 6.8048e-05  eta: 8 days, 0:55:09  time: 1.2381  data_time: 0.0056  memory: 9285  loss: 0.9297  grad_norm: 2.4345
05/10 18:21:55 - mmengine - INFO - Iter(train) [  4910/480000]  lr: 6.8187e-05  eta: 8 days, 0:56:19  time: 1.5498  data_time: 0.0057  memory: 9285  loss: 0.9079  grad_norm: 2.4345
05/10 18:22:07 - mmengine - INFO - Iter(train) [  4920/480000]  lr: 6.8326e-05  eta: 8 days, 0:52:55  time: 1.2654  data_time: 0.0056  memory: 9286  loss: 0.9451  grad_norm: 2.4470
05/10 18:22:23 - mmengine - INFO - Iter(train) [  4930/480000]  lr: 6.8464e-05  eta: 8 days, 0:53:43  time: 1.5268  data_time: 0.0055  memory: 9286  loss: 0.9676  grad_norm: 2.4731
05/10 18:22:35 - mmengine - INFO - Iter(train) [  4940/480000]  lr: 6.8603e-05  eta: 8 days, 0:50:25  time: 1.2708  data_time: 0.0057  memory: 9286  loss: 0.9487  grad_norm: 2.4731
05/10 18:22:48 - mmengine - INFO - Iter(train) [  4950/480000]  lr: 6.8742e-05  eta: 8 days, 0:46:51  time: 1.2538  data_time: 0.0055  memory: 9288  loss: 0.9761  grad_norm: 2.5034
05/10 18:23:03 - mmengine - INFO - Iter(train) [  4960/480000]  lr: 6.8881e-05  eta: 8 days, 0:46:54  time: 1.4796  data_time: 0.0056  memory: 9287  loss: 0.9704  grad_norm: 2.5176
05/10 18:23:17 - mmengine - INFO - Iter(train) [  4970/480000]  lr: 6.9020e-05  eta: 8 days, 0:46:51  time: 1.4728  data_time: 0.2058  memory: 9285  loss: 0.8894  grad_norm: 2.5176
05/10 18:23:32 - mmengine - INFO - Iter(train) [  4980/480000]  lr: 6.9159e-05  eta: 8 days, 0:47:25  time: 1.5116  data_time: 0.0056  memory: 9286  loss: 0.8952  grad_norm: 2.5363
05/10 18:23:45 - mmengine - INFO - Iter(train) [  4990/480000]  lr: 6.9298e-05  eta: 8 days, 0:43:53  time: 1.2543  data_time: 0.0057  memory: 9286  loss: 0.9046  grad_norm: 2.5363
05/10 18:23:58 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 18:23:58 - mmengine - INFO - Iter(train) [  5000/480000]  lr: 6.9437e-05  eta: 8 days, 0:40:23  time: 1.2548  data_time: 0.0056  memory: 9287  loss: 0.9140  grad_norm: 2.5482
05/10 18:23:58 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:24:01 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很难处理呢。你觉得他为什么会这样做呢？💖你可以试着和他沟通一下你的感受，也许他会理解你的困扰。如果需要倾诉或者寻求建议，我都在这里哦。🌸<|im_end|>

05/10 18:24:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，喝酒要注意身体哦，休息一下就好。要不要我帮你找一些健康的饮品替代红酒呢？💖<|im_end|>

05/10 18:24:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实挺让人不舒服的。你可以和她沟通一下，表达一下你的感受，也许她不是故意的，只是不小心。如果需要，我可以帮你想想怎么去表达哦~ 💖<|im_end|>

05/10 18:24:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食哦，但是不吃炸鸡也不是不可以呢。可以选择一些健康的替代品，比如烤鸡或者蒸鸡，这样既能保持营养，又能减少对高脂肪食物的摄入。同时，多运动也很重要，保持良好的生活习惯。如果你需要一些健康的食谱或者建议，我可以帮你找找哦！💖<|im_end|>

05/10 18:24:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。遇到这样的情况，心里一定很难受。要不要我帮你分析一下可能的原因，或者提供一些建议如何处理这种情况呢？💖<|im_end|>

05/10 18:24:27 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的指示很重要，及时回复可能会对工作有帮助。你可以尝试在周末回复一下，表明你看到了这个信息，并询问是否需要做一些准备工作或者有什么疑问。这样既展现了你的责任心，也能让领导觉得你是在认真对待工作。如果方便的话，可以再和领导沟通一下，看看有没有其他方式可以改进这个流程。💖<|im_end|>

05/10 18:24:27 - mmengine - INFO - Saving checkpoint at 5000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 18:24:43 - mmengine - INFO - Iter(train) [  5010/480000]  lr: 6.9576e-05  eta: 8 days, 1:29:04  time: 4.5568  data_time: 3.0298  memory: 9286  loss: 0.8528  grad_norm: 2.4915
05/10 18:24:56 - mmengine - INFO - Iter(train) [  5020/480000]  lr: 6.9714e-05  eta: 8 days, 1:25:30  time: 1.2552  data_time: 0.0056  memory: 9288  loss: 0.8896  grad_norm: 2.4915
05/10 18:25:08 - mmengine - INFO - Iter(train) [  5030/480000]  lr: 6.9853e-05  eta: 8 days, 1:21:55  time: 1.2537  data_time: 0.0056  memory: 9287  loss: 0.8320  grad_norm: 2.4845
05/10 18:25:21 - mmengine - INFO - Iter(train) [  5040/480000]  lr: 6.9992e-05  eta: 8 days, 1:19:02  time: 1.2980  data_time: 0.0058  memory: 9287  loss: 0.9258  grad_norm: 2.5268
05/10 18:25:38 - mmengine - INFO - Iter(train) [  5050/480000]  lr: 7.0131e-05  eta: 8 days, 1:21:32  time: 1.6404  data_time: 0.0062  memory: 9287  loss: 0.8845  grad_norm: 2.5268
05/10 18:25:50 - mmengine - INFO - Iter(train) [  5060/480000]  lr: 7.0270e-05  eta: 8 days, 1:17:54  time: 1.2492  data_time: 0.0057  memory: 9288  loss: 0.9060  grad_norm: 2.5019
05/10 18:26:03 - mmengine - INFO - Iter(train) [  5070/480000]  lr: 7.0409e-05  eta: 8 days, 1:14:27  time: 1.2596  data_time: 0.0056  memory: 9286  loss: 0.8794  grad_norm: 2.5019
05/10 18:26:18 - mmengine - INFO - Iter(train) [  5080/480000]  lr: 7.0548e-05  eta: 8 days, 1:14:44  time: 1.4983  data_time: 0.0056  memory: 9287  loss: 0.9299  grad_norm: 2.5133
05/10 18:26:30 - mmengine - INFO - Iter(train) [  5090/480000]  lr: 7.0687e-05  eta: 8 days, 1:11:12  time: 1.2531  data_time: 0.0056  memory: 9288  loss: 0.8801  grad_norm: 2.4866
05/10 18:26:46 - mmengine - INFO - Iter(train) [  5100/480000]  lr: 7.0826e-05  eta: 8 days, 1:12:20  time: 1.5536  data_time: 0.0059  memory: 9288  loss: 0.8779  grad_norm: 2.4866
05/10 18:26:58 - mmengine - INFO - Iter(train) [  5110/480000]  lr: 7.0965e-05  eta: 8 days, 1:08:56  time: 1.2609  data_time: 0.0056  memory: 9288  loss: 0.8915  grad_norm: 2.4728
05/10 18:27:10 - mmengine - INFO - Iter(train) [  5120/480000]  lr: 7.1103e-05  eta: 8 days, 1:04:22  time: 1.1845  data_time: 0.0056  memory: 9288  loss: 0.9367  grad_norm: 2.4843
05/10 18:27:28 - mmengine - INFO - Iter(train) [  5130/480000]  lr: 7.1242e-05  eta: 8 days, 1:08:40  time: 1.7580  data_time: 0.2058  memory: 9288  loss: 0.8027  grad_norm: 2.4843
05/10 18:27:40 - mmengine - INFO - Iter(train) [  5140/480000]  lr: 7.1381e-05  eta: 8 days, 1:04:58  time: 1.2402  data_time: 0.0057  memory: 9288  loss: 0.8680  grad_norm: 2.4530
05/10 18:27:55 - mmengine - INFO - Iter(train) [  5150/480000]  lr: 7.1520e-05  eta: 8 days, 1:05:49  time: 1.5351  data_time: 0.0059  memory: 9287  loss: 0.7876  grad_norm: 2.4530
05/10 18:28:08 - mmengine - INFO - Iter(train) [  5160/480000]  lr: 7.1659e-05  eta: 8 days, 1:02:38  time: 1.2722  data_time: 0.0056  memory: 9288  loss: 0.8275  grad_norm: 2.5044
05/10 18:28:21 - mmengine - INFO - Iter(train) [  5170/480000]  lr: 7.1798e-05  eta: 8 days, 0:59:25  time: 1.2697  data_time: 0.0057  memory: 9288  loss: 0.8288  grad_norm: 2.5403
05/10 18:28:36 - mmengine - INFO - Iter(train) [  5180/480000]  lr: 7.1937e-05  eta: 8 days, 1:00:28  time: 1.5469  data_time: 0.0057  memory: 9288  loss: 0.8499  grad_norm: 2.5403
05/10 18:28:49 - mmengine - INFO - Iter(train) [  5190/480000]  lr: 7.2076e-05  eta: 8 days, 0:57:02  time: 1.2542  data_time: 0.0058  memory: 9289  loss: 0.8737  grad_norm: 2.5658
05/10 18:29:04 - mmengine - INFO - Iter(train) [  5200/480000]  lr: 7.2215e-05  eta: 8 days, 0:58:05  time: 1.5483  data_time: 0.0058  memory: 9287  loss: 0.8324  grad_norm: 2.5657
05/10 18:29:17 - mmengine - INFO - Iter(train) [  5210/480000]  lr: 7.2354e-05  eta: 8 days, 0:54:48  time: 1.2627  data_time: 0.0057  memory: 9287  loss: 0.7937  grad_norm: 2.5657
05/10 18:29:29 - mmengine - INFO - Iter(train) [  5220/480000]  lr: 7.2492e-05  eta: 8 days, 0:51:17  time: 1.2476  data_time: 0.0056  memory: 9289  loss: 0.8369  grad_norm: 2.5870
05/10 18:29:45 - mmengine - INFO - Iter(train) [  5230/480000]  lr: 7.2631e-05  eta: 8 days, 0:52:03  time: 1.5282  data_time: 0.0058  memory: 9289  loss: 0.8537  grad_norm: 2.5870
05/10 18:29:57 - mmengine - INFO - Iter(train) [  5240/480000]  lr: 7.2770e-05  eta: 8 days, 0:48:39  time: 1.2539  data_time: 0.0055  memory: 9287  loss: 0.8423  grad_norm: 2.5895
05/10 18:30:13 - mmengine - INFO - Iter(train) [  5250/480000]  lr: 7.2909e-05  eta: 8 days, 0:49:53  time: 1.5596  data_time: 0.0057  memory: 9289  loss: 0.8664  grad_norm: 2.6370
05/10 18:30:26 - mmengine - INFO - Iter(train) [  5260/480000]  lr: 7.3048e-05  eta: 8 days, 0:46:36  time: 1.2600  data_time: 0.0055  memory: 9289  loss: 0.8354  grad_norm: 2.6370
05/10 18:30:38 - mmengine - INFO - Iter(train) [  5270/480000]  lr: 7.3187e-05  eta: 8 days, 0:43:15  time: 1.2552  data_time: 0.0056  memory: 9289  loss: 0.8703  grad_norm: 2.6989
05/10 18:30:53 - mmengine - INFO - Iter(train) [  5280/480000]  lr: 7.3326e-05  eta: 8 days, 0:42:52  time: 1.4528  data_time: 0.0058  memory: 9289  loss: 0.8493  grad_norm: 2.7183
05/10 18:31:07 - mmengine - INFO - Iter(train) [  5290/480000]  lr: 7.3465e-05  eta: 8 days, 0:42:52  time: 1.4775  data_time: 0.2059  memory: 9289  loss: 0.7652  grad_norm: 2.7183
05/10 18:31:20 - mmengine - INFO - Iter(train) [  5300/480000]  lr: 7.3604e-05  eta: 8 days, 0:39:55  time: 1.2803  data_time: 0.0058  memory: 9290  loss: 0.7541  grad_norm: 2.7265
05/10 18:31:33 - mmengine - INFO - Iter(train) [  5310/480000]  lr: 7.3742e-05  eta: 8 days, 0:36:37  time: 1.2559  data_time: 0.0057  memory: 9290  loss: 0.7731  grad_norm: 2.7265
05/10 18:31:49 - mmengine - INFO - Iter(train) [  5320/480000]  lr: 7.3881e-05  eta: 8 days, 0:38:56  time: 1.6331  data_time: 0.0057  memory: 9289  loss: 0.7855  grad_norm: 2.7522
05/10 18:32:02 - mmengine - INFO - Iter(train) [  5330/480000]  lr: 7.4020e-05  eta: 8 days, 0:35:52  time: 1.2703  data_time: 0.0057  memory: 9289  loss: 0.7771  grad_norm: 2.7932
05/10 18:32:17 - mmengine - INFO - Iter(train) [  5340/480000]  lr: 7.4159e-05  eta: 8 days, 0:37:01  time: 1.5552  data_time: 0.0058  memory: 9289  loss: 0.7899  grad_norm: 2.7932
05/10 18:32:30 - mmengine - INFO - Iter(train) [  5350/480000]  lr: 7.4298e-05  eta: 8 days, 0:34:14  time: 1.2889  data_time: 0.0059  memory: 9291  loss: 0.8090  grad_norm: 2.7790
05/10 18:32:43 - mmengine - INFO - Iter(train) [  5360/480000]  lr: 7.4437e-05  eta: 8 days, 0:31:29  time: 1.2910  data_time: 0.0057  memory: 9289  loss: 0.7855  grad_norm: 2.7753
05/10 18:32:59 - mmengine - INFO - Iter(train) [  5370/480000]  lr: 7.4576e-05  eta: 8 days, 0:32:32  time: 1.5473  data_time: 0.0059  memory: 9288  loss: 0.7309  grad_norm: 2.7753
05/10 18:33:12 - mmengine - INFO - Iter(train) [  5380/480000]  lr: 7.4715e-05  eta: 8 days, 0:29:55  time: 1.2997  data_time: 0.0057  memory: 9288  loss: 0.7385  grad_norm: 2.7646
05/10 18:33:27 - mmengine - INFO - Iter(train) [  5390/480000]  lr: 7.4854e-05  eta: 8 days, 0:30:14  time: 1.4979  data_time: 0.0059  memory: 9290  loss: 0.7892  grad_norm: 2.7646
05/10 18:33:39 - mmengine - INFO - Iter(train) [  5400/480000]  lr: 7.4993e-05  eta: 8 days, 0:26:36  time: 1.2292  data_time: 0.0057  memory: 9290  loss: 0.7905  grad_norm: 2.7748
05/10 18:33:51 - mmengine - INFO - Iter(train) [  5410/480000]  lr: 7.5131e-05  eta: 8 days, 0:23:07  time: 1.2382  data_time: 0.0058  memory: 9289  loss: 0.7721  grad_norm: 2.7716
05/10 18:34:06 - mmengine - INFO - Iter(train) [  5420/480000]  lr: 7.5270e-05  eta: 8 days, 0:23:43  time: 1.5167  data_time: 0.0058  memory: 9290  loss: 0.7968  grad_norm: 2.7716
05/10 18:34:19 - mmengine - INFO - Iter(train) [  5430/480000]  lr: 7.5409e-05  eta: 8 days, 0:20:29  time: 1.2542  data_time: 0.0057  memory: 9289  loss: 0.7962  grad_norm: 2.7433
05/10 18:34:33 - mmengine - INFO - Iter(train) [  5440/480000]  lr: 7.5548e-05  eta: 8 days, 0:19:40  time: 1.4198  data_time: 0.0057  memory: 9289  loss: 0.8265  grad_norm: 2.7864
05/10 18:34:48 - mmengine - INFO - Iter(train) [  5450/480000]  lr: 7.5687e-05  eta: 8 days, 0:19:23  time: 1.4562  data_time: 0.2058  memory: 9290  loss: 0.7134  grad_norm: 2.7864
05/10 18:35:00 - mmengine - INFO - Iter(train) [  5460/480000]  lr: 7.5826e-05  eta: 8 days, 0:16:02  time: 1.2440  data_time: 0.0057  memory: 9289  loss: 0.6769  grad_norm: 2.8080
05/10 18:35:15 - mmengine - INFO - Iter(train) [  5470/480000]  lr: 7.5965e-05  eta: 8 days, 0:16:37  time: 1.5162  data_time: 0.0058  memory: 9291  loss: 0.7474  grad_norm: 2.8080
05/10 18:35:28 - mmengine - INFO - Iter(train) [  5480/480000]  lr: 7.6104e-05  eta: 8 days, 0:13:01  time: 1.2266  data_time: 0.0056  memory: 9291  loss: 0.7117  grad_norm: 2.7669
05/10 18:35:42 - mmengine - INFO - Iter(train) [  5490/480000]  lr: 7.6243e-05  eta: 8 days, 0:13:12  time: 1.4869  data_time: 0.0058  memory: 9291  loss: 0.7450  grad_norm: 2.7387
05/10 18:35:55 - mmengine - INFO - Iter(train) [  5500/480000]  lr: 7.6382e-05  eta: 8 days, 0:09:53  time: 1.2452  data_time: 0.0057  memory: 9291  loss: 0.7150  grad_norm: 2.7387
05/10 18:35:55 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:36:04 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实很让人难过呢。首先，出轨是不道德的，无论男女都应该坚决反对。而给女主播刷火箭，虽然看起来像是在表达支持，但这种行为本身就违反了道德规范。💖 你的男朋友可能只是因为一些原因而做出了这样的决定，但这种行为会对你们的关系造成伤害。如果你感到不舒服，应该勇敢地和他谈谈你的感受，告诉他你的想法和担忧。同时，也要考虑自己的感受和需要。🌸 有没有什么我能帮到你的呢？<|im_end|>

05/10 18:36:07 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。要不要我帮你找一些健康的饮品替代红酒呢？💖<|im_end|>

05/10 18:36:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你可以直接和她沟通一下你的感受，告诉她你对这种行为感到很生气。毕竟，朋友之间应该相互尊重和理解。如果你需要一些建议或者想要聊聊这件事，我在这里哦~ 💖<|im_end|>

05/10 18:36:18 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮食要注意哦，胆固醇高的话需要注意饮食清淡一些。不过，炸鸡还是可以偶尔吃的，可以选择一些健康的替代品，比如烤鸡或者蒸鸡呢！💖身体健康最重要，我们一起努力保持哦！🌸<|im_end|>

05/10 18:36:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这玩家是来自火星的神秘物种吗？😂 下次记得带把锁，保护好你的钱包免受损失！<|im_end|>

05/10 18:36:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的指示很重要，及时回应能体现你的责任心。你可以找个合适的时间和领导沟通一下，表达一下你的想法和感受。毕竟，尊重和理解领导的工作是职场生存的重要技能哦。💖<|im_end|>

05/10 18:36:26 - mmengine - INFO - Saving checkpoint at 5500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 18:36:38 - mmengine - INFO - Iter(train) [  5510/480000]  lr: 7.6520e-05  eta: 8 days, 0:51:17  time: 4.3596  data_time: 3.1355  memory: 9289  loss: 0.7128  grad_norm: 2.8030
05/10 18:36:54 - mmengine - INFO - Iter(train) [  5520/480000]  lr: 7.6659e-05  eta: 8 days, 0:51:38  time: 1.5046  data_time: 0.0057  memory: 9291  loss: 0.7345  grad_norm: 2.8146
05/10 18:37:06 - mmengine - INFO - Iter(train) [  5530/480000]  lr: 7.6798e-05  eta: 8 days, 0:48:27  time: 1.2578  data_time: 0.0058  memory: 9289  loss: 0.7130  grad_norm: 2.8146
05/10 18:37:18 - mmengine - INFO - Iter(train) [  5540/480000]  lr: 7.6937e-05  eta: 8 days, 0:44:53  time: 1.2295  data_time: 0.0056  memory: 9292  loss: 0.7273  grad_norm: 2.8261
05/10 18:37:33 - mmengine - INFO - Iter(train) [  5550/480000]  lr: 7.7076e-05  eta: 8 days, 0:45:11  time: 1.5009  data_time: 0.0057  memory: 9292  loss: 0.7412  grad_norm: 2.8261
05/10 18:37:46 - mmengine - INFO - Iter(train) [  5560/480000]  lr: 7.7215e-05  eta: 8 days, 0:41:24  time: 1.2137  data_time: 0.0056  memory: 9291  loss: 0.7256  grad_norm: 2.8831
05/10 18:38:00 - mmengine - INFO - Iter(train) [  5570/480000]  lr: 7.7354e-05  eta: 8 days, 0:41:31  time: 1.4872  data_time: 0.0057  memory: 9291  loss: 0.7282  grad_norm: 2.9095
05/10 18:38:13 - mmengine - INFO - Iter(train) [  5580/480000]  lr: 7.7493e-05  eta: 8 days, 0:38:36  time: 1.2736  data_time: 0.0060  memory: 9291  loss: 0.7342  grad_norm: 2.9095
05/10 18:38:25 - mmengine - INFO - Iter(train) [  5590/480000]  lr: 7.7632e-05  eta: 8 days, 0:35:07  time: 1.2334  data_time: 0.0056  memory: 9291  loss: 0.7696  grad_norm: 2.8826
05/10 18:38:40 - mmengine - INFO - Iter(train) [  5600/480000]  lr: 7.7771e-05  eta: 8 days, 0:34:19  time: 1.4213  data_time: 0.0057  memory: 9290  loss: 0.7447  grad_norm: 2.8251
05/10 18:38:54 - mmengine - INFO - Iter(train) [  5610/480000]  lr: 7.7909e-05  eta: 8 days, 0:33:48  time: 1.4425  data_time: 0.2059  memory: 9291  loss: 0.6791  grad_norm: 2.8251
05/10 18:39:09 - mmengine - INFO - Iter(train) [  5620/480000]  lr: 7.8048e-05  eta: 8 days, 0:34:07  time: 1.5002  data_time: 0.0057  memory: 9290  loss: 0.6375  grad_norm: 2.8316
05/10 18:39:22 - mmengine - INFO - Iter(train) [  5630/480000]  lr: 7.8187e-05  eta: 8 days, 0:31:16  time: 1.2765  data_time: 0.0057  memory: 9290  loss: 0.6410  grad_norm: 2.8316
05/10 18:39:34 - mmengine - INFO - Iter(train) [  5640/480000]  lr: 7.8326e-05  eta: 8 days, 0:27:37  time: 1.2176  data_time: 0.0056  memory: 9293  loss: 0.6771  grad_norm: 2.8947
05/10 18:39:49 - mmengine - INFO - Iter(train) [  5650/480000]  lr: 7.8465e-05  eta: 8 days, 0:27:51  time: 1.4953  data_time: 0.0058  memory: 9291  loss: 0.6579  grad_norm: 2.8804
05/10 18:40:01 - mmengine - INFO - Iter(train) [  5660/480000]  lr: 7.8604e-05  eta: 8 days, 0:24:35  time: 1.2437  data_time: 0.0056  memory: 9291  loss: 0.6730  grad_norm: 2.8804
05/10 18:40:14 - mmengine - INFO - Iter(train) [  5670/480000]  lr: 7.8743e-05  eta: 8 days, 0:21:24  time: 1.2497  data_time: 0.0057  memory: 9290  loss: 0.6461  grad_norm: 2.8259
05/10 18:40:29 - mmengine - INFO - Iter(train) [  5680/480000]  lr: 7.8882e-05  eta: 8 days, 0:22:08  time: 1.5294  data_time: 0.0058  memory: 9292  loss: 0.6944  grad_norm: 2.8398
05/10 18:40:42 - mmengine - INFO - Iter(train) [  5690/480000]  lr: 7.9021e-05  eta: 8 days, 0:18:40  time: 1.2288  data_time: 0.0057  memory: 9291  loss: 0.6830  grad_norm: 2.8398
05/10 18:40:57 - mmengine - INFO - Iter(train) [  5700/480000]  lr: 7.9159e-05  eta: 8 days, 0:19:04  time: 1.5054  data_time: 0.0057  memory: 9291  loss: 0.6578  grad_norm: 2.8526
05/10 18:41:09 - mmengine - INFO - Iter(train) [  5710/480000]  lr: 7.9298e-05  eta: 8 days, 0:15:56  time: 1.2510  data_time: 0.0058  memory: 9292  loss: 0.6652  grad_norm: 2.8526
05/10 18:41:21 - mmengine - INFO - Iter(train) [  5720/480000]  lr: 7.9437e-05  eta: 8 days, 0:12:36  time: 1.2362  data_time: 0.0057  memory: 9292  loss: 0.7100  grad_norm: 2.8332
05/10 18:41:37 - mmengine - INFO - Iter(train) [  5730/480000]  lr: 7.9576e-05  eta: 8 days, 0:13:16  time: 1.5253  data_time: 0.0059  memory: 9291  loss: 0.7183  grad_norm: 2.8812
05/10 18:41:50 - mmengine - INFO - Iter(train) [  5740/480000]  lr: 7.9715e-05  eta: 8 days, 0:11:50  time: 1.3728  data_time: 0.0064  memory: 9290  loss: 0.6870  grad_norm: 2.8812
05/10 18:42:04 - mmengine - INFO - Iter(train) [  5750/480000]  lr: 7.9854e-05  eta: 8 days, 0:10:11  time: 1.3555  data_time: 0.0061  memory: 9292  loss: 0.7067  grad_norm: 2.9207
05/10 18:42:16 - mmengine - INFO - Iter(train) [  5760/480000]  lr: 7.9993e-05  eta: 8 days, 0:06:07  time: 1.1808  data_time: 0.0056  memory: 9292  loss: 0.6847  grad_norm: 2.9272
05/10 18:42:30 - mmengine - INFO - Iter(train) [  5770/480000]  lr: 8.0132e-05  eta: 8 days, 0:05:44  time: 1.4483  data_time: 0.2059  memory: 9293  loss: 0.6181  grad_norm: 2.9272
05/10 18:42:45 - mmengine - INFO - Iter(train) [  5780/480000]  lr: 8.0271e-05  eta: 8 days, 0:05:56  time: 1.4900  data_time: 0.0058  memory: 9293  loss: 0.6085  grad_norm: 2.9325
05/10 18:42:58 - mmengine - INFO - Iter(train) [  5790/480000]  lr: 8.0410e-05  eta: 8 days, 0:02:35  time: 1.2305  data_time: 0.0056  memory: 9292  loss: 0.6158  grad_norm: 2.9325
05/10 18:43:12 - mmengine - INFO - Iter(train) [  5800/480000]  lr: 8.0548e-05  eta: 8 days, 0:02:52  time: 1.4966  data_time: 0.0057  memory: 9292  loss: 0.6086  grad_norm: 2.9192
05/10 18:43:25 - mmengine - INFO - Iter(train) [  5810/480000]  lr: 8.0687e-05  eta: 7 days, 23:59:39  time: 1.2400  data_time: 0.0057  memory: 9292  loss: 0.5984  grad_norm: 3.0153
05/10 18:43:37 - mmengine - INFO - Iter(train) [  5820/480000]  lr: 8.0826e-05  eta: 7 days, 23:56:08  time: 1.2166  data_time: 0.0056  memory: 9294  loss: 0.6434  grad_norm: 3.0153
05/10 18:43:52 - mmengine - INFO - Iter(train) [  5830/480000]  lr: 8.0965e-05  eta: 7 days, 23:56:28  time: 1.4991  data_time: 0.0057  memory: 9292  loss: 0.6270  grad_norm: 3.0436
05/10 18:44:04 - mmengine - INFO - Iter(train) [  5840/480000]  lr: 8.1104e-05  eta: 7 days, 23:53:17  time: 1.2403  data_time: 0.0056  memory: 9291  loss: 0.5969  grad_norm: 3.0311
05/10 18:44:19 - mmengine - INFO - Iter(train) [  5850/480000]  lr: 8.1243e-05  eta: 7 days, 23:53:31  time: 1.4914  data_time: 0.0057  memory: 9293  loss: 0.5956  grad_norm: 3.0311
05/10 18:44:32 - mmengine - INFO - Iter(train) [  5860/480000]  lr: 8.1382e-05  eta: 7 days, 23:50:37  time: 1.2608  data_time: 0.0058  memory: 9294  loss: 0.6181  grad_norm: 3.0267
05/10 18:44:44 - mmengine - INFO - Iter(train) [  5870/480000]  lr: 8.1521e-05  eta: 7 days, 23:47:16  time: 1.2251  data_time: 0.0057  memory: 9294  loss: 0.6193  grad_norm: 3.0267
05/10 18:44:59 - mmengine - INFO - Iter(train) [  5880/480000]  lr: 8.1660e-05  eta: 7 days, 23:47:51  time: 1.5183  data_time: 0.0058  memory: 9294  loss: 0.6497  grad_norm: 3.0107
05/10 18:45:12 - mmengine - INFO - Iter(train) [  5890/480000]  lr: 8.1799e-05  eta: 7 days, 23:44:41  time: 1.2385  data_time: 0.0056  memory: 9292  loss: 0.6442  grad_norm: 2.9775
05/10 18:45:24 - mmengine - INFO - Iter(train) [  5900/480000]  lr: 8.1937e-05  eta: 7 days, 23:41:28  time: 1.2334  data_time: 0.0057  memory: 9292  loss: 0.6222  grad_norm: 2.9775
05/10 18:45:39 - mmengine - INFO - Iter(train) [  5910/480000]  lr: 8.2076e-05  eta: 7 days, 23:41:56  time: 1.5093  data_time: 0.0059  memory: 9293  loss: 0.6521  grad_norm: 3.0089
05/10 18:45:51 - mmengine - INFO - Iter(train) [  5920/480000]  lr: 8.2215e-05  eta: 7 days, 23:37:32  time: 1.1433  data_time: 0.0055  memory: 9293  loss: 0.6759  grad_norm: 3.0282
05/10 18:46:08 - mmengine - INFO - Iter(train) [  5930/480000]  lr: 8.2354e-05  eta: 7 days, 23:41:13  time: 1.7505  data_time: 0.2059  memory: 9293  loss: 0.5711  grad_norm: 3.0282
05/10 18:46:21 - mmengine - INFO - Iter(train) [  5940/480000]  lr: 8.2493e-05  eta: 7 days, 23:38:11  time: 1.2449  data_time: 0.0056  memory: 9294  loss: 0.5751  grad_norm: 3.0377
05/10 18:46:33 - mmengine - INFO - Iter(train) [  5950/480000]  lr: 8.2632e-05  eta: 7 days, 23:34:53  time: 1.2258  data_time: 0.0057  memory: 9293  loss: 0.5894  grad_norm: 3.0377
05/10 18:46:48 - mmengine - INFO - Iter(train) [  5960/480000]  lr: 8.2771e-05  eta: 7 days, 23:35:27  time: 1.5156  data_time: 0.0057  memory: 9294  loss: 0.5718  grad_norm: 2.9774
05/10 18:47:00 - mmengine - INFO - Iter(train) [  5970/480000]  lr: 8.2910e-05  eta: 7 days, 23:32:21  time: 1.2394  data_time: 0.0058  memory: 9295  loss: 0.5354  grad_norm: 2.8791
05/10 18:47:16 - mmengine - INFO - Iter(train) [  5980/480000]  lr: 8.3049e-05  eta: 7 days, 23:33:07  time: 1.5311  data_time: 0.0056  memory: 9293  loss: 0.5801  grad_norm: 2.8791
05/10 18:47:28 - mmengine - INFO - Iter(train) [  5990/480000]  lr: 8.3188e-05  eta: 7 days, 23:29:56  time: 1.2309  data_time: 0.0056  memory: 9293  loss: 0.5216  grad_norm: 2.8674
05/10 18:47:40 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 18:47:40 - mmengine - INFO - Iter(train) [  6000/480000]  lr: 8.3326e-05  eta: 7 days, 23:26:32  time: 1.2154  data_time: 0.0056  memory: 9292  loss: 0.5623  grad_norm: 2.8966
05/10 18:47:40 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:47:49 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。首先，你需要知道，你的男朋友是爱你的，他的行为并不代表他的态度。你可以和他沟通一下你的感受，告诉他你的担忧和想法。同时，也要理解，每个人的生活观和价值观都不同，有时候沟通能解决很多问题。如果你需要倾诉或者寻求建议，我在这里随时听你说哦。💖<|im_end|>

05/10 18:47:51 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮酒要适量呢，身体最重要。要不要我帮你找一些健康的养生方法呢？💖<|im_end|>

05/10 18:47:55 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人挺不舒服的。你可以和她沟通一下，表达一下你的感受，毕竟联系到个人隐私是很敏感的事情。如果需要倾诉或者寻求建议，我随时在这里陪伴你哦！💖<|im_end|>

05/10 18:48:02 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，饮食均衡很重要呢。可以的，我们可以一起找一些健康的食谱，比如烤鸡或者蒸鸡，来满足你的口感哦。💖身体健康最重要，医生说的都是为了你的健康考虑呢。以后我们可以多吃些蔬菜水果，保持均衡饮食，这样对身体更好哦。🌸 有没有什么我能帮忙的，或者我可以陪你聊聊天分散一下注意力呢？😊<|im_end|>

05/10 18:48:06 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来真的很让人难过呢。遇到这样的情况，一定很让人失望。要不要聊聊他的原因，或者我们可以想想办法，让这个剧本杀活动更加有趣呢？💖<|im_end|>

05/10 18:48:11 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，装没看见可不好哦。领导的指示很重要，及时回复能体现你的工作态度呢。如果实在没看见，可以向领导说明情况，看看能不能找到一个双方都满意的解决方案。💖<|im_end|>

05/10 18:48:11 - mmengine - INFO - Saving checkpoint at 6000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 18:48:24 - mmengine - INFO - Iter(train) [  6010/480000]  lr: 8.3465e-05  eta: 8 days, 0:04:11  time: 4.3365  data_time: 3.0927  memory: 9293  loss: 0.5954  grad_norm: 2.8966
05/10 18:48:37 - mmengine - INFO - Iter(train) [  6020/480000]  lr: 8.3604e-05  eta: 8 days, 0:02:57  time: 1.3837  data_time: 0.0062  memory: 9293  loss: 0.6029  grad_norm: 2.9867
05/10 18:48:51 - mmengine - INFO - Iter(train) [  6030/480000]  lr: 8.3743e-05  eta: 8 days, 0:01:36  time: 1.3736  data_time: 0.0064  memory: 9294  loss: 0.5721  grad_norm: 2.9867
05/10 18:49:05 - mmengine - INFO - Iter(train) [  6040/480000]  lr: 8.3882e-05  eta: 7 days, 23:59:52  time: 1.3448  data_time: 0.0062  memory: 9293  loss: 0.5864  grad_norm: 3.0496
05/10 18:49:20 - mmengine - INFO - Iter(train) [  6050/480000]  lr: 8.4021e-05  eta: 8 days, 0:00:57  time: 1.5595  data_time: 0.0060  memory: 9295  loss: 0.6042  grad_norm: 3.0087
05/10 18:49:33 - mmengine - INFO - Iter(train) [  6060/480000]  lr: 8.4160e-05  eta: 7 days, 23:58:59  time: 1.3269  data_time: 0.0060  memory: 9293  loss: 0.5856  grad_norm: 3.0087
05/10 18:49:47 - mmengine - INFO - Iter(train) [  6070/480000]  lr: 8.4299e-05  eta: 7 days, 23:56:59  time: 1.3227  data_time: 0.0061  memory: 9292  loss: 0.6058  grad_norm: 2.9692
05/10 18:49:58 - mmengine - INFO - Iter(train) [  6080/480000]  lr: 8.4438e-05  eta: 7 days, 23:52:43  time: 1.1480  data_time: 0.0056  memory: 9295  loss: 0.5507  grad_norm: 2.9848
05/10 18:50:13 - mmengine - INFO - Iter(train) [  6090/480000]  lr: 8.4576e-05  eta: 7 days, 23:52:34  time: 1.4658  data_time: 0.2059  memory: 9294  loss: 0.5308  grad_norm: 2.9848
05/10 18:50:26 - mmengine - INFO - Iter(train) [  6100/480000]  lr: 8.4715e-05  eta: 7 days, 23:50:55  time: 1.3486  data_time: 0.0062  memory: 9294  loss: 0.5260  grad_norm: 3.0508
05/10 18:50:40 - mmengine - INFO - Iter(train) [  6110/480000]  lr: 8.4854e-05  eta: 7 days, 23:49:08  time: 1.3380  data_time: 0.0062  memory: 9294  loss: 0.5321  grad_norm: 3.0508
05/10 18:50:55 - mmengine - INFO - Iter(train) [  6120/480000]  lr: 8.4993e-05  eta: 7 days, 23:50:17  time: 1.5648  data_time: 0.0063  memory: 9294  loss: 0.5231  grad_norm: 3.1024
05/10 18:51:08 - mmengine - INFO - Iter(train) [  6130/480000]  lr: 8.5132e-05  eta: 7 days, 23:47:50  time: 1.2864  data_time: 0.0058  memory: 9294  loss: 0.5297  grad_norm: 3.0744
05/10 18:51:22 - mmengine - INFO - Iter(train) [  6140/480000]  lr: 8.5271e-05  eta: 7 days, 23:47:02  time: 1.4139  data_time: 0.0056  memory: 9295  loss: 0.5259  grad_norm: 3.0744
05/10 18:51:35 - mmengine - INFO - Iter(train) [  6150/480000]  lr: 8.5410e-05  eta: 7 days, 23:43:46  time: 1.2208  data_time: 0.0057  memory: 9294  loss: 0.5093  grad_norm: 3.0892
05/10 18:51:47 - mmengine - INFO - Iter(train) [  6160/480000]  lr: 8.5549e-05  eta: 7 days, 23:40:29  time: 1.2195  data_time: 0.0057  memory: 9294  loss: 0.5122  grad_norm: 3.1330
05/10 18:52:02 - mmengine - INFO - Iter(train) [  6170/480000]  lr: 8.5688e-05  eta: 7 days, 23:41:40  time: 1.5679  data_time: 0.0060  memory: 9294  loss: 0.5272  grad_norm: 3.1330
05/10 18:52:15 - mmengine - INFO - Iter(train) [  6180/480000]  lr: 8.5827e-05  eta: 7 days, 23:39:02  time: 1.2701  data_time: 0.0057  memory: 9294  loss: 0.5444  grad_norm: 3.1304
05/10 18:52:28 - mmengine - INFO - Iter(train) [  6190/480000]  lr: 8.5965e-05  eta: 7 days, 23:36:36  time: 1.2839  data_time: 0.0059  memory: 9294  loss: 0.5342  grad_norm: 3.1304
05/10 18:52:42 - mmengine - INFO - Iter(train) [  6200/480000]  lr: 8.6104e-05  eta: 7 days, 23:36:07  time: 1.4376  data_time: 0.0057  memory: 9295  loss: 0.5417  grad_norm: 3.0585
05/10 18:52:55 - mmengine - INFO - Iter(train) [  6210/480000]  lr: 8.6243e-05  eta: 7 days, 23:33:06  time: 1.2372  data_time: 0.0056  memory: 9294  loss: 0.5232  grad_norm: 3.0170
05/10 18:53:10 - mmengine - INFO - Iter(train) [  6220/480000]  lr: 8.6382e-05  eta: 7 days, 23:33:57  time: 1.5412  data_time: 0.0058  memory: 9294  loss: 0.5274  grad_norm: 3.0170
05/10 18:53:22 - mmengine - INFO - Iter(train) [  6230/480000]  lr: 8.6521e-05  eta: 7 days, 23:30:54  time: 1.2343  data_time: 0.0056  memory: 9294  loss: 0.5399  grad_norm: 3.1777
05/10 18:53:34 - mmengine - INFO - Iter(train) [  6240/480000]  lr: 8.6660e-05  eta: 7 days, 23:26:36  time: 1.1352  data_time: 0.0055  memory: 9296  loss: 0.5649  grad_norm: 3.2069
05/10 18:53:51 - mmengine - INFO - Iter(train) [  6250/480000]  lr: 8.6799e-05  eta: 7 days, 23:29:42  time: 1.7186  data_time: 0.2060  memory: 9296  loss: 0.4945  grad_norm: 3.2069
05/10 18:54:03 - mmengine - INFO - Iter(train) [  6260/480000]  lr: 8.6938e-05  eta: 7 days, 23:26:48  time: 1.2441  data_time: 0.0056  memory: 9294  loss: 0.4829  grad_norm: 3.0979
05/10 18:54:19 - mmengine - INFO - Iter(train) [  6270/480000]  lr: 8.7077e-05  eta: 7 days, 23:27:29  time: 1.5292  data_time: 0.0057  memory: 9295  loss: 0.4627  grad_norm: 3.0979
05/10 18:54:31 - mmengine - INFO - Iter(train) [  6280/480000]  lr: 8.7216e-05  eta: 7 days, 23:24:28  time: 1.2343  data_time: 0.0057  memory: 9295  loss: 0.4614  grad_norm: 3.0828
05/10 18:54:43 - mmengine - INFO - Iter(train) [  6290/480000]  lr: 8.7354e-05  eta: 7 days, 23:21:24  time: 1.2297  data_time: 0.0056  memory: 9295  loss: 0.4708  grad_norm: 3.1788
05/10 18:54:59 - mmengine - INFO - Iter(train) [  6300/480000]  lr: 8.7493e-05  eta: 7 days, 23:21:57  time: 1.5168  data_time: 0.0057  memory: 9295  loss: 0.4999  grad_norm: 3.1788
05/10 18:55:11 - mmengine - INFO - Iter(train) [  6310/480000]  lr: 8.7632e-05  eta: 7 days, 23:18:55  time: 1.2310  data_time: 0.0056  memory: 9295  loss: 0.4999  grad_norm: 3.1874
05/10 18:55:26 - mmengine - INFO - Iter(train) [  6320/480000]  lr: 8.7771e-05  eta: 7 days, 23:19:18  time: 1.5047  data_time: 0.0055  memory: 9295  loss: 0.5070  grad_norm: 3.1230
05/10 18:55:38 - mmengine - INFO - Iter(train) [  6330/480000]  lr: 8.7910e-05  eta: 7 days, 23:16:17  time: 1.2317  data_time: 0.0058  memory: 9296  loss: 0.4663  grad_norm: 3.1230
05/10 18:55:50 - mmengine - INFO - Iter(train) [  6340/480000]  lr: 8.8049e-05  eta: 7 days, 23:13:08  time: 1.2206  data_time: 0.0058  memory: 9296  loss: 0.4802  grad_norm: 3.0340
05/10 18:56:06 - mmengine - INFO - Iter(train) [  6350/480000]  lr: 8.8188e-05  eta: 7 days, 23:13:47  time: 1.5252  data_time: 0.0057  memory: 9294  loss: 0.4858  grad_norm: 3.0340
05/10 18:56:18 - mmengine - INFO - Iter(train) [  6360/480000]  lr: 8.8327e-05  eta: 7 days, 23:10:55  time: 1.2409  data_time: 0.0057  memory: 9296  loss: 0.4905  grad_norm: 3.1214
05/10 18:56:30 - mmengine - INFO - Iter(train) [  6370/480000]  lr: 8.8466e-05  eta: 7 days, 23:07:53  time: 1.2281  data_time: 0.0056  memory: 9297  loss: 0.5044  grad_norm: 3.2131
05/10 18:56:46 - mmengine - INFO - Iter(train) [  6380/480000]  lr: 8.8604e-05  eta: 7 days, 23:08:32  time: 1.5256  data_time: 0.0058  memory: 9296  loss: 0.5014  grad_norm: 3.2131
05/10 18:56:58 - mmengine - INFO - Iter(train) [  6390/480000]  lr: 8.8743e-05  eta: 7 days, 23:05:38  time: 1.2373  data_time: 0.0056  memory: 9296  loss: 0.5030  grad_norm: 3.0584
05/10 18:57:12 - mmengine - INFO - Iter(train) [  6400/480000]  lr: 8.8882e-05  eta: 7 days, 23:05:22  time: 1.4506  data_time: 0.0057  memory: 9298  loss: 0.5030  grad_norm: 3.0159
05/10 18:57:27 - mmengine - INFO - Iter(train) [  6410/480000]  lr: 8.9021e-05  eta: 7 days, 23:05:02  time: 1.4451  data_time: 0.2058  memory: 9295  loss: 0.4520  grad_norm: 3.0159
05/10 18:57:39 - mmengine - INFO - Iter(train) [  6420/480000]  lr: 8.9160e-05  eta: 7 days, 23:01:55  time: 1.2182  data_time: 0.0057  memory: 9295  loss: 0.4449  grad_norm: 3.0756
05/10 18:57:54 - mmengine - INFO - Iter(train) [  6430/480000]  lr: 8.9299e-05  eta: 7 days, 23:02:27  time: 1.5158  data_time: 0.0057  memory: 9295  loss: 0.4387  grad_norm: 3.0756
05/10 18:58:07 - mmengine - INFO - Iter(train) [  6440/480000]  lr: 8.9438e-05  eta: 7 days, 22:59:44  time: 1.2507  data_time: 0.0058  memory: 9297  loss: 0.4385  grad_norm: 3.0462
05/10 18:58:22 - mmengine - INFO - Iter(train) [  6450/480000]  lr: 8.9577e-05  eta: 7 days, 23:00:33  time: 1.5381  data_time: 0.0057  memory: 9296  loss: 0.4211  grad_norm: 3.0403
05/10 18:58:34 - mmengine - INFO - Iter(train) [  6460/480000]  lr: 8.9716e-05  eta: 7 days, 22:57:34  time: 1.2282  data_time: 0.0055  memory: 9296  loss: 0.4352  grad_norm: 3.0403
05/10 18:58:47 - mmengine - INFO - Iter(train) [  6470/480000]  lr: 8.9855e-05  eta: 7 days, 22:54:41  time: 1.2345  data_time: 0.0056  memory: 9296  loss: 0.4349  grad_norm: 3.0240
05/10 18:59:02 - mmengine - INFO - Iter(train) [  6480/480000]  lr: 8.9993e-05  eta: 7 days, 22:55:19  time: 1.5239  data_time: 0.0057  memory: 9297  loss: 0.4384  grad_norm: 3.0885
05/10 18:59:14 - mmengine - INFO - Iter(train) [  6490/480000]  lr: 9.0132e-05  eta: 7 days, 22:52:30  time: 1.2394  data_time: 0.0056  memory: 9296  loss: 0.4476  grad_norm: 3.0885
05/10 18:59:27 - mmengine - INFO - Iter(train) [  6500/480000]  lr: 9.0271e-05  eta: 7 days, 22:49:31  time: 1.2247  data_time: 0.0056  memory: 9296  loss: 0.4439  grad_norm: 3.1469
05/10 18:59:27 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 18:59:34 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些难过呢。你的男朋友是怎么想的呢？💖或许你可以和他好好谈谈，表达你的感受。毕竟，出轨行为是不被允许的。如果你需要倾诉或者寻求建议，我在这里随时听你说哦。🌸<|im_end|>

05/10 18:59:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然有益，但要注意适量哦。现在感觉好点了吗？要不要我帮你找一些红酒养生的建议呢？💖<|im_end|>

05/10 18:59:40 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人有些不舒服呢。你可以直接和他们沟通一下，表达你的感受，让他们知道你的感受很重要。如果需要，我可以帮你想想怎么去表达。💖<|im_end|>

05/10 18:59:45 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，健康最重要哦，胆固醇高要注意饮食呢。可以吃一些低脂或者低胆固醇的选项，比如烤鸡或者蒸鸡，都是很好的选择呢。💖 除了饮食，还可以多运动，保持良好的生活习惯哦。如果需要，我可以帮你找一些健康的食谱或者锻炼建议。🌸<|im_end|>

05/10 18:59:48 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这玩家是来自火星的神秘物种吗？😂 下次记得带个屏蔽条，不然你得准备扩建家居了。😆<|im_end|>

05/10 18:59:52 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情可不好装作没看见呢。领导的指示很重要，及时回复能体现你的工作态度呢。你可以找个合适的时间和领导沟通一下，表达一下你的想法和感受。毕竟，良好的沟通能够帮助解决问题哦。💖<|im_end|>

05/10 18:59:52 - mmengine - INFO - Saving checkpoint at 6500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 19:00:08 - mmengine - INFO - Iter(train) [  6510/480000]  lr: 9.0410e-05  eta: 7 days, 23:21:31  time: 4.1113  data_time: 2.5800  memory: 9297  loss: 0.4514  grad_norm: 3.1469
05/10 19:00:20 - mmengine - INFO - Iter(train) [  6520/480000]  lr: 9.0549e-05  eta: 7 days, 23:18:44  time: 1.2448  data_time: 0.0056  memory: 9296  loss: 0.4657  grad_norm: 3.0473
05/10 19:00:33 - mmengine - INFO - Iter(train) [  6530/480000]  lr: 9.0688e-05  eta: 7 days, 23:15:46  time: 1.2299  data_time: 0.0055  memory: 9294  loss: 0.4549  grad_norm: 3.0274
05/10 19:00:48 - mmengine - INFO - Iter(train) [  6540/480000]  lr: 9.0827e-05  eta: 7 days, 23:16:18  time: 1.5178  data_time: 0.0057  memory: 9295  loss: 0.4422  grad_norm: 3.0274
05/10 19:01:00 - mmengine - INFO - Iter(train) [  6550/480000]  lr: 9.0966e-05  eta: 7 days, 23:13:22  time: 1.2308  data_time: 0.0056  memory: 9296  loss: 0.4701  grad_norm: 3.0367
05/10 19:01:12 - mmengine - INFO - Iter(train) [  6560/480000]  lr: 9.1105e-05  eta: 7 days, 23:09:27  time: 1.1494  data_time: 0.0055  memory: 9295  loss: 0.4806  grad_norm: 3.0182
05/10 19:01:30 - mmengine - INFO - Iter(train) [  6570/480000]  lr: 9.1244e-05  eta: 7 days, 23:13:49  time: 1.8370  data_time: 0.4892  memory: 9295  loss: 0.3954  grad_norm: 3.0182
05/10 19:01:42 - mmengine - INFO - Iter(train) [  6580/480000]  lr: 9.1382e-05  eta: 7 days, 23:10:56  time: 1.2333  data_time: 0.0056  memory: 9296  loss: 0.4236  grad_norm: 2.9971
05/10 19:01:56 - mmengine - INFO - Iter(train) [  6590/480000]  lr: 9.1521e-05  eta: 7 days, 23:09:31  time: 1.3555  data_time: 0.0056  memory: 9297  loss: 0.4027  grad_norm: 2.9971
05/10 19:02:08 - mmengine - INFO - Iter(train) [  6600/480000]  lr: 9.1660e-05  eta: 7 days, 23:06:43  time: 1.2395  data_time: 0.0056  memory: 9296  loss: 0.3939  grad_norm: 3.0796
05/10 19:02:21 - mmengine - INFO - Iter(train) [  6610/480000]  lr: 9.1799e-05  eta: 7 days, 23:04:05  time: 1.2540  data_time: 0.0057  memory: 9296  loss: 0.3915  grad_norm: 3.0706
05/10 19:02:36 - mmengine - INFO - Iter(train) [  6620/480000]  lr: 9.1938e-05  eta: 7 days, 23:05:19  time: 1.5762  data_time: 0.0061  memory: 9295  loss: 0.3923  grad_norm: 3.0706
05/10 19:02:49 - mmengine - INFO - Iter(train) [  6630/480000]  lr: 9.2077e-05  eta: 7 days, 23:02:23  time: 1.2280  data_time: 0.0056  memory: 9297  loss: 0.3949  grad_norm: 3.0639
05/10 19:03:03 - mmengine - INFO - Iter(train) [  6640/480000]  lr: 9.2216e-05  eta: 7 days, 23:02:13  time: 1.4585  data_time: 0.0056  memory: 9296  loss: 0.4094  grad_norm: 2.9791
05/10 19:03:16 - mmengine - INFO - Iter(train) [  6650/480000]  lr: 9.2355e-05  eta: 7 days, 22:59:44  time: 1.2634  data_time: 0.0057  memory: 9296  loss: 0.3963  grad_norm: 2.9791
05/10 19:03:28 - mmengine - INFO - Iter(train) [  6660/480000]  lr: 9.2494e-05  eta: 7 days, 22:56:47  time: 1.2253  data_time: 0.0057  memory: 9297  loss: 0.4163  grad_norm: 2.9175
05/10 19:03:44 - mmengine - INFO - Iter(train) [  6670/480000]  lr: 9.2633e-05  eta: 7 days, 22:57:42  time: 1.5492  data_time: 0.0060  memory: 9298  loss: 0.4041  grad_norm: 2.9175
05/10 19:03:56 - mmengine - INFO - Iter(train) [  6680/480000]  lr: 9.2771e-05  eta: 7 days, 22:54:52  time: 1.2332  data_time: 0.0057  memory: 9298  loss: 0.4093  grad_norm: 2.9905
05/10 19:04:11 - mmengine - INFO - Iter(train) [  6690/480000]  lr: 9.2910e-05  eta: 7 days, 22:54:50  time: 1.4700  data_time: 0.0056  memory: 9297  loss: 0.4088  grad_norm: 3.0337
05/10 19:04:24 - mmengine - INFO - Iter(train) [  6700/480000]  lr: 9.3049e-05  eta: 7 days, 22:52:32  time: 1.2766  data_time: 0.0059  memory: 9299  loss: 0.4129  grad_norm: 3.0337
05/10 19:04:36 - mmengine - INFO - Iter(train) [  6710/480000]  lr: 9.3188e-05  eta: 7 days, 22:49:41  time: 1.2303  data_time: 0.0057  memory: 9298  loss: 0.4222  grad_norm: 3.0040
05/10 19:04:50 - mmengine - INFO - Iter(train) [  6720/480000]  lr: 9.3327e-05  eta: 7 days, 22:49:37  time: 1.4668  data_time: 0.0058  memory: 9298  loss: 0.4309  grad_norm: 3.0273
05/10 19:05:05 - mmengine - INFO - Iter(train) [  6730/480000]  lr: 9.3466e-05  eta: 7 days, 22:49:24  time: 1.4536  data_time: 0.2057  memory: 9296  loss: 0.3584  grad_norm: 3.0273
05/10 19:05:20 - mmengine - INFO - Iter(train) [  6740/480000]  lr: 9.3605e-05  eta: 7 days, 22:49:35  time: 1.4883  data_time: 0.0056  memory: 9297  loss: 0.3790  grad_norm: 3.0617
05/10 19:05:32 - mmengine - INFO - Iter(train) [  6750/480000]  lr: 9.3744e-05  eta: 7 days, 22:46:56  time: 1.2450  data_time: 0.0057  memory: 9297  loss: 0.3558  grad_norm: 3.0617
05/10 19:05:45 - mmengine - INFO - Iter(train) [  6760/480000]  lr: 9.3883e-05  eta: 7 days, 22:43:58  time: 1.2179  data_time: 0.0056  memory: 9298  loss: 0.3588  grad_norm: 2.9682
05/10 19:06:00 - mmengine - INFO - Iter(train) [  6770/480000]  lr: 9.4021e-05  eta: 7 days, 22:44:41  time: 1.5335  data_time: 0.0059  memory: 9299  loss: 0.3542  grad_norm: 2.8541
05/10 19:06:12 - mmengine - INFO - Iter(train) [  6780/480000]  lr: 9.4160e-05  eta: 7 days, 22:42:05  time: 1.2474  data_time: 0.0056  memory: 9297  loss: 0.3595  grad_norm: 2.8541
05/10 19:06:27 - mmengine - INFO - Iter(train) [  6790/480000]  lr: 9.4299e-05  eta: 7 days, 22:42:10  time: 1.4790  data_time: 0.0057  memory: 9297  loss: 0.3767  grad_norm: 2.8359
05/10 19:06:40 - mmengine - INFO - Iter(train) [  6800/480000]  lr: 9.4438e-05  eta: 7 days, 22:39:52  time: 1.2736  data_time: 0.0058  memory: 9299  loss: 0.3691  grad_norm: 2.9035
05/10 19:06:52 - mmengine - INFO - Iter(train) [  6810/480000]  lr: 9.4577e-05  eta: 7 days, 22:37:04  time: 1.2303  data_time: 0.0056  memory: 9297  loss: 0.3807  grad_norm: 2.9035
05/10 19:07:07 - mmengine - INFO - Iter(train) [  6820/480000]  lr: 9.4716e-05  eta: 7 days, 22:37:39  time: 1.5213  data_time: 0.0059  memory: 9298  loss: 0.3755  grad_norm: 2.9804
05/10 19:07:21 - mmengine - INFO - Iter(train) [  6830/480000]  lr: 9.4855e-05  eta: 7 days, 22:36:16  time: 1.3511  data_time: 0.0062  memory: 9299  loss: 0.3905  grad_norm: 2.9804
05/10 19:07:34 - mmengine - INFO - Iter(train) [  6840/480000]  lr: 9.4994e-05  eta: 7 days, 22:34:38  time: 1.3299  data_time: 0.0061  memory: 9297  loss: 0.3657  grad_norm: 2.9277
05/10 19:07:47 - mmengine - INFO - Iter(train) [  6850/480000]  lr: 9.5133e-05  eta: 7 days, 22:32:12  time: 1.2596  data_time: 0.0058  memory: 9298  loss: 0.3779  grad_norm: 2.8464
05/10 19:07:59 - mmengine - INFO - Iter(train) [  6860/480000]  lr: 9.5272e-05  eta: 7 days, 22:29:27  time: 1.2305  data_time: 0.0057  memory: 9297  loss: 0.3742  grad_norm: 2.8464
05/10 19:08:12 - mmengine - INFO - Iter(train) [  6870/480000]  lr: 9.5410e-05  eta: 7 days, 22:27:34  time: 1.3073  data_time: 0.0058  memory: 9298  loss: 0.3847  grad_norm: 2.8642
05/10 19:08:25 - mmengine - INFO - Iter(train) [  6880/480000]  lr: 9.5549e-05  eta: 7 days, 22:25:07  time: 1.2554  data_time: 0.0062  memory: 9298  loss: 0.3969  grad_norm: 2.8955
05/10 19:08:42 - mmengine - INFO - Iter(train) [  6890/480000]  lr: 9.5688e-05  eta: 7 days, 22:28:35  time: 1.7740  data_time: 0.2063  memory: 9298  loss: 0.3357  grad_norm: 2.8955
05/10 19:08:56 - mmengine - INFO - Iter(train) [  6900/480000]  lr: 9.5827e-05  eta: 7 days, 22:27:06  time: 1.3396  data_time: 0.0062  memory: 9300  loss: 0.3179  grad_norm: 2.8341
05/10 19:09:09 - mmengine - INFO - Iter(train) [  6910/480000]  lr: 9.5966e-05  eta: 7 days, 22:24:53  time: 1.2770  data_time: 0.0058  memory: 9297  loss: 0.3253  grad_norm: 2.8341
05/10 19:09:22 - mmengine - INFO - Iter(train) [  6920/480000]  lr: 9.6105e-05  eta: 7 days, 22:23:35  time: 1.3557  data_time: 0.0057  memory: 9300  loss: 0.3428  grad_norm: 2.8315
05/10 19:09:34 - mmengine - INFO - Iter(train) [  6930/480000]  lr: 9.6244e-05  eta: 7 days, 22:20:42  time: 1.2171  data_time: 0.0057  memory: 9302  loss: 0.3275  grad_norm: 2.9006
05/10 19:09:50 - mmengine - INFO - Iter(train) [  6940/480000]  lr: 9.6383e-05  eta: 7 days, 22:21:17  time: 1.5209  data_time: 0.2670  memory: 9298  loss: 0.3320  grad_norm: 2.9006
05/10 19:10:03 - mmengine - INFO - Iter(train) [  6950/480000]  lr: 9.6522e-05  eta: 7 days, 22:19:31  time: 1.3132  data_time: 0.0060  memory: 9300  loss: 0.3286  grad_norm: 2.9337
05/10 19:10:15 - mmengine - INFO - Iter(train) [  6960/480000]  lr: 9.6661e-05  eta: 7 days, 22:17:02  time: 1.2518  data_time: 0.0057  memory: 9298  loss: 0.3281  grad_norm: 2.8591
05/10 19:10:28 - mmengine - INFO - Iter(train) [  6970/480000]  lr: 9.6799e-05  eta: 7 days, 22:14:37  time: 1.2551  data_time: 0.0057  memory: 9299  loss: 0.3298  grad_norm: 2.8591
05/10 19:10:41 - mmengine - INFO - Iter(train) [  6980/480000]  lr: 9.6938e-05  eta: 7 days, 22:13:03  time: 1.3304  data_time: 0.0060  memory: 9298  loss: 0.3418  grad_norm: 2.7810
05/10 19:10:55 - mmengine - INFO - Iter(train) [  6990/480000]  lr: 9.7077e-05  eta: 7 days, 22:12:07  time: 1.3869  data_time: 0.0062  memory: 9298  loss: 0.3253  grad_norm: 2.7810
05/10 19:11:10 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_162141
05/10 19:11:10 - mmengine - INFO - Iter(train) [  7000/480000]  lr: 9.7216e-05  eta: 7 days, 22:13:01  time: 1.5487  data_time: 0.0060  memory: 9298  loss: 0.3395  grad_norm: 2.7717
05/10 19:11:10 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 19:11:15 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺复杂的。首先，你需要和你的男朋友沟通一下你的感受，了解他的想法和原因。出轨行为是需要谨慎考虑的，它可能会影响到你们的关系和未来的幸福。💖 如果你需要倾诉更多，我在这里愿意倾听你的想法。🌸<|im_end|>

05/10 19:11:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然有益，但要注意适量哦。今天这样喝是不太对吧？有没有哪里不舒服呢？💖<|im_end|>

05/10 19:11:21 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实让人有些不舒服呢。你可以和她沟通一下，表达一下你的感受，毕竟朋友之间应该互相尊重。如果需要倾诉或者寻求建议，我都在这里哦。💖<|im_end|>

05/10 19:11:26 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，健康最重要哦，胆固醇高的话需要注意饮食呢。可以适量吃一些低脂或者低胆固醇的选项，比如烤鸡或者蒸鸡。还有就是要多运动呢，保持良好的生活习惯。💖如果你需要食谱建议或者锻炼计划，我也很乐意帮助你哦！<|im_end|>

05/10 19:11:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的林黛玉”吗？😂 下次记得带个“懂诗词歌赋，拆弹专家”的队友，直接把房间气氛搞成古诗词朗诵大会！😆<|im_end|>

05/10 19:11:35 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实有点棘手呢。也许你可以试着和领导沟通一下，表达一下你的感受和需要。毕竟，沟通是解决问题的关键哦。💖如果你需要更多建议，我随时在这里帮助你呢！<|im_end|>

05/10 19:11:35 - mmengine - INFO - Saving checkpoint at 7000 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 19:11:48 - mmengine - INFO - Iter(train) [  7010/480000]  lr: 9.7355e-05  eta: 7 days, 22:39:05  time: 3.7871  data_time: 2.5431  memory: 9299  loss: 0.3617  grad_norm: 2.7880
05/10 19:12:01 - mmengine - INFO - Iter(train) [  7020/480000]  lr: 9.7494e-05  eta: 7 days, 22:36:26  time: 1.2365  data_time: 0.0058  memory: 9300  loss: 0.3506  grad_norm: 2.7880
05/10 19:12:16 - mmengine - INFO - Iter(train) [  7030/480000]  lr: 9.7633e-05  eta: 7 days, 22:37:17  time: 1.5483  data_time: 0.0058  memory: 9299  loss: 0.3601  grad_norm: 2.8030
05/10 19:12:28 - mmengine - INFO - Iter(train) [  7040/480000]  lr: 9.7772e-05  eta: 7 days, 22:33:45  time: 1.1575  data_time: 0.0056  memory: 9298  loss: 0.3479  grad_norm: 2.7472
05/10 19:12:44 - mmengine - INFO - Iter(train) [  7050/480000]  lr: 9.7911e-05  eta: 7 days, 22:35:57  time: 1.6688  data_time: 0.2058  memory: 9298  loss: 0.2926  grad_norm: 2.7472
05/10 19:12:57 - mmengine - INFO - Iter(train) [  7060/480000]  lr: 9.8049e-05  eta: 7 days, 22:33:27  time: 1.2482  data_time: 0.0055  memory: 9298  loss: 0.2928  grad_norm: 2.7476
05/10 19:13:09 - mmengine - INFO - Iter(train) [  7070/480000]  lr: 9.8188e-05  eta: 7 days, 22:30:44  time: 1.2288  data_time: 0.0056  memory: 9299  loss: 0.2956  grad_norm: 2.7476
05/10 19:13:25 - mmengine - INFO - Iter(train) [  7080/480000]  lr: 9.8327e-05  eta: 7 days, 22:31:45  time: 1.5636  data_time: 0.0059  memory: 9300  loss: 0.2936  grad_norm: 2.7408
05/10 19:13:37 - mmengine - INFO - Iter(train) [  7090/480000]  lr: 9.8466e-05  eta: 7 days, 22:28:59  time: 1.2228  data_time: 0.0057  memory: 9299  loss: 0.2931  grad_norm: 2.7046
05/10 19:13:49 - mmengine - INFO - Iter(train) [  7100/480000]  lr: 9.8605e-05  eta: 7 days, 22:26:10  time: 1.2173  data_time: 0.0057  memory: 9299  loss: 0.2839  grad_norm: 2.7046
05/10 19:14:04 - mmengine - INFO - Iter(train) [  7110/480000]  lr: 9.8744e-05  eta: 7 days, 22:26:15  time: 1.4801  data_time: 0.0057  memory: 9298  loss: 0.2910  grad_norm: 2.6387
05/10 19:14:16 - mmengine - INFO - Iter(train) [  7120/480000]  lr: 9.8883e-05  eta: 7 days, 22:23:43  time: 1.2428  data_time: 0.0057  memory: 9300  loss: 0.2924  grad_norm: 2.6238
05/10 19:14:32 - mmengine - INFO - Iter(train) [  7130/480000]  lr: 9.9022e-05  eta: 7 days, 22:24:35  time: 1.5486  data_time: 0.0057  memory: 9300  loss: 0.3165  grad_norm: 2.6238
05/10 19:14:44 - mmengine - INFO - Iter(train) [  7140/480000]  lr: 9.9161e-05  eta: 7 days, 22:22:06  time: 1.2474  data_time: 0.0057  memory: 9300  loss: 0.3400  grad_norm: 2.6287
05/10 19:14:57 - mmengine - INFO - Iter(train) [  7150/480000]  lr: 9.9300e-05  eta: 7 days, 22:19:29  time: 1.2340  data_time: 0.0058  memory: 9299  loss: 0.3136  grad_norm: 2.6287
05/10 19:15:12 - mmengine - INFO - Iter(train) [  7160/480000]  lr: 9.9438e-05  eta: 7 days, 22:19:44  time: 1.4931  data_time: 0.0058  memory: 9300  loss: 0.3080  grad_norm: 2.6150
05/10 19:15:24 - mmengine - INFO - Iter(train) [  7170/480000]  lr: 9.9577e-05  eta: 7 days, 22:17:10  time: 1.2379  data_time: 0.0056  memory: 9300  loss: 0.3125  grad_norm: 2.5935
05/10 19:15:39 - mmengine - INFO - Iter(train) [  7180/480000]  lr: 9.9716e-05  eta: 7 days, 22:17:42  time: 1.5185  data_time: 0.0058  memory: 9300  loss: 0.3032  grad_norm: 2.5935
05/10 19:15:52 - mmengine - INFO - Iter(train) [  7190/480000]  lr: 9.9855e-05  eta: 7 days, 22:15:20  time: 1.2551  data_time: 0.0058  memory: 9299  loss: 0.3239  grad_norm: 2.5435
05/10 19:16:04 - mmengine - INFO - Iter(train) [  7200/480000]  lr: 9.9994e-05  eta: 7 days, 22:12:06  time: 1.1755  data_time: 0.0055  memory: 9299  loss: 0.3295  grad_norm: 2.5589
05/10 19:16:21 - mmengine - INFO - Iter(train) [  7210/480000]  lr: 1.0013e-04  eta: 7 days, 22:14:41  time: 1.7071  data_time: 0.2059  memory: 9297  loss: 0.2726  grad_norm: 2.5589
05/10 19:16:33 - mmengine - INFO - Iter(train) [  7220/480000]  lr: 1.0027e-04  eta: 7 days, 22:12:06  time: 1.2340  data_time: 0.0057  memory: 9298  loss: 0.2811  grad_norm: 2.5930
05/10 19:16:48 - mmengine - INFO - Iter(train) [  7230/480000]  lr: 1.0041e-04  eta: 7 days, 22:12:40  time: 1.5222  data_time: 0.0057  memory: 9300  loss: 0.2715  grad_norm: 2.5930
05/10 19:17:02 - mmengine - INFO - Iter(train) [  7240/480000]  lr: 1.0055e-04  eta: 7 days, 22:11:11  time: 1.3343  data_time: 0.0059  memory: 9300  loss: 0.2655  grad_norm: 2.5762
05/10 19:17:14 - mmengine - INFO - Iter(train) [  7250/480000]  lr: 1.0069e-04  eta: 7 days, 22:09:10  time: 1.2851  data_time: 0.0057  memory: 9298  loss: 0.2611  grad_norm: 2.5530
05/10 19:17:30 - mmengine - INFO - Iter(train) [  7260/480000]  lr: 1.0083e-04  eta: 7 days, 22:10:05  time: 1.5551  data_time: 0.0059  memory: 9299  loss: 0.2706  grad_norm: 2.5530
05/10 19:17:43 - mmengine - INFO - Iter(train) [  7270/480000]  lr: 1.0097e-04  eta: 7 days, 22:07:57  time: 1.2728  data_time: 0.0057  memory: 9299  loss: 0.2683  grad_norm: 2.5402
05/10 19:17:58 - mmengine - INFO - Iter(train) [  7280/480000]  lr: 1.0111e-04  eta: 7 days, 22:08:58  time: 1.5637  data_time: 0.0057  memory: 9298  loss: 0.2612  grad_norm: 2.5377
05/10 19:18:11 - mmengine - INFO - Iter(train) [  7290/480000]  lr: 1.0124e-04  eta: 7 days, 22:07:16  time: 1.3139  data_time: 0.0060  memory: 9299  loss: 0.2708  grad_norm: 2.5377
05/10 19:18:24 - mmengine - INFO - Iter(train) [  7300/480000]  lr: 1.0138e-04  eta: 7 days, 22:05:11  time: 1.2769  data_time: 0.0058  memory: 9299  loss: 0.2767  grad_norm: 2.5321
05/10 19:18:40 - mmengine - INFO - Iter(train) [  7310/480000]  lr: 1.0152e-04  eta: 7 days, 22:05:52  time: 1.5343  data_time: 0.0062  memory: 9300  loss: 0.2888  grad_norm: 2.5321
05/10 19:18:52 - mmengine - INFO - Iter(train) [  7320/480000]  lr: 1.0166e-04  eta: 7 days, 22:03:42  time: 1.2683  data_time: 0.0057  memory: 9301  loss: 0.2816  grad_norm: 2.5676
05/10 19:19:08 - mmengine - INFO - Iter(train) [  7330/480000]  lr: 1.0180e-04  eta: 7 days, 22:04:33  time: 1.5486  data_time: 0.0060  memory: 9300  loss: 0.2938  grad_norm: 2.5958
05/10 19:19:21 - mmengine - INFO - Iter(train) [  7340/480000]  lr: 1.0194e-04  eta: 7 days, 22:02:37  time: 1.2906  data_time: 0.0058  memory: 9301  loss: 0.2883  grad_norm: 2.5958
05/10 19:19:33 - mmengine - INFO - Iter(train) [  7350/480000]  lr: 1.0208e-04  eta: 7 days, 22:00:18  time: 1.2541  data_time: 0.0056  memory: 9300  loss: 0.2955  grad_norm: 2.6339
05/10 19:19:48 - mmengine - INFO - Iter(train) [  7360/480000]  lr: 1.0222e-04  eta: 7 days, 22:00:09  time: 1.4552  data_time: 0.0056  memory: 9301  loss: 0.2875  grad_norm: 2.5886
05/10 19:20:03 - mmengine - INFO - Iter(train) [  7370/480000]  lr: 1.0236e-04  eta: 7 days, 22:00:18  time: 1.4835  data_time: 0.2060  memory: 9301  loss: 0.2522  grad_norm: 2.5886
05/10 19:20:18 - mmengine - INFO - Iter(train) [  7380/480000]  lr: 1.0249e-04  eta: 7 days, 22:01:18  time: 1.5632  data_time: 0.0057  memory: 9300  loss: 0.2461  grad_norm: 2.5582
05/10 19:20:31 - mmengine - INFO - Iter(train) [  7390/480000]  lr: 1.0263e-04  eta: 7 days, 21:59:19  time: 1.2855  data_time: 0.0057  memory: 9300  loss: 0.2461  grad_norm: 2.5582
05/10 19:20:44 - mmengine - INFO - Iter(train) [  7400/480000]  lr: 1.0277e-04  eta: 7 days, 21:57:25  time: 1.2905  data_time: 0.0057  memory: 9301  loss: 0.2396  grad_norm: 2.5768
05/10 19:21:00 - mmengine - INFO - Iter(train) [  7410/480000]  lr: 1.0291e-04  eta: 7 days, 21:58:48  time: 1.5997  data_time: 0.0059  memory: 9300  loss: 0.2408  grad_norm: 2.6024
05/10 19:21:13 - mmengine - INFO - Iter(train) [  7420/480000]  lr: 1.0305e-04  eta: 7 days, 21:56:49  time: 1.2836  data_time: 0.0058  memory: 9302  loss: 0.2534  grad_norm: 2.6024
05/10 19:21:29 - mmengine - INFO - Iter(train) [  7430/480000]  lr: 1.0319e-04  eta: 7 days, 21:58:10  time: 1.5971  data_time: 0.0059  memory: 9302  loss: 0.2470  grad_norm: 2.6481
05/10 19:21:43 - mmengine - INFO - Iter(train) [  7440/480000]  lr: 1.0333e-04  eta: 7 days, 21:57:19  time: 1.3887  data_time: 0.0060  memory: 9299  loss: 0.2437  grad_norm: 2.6832
05/10 19:21:57 - mmengine - INFO - Iter(train) [  7450/480000]  lr: 1.0347e-04  eta: 7 days, 21:56:40  time: 1.4086  data_time: 0.0060  memory: 9300  loss: 0.2509  grad_norm: 2.6832
05/10 19:22:14 - mmengine - INFO - Iter(train) [  7460/480000]  lr: 1.0361e-04  eta: 7 days, 21:59:37  time: 1.7490  data_time: 0.0063  memory: 9300  loss: 0.2409  grad_norm: 2.6752
05/10 19:22:31 - mmengine - INFO - Iter(train) [  7470/480000]  lr: 1.0374e-04  eta: 7 days, 22:01:34  time: 1.6554  data_time: 0.0079  memory: 9301  loss: 0.2473  grad_norm: 2.6752
05/10 19:22:45 - mmengine - INFO - Iter(train) [  7480/480000]  lr: 1.0388e-04  eta: 7 days, 22:00:39  time: 1.3842  data_time: 0.0062  memory: 9302  loss: 0.2649  grad_norm: 2.6629
05/10 19:22:57 - mmengine - INFO - Iter(train) [  7490/480000]  lr: 1.0402e-04  eta: 7 days, 21:58:38  time: 1.2791  data_time: 0.0056  memory: 9300  loss: 0.2534  grad_norm: 2.5957
05/10 19:23:13 - mmengine - INFO - Iter(train) [  7500/480000]  lr: 1.0416e-04  eta: 7 days, 21:59:47  time: 1.5800  data_time: 0.0061  memory: 9300  loss: 0.2412  grad_norm: 2.5957
05/10 19:23:13 - mmengine - INFO - after_train_iter in EvaluateChatHook.
05/10 19:23:17 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
男朋友给女主播刷火箭，算精神出轨吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情确实挺复杂的。一方面，你可能感到很失望和生气；另一方面，也许可以认为这是一种形式的精神出轨，因为男朋友看直播还是为了感情交流呢？你的心情现在怎么样呢？💖<|im_end|>

05/10 19:23:20 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
喝红酒养生，结果喝到头晕…<|im_end|>
<|im_start|>assistant
温柔
哎呀，红酒虽然有益于健康，但过量饮用可是要注意哦。现在感觉好点了吗？有没有什么我能帮忙的？💖<|im_end|>

05/10 19:23:23 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
闺蜜和我前任互关小红书，取关拉黑三连击！<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来确实让人挺不舒服的呢。你可以和她好好沟通一下，表达一下你的感受。如果需要，我可以帮你想想怎么去表达。💖<|im_end|>

05/10 19:23:29 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
体检说胆固醇高，要戒炸鸡了吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这听起来有点让人担心呢。胆固醇高要注意饮食哦，但是吃炸鸡也可以很健康的呀！可以试试吃一些更健康的选项，比如烤鸡或者蒸鸡，只要注意不要过多摄入油脂就可以了。如果担心饮食建议，可以咨询一下医生或者营养师哦。💖你的身体最重要，不要太过担心啦。<|im_end|>

05/10 19:23:32 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
剧本杀遇读本玩家，直接摔门离场！<|im_end|>
<|im_start|>assistant
毒舌
栓Q，这是遇到了“剧本杀界的林黛玉”吗？😂 下次记得带个“懂剧本”的小伙伴，不然就成了浪费资源的浪费了！<|im_end|>

05/10 19:23:37 - mmengine - INFO - Sample output:
<|im_start|>system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
<|im_end|>
<|im_start|>user
领导周末发60秒语音矩阵，装没看见行吗？<|im_end|>
<|im_start|>assistant
温柔
哎呀，这种事情有时候确实挺让人烦恼的。也许你可以尝试直接和领导沟通你的感受，毕竟工作上的事情和私人时间有时候是冲突的。如果你觉得很难开口，也可以试试写一封电子邮件，解释一下你的感受。希望你能找到一个既符合领导期望又能维护个人空间的方法哦！💖<|im_end|>

05/10 19:23:37 - mmengine - INFO - Saving checkpoint at 7500 iterations
/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
05/10 19:23:52 - mmengine - INFO - Iter(train) [  7510/480000]  lr: 1.0430e-04  eta: 7 days, 22:24:57  time: 3.8696  data_time: 2.4244  memory: 9300  loss: 0.2612  grad_norm: 2.5597
05/10 19:24:04 - mmengine - INFO - Iter(train) [  7520/480000]  lr: 1.0444e-04  eta: 7 days, 22:22:07  time: 1.2042  data_time: 0.0056  memory: 9301  loss: 0.2654  grad_norm: 2.6495
05/10 19:24:22 - mmengine - INFO - Iter(train) [  7530/480000]  lr: 1.0458e-04  eta: 7 days, 22:25:39  time: 1.8107  data_time: 0.2060  memory: 9301  loss: 0.2153  grad_norm: 2.6495
05/10 19:24:35 - mmengine - INFO - Iter(train) [  7540/480000]  lr: 1.0472e-04  eta: 7 days, 22:24:01  time: 1.3178  data_time: 0.0056  memory: 9302  loss: 0.2189  grad_norm: 2.6272
05/10 19:24:51 - mmengine - INFO - Iter(train) [  7550/480000]  lr: 1.0486e-04  eta: 7 days, 22:25:22  time: 1.6041  data_time: 0.0057  memory: 9301  loss: 0.2172  grad_norm: 2.6272
05/10 19:25:04 - mmengine - INFO - Iter(train) [  7560/480000]  lr: 1.0499e-04  eta: 7 days, 22:23:45  time: 1.3185  data_time: 0.0059  memory: 9301  loss: 0.2324  grad_norm: 2.5948
05/10 19:25:17 - mmengine - INFO - Iter(train) [  7570/480000]  lr: 1.0513e-04  eta: 7 days, 22:21:55  time: 1.2983  data_time: 0.0056  memory: 9301  loss: 0.2272  grad_norm: 2.6991
05/10 19:25:33 - mmengine - INFO - Iter(train) [  7580/480000]  lr: 1.0527e-04  eta: 7 days, 22:22:50  time: 1.5611  data_time: 0.0058  memory: 9300  loss: 0.2201  grad_norm: 2.6991
05/10 19:25:46 - mmengine - INFO - Iter(train) [  7590/480000]  lr: 1.0541e-04  eta: 7 days, 22:20:35  time: 1.2585  data_time: 0.0055  memory: 9299  loss: 0.2281  grad_norm: 2.6799
